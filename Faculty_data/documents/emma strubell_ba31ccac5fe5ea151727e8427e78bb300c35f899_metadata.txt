Faculty Name: emma strubell
Metadata:
Paperid: ba31ccac5fe5ea151727e8427e78bb300c35f899
Title: Data-efficient Active Learning for Structured Prediction with Partial Annotation and Self-Training
Year: 2023
Abstract: In this work we propose a pragmatic method that reduces the annotation cost for structured label spaces using active learning. Our approach leverages partial annotation, which reduces labeling costs for structured outputs by selecting only the most informative sub-structures for annotation. We also utilize self-training to incorporate the current model's automatic predictions as pseudo-labels for un-annotated sub-structures. A key challenge in effectively combining partial annotation with self-training to reduce annotation cost is determining which sub-structures to select to label. To address this challenge, we adopt an error estimator to adaptively decide the partial selection ratio according to the current model's capability. In evaluations spanning four structured prediction tasks, we show that our combination of partial annotation and self-training using an adaptive selection ratio reduces annotation cost over strong full annotation baselines under a fair comparison scheme that takes reading time into consideration.
Authors: Zhisong Zhang, Emma Strubell, E. Hovy
Venue: Conference on Empirical Methods in Natural Language Processing
Tldr: {'model': 'tldr@v2.0.0', 'text': "This work proposes a pragmatic method that reduces the annotation cost for structured label spaces using active learning by adopting an error estimator to adaptively decide the partial selection ratio according to the current model's capability."}
