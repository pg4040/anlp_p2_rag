Faculty Name: alexander waibel
Metadata:
Paperid: 954ca9ab894df43e2cac18bc3813e9f9bc1bd488
Title: Continually learning new languages
Year: 2023
Abstract: Multilingual speech recognition with neural networks is often implemented with batch-learning, when all of the languages are available before training. An ability to add new languages after the prior training sessions can be economically bene-Ô¨Åcial, but the main challenge is catastrophic forgetting. In this work, we combine the qualities of weight factorization, transfer learning and Elastic Weight Consolidation in order to counter catastrophic forgetting and facilitate learning new languages quickly. Such combination allowed us to eliminate catastrophic forgetting while still achieving performance for the new languages comparable with having all languages at once, in experiments of learning from an initial 10 languages to achieve 27 languages.
Authors: Ngoc-Quan Pham, J. Niehues, A. Waibel
Venue: arXiv.org
Tldr: {'model': 'tldr@v2.0.0', 'text': 'This work combines the qualities of weight factorization, transfer learning and Elastic Weight Consolidation in order to counter catastrophic forgetting and facilitate learning new languages quickly.'}
