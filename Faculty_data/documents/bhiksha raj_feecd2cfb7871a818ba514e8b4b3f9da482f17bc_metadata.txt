Faculty Name: bhiksha raj
Metadata:
Paperid: feecd2cfb7871a818ba514e8b4b3f9da482f17bc
Title: Synergy between human and machine approaches to sound/scene recognition and processing: An overview of ICASSP special session
Year: 2023
Abstract: Machine Listening, as usually formalized, attempts to perform a task that is, from our perspective, fundamentally human-performable, and performed by humans. Current automated models of Machine Listening vary from purely data-driven approaches to approaches imitating human systems. In recent years, the most promising approaches have been hybrid in that they have used data-driven approaches informed by models of the perceptual, cognitive, and semantic processes of the human system. Not only does the guidance provided by models of human perception and domain knowledge enable better, and more generalizable Machine Listening, in the converse, the lessons learned from these models may be used to verify or improve our models of human perception themselves. This paper summarizes advances in the development of such hybrid approaches, ranging from Machine Listening models that are informed by models of peripheral (human) auditory processes, to those that employ or derive semantic information encoded in relations between sounds. The research described herein was presented in a special session on"Synergy between human and machine approaches to sound/scene recognition and processing"at the 2023 ICASSP meeting.
Authors: L. Heller, Benjamin Elizalde, B. Raj, Soham Deshmukh
Venue: arXiv.org
Tldr: {'model': 'tldr@v2.0.0', 'text': 'Advances in the development of hybrid approaches to Machine Listening models that are informed by models of peripheral (human) auditory processes, to those that employ or derive semantic information encoded in relations between sounds are summarized.'}
