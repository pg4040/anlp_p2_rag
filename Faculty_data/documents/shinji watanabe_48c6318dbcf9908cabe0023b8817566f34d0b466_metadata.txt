Faculty Name: shinji watanabe
Metadata:
Paperid: 48c6318dbcf9908cabe0023b8817566f34d0b466
Title: I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition
Year: 2023
Abstract: Transformer-based end-to-end speech recognition has achieved great success. However, the large footprint and computational overhead make it difficult to deploy these models in some real-world applications. Model compression techniques can reduce the model size and speed up inference, but the compressed model has a fixed architecture which might be suboptimal. We propose a novel Transformer encoder with Input-Dependent Dynamic Depth (I3D) to achieve strong performance-efficiency trade-offs. With a similar number of layers at inference time, I3D-based models outperform the vanilla Transformer and the static pruned model via iterative layer pruning. We also present interesting analysis on the gate probabilities and the input-dependency, which helps us better understand deep encoders.
Authors: Yifan Peng, Jaesong Lee, Shinji Watanabe
Venue: IEEE International Conference on Acoustics, Speech, and Signal Processing
Tldr: {'model': 'tldr@v2.0.0', 'text': 'A novel Transformer encoder with Input-Dependent Dynamic Depth (I3D) to achieve strong performance-efficiency trade-offs and interesting analysis on the gate probabilities and the input-dependency, which helps to better understand deep encoders.'}
