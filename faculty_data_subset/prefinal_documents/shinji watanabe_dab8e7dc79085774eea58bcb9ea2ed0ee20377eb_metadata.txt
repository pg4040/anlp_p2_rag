Faculty Name: shinji watanabe
Paperid: dab8e7dc79085774eea58bcb9ea2ed0ee20377eb
Title: ESPnet-ST-v2: Multipurpose Spoken Language Translation Toolkit
Year: 2023
Abstract: ESPnet-ST-v2 is a revamp of the open-source ESPnet-ST toolkit necessitated by the broadening interests of the spoken language translation community. ESPnet-ST-v2 supports 1) offline speech-to-text translation (ST), 2) simultaneous speech-to-text translation (SST), and 3) offline speech-to-speech translation (S2ST) â€“ each task is supported with a wide variety of approaches, differentiating ESPnet-ST-v2 from other open source spoken language translation toolkits. This toolkit offers state-of-the-art architectures such as transducers, hybrid CTC/attention, multi-decoders with searchable intermediates, time-synchronous blockwise CTC/attention, Translatotron models, and direct discrete unit models. In this paper, we describe the overall design, example models for each task, and performance benchmarking behind ESPnet-ST-v2, which is publicly available at https://github.com/espnet/espnet.
Authors: Brian Yan, Jiatong Shi, Yun Tang, H. Inaguma, Yifan Peng, Siddharth Dalmia, Peter Pol'ak, Patrick Fernandes, Dan Berrebbi, Tomoki Hayashi, Xiaohui Zhang, Zhaoheng Ni, Moto Hira, Soumi Maiti, J. Pino, Shinji Watanabe
Venue: Annual Meeting of the Association for Computational Linguistics
Tldr: {'model': 'tldr@v2.0.0', 'text': 'The overall design, example models for each task, and performance benchmarking behind ESPnet-ST-v2 are described, which is publicly available at https://github.com/espnet/esp net.'}
Url: https://arxiv.org/pdf/2304.04596
