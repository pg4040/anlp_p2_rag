Faculty Name: shinji watanabe
Paperid: 090b284b2f8fc93ac3e7a92fc9f91bf4965ba75c
Title: ML-SUPERB: Multilingual Speech Universal PERformance Benchmark
Year: 2023
Abstract: Speech processing Universal PERformance Benchmark (SUPERB) is a leaderboard to benchmark the performance of Self-Supervised Learning (SSL) models on various speech processing tasks. However, SUPERB largely considers English speech in its evaluation. This paper presents multilingual SUPERB (ML-SUPERB), covering 143 languages (ranging from high-resource to endangered), and considering both automatic speech recognition and language identification. Following the concept of SUPERB, ML-SUPERB utilizes frozen SSL features and employs a simple framework for multilingual tasks by learning a shallow downstream model. Similar to the SUPERB benchmark, we find speech SSL models can significantly improve performance compared to FBANK features. Furthermore, we find that multilingual models do not always perform better than their monolingual counterparts. We will release ML-SUPERB as a challenge with organized datasets and reproducible training scripts for future multilingual representation research.
Authors: Jiatong Shi, Dan Berrebbi, William Chen, Ho-Lam Chung, En-Pei Hu, Wei Huang, Xuankai Chang, Shang-Wen Li, Abdel-rahman Mohamed, Hung-yi Lee, Shinji Watanabe
Venue: Interspeech
Tldr: {'model': 'tldr@v2.0.0', 'text': None}
Url: https://arxiv.org/pdf/2305.10615
