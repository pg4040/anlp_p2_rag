Faculty Name: justine cassell
Paperid: 74fedee9d809ec766a2089a89435fa7dd1346693
Title: How About Kind of Generating Hedges using End-to-End Neural Models?
Year: 2023
Abstract: Hedging is a strategy for softening the impact of a statement in conversation. In reducing the strength of an expression, it may help to avoid embarrassment (more technically, “face threat”) to one’s listener. For this reason, it is often found in contexts of instruction, such as tutoring. In this work, we develop a model of hedge generation based on i) fine-tuning state-of-the-art language models trained on human-human tutoring data, followed by ii) reranking to select the candidate that best matches the expected hedging strategy within a candidate pool using a hedge classifier. We apply this method to a natural peer-tutoring corpus containing a significant number of disfluencies, repetitions, and repairs. The results show that generation in this noisy environment is feasible with reranking. By conducting an error analysis for both approaches, we reveal the challenges faced by systems attempting to accomplish both social and task-oriented goals in conversation.
Authors: Alafate Abulimiti, C. Clavel, Justine Cassell
Venue: Annual Meeting of the Association for Computational Linguistics
Tldr: {'model': 'tldr@v2.0.0', 'text': 'This work develops a model of hedge generation based on fine-tuning state-of-the-art language models trained on human-human tutoring data, followed by reranking to select the candidate that best matches the expected hedging strategy within a candidate pool using a hedge classifier.'}
Url: http://arxiv.org/pdf/2306.14696
