Faculty Name: richard stern
Metadata:
Paperid: cac3431a30d7a1d3479d25510aadb30182f88b5c
Title: Online Active Learning For Sound Event Detection
Year: 2023
Abstract: Data collection and annotation is a laborious, time-consuming prerequisite for supervised machine learning tasks. Online Active Learning (OAL) is a paradigm that addresses this issue by simultaneously minimizing the amount of annotation required to train a classifier and adapting to changes in the data over the duration of the data collection process. Prior work has indicated that fluctuating class distributions and data drift are still common problems for OAL. This work presents new loss functions that address these challenges when OAL is applied to Sound Event Detection (SED). Experimental results from the SONYC dataset and two Voice-Type Discrimination (VTD) corpora indicate that OAL can reduce the time and effort required to train SED classifiers by a factor of 5 for SONYC, and that the new methods presented here successfully resolve issues present in existing OAL methods.
Authors: Mark Lindsey, Ankit Shah, Francis Kubala, R. M. Stern
Venue: arXiv.org
Tldr: {'model': 'tldr@v2.0.0', 'text': 'Experimental results from the SonyC dataset and two Voice-Type Discrimination corpora indicate that OAL can reduce the time and effort required to train SED classifiers by a factor of 5 for SONYC, and that the new methods presented here successfully resolve issues present in existing OAL methods.'}
