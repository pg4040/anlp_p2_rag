Faculty Name: yang yiming
Metadata:
Paperid: 938d2951ba3aa26f3752d489c3c044ae67d5e809
Title: Retrieval-Enhanced Generative Model for Large-Scale Knowledge Graph Completion
Year: 2023
Abstract: The task of knowledge graph completion (KGC) is of great importance. To achieve scalability when dealing with large-scale knowledge graphs, recent works formulate KGC as a sequence-to-sequence process, where the incomplete triplet (input) and the missing entity (output) are both verbalized as text sequences. However, inference with these methods relies solely on the model parameters for implicit reasoning and neglects the use of KG itself, which limits the performance since the model lacks the capacity to memorize a vast number of triplets. To tackle this issue, we introduce ReSKGC, a Retrieval-enhanced Seq2seq KGC model, which selects semantically relevant triplets from the KG and uses them as evidence to guide output generation with explicit reasoning. Our method has demonstrated state-of-the-art performance on benchmark datasets Wikidata5M and WikiKG90Mv2, which contain about 5M and 90M entities, respectively.
Authors: Donghan Yu, Yiming Yang
Venue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval
Tldr: {'model': 'tldr@v2.0.0', 'text': 'ReSKGC is introduced, a Retrieval-enhanced Seq2seq KGC model, which selects semantically relevant triplets from the KG and uses them as evidence to guide output generation with explicit reasoning, and has demonstrated state-of-the-art performance on benchmark datasets Wikidata5M and WikiKG90Mv2.'}
