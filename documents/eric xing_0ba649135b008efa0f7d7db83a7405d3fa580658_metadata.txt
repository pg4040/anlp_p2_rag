Faculty Name: eric xing
Metadata:
Paperid: 0ba649135b008efa0f7d7db83a7405d3fa580658
Title: Effective Multi-Agent Deep Reinforcement Learning Control with Relative Entropy Regularization
Year: 2023
Abstract: In this paper, a novel Multi-agent Reinforcement Learning (MARL) approach, Multi-Agent Continuous Dynamic Policy Gradient (MACDPP) was proposed to tackle the issues of limited capability and sample efficiency in various scenarios controlled by multiple agents. It alleviates the inconsistency of multiple agents' policy updates by introducing the relative entropy regularization to the Centralized Training with Decentralized Execution (CTDE) framework with the Actor-Critic (AC) structure. Evaluated by multi-agent cooperation and competition tasks and traditional control tasks including OpenAI benchmarks and robot arm manipulation, MACDPP demonstrates significant superiority in learning capability and sample efficiency compared with both related multi-agent and widely implemented signal-agent baselines and therefore expands the potential of MARL in effectively learning challenging control scenarios.
Authors: Chenyang Miao, Yunduan Cui, Huiyun Li, Xin Wu
Venue: arXiv.org
Tldr: {'model': 'tldr@v2.0.0', 'text': 'Evaluated by multi-agent cooperation and competition tasks and traditional control tasks including OpenAI benchmarks and robot arm manipulation, MACDPP demonstrates significant superiority in learning capability and sample efficiency compared with both related multi- agent and widely implemented signal-agent baselines and therefore expands the potential of MARL in effectively learning challenging control scenarios.'}
