Question,RAG Prompt
"What year was the paper titled ""Median mandibular flexure—the unique physiological phenomenon of the mandible and its clinical significance in implant restoration"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: What year was the paper titled ""Median mandibular flexure—the unique physiological phenomenon of the mandible and its clinical significance in implant restoration"" published?\nContext: Document 0: Faculty Name: lu jiang\nMetadata:\nPaperid: bc2587ae1df64c64ce9a7614373e5a1d49051265\nTitle: Median mandibular flexure—the unique physiological phenomenon of the mandible and its clinical significance in implant restoration\nYear: 2023\nAbstract: Mandibular flexure, characterized by unique biomechanical behaviors such as elastic bending and torsion under functional loading, has emerged as a crucial factor in oral clinical diagnosis and treatment. This paper presents a comprehensive review of the current research status on mandibular flexure, drawing insights from relevant studies retrieved from the PubMed database (www.ncbi.nlm.nih.gov/pubmed), including research conclusions, literature reviews, case reports, and authoritative reference books. This paper thoroughly explores the physiological mechanisms underlying mandibular flexure, discussing different concurrent deformation types and the essential factors influencing this process. Moreover, it explores the profound implications of mandibular flexure on clinical aspects such as bone absorption around dental implants, the precision of prosthesis fabrication, and the selection and design of superstructure materials. Based on the empirical findings, this review provides crucial clinical recommendations. \nDocument 1: Rays with the DAMPE Experiment\nCosmic Ray Carbon and Oxygen Flux Measurements with the DAMPE Experiment\nStudy of hadronic cross-sections with cosmic ray Carbon from GeV to TeV by the DAMPE experiment\nLatest results on searching for fractionally charged particles with the DAMPE experiment\nAnalysis of cosmic lithium, beryllium and boron with the DAMPE mission\nMedian mandibular flexure—the unique physiological phenomenon of the mandible and its clinical significance in implant restoration\nBAC Transgenic Expression of Human TREM2-R47H Remodels Amyloid Plaques but Unable to Reprogram Plaque-associated Microglial Reactivity in 5xFAD Mice\nTMEM241 is a UDP-N-acetylglucosamine transporter required for M6P modification of NPC2 and cholesterol transport\nReduced electron relaxation time of perovskite films via g-C3N4 quantum dot doping for high-performance perovskite solar cells\nHow to drive corporate responsible innovation? \n\n"
"In which venue was the paper titled ""Training Audio Captioning Models without Audio"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: In which venue was the paper titled ""Training Audio Captioning Models without Audio"" published?\nContext: Document 0: Faculty Name: bhiksha raj\nMetadata:\nPaperid: e2572e0adacfb116b19b25691e7f6b3749490a88\nTitle: Training Audio Captioning Models without Audio\nYear: 2023\nAbstract: Automated Audio Captioning (AAC) is the task of generating natural language descriptions given an audio stream. A typical AAC system requires manually curated training data of audio segments and corresponding text caption annotations. The creation of these audio-caption pairs is costly, resulting in general data scarcity for the task. In this work, we address this major limitation and propose an approach to train AAC systems using only text. Our approach leverages the multimodal space of contrastively trained audio-text models, such as CLAP. During training, a decoder generates captions conditioned on the pretrained CLAP text encoder. During inference, the text encoder is replaced with the pretrained CLAP audio encoder. To bridge the modality gap between text and audio embeddings, we propose the use of noise injection or a learnable adapter, during training. \nDocument 1: Faculty Name: rita singh\nMetadata:\nPaperid: e2572e0adacfb116b19b25691e7f6b3749490a88\nTitle: Training Audio Captioning Models without Audio\nYear: 2023\nAbstract: Automated Audio Captioning (AAC) is the task of generating natural language descriptions given an audio stream. A typical AAC system requires manually curated training data of audio segments and corresponding text caption annotations. The creation of these audio-caption pairs is costly, resulting in general data scarcity for the task. In this work, we address this major limitation and propose an approach to train AAC systems using only text. Our approach leverages the multimodal space of contrastively trained audio-text models, such as CLAP. During training, a decoder generates captions conditioned on the pretrained CLAP text encoder. During inference, the text encoder is replaced with the pretrained CLAP audio encoder. To bridge the modality gap between text and audio embeddings, we propose the use of noise injection or a learnable adapter, during training. \n\n"
"Who is the faculty member associated with the paper titled ""La forêt et la faune de Côte d’Ivoire dans une situation alarmante – Synthèse des résultats de l’Inventaire forestier et faunique national""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Who is the faculty member associated with the paper titled ""La forêt et la faune de Côte d’Ivoire dans une situation alarmante – Synthèse des résultats de l’Inventaire forestier et faunique national""?\nContext: Document 0: Faculty Name: bio\nMetadata:\nPaperid: fb1b32c8073b31a7e4ec0cd1ed4a0370820dc249\nTitle: La forêt et la faune de Côte d’Ivoire dans une situation alarmante – Synthèse des résultats de l’Inventaire forestier et faunique national\nYear: 2023\nAbstract: La Côte d’Ivoire a engagé début 2019 un inventaire national de ses forêts et de sa faune, accompagné par des enquêtes socio-économiques auprès des agriculteurs. Cet inventaire, déployé sur l’ensemble du territoire, fournit une grande quantité d’informations. Il montre que l’état des forêts et de la faune est fortement dégradé et que les cultures industrielles (cacaoyer, hévéa, palmier à huile dans le sud, anacardier et coton dans le centre et le nord) sont devenues dominantes. \nDocument 1: West Africa, 2018\nNonmedical Use of Prescription Psychotropic Drugs among Secondary School Students in Parakou, northern Benin\nLa forêt et la faune de Côte d’Ivoire dans une situation alarmante – Synthèse des résultats de l’Inventaire forestier et faunique national\nPengaruh Konsumsi Informasi terhadap Perilaku Pencegahan COVID-19: Studi Quasi Eksperimental Time Series\nVSC-HVDC transmission line fault location based on transient characteristics\nEpidemiological description of measles outbreaks following a mass vaccination Campaign in Bayelsa State, \n\n"
"Who are the authors of the paper titled ""Cross-Modal Fine-Tuning: Align then Refine""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Who are the authors of the paper titled ""Cross-Modal Fine-Tuning: Align then Refine""?\nContext: Document 0: Faculty Name: graham neubig\nMetadata:\nPaperid: 03c7f61b0c6bc4c480ed6da4e9d7dda104ddfec3\nTitle: Cross-Modal Fine-Tuning: Align then Refine\nYear: 2023\nAbstract: Fine-tuning large-scale pretrained models has led to tremendous progress in well-studied modalities such as vision and NLP. However, similar gains have not been observed in many other modalities due to a lack of relevant pretrained models. In this work, we propose ORCA, a general cross-modal fine-tuning framework that extends the applicability of a single large-scale pretrained model to diverse modalities. ORCA adapts to a target task via an align-then-refine workflow: given the target input, ORCA first learns an embedding network that aligns the embedded feature distribution with the pretraining modality. The pretrained model is then fine-tuned on the embedded data to exploit the knowledge shared across modalities. \nDocument 1: List of 2023 Open Access papers by graham neubig are:\nCross-Modal Fine-Tuning: Align then Refine\nChatGPT MT: Competitive for High- (but Not Low-) Resource Languages\nGlobalBench: A Benchmark for Global Progress in Natural Language Processing\nLearning Performance-Improving Code Edits\nCodeBERTScore: Evaluating Code Generation with Pretrained Models of Code\nNeural Machine Translation for the Indigenous Languages of the Americas: An Introduction\nUser-Centric Evaluation of OCR Systems for Kwak’wala\nMulti-Dimensional Evaluation of Text Summarization with In-Context Learning\nA Gold Standard Dataset for the Reviewer Assignment Problem\nSigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing\nBridging the Gap: A Survey on Integrating (Human) Feedback for Natural Language Generation\nFacTool: Factuality Detection in Generative AI - A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios\nActive Retrieval Augmented Generation\nLarge Language Models Enable Few-Shot Clustering\nSolving NLP Problems through Human-System Collaboration: A Discussion-based Approach\nCrossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss \n\n"
"Who is the faculty member associated with the paper titled ""Transformed Protoform Reconstruction""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Who is the faculty member associated with the paper titled ""Transformed Protoform Reconstruction""?\nContext: Document 0: Faculty Name: david mortensen\nMetadata:\nPaperid: c5c6d006e399386c99068daba138021a62d6cc17\nTitle: Transformed Protoform Reconstruction\nYear: 2023\nAbstract: Protoform reconstruction is the task of inferring what morphemes or words appeared like in the ancestral languages of a set of daughter languages. Meloni et al (2021) achieved the state-of-the-art on Latin protoform reconstruction with an RNN-based encoder-decoder with attention model. We update their model with the state-of-the-art seq2seq model: the Transformer. Our model outperforms their model on a suite of different metrics on two different datasets: their Romance data of 8,000 cognates spanning 5 languages and a Chinese dataset (Hou 2004) of 800+ cognates spanning 39 varieties. We also probe our model for potential phylogenetic signal contained in the model. Our code is publicly available at https://github.com/cmu-llab/acl-2023. \nDocument 1: List of 2023 Open Access papers by david mortensen are:\nChatGPT MT: Competitive for High- (but Not Low-) Resource Languages\nDo All Languages Cost the Same? Tokenization in the Era of Commercial Language Models\nSigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing\nConstruction Grammar Provides Unique Insight into Neural Language Models\nGeneralized Glossing Guidelines: An Explicit, Human- and Machine-Readable, Item-and-Process Convention for Morphological Annotation\nTransformed Protoform Reconstruction\nPWESuite: Phonetic Word Embeddings and Tasks They Facilitate\nKuki-Chin Phonology: An Overview \n\n"
"Who are the authors of the paper titled ""Research on the Training Path of Live E-commerce Talents Oriented by Industry Development""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Who are the authors of the paper titled ""Research on the Training Path of Live E-commerce Talents Oriented by Industry Development""?\nContext: Document 0: Faculty Name: eric xing\nMetadata:\nPaperid: 043512db27dbb03eb05eb5f5679b5bd5f59d18ca\nTitle: Research on the Training Path of Live E-commerce Talents Oriented by Industry Development\nYear: 2023\nAbstract: The growth of user scale and application popularization of live streaming e-commerce promote the transformation of live streaming stores to store live streaming, live streaming scene to scene live streaming, and the transformation of web celebrity staff to staff web celebrity. The stock talents of live streaming e-commerce can no longer meet the development of the industry. Long-term training of applied talents in higher vocational colleges can provide human resources to the industry and promote the development of local industries. However, the rapid development of live-streaming e-commerce industry leads to the shortage of industrial development and talent supply, the dislocation of industrial demand and talent training, the disconnect between practical training conditions and training requirements, and the lack of complementarity between higher vocational teachers and industries. \nDocument 1: Contextualized Policy Recovery: Modeling and Interpreting Medical Decisions with Adaptive Imitation Learning\nGET: a foundation model of transcription across human cell types\nContextualized Networks Reveal Heterogeneous Transcriptomic Regulation in Tumors at Sample-Specific Resolution\nResearch on the Training Path of Live E-commerce Talents Oriented by Industry Development\nRecent progresses on the gamma-ray observations of DAMPE\nEffective Multi-Agent Deep Reinforcement Learning Control with Relative Entropy Regularization\nConvolutional Neural Network Measurement of Non-Fiducial Electrons Cosmic-Rays Using the DAMPE Experiment. \n\n"
"In which venue was the paper titled ""Towards Improved Identification of Vertebral Fractures in Routine Computed Tomography (CT) Scans: Development and External Validation of a Machine Learning Algorithm"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: In which venue was the paper titled ""Towards Improved Identification of Vertebral Fractures in Routine Computed Tomography (CT) Scans: Development and External Validation of a Machine Learning Algorithm"" published?\nContext: Document 0: Faculty Name: christopher dyer\nMetadata:\nPaperid: 77563837a811329c901d0639b7b3b630600b844d\nTitle: Towards Improved Identification of Vertebral Fractures in Routine Computed Tomography (CT) Scans: Development and External Validation of a Machine Learning Algorithm\nYear: 2023\nAbstract: Vertebral fractures (VFs) are the hallmark of osteoporosis, being one of the most frequent types of fragility fracture and an early sign of the disease. They are associated with significant morbidity and mortality. VFs are incidentally found in one out of five imaging studies, however, more than half of the VFs are not identified nor reported in patient computed tomography (CT) scans. Our study aimed to develop a machine learning algorithm to identify VFs in abdominal/chest CT scans and evaluate its performance. \nDocument 1: List of 2023 Open Access papers by christopher dyer are:\nMurder in a Landscape: The Significance of the Death of Henry Flackett in the Staffordshire Moorlands in 1515\nA simple food with many meanings: bread in late medieval England\nEpidemiological Factors Associated with Prescription of Opioids for Chronic Non-Cancer Pain in Adults: A Country-Wide, Registry-Based Study in Denmark Spans 2004–2018\nTowards Improved Identification of Vertebral Fractures in Routine Computed Tomography (CT) Scans: Development and External Validation of a Machine Learning Algorithm\nFracture Risk in Men and Women With Vertebral Fractures Identified Opportunistically on Routine Computed Tomography Scans and Not Treated for Osteoporosis: An Observational Cohort Study \n\n"
"What year was the paper titled ""Single-cell immune profiling reveals immune responses in oral lichen planus"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: What year was the paper titled ""Single-cell immune profiling reveals immune responses in oral lichen planus"" published?\nContext: Document 0: Faculty Name: lu jiang\nMetadata:\nPaperid: ea492b5bcb8fc9dc09637f8e89829916093a2536\nTitle: Single-cell immune profiling reveals immune responses in oral lichen planus\nYear: 2023\nAbstract: Introduction Oral lichen planus (OLP) is a common chronic inflammatory disorder of the oral mucosa with an unclear etiology. Several types of immune cells are involved in the pathogenesis of OLP. Methods We used single-cell RNA sequencing and immune repertoire sequencing to characterize the mucosal immune microenvironment of OLP. The presence of tissue-resident memory CD8+ T cells are validated by multiplex immunofluorescence. Results We generated a transcriptome atlas from four OLP biopsy samples and their paired peripheral blood mononuclear cells (PBMCs), and compared them with two healthy tissues and three healthy PBMCs samples. Our analysis revealed activated tissue-resident memory CD8+ T cells in OLP tissues. T cell receptor repertoires displayed apperant clonal expansion and preferrential gene pairing in OLP patients. Additionally, obvious BCR clonal expansion was observed in OLP lesions. \nDocument 1: Faculty Name: lu jiang\nMetadata:\nPaperid: b4d94a380f2f7ba93013effe556705d96932a6c4\nTitle: CD8+ tissue-resident memory T cells induce oral lichen planus erosion via cytokine network\nYear: 2023\nAbstract: CD8+ tissue-resident memory T (CD8+ Trm) cells play key roles in many immune-inflammation-related diseases. However, their characteristics in the pathological process of oral lichen planus (OLP) remains unclear. Therefore, we investigated the function of CD8+ Trm cells in the process of OLP. By using single-cell RNA sequencing profiling and spatial transcriptomics, we revealed that CD8+ Trm cells were predominantly located in the lamina propria adjacent to the basement membrane and were significantly increased in patients with erosive oral lichen planus (EOLP) compared to those with non-erosive oral lichen planus (NEOLP). \n\n"
"Can you provide the abstract of the paper titled ""Amortizing Pragmatic Program Synthesis with Rankings""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Can you provide the abstract of the paper titled ""Amortizing Pragmatic Program Synthesis with Rankings""?\nContext: Document 0: Faculty Name: daniel fried\nMetadata:\nPaperid: 5016766c87982f5c62ef6580e120939ab155d776\nTitle: Amortizing Pragmatic Program Synthesis with Rankings\nYear: 2023\nAbstract: In program synthesis, an intelligent system takes in a set of user-generated examples and returns a program that is logically consistent with these examples. The usage of Rational Speech Acts (RSA) framework has been successful in building \emph{pragmatic} program synthesizers that return programs which -- in addition to being logically consistent -- account for the fact that a user chooses their examples informatively. However, the computational burden of running the RSA algorithm has restricted the application of pragmatic program synthesis to domains with a small number of possible programs. This work presents a novel method of amortizing the RSA algorithm by leveraging a \emph{global pragmatic ranking} -- a single, total ordering of all the hypotheses. We prove that for a pragmatic synthesizer that uses a single demonstration, our global ranking method exactly replicates RSA's ranked responses. We further empirically show that global rankings effectively approximate the full pragmatic synthesizer in an online, multi-demonstration setting. \nDocument 1: We prove that for a pragmatic synthesizer that uses a single demonstration, our global ranking method exactly replicates RSA's ranked responses. We further empirically show that global rankings effectively approximate the full pragmatic synthesizer in an online, multi-demonstration setting. Experiments on two program synthesis domains using our pragmatic ranking method resulted in orders of magnitudes of speed ups compared to the RSA synthesizer, while outperforming the standard, non-pragmatic synthesizer.\nAuthors: Yewen Pu, Saujas Vaduguru, Priyan Vaithilingam, Elena L. Glassman, Daniel Fried\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': ""This work presents a novel method of amortizing the RSA algorithm by leveraging a single, total ordering of all the hypotheses, and proves that for a pragmatic synthesizer that uses a single demonstration, the global ranking method exactly replicates RSA's ranked responses.""} \n\n"
"Who are the authors of the paper titled ""Token Prediction as Implicit Classification to Identify LLM-Generated Text""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Who are the authors of the paper titled ""Token Prediction as Implicit Classification to Identify LLM-Generated Text""?\nContext: Document 0: Faculty Name: rita singh\nMetadata:\nPaperid: 7a25aa397ae2a7f82df87a936ce6ff7f03b7ac4c\nTitle: Token Prediction as Implicit Classification to Identify LLM-Generated Text\nYear: 2023\nAbstract: This paper introduces a novel approach for identifying the possible large language models (LLMs) involved in text generation. Instead of adding an additional classification layer to a base LM, we reframe the classification task as a next-token prediction task and directly fine-tune the base LM to perform it. We utilize the Text-to-Text Transfer Transformer (T5) model as the backbone for our experiments. We compared our approach to the more direct approach of utilizing hidden states for classification. Evaluation shows the exceptional performance of our method in the text classification task, highlighting its simplicity and efficiency. Furthermore, interpretability studies on the features extracted by our model reveal its ability to differentiate distinctive writing styles among various LLMs even in the absence of an explicit classifier. \nDocument 1: Faculty Name: bhiksha raj\nMetadata:\nPaperid: 7a25aa397ae2a7f82df87a936ce6ff7f03b7ac4c\nTitle: Token Prediction as Implicit Classification to Identify LLM-Generated Text\nYear: 2023\nAbstract: This paper introduces a novel approach for identifying the possible large language models (LLMs) involved in text generation. Instead of adding an additional classification layer to a base LM, we reframe the classification task as a next-token prediction task and directly fine-tune the base LM to perform it. We utilize the Text-to-Text Transfer Transformer (T5) model as the backbone for our experiments. We compared our approach to the more direct approach of utilizing hidden states for classification. Evaluation shows the exceptional performance of our method in the text classification task, highlighting its simplicity and efficiency. Furthermore, interpretability studies on the features extracted by our model reveal its ability to differentiate distinctive writing styles among various LLMs even in the absence of an explicit classifier. \n\n"
"In which venue was the paper titled ""The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: In which venue was the paper titled ""The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment"" published?\nContext: Document 0: Faculty Name: emma strubell\nMetadata:\nPaperid: b777aa86b5a1d49ce8eababc5c2ee56d3562801e\nTitle: The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment\nYear: 2023\nAbstract: Increased focus on the computational efficiency of NLP systems has motivated the design of efficient model architectures and improvements to underlying hardware accelerators. However, the resulting increases in computational throughput and reductions in floating point operations have not directly translated to improvements in wall-clock inference latency. We demonstrate that these discrepancies can be largely attributed to bottlenecks introduced by deep learning frameworks. We denote this phenomenon as the \textit{framework tax}, and observe that the disparity is growing as hardware speed increases over time. In this work, we examine this phenomenon through a series of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency. Code is available at https://github.com/JaredFern/Framework-Tax. \nDocument 1: Faculty Name: yonatan bisk\nMetadata:\nPaperid: b777aa86b5a1d49ce8eababc5c2ee56d3562801e\nTitle: The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment\nYear: 2023\nAbstract: Increased focus on the computational efficiency of NLP systems has motivated the design of efficient model architectures and improvements to underlying hardware accelerators. However, the resulting increases in computational throughput and reductions in floating point operations have not directly translated to improvements in wall-clock inference latency. We demonstrate that these discrepancies can be largely attributed to bottlenecks introduced by deep learning frameworks. We denote this phenomenon as the \textit{framework tax}, and observe that the disparity is growing as hardware speed increases over time. In this work, we examine this phenomenon through a series of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency. Code is available at https://github.com/JaredFern/Framework-Tax. \n\n"
"In which venue was the paper titled ""FedNAR: Federated Optimization with Normalized Annealing Regularization"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: In which venue was the paper titled ""FedNAR: Federated Optimization with Normalized Annealing Regularization"" published?\nContext: Document 0: Faculty Name: eric xing\nMetadata:\nPaperid: ab70103b8cc85fd1cd52200aa134c58c7e9c0e03\nTitle: FedNAR: Federated Optimization with Normalized Annealing Regularization\nYear: 2023\nAbstract: Weight decay is a standard technique to improve generalization performance in modern deep neural network optimization, and is also widely adopted in federated learning (FL) to prevent overfitting in local clients. In this paper, we first explore the choices of weight decay and identify that weight decay value appreciably influences the convergence of existing FL algorithms. While preventing overfitting is crucial, weight decay can introduce a different optimization goal towards the global objective, which is further amplified in FL due to multiple local updates and heterogeneous data distribution. To address this challenge, we develop {\it Federated optimization with Normalized Annealing Regularization} (FedNAR), a simple yet effective and versatile algorithmic plug-in that can be seamlessly integrated into any existing FL algorithms. Essentially, we regulate the magnitude of each update by performing co-clipping of the gradient and weight decay. \nDocument 1: Federated Learning as Variational Inference: A Scalable Expectation Propagation Approach\nMemory-adaptive Depth-wise Heterogenous Federated Learning\nIdentification of Nonlinear Latent Hierarchical Models\nStyleRF: Zero-Shot 3D Style Transfer of Neural Radiance Fields\nJudging LLM-as-a-judge with MT-Bench and Chatbot Arena\nUnderstanding Masked Autoencoders via Hierarchical Latent Variable Models\nLightSeq: Sequence Level Parallelism for Distributed Training of Long Context Transformers\nLMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset\nFedNAR: Federated Optimization with Normalized Annealing Regularization\nUS residents' preferences for sharing of electronic health record and genetic information: a discrete choice experiment. \n\n"
"Who is the faculty member associated with the paper titled ""Hyperbolic vs Euclidean Embeddings in Few-Shot Learning: Two Sides of the Same Coin""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Who is the faculty member associated with the paper titled ""Hyperbolic vs Euclidean Embeddings in Few-Shot Learning: Two Sides of the Same Coin""?\nContext: Document 0: Faculty Name: alexander hauptmann\nMetadata:\nPaperid: e371d10dd65c8bb25375f3c09d1c0cac777cca65\nTitle: Hyperbolic vs Euclidean Embeddings in Few-Shot Learning: Two Sides of the Same Coin\nYear: 2023\nAbstract: Recent research in representation learning has shown that hierarchical data lends itself to low-dimensional and highly informative representations in hyperbolic space. However, even if hyperbolic embeddings have gathered attention in image recognition, their optimization is prone to numerical hurdles. Further, it remains unclear which applications stand to benefit the most from the implicit bias imposed by hyperbolicity, when compared to traditional Euclidean features. In this paper, we focus on prototypical hyperbolic neural networks. In particular, the tendency of hyperbolic embeddings to converge to the boundary of the Poincar\'e ball in high dimensions and the effect this has on few-shot classification. We show that the best few-shot results are attained for hyperbolic embeddings at a common hyperbolic radius. \nDocument 1: List of 2023 Open Access papers by alexander hauptmann are:\nTowards Open-Domain Twitter User Profile Inference\nZero-Shot and Few-Shot Stance Detection on Varied Topics via Conditional Generation\nSPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs\nSTMT: A Spatial-Temporal Mesh Transformer for MoCap-Based Action Recognition\nDocumentNet: Bridging the Data Gap in Document Pre-training\nLanguage Model Beats Diffusion - Tokenizer is Key to Visual Generation\nHyperbolic vs Euclidean Embeddings in Few-Shot Learning: Two Sides of the Same Coin \n\n"
"In which venue was the paper titled ""Understanding How to Inform Blind and Low-Vision Users about Data Privacy through Privacy Question Answering Assistants"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: In which venue was the paper titled ""Understanding How to Inform Blind and Low-Vision Users about Data Privacy through Privacy Question Answering Assistants"" published?\nContext: Document 0: Faculty Name: norman sadeh\nMetadata:\nPaperid: 8f93ba514aee5e56d9d888f07e6625f8b3a40fcc\nTitle: Understanding How to Inform Blind and Low-Vision Users about Data Privacy through Privacy Question Answering Assistants\nYear: 2023\nAbstract: Understanding and managing data privacy in the digital world can be challenging for sighted users, let alone blind and low-vision (BLV) users. There is limited research on how BLV users, who have special accessibility needs, navigate data privacy, and how potential privacy tools could assist them. We conducted an in-depth qualitative study with 21 US BLV participants to understand their data privacy risk perception and mitigation, as well as their information behaviors related to data privacy. We also explored BLV users' attitudes towards potential privacy question answering (Q&A) assistants that enable them to better navigate data privacy information. We found that BLV users face heightened security and privacy risks, but their risk mitigation is often insufficient. They do not necessarily seek data privacy information but clearly recognize the benefits of a potential privacy Q&A assistant. \nDocument 1: List of 2023 Open Access papers by norman sadeh are:\nDo Privacy Labels Answer Users' Privacy Questions?\nExploring Smart Commercial Building Occupants’ Perceptions and Notification Preferences of Internet of Things Data Collection in the United States\nComparing Privacy Label Disclosures of Apps Published in both the App Store and Google Play Stores\nATLAS: Automatically Detecting Discrepancies Between Privacy Policies and Privacy Labels\nPurpose in the Machine: Do Traffic Simulators Produce Distributionally Equivalent Outcomes for Reinforcement Learning Applications?\nUnderstanding How to Inform Blind and Low-Vision Users about Data Privacy through Privacy Question Answering Assistants \n\n"
"Who is the faculty member associated with the paper titled ""Population pharmacokinetic analysis and dosing regimen optimization of teicoplanin in critically ill patients with sepsis""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Who is the faculty member associated with the paper titled ""Population pharmacokinetic analysis and dosing regimen optimization of teicoplanin in critically ill patients with sepsis""?\nContext: Document 0: Faculty Name: lei li\nMetadata:\nPaperid: 81a0ff93d7a3678330c0fb362fab427217bf2483\nTitle: Population pharmacokinetic analysis and dosing regimen optimization of teicoplanin in critically ill patients with sepsis\nYear: 2023\nAbstract: Objectives: Teicoplanin has been extensively used in the treatment for infections caused by gram-positive bacteria including methicillin-resistant Staphylococcus aureus (MRSA). However, current teicoplanin treatment is challenging due to relatively low and variable concentrations under standard dosage regimens. This study aimed to investigate the population pharmacokinetics (PPK) characteristics of teicoplanin in adult sepsis patients and provide recommendations for optimal teicoplanin dosing regimens. Methods: A total of 249 serum concentration samples from 59 septic patients were prospectively collected in the intensive care unit (ICU). Teicoplanin concentrations were detected, and patients’ clinical data were recorded. PPK analysis was performed using a non-linear, mixed-effect modeling approach. Monte Carlo simulations were performed to evaluate currently recommended dosing and other dosage regimens. \nDocument 1: List of 2023 Open Access papers by lei li are:\nEstablishment of a N1-methyladenosine-related risk signature for breast carcinoma by bioinformatics analysis and experimental validation\nPopulation pharmacokinetic analysis and dosing regimen optimization of teicoplanin in critically ill patients with sepsis\nThe effects of pharmaceutical interventions on potentially inappropriate medications in older patients: a systematic review and meta-analysis\nP53 protein and the diseases in central nervous system\nCorrection: Polydopamine-functionalized selenium nanoparticles as an efficient photoresponsive antibacterial platform\nEditorial: Strategies for functional polymeric nanocomposites and its multifunctional applications\nPolydopamine-functionalized selenium nanoparticles as an efficient photoresponsive antibacterial platform\nAntimicrobial properties of heterojunction BiSnSbO_6-ZnO composites in wastewater treatment\nResearch on torsional stiffness of flexspline-flexible bearing contact pair in harmonic drive based on macro-micro scale modeling\nIntegrated Valve Product Fluid Simulation and Test Verification\nFailure Analysis and Improvement of Check Valve Reverse Cut-off Seal\nA Study of Yuediao Folk Music Knowledge Development in Zhoukou, Henan Province, \n\n"
"Who are the authors of the paper titled ""Coverage and impact of influenza vaccination among children in Minhang District, China, 2013–2020""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Who are the authors of the paper titled ""Coverage and impact of influenza vaccination among children in Minhang District, China, 2013–2020""?\nContext: Document 0: Faculty Name: lu jiang\nMetadata:\nPaperid: 269a18fbff6f0079e7ea2463b96654ce6563c49a\nTitle: Coverage and impact of influenza vaccination among children in Minhang District, China, 2013–2020\nYear: 2023\nAbstract: Background Young children have a great disease burden and are particularly vulnerable to influenza. This study aimed to assess the direct effect of influenza vaccination among children and to evaluate the indirect benefit of immunizing children. Methods The influenza vaccination records for all children born during 2013–2019 in Minhang District and surveillance data for reported influenza cases were obtained from the Minhang CDC. 17,905 children were recorded in the vaccination system and included in this study. Descriptive epidemiology methods were used for data analysis, including an ecological approach to estimate the number of influenza cases averted by vaccination and linear regression to estimate the reduction in influenza cases in the general population per thousand additional childhood vaccination doses. Results During the study period, the annual vaccination coverage rate ranged from 10.40% in 2013–2014 to 27.62% in 2015–2016. \nDocument 1: Impact of Varicella Immunization and Public Health and Social Measures on Varicella Incidence: Insights from Surveillance Data in Shanghai, 2013–2022\nCoverage and impact of influenza vaccination among children in Minhang District, China, 2013–2020\nAssociations of Morphological Changes in Skeletal Muscles of Preschool Children in China Following Physical Activity\nQualitative study of the association between psychosocial health and physical activity/sleep quality in toddlers\nEstimability study on the age of toddlers’ gait development based on gait parameters\nAdvances in gene therapy hold promise for treating hereditary hearing loss. \n\n"
"In which venue was the paper titled ""Exploring Smart Commercial Building Occupants’ Perceptions and Notification Preferences of Internet of Things Data Collection in the United States"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: In which venue was the paper titled ""Exploring Smart Commercial Building Occupants’ Perceptions and Notification Preferences of Internet of Things Data Collection in the United States"" published?\nContext: Document 0: Faculty Name: norman sadeh\nMetadata:\nPaperid: 3f165dae2310a5d8aa7294ffdc45573a51c957b8\nTitle: Exploring Smart Commercial Building Occupants’ Perceptions and Notification Preferences of Internet of Things Data Collection in the United States\nYear: 2023\nAbstract: Data collection through the Internet of Things (IoT) devices, or smart devices, in commercial buildings enables possibilities for increased convenience and energy efficiency. However, such benefits face a large perceptual challenge when being implemented in practice, due to the different ways occupants working in the buildings understand and trust in the data collection. The semi-public, pervasive, and multi-modal nature of data collection in smart buildings points to the need to study occupants’ understanding of data collection and notification preferences. We conduct an online study with 492 participants in the US who report working in smart commercial buildings regarding: 1) awareness and perception of data collection in smart commercial buildings, 2) privacy notification preferences, and 3) potential factors for privacy notification preferences. \nDocument 1: List of 2023 Open Access papers by norman sadeh are:\nDo Privacy Labels Answer Users' Privacy Questions?\nExploring Smart Commercial Building Occupants’ Perceptions and Notification Preferences of Internet of Things Data Collection in the United States\nComparing Privacy Label Disclosures of Apps Published in both the App Store and Google Play Stores\nATLAS: Automatically Detecting Discrepancies Between Privacy Policies and Privacy Labels\nPurpose in the Machine: Do Traffic Simulators Produce Distributionally Equivalent Outcomes for Reinforcement Learning Applications?\nUnderstanding How to Inform Blind and Low-Vision Users about Data Privacy through Privacy Question Answering Assistants \n\n"
"In which venue was the paper titled ""Towards Multilingual Automatic Open-Domain Dialogue Evaluation"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: In which venue was the paper titled ""Towards Multilingual Automatic Open-Domain Dialogue Evaluation"" published?\nContext: Document 0: List of 2023 Open Access papers by alon lavie are:\nThe Inside Story: Towards Better Understanding of Machine Translation Neural Evaluation Metrics\nTowards Multilingual Automatic Dialogue Evaluation\nResults of WMT23 Metrics Shared Task: Metrics Might Be Guilty but References Are Not Innocent\nAppropriateness is all you need!\nTowards Multilingual Automatic Open-Domain Dialogue Evaluation\nSimple LLM Prompting is State-of-the-Art for Robust and Multilingual Dialogue Evaluation\nAssessing and comparing alternative certification programs: The teacher-classroom-community model\nUsing citizen science to protect threatened amphibian populations in urban spaces: ecology, life history, and conservation of green toads and fire salamanders in Jerusalem and Haifa \nDocument 1: Faculty Name: alon lavie\nMetadata:\nPaperid: 9e8f125ef479af7e95ee5b8949b24e750c7df367\nTitle: Towards Multilingual Automatic Open-Domain Dialogue Evaluation\nYear: 2023\nAbstract: The main limiting factor in the development of robust multilingual open-domain dialogue evaluation metrics is the lack of multilingual data and the limited availability of open-sourced multilingual dialogue systems. In this work, we propose a workaround for this lack of data by leveraging a strong multilingual pretrained encoder-based Language Model and augmenting existing English dialogue data using Machine Translation. We empirically show that the naive approach of finetuning a pretrained multilingual encoder model with translated data is insufficient to outperform the strong baseline of finetuning a multilingual model with only source data. Instead, the best approach consists in the careful curation of translated data using MT Quality Estimation metrics, excluding low quality translations that hinder its performance. \n\n"
"What year was the paper titled ""Genitourinary Management and Follow-Up for Patients with Stevens-Johnson Syndrome/Toxic Epidermal Necrolysis"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: What year was the paper titled ""Genitourinary Management and Follow-Up for Patients with Stevens-Johnson Syndrome/Toxic Epidermal Necrolysis"" published?\nContext: Document 0: Faculty Name: tom mitchell\nMetadata:\nPaperid: e98e4af918f3ad0f6ea65f2c68e2846a5b7eb333\nTitle: Genitourinary Management and Follow-Up for Patients with Stevens-Johnson Syndrome/Toxic Epidermal Necrolysis\nYear: 2023\nAbstract: None\nAuthors: Gina T. Baaklini, Tom Michael Mitchell, Jordan Davis, Kevin McGovern, J. Aden, L. Cancio\nVenue: Burns Open\nTldr: None \nDocument 1: List of 2023 Open Access papers by tom mitchell are:\nPlan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents\nThe Roles of Symbols in Neural-based AI: They are Not What You Think!\nThe Internal State of an LLM Knows When its Lying\nNeuropilin-1 interacts with VE-cadherin and TGFBR2 to stabilize adherens junctions and prevent activation of endothelium under flow\nThe unconventional Myosin-1C augments endothelial secretion of von Willebrand factor by linking contractile actomyosin machinery to the plasma membrane\nRuffle&Riley: Towards the Automated Induction of Conversational Tutoring Systems\nSynthetic biology open language (SBOL) version 3.1.0\nRead and Reap the Rewards: Learning to Play Atari with the Help of Instruction Manuals\nLearning to Give Useful Hints: Assistance Action Evaluation and Policy Improvements\nGenitourinary Management and Follow-Up for Patients with Stevens-Johnson Syndrome/Toxic Epidermal Necrolysis\nFumarate induces vesicular release of mtDNA to drive innate immunity\nFLAIRR-Seq: A Method for Single-Molecule Resolution of Near Full-Length Antibody H Chain Repertoires. \n\n"
"Can you provide the abstract of the paper titled ""Study of hadronic cross-sections with cosmic ray Carbon from GeV to TeV by the DAMPE experiment""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Can you provide the abstract of the paper titled ""Study of hadronic cross-sections with cosmic ray Carbon from GeV to TeV by the DAMPE experiment""?\nContext: Document 0: Faculty Name: eric xing\nMetadata:\nPaperid: cd76c60e754330964796ec980528b00ad38346a5\nTitle: Study of hadronic cross-sections with cosmic ray Carbon from GeV to TeV by the DAMPE experiment\nYear: 2023\nAbstract: None\nAuthors: E. Xu, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Y. Cui, I. De Mitri, F. de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, J. Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. \nDocument 1: Faculty Name: lu jiang\nMetadata:\nPaperid: cd76c60e754330964796ec980528b00ad38346a5\nTitle: Study of hadronic cross-sections with cosmic ray Carbon from GeV to TeV by the DAMPE experiment\nYear: 2023\nAbstract: None\nAuthors: E. Xu, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Y. Cui, I. De Mitri, F. de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, J. Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. \n\n"
"Who is the faculty member associated with the paper titled ""Towards Automated Accessibility Report Generation for Mobile Apps""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Who is the faculty member associated with the paper titled ""Towards Automated Accessibility Report Generation for Mobile Apps""?\nContext: Document 0: Faculty Name: jeffrey bigham\nMetadata:\nPaperid: dc73363f3a550abc41fefdc182763e183531869f\nTitle: Towards Automated Accessibility Report Generation for Mobile Apps\nYear: 2023\nAbstract: Many apps have basic accessibility issues, like missing labels or low contrast. Automated tools can help app developers catch basic issues, but can be laborious or require writing dedicated tests. We propose a system, motivated by a collaborative process with accessibility stakeholders at a large technology company, to generate whole app accessibility reports by combining varied data collection methods (e.g., app crawling, manual recording) with an existing accessibility scanner. Many such scanners are based on single-screen scanning, and a key problem in whole app accessibility reporting is to effectively de-duplicate and summarize issues collected across an app. To this end, we developed a screen grouping model with 96.9% accuracy (88.8% F1-score) and UI element matching heuristics with 97% accuracy (98.2% F1-score). \nDocument 1: Faculty Name: jamie callan\nMetadata:\nPaperid: ac9ee72a5cd611e9143e385f668af662583721ee\nTitle: Multi-Objective Improvement of Android Applications\nYear: 2023\nAbstract: Non-functional properties, such as runtime or memory use, are important to mobile app users and developers, as they affect user experience. Previous work on automated improvement of non-functional properties in mobile apps failed to address the inherent trade-offs between such properties. We propose a practical approach and the first open-source tool, GIDroid (2023), for multi-objective automated improvement of Android apps. In particular, we use Genetic improvement, a search-based technique that navigates the space of software variants to find improved software. We use a simulation-based testing framework to greatly improve the speed of search. GIDroid contains three state-of-the-art multi-objective algorithms, and two new mutation operators, which cache the results of method calls. Genetic improvement relies on testing to validate patches. Previous work showed that tests in open-source Android applications are scarce. We thus wrote tests for 21 versions of 7 Android apps, creating a new benchmark for performance improvements. \n\n"
"In which venue was the paper titled ""Measurement of the p+He energy spectrum with the DAMPE space mission"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: In which venue was the paper titled ""Measurement of the p+He energy spectrum with the DAMPE space mission"" published?\nContext: Document 0: Faculty Name: lu jiang\nMetadata:\nPaperid: cc48851430aca07e19f7f48c1733b009ea654bdf\nTitle: Measurement of the p+He energy spectrum with the DAMPE space mission\nYear: 2023\nAbstract: None\nAuthors: Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, F. de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, \nDocument 1: Faculty Name: eric xing\nMetadata:\nPaperid: cc48851430aca07e19f7f48c1733b009ea654bdf\nTitle: Measurement of the p+He energy spectrum with the DAMPE space mission\nYear: 2023\nAbstract: None\nAuthors: Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, F. de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, \n\n"
"In which venue was the paper titled ""SigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: In which venue was the paper titled ""SigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing"" published?\nContext: Document 0: Faculty Name: david mortensen\nMetadata:\nPaperid: 659be1ff350634f50cc066d258ee6a45e697e552\nTitle: SigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing\nYear: 2023\nAbstract: In our submission to the SIGMORPHON 2023 Shared Task on interlinear glossing (IGT), we explore approaches to data augmentation and modeling across seven low-resource languages. For data augmentation, we explore two approaches: creating artificial data from the provided training data and utilizing existing IGT resources in other languages. On the modeling side, we test an enhanced version of the provided token classification baseline as well as a pretrained multilingual seq2seq model. Additionally, we apply post-correction using a dictionary for Gitksan, the language with the smallest amount of data. We find that our token classification models are the best performing, with the highest word-level accuracy for Arapaho and highest morpheme-level accuracy for Gitksan out of all submissions. We also show that data augmentation is an effective strategy, though applying artificial data pretraining has very different effects across both models tested. \nDocument 1: Faculty Name: graham neubig\nMetadata:\nPaperid: 659be1ff350634f50cc066d258ee6a45e697e552\nTitle: SigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing\nYear: 2023\nAbstract: In our submission to the SIGMORPHON 2023 Shared Task on interlinear glossing (IGT), we explore approaches to data augmentation and modeling across seven low-resource languages. For data augmentation, we explore two approaches: creating artificial data from the provided training data and utilizing existing IGT resources in other languages. On the modeling side, we test an enhanced version of the provided token classification baseline as well as a pretrained multilingual seq2seq model. Additionally, we apply post-correction using a dictionary for Gitksan, the language with the smallest amount of data. We find that our token classification models are the best performing, with the highest word-level accuracy for Arapaho and highest morpheme-level accuracy for Gitksan out of all submissions. We also show that data augmentation is an effective strategy, though applying artificial data pretraining has very different effects across both models tested. \n\n"
"Who are the authors of the paper titled ""Neural Machine Translation for the Indigenous Languages of the Americas: An Introduction""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Who are the authors of the paper titled ""Neural Machine Translation for the Indigenous Languages of the Americas: An Introduction""?\nContext: Document 0: Faculty Name: graham neubig\nMetadata:\nPaperid: 405f1a5602867c66e015491c26d2be5504eed458\nTitle: Neural Machine Translation for the Indigenous Languages of the Americas: An Introduction\nYear: 2023\nAbstract: Neural models have drastically advanced state of the art for machine translation (MT) between high-resource languages. Traditionally, these models rely on large amounts of training data, but many language pairs lack these resources. However, an important part of the languages in the world do not have this amount of data. Most languages from the Americas are among them, having a limited amount of parallel and monolingual data, if any. Here, we present an introduction to the interested reader to the basic challenges, concepts, and techniques that involve the creation of MT systems for these languages. Finally, we discuss the recent advances and findings and open questions, product of an increased interest of the NLP community in these languages. \nDocument 1: List of 2023 Open Access papers by graham neubig are:\nCross-Modal Fine-Tuning: Align then Refine\nChatGPT MT: Competitive for High- (but Not Low-) Resource Languages\nGlobalBench: A Benchmark for Global Progress in Natural Language Processing\nLearning Performance-Improving Code Edits\nCodeBERTScore: Evaluating Code Generation with Pretrained Models of Code\nNeural Machine Translation for the Indigenous Languages of the Americas: An Introduction\nUser-Centric Evaluation of OCR Systems for Kwak’wala\nMulti-Dimensional Evaluation of Text Summarization with In-Context Learning\nA Gold Standard Dataset for the Reviewer Assignment Problem\nSigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing\nBridging the Gap: A Survey on Integrating (Human) Feedback for Natural Language Generation\nFacTool: Factuality Detection in Generative AI - A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios\nActive Retrieval Augmented Generation\nLarge Language Models Enable Few-Shot Clustering\nSolving NLP Problems through Human-System Collaboration: A Discussion-based Approach\nCrossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss \n\n"
"Who are the authors of the paper titled ""Incremental Blockwise Beam Search for Simultaneous Speech Translation with Controllable Quality-Latency Tradeoff""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Who are the authors of the paper titled ""Incremental Blockwise Beam Search for Simultaneous Speech Translation with Controllable Quality-Latency Tradeoff""?\nContext: Document 0: Faculty Name: alexander waibel\nMetadata:\nPaperid: d24d60719e90e69749a75c160cb760d1d9fca44a\nTitle: Incremental Blockwise Beam Search for Simultaneous Speech Translation with Controllable Quality-Latency Tradeoff\nYear: 2023\nAbstract: Blockwise self-attentional encoder models have recently emerged as one promising end-to-end approach to simultaneous speech translation. These models employ a blockwise beam search with hypothesis reliability scoring to determine when to wait for more input speech before translating further. However, this method maintains multiple hypotheses until the entire speech input is consumed -- this scheme cannot directly show a single \textit{incremental} translation to users. Further, this method lacks mechanisms for \textit{controlling} the quality vs. latency tradeoff. We propose a modified incremental blockwise beam search incorporating local agreement or hold-$n$ policies for quality-latency control. We apply our framework to models trained for online or offline translation and demonstrate that both types can be effectively used in online mode. \nDocument 1: Faculty Name: shinji watanabe\nMetadata:\nPaperid: d24d60719e90e69749a75c160cb760d1d9fca44a\nTitle: Incremental Blockwise Beam Search for Simultaneous Speech Translation with Controllable Quality-Latency Tradeoff\nYear: 2023\nAbstract: Blockwise self-attentional encoder models have recently emerged as one promising end-to-end approach to simultaneous speech translation. These models employ a blockwise beam search with hypothesis reliability scoring to determine when to wait for more input speech before translating further. However, this method maintains multiple hypotheses until the entire speech input is consumed -- this scheme cannot directly show a single \textit{incremental} translation to users. Further, this method lacks mechanisms for \textit{controlling} the quality vs. latency tradeoff. We propose a modified incremental blockwise beam search incorporating local agreement or hold-$n$ policies for quality-latency control. We apply our framework to models trained for online or offline translation and demonstrate that both types can be effectively used in online mode. \n\n"
"What year was the paper titled ""Reconstructing ice force-displacement development in structural assessments of freshwater, polycrystalline ice impacts"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: What year was the paper titled ""Reconstructing ice force-displacement development in structural assessments of freshwater, polycrystalline ice impacts"" published?\nContext: Document 0: List of 2023 Open Access papers by robert frederking are:\nReconstructing ice force-displacement development in structural assessments of freshwater, polycrystalline ice impacts \nDocument 1: Faculty Name: robert frederking\nMetadata:\nPaperid: 42f711ca3491d4bf33b35683944d9b8f5bc1c558\nTitle: Reconstructing ice force-displacement development in structural assessments of freshwater, polycrystalline ice impacts\nYear: 2023\nAbstract: None\nAuthors: Ekaterina Kim, K. Høyland, R. Frederking\nVenue: International Journal of Impact Engineering\nTldr: None \n\n"
"What year was the paper titled ""BUFFET: Benchmarking Large Language Models for Few-shot Cross-lingual Transfer"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: What year was the paper titled ""BUFFET: Benchmarking Large Language Models for Few-shot Cross-lingual Transfer"" published?\nContext: Document 0: Faculty Name: yulia tsvetkov\nMetadata:\nPaperid: ad454e24bd32408559512b4bac4cd5237794210f\nTitle: BUFFET: Benchmarking Large Language Models for Few-shot Cross-lingual Transfer\nYear: 2023\nAbstract: Despite remarkable advancements in few-shot generalization in natural language processing, most models are developed and evaluated primarily in English. To facilitate research on few-shot cross-lingual transfer, we introduce a new benchmark, called BUFFET, which unifies 15 diverse tasks across 54 languages in a sequence-to-sequence format and provides a fixed set of few-shot examples and instructions. BUFFET is designed to establish a rigorous and equitable evaluation framework for few-shot cross-lingual transfer across a broad range of tasks and languages. Using BUFFET, we perform thorough evaluations of state-of-the-art multilingual large language models with different transfer methods, namely in-context learning and fine-tuning. Our findings reveal significant room for improvement in few-shot in-context cross-lingual transfer. \nDocument 1: Using BUFFET, we perform thorough evaluations of state-of-the-art multilingual large language models with different transfer methods, namely in-context learning and fine-tuning. Our findings reveal significant room for improvement in few-shot in-context cross-lingual transfer. In particular, ChatGPT with in-context learning often performs worse than much smaller mT5-base models fine-tuned on English task data and few-shot in-language examples. Our analysis suggests various avenues for future research in few-shot cross-lingual transfer, such as improved pretraining, understanding, and future evaluations. \n\n"
"In which venue was the paper titled ""Low-Light Image Enhancement via Structure Modeling and Guidance"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: In which venue was the paper titled ""Low-Light Image Enhancement via Structure Modeling and Guidance"" published?\nContext: Document 0: Faculty Name: lu jiang\nMetadata:\nPaperid: 2386a482b661fd3b65d7509f6dd900020116d9a2\nTitle: Low-Light Image Enhancement via Structure Modeling and Guidance\nYear: 2023\nAbstract: This paper proposes a new framework for low-light image enhancement by simultaneously conducting the appearance as well as structure modeling. It employs the structural feature to guide the appearance enhancement, leading to sharp and realistic results. The structure modeling in our framework is implemented as the edge detection in low-light images. It is achieved with a modified generative model via designing a structure-aware feature extractor and generator. The detected edge maps can accurately emphasize the essential structural information, and the edge prediction is robust towards the noises in dark areas. Moreover, to improve the appearance modeling, which is implemented with a simple U-Net, a novel structure-guided enhancement module is proposed with structure-guided feature synthesis layers. The appearance modeling, edge detector, and enhancement module can be trained end-to-end. The experiments are conducted on representative datasets (sRGB and RAW domains), showing that our model consistently achieves SOTA performance on all datasets with the same architecture. \nDocument 1: Research on integrated coastal zone management from past to the future: a bibliometric analysis\nLow-Light Image Enhancement via Structure Modeling and Guidance\nEdge Preserving Implicit Surface Representation of Point Clouds\nAccuracy of narrow band imaging for detecting the malignant transformation of oral potentially malignant disorders: A systematic review and meta-analysis\nUpdates on immunological mechanistic insights and targeting of the oral lichen planus microenvironment\nCD8+ tissue-resident memory T cells induce oral lichen planus erosion via cytokine network\nSingle-cell immune profiling reveals immune responses in oral lichen planus\nAuditing Gender Presentation Differences in Text-to-Image Models\n“Easier or Harder, Depending on Who the Hearing Person Is”: Codesigning Videoconferencing Tools for Small Groups with Mixed Hearing Status\nEfficient conversion of biomass waste to N/O co-doped hierarchical porous carbon for high performance supercapacitors\nEditorial: Emerging talents in comparative immunology: 2022 \n\n"
"In which venue was the paper titled ""SigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: In which venue was the paper titled ""SigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing"" published?\nContext: Document 0: Faculty Name: david mortensen\nMetadata:\nPaperid: 659be1ff350634f50cc066d258ee6a45e697e552\nTitle: SigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing\nYear: 2023\nAbstract: In our submission to the SIGMORPHON 2023 Shared Task on interlinear glossing (IGT), we explore approaches to data augmentation and modeling across seven low-resource languages. For data augmentation, we explore two approaches: creating artificial data from the provided training data and utilizing existing IGT resources in other languages. On the modeling side, we test an enhanced version of the provided token classification baseline as well as a pretrained multilingual seq2seq model. Additionally, we apply post-correction using a dictionary for Gitksan, the language with the smallest amount of data. We find that our token classification models are the best performing, with the highest word-level accuracy for Arapaho and highest morpheme-level accuracy for Gitksan out of all submissions. We also show that data augmentation is an effective strategy, though applying artificial data pretraining has very different effects across both models tested. \nDocument 1: Faculty Name: graham neubig\nMetadata:\nPaperid: 659be1ff350634f50cc066d258ee6a45e697e552\nTitle: SigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing\nYear: 2023\nAbstract: In our submission to the SIGMORPHON 2023 Shared Task on interlinear glossing (IGT), we explore approaches to data augmentation and modeling across seven low-resource languages. For data augmentation, we explore two approaches: creating artificial data from the provided training data and utilizing existing IGT resources in other languages. On the modeling side, we test an enhanced version of the provided token classification baseline as well as a pretrained multilingual seq2seq model. Additionally, we apply post-correction using a dictionary for Gitksan, the language with the smallest amount of data. We find that our token classification models are the best performing, with the highest word-level accuracy for Arapaho and highest morpheme-level accuracy for Gitksan out of all submissions. We also show that data augmentation is an effective strategy, though applying artificial data pretraining has very different effects across both models tested. \n\n"
"Who are the authors of the paper titled ""PWESuite: Phonetic Word Embeddings and Tasks They Facilitate""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Who are the authors of the paper titled ""PWESuite: Phonetic Word Embeddings and Tasks They Facilitate""?\nContext: Document 0: Faculty Name: david mortensen\nMetadata:\nPaperid: db14d05b18ec852f8afcd6d2d10bbd9eeaef8325\nTitle: PWESuite: Phonetic Word Embeddings and Tasks They Facilitate\nYear: 2023\nAbstract: Mapping words into a fixed-dimensional vector space is the backbone of modern NLP. While most word embedding methods successfully encode semantic information, they overlook phonetic information that is crucial for many tasks. We develop three methods that use articulatory features to build phonetically informed word embeddings. To address the inconsistent evaluation of existing phonetic word embedding methods, we also contribute a task suite to fairly evaluate past, current, and future methods. We evaluate both (1) intrinsic aspects of phonetic word embeddings, such as word retrieval and correlation with sound similarity, and (2) extrinsic performance on tasks such as rhyme and cognate detection and sound analogies. We hope our task suite will promote reproducibility and inspire future phonetic embedding research. \nDocument 1: List of 2023 Open Access papers by david mortensen are:\nChatGPT MT: Competitive for High- (but Not Low-) Resource Languages\nDo All Languages Cost the Same? Tokenization in the Era of Commercial Language Models\nSigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing\nConstruction Grammar Provides Unique Insight into Neural Language Models\nGeneralized Glossing Guidelines: An Explicit, Human- and Machine-Readable, Item-and-Process Convention for Morphological Annotation\nTransformed Protoform Reconstruction\nPWESuite: Phonetic Word Embeddings and Tasks They Facilitate\nKuki-Chin Phonology: An Overview \n\n"
"Who are the authors of the paper titled ""Automatic synchrotron tomographic alignment schemes based on genetic algorithms and human-in-the-loop software""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Who are the authors of the paper titled ""Automatic synchrotron tomographic alignment schemes based on genetic algorithms and human-in-the-loop software""?\nContext: Document 0: Faculty Name: yang yiming\nMetadata:\nPaperid: 0a187bee2436f4a2e98dd94d3c2f18b83281efdb\nTitle: Automatic synchrotron tomographic alignment schemes based on genetic algorithms and human-in-the-loop software\nYear: 2023\nAbstract: A highly automatic alignment scheme is proposed to address the pressing challenge in tomographic alignment of future scanning tomography experiments. The results show that the proposed method exhibits excellent sub-pixel alignment accuracy and high time efficiency.\nAuthors: Zhen Zhang, Xiaoxue Bi, Pengcheng Li, Chenglong Zhang, Yiming Yang, Yu Liu, Gang Chen, Yuhui Dong, Gongfa Liu, Yi Zhang\nVenue: Journal of Synchrotron Radiation\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The results show that the proposed method exhibits excellent sub-pixel alignment accuracy and high time efficiency.'} \nDocument 1: List of 2023 Open Access papers by yang yiming are:\nFunctional targeted therapy for glioma based on platelet membrane-coated nanogels\nDual Responsive Magnetic Drug Delivery Nanomicelles with Tumor Targeting for Enhanced Cancer Chemo/Magnetothermal Synergistic Therapy\nExpression of ALCAM in Clinical Colon Cancer and Relationship With Patients’ Treatment Responses\nClaudin-10 in the Blood Brain Barrier Function of Cerebral Endothelial Cells and Transendothelial Invasion of Breast Cancer Cells\nAccelerating Diffusion-based Combinatorial Optimization Solvers by Progressive Distillation\nAutomatic synchrotron tomographic alignment schemes based on genetic algorithms and human-in-the-loop software\nHigh CD8+tumor-infiltrating lymphocytes indicate severe exhaustion and poor prognosis in angioimmunoblastic T-cell lymphoma\nNumerical Investigation of Fatigue Crack Propagation Behaviour of 550E High-Performance Steel\nAssociation between albumin-to-globulin ratio and the risk of overall survival in advanced non-small cell lung cancer patients with anlotinib treatment: a retrospective cohort study\nAnalysis of Volatile Components in Dried Fruits and Branch Exudates of Schisandra chinensis with Different Fruit Colors Using GC-IMS Technology\nSecreted \n\n"
"In which venue was the paper titled ""Towards Improving Harmonic Sensitivity and Prediction Stability for Singing Melody Extraction"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: In which venue was the paper titled ""Towards Improving Harmonic Sensitivity and Prediction Stability for Singing Melody Extraction"" published?\nContext: Document 0: Faculty Name: berg kirkpatrick taylor\nMetadata:\nPaperid: 15b08595533bfc640f4dd470ca7a2273badec20a\nTitle: Towards Improving Harmonic Sensitivity and Prediction Stability for Singing Melody Extraction\nYear: 2023\nAbstract: In deep learning research, many melody extraction models rely on redesigning neural network architectures to improve performance. In this paper, we propose an input feature modification and a training objective modification based on two assumptions. First, harmonics in the spectrograms of audio data decay rapidly along the frequency axis. To enhance the model's sensitivity on the trailing harmonics, we modify the Combined Frequency and Periodicity (CFP) representation using discrete z-transform. Second, the vocal and non-vocal segments with extremely short duration are uncommon. To ensure a more stable melody contour, we design a differentiable loss function that prevents the model from predicting such segments. We apply these modifications to several models, including MSNet, FTANet, and a newly introduced model, PianoNet, modified from a piano transcription network. Our experimental results demonstrate that the proposed modifications are empirically effective for singing melody extraction. \nDocument 1: List of 2023 Open Access papers by berg kirkpatrick taylor are:\nSmaller Language Models are Better Black-box Machine-Generated Text Detectors\nTowards Improving Harmonic Sensitivity and Prediction Stability for Singing Melody Extraction\nJointly modeling products and resource pages for task-oriented recommendation\nMusicLDM: Enhancing Novelty in Text-to-Music Generation Using Beat-Synchronous Mixup Strategies\nUniversal Source Separation with Weakly Labelled Data\nCLIPSonic: Text-to-Audio Synthesis with Unlabeled Videos and Pretrained Language-Vision Models\nMembership Inference Attacks against Language Models via Neighbourhood Comparison\nContrastive Attention Networks for Attribution of Early Modern Print\nText Conditional Alt-Text Generation for Twitter Images\nExploring the Relationship Between Model Architecture and In-Context Learning Ability\nA Block Metropolis-Hastings Sampler for Controllable Energy-based Text Generation\nMisusing Tools in Large Language Models With Visual Adversarial Examples\nSimple Temporal Adaptation to Changing Label Sets: Hashtag Prediction via Dense KNN\nCuneiML: A Cuneiform Dataset for Machine Learning \n\n"
"Who is the faculty member associated with the paper titled ""A Study of Yuediao Folk Music Knowledge Development in Zhoukou, Henan Province, China""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Who is the faculty member associated with the paper titled ""A Study of Yuediao Folk Music Knowledge Development in Zhoukou, Henan Province, China""?\nContext: Document 0: Faculty Name: lei li\nMetadata:\nPaperid: 0c840a5a5e483ff48cec60e81aa0b0bfa1a99498\nTitle: A Study of Yuediao Folk Music Knowledge Development in Zhoukou, Henan Province, China\nYear: 2023\nAbstract: None\nAuthors: Lei Li, Awirut Thotham\nVenue: Education Quarterly Reviews\nTldr: None \nDocument 1: List of 2023 Open Access papers by lei li are:\nEstablishment of a N1-methyladenosine-related risk signature for breast carcinoma by bioinformatics analysis and experimental validation\nPopulation pharmacokinetic analysis and dosing regimen optimization of teicoplanin in critically ill patients with sepsis\nThe effects of pharmaceutical interventions on potentially inappropriate medications in older patients: a systematic review and meta-analysis\nP53 protein and the diseases in central nervous system\nCorrection: Polydopamine-functionalized selenium nanoparticles as an efficient photoresponsive antibacterial platform\nEditorial: Strategies for functional polymeric nanocomposites and its multifunctional applications\nPolydopamine-functionalized selenium nanoparticles as an efficient photoresponsive antibacterial platform\nAntimicrobial properties of heterojunction BiSnSbO_6-ZnO composites in wastewater treatment\nResearch on torsional stiffness of flexspline-flexible bearing contact pair in harmonic drive based on macro-micro scale modeling\nIntegrated Valve Product Fluid Simulation and Test Verification\nFailure Analysis and Improvement of Check Valve Reverse Cut-off Seal\nA Study of Yuediao Folk Music Knowledge Development in Zhoukou, Henan Province, \n\n"
"What year was the paper titled ""CSurF: Sparse Lexical Retrieval through Contextualized Surface Forms"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: What year was the paper titled ""CSurF: Sparse Lexical Retrieval through Contextualized Surface Forms"" published?\nContext: Document 0: Faculty Name: jamie callan\nMetadata:\nPaperid: 6b7eefa15c0a461afeab4fa13cf862c5340fdc2a\nTitle: CSurF: Sparse Lexical Retrieval through Contextualized Surface Forms\nYear: 2023\nAbstract: Lexical exact-match systems perform text retrieval efficiently with sparse matching signals and fast retrieval through inverted lists, but naturally suffer from the mismatch between lexical surface form and implicit term semantics. This paper proposes to directly bridge the surface form space and the term semantics space in lexical exact-match retrieval via contextualized surface forms (CSF). Each CSF pairs a lexical surface form with a context source, and is represented by a lexical form weight and a contextualized semantic vector representation. This framework is able to perform sparse lexicon-based retrieval by learning to represent each query and document as a ""bag-of-CSFs"", simultaneously addressing two key factors in sparse retrieval: vocabulary expansion of surface form and semantic representation of term meaning. At retrieval time, it efficiently matches CSFs through exact-match of learned surface forms, and effectively scores each CSF pair via contextual semantic representations, leading to joint improvement in both term match and term scoring. \nDocument 1: List of 2023 Open Access papers by jamie callan are:\nConversational Search with Random Walks over Entity Graphs\nKALE: Using a K-Sparse Projector for Lexical Expansion\nCSurF: Sparse Lexical Retrieval through Contextualized Surface Forms\nActive Retrieval Augmented Generation\nMulti-Objective Improvement of Android Applications \n\n"
"Who is the faculty member associated with the paper titled ""Integrating Pretrained ASR and LM to Perform Sequence Generation for Spoken Language Understanding""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Who is the faculty member associated with the paper titled ""Integrating Pretrained ASR and LM to Perform Sequence Generation for Spoken Language Understanding""?\nContext: Document 0: Faculty Name: shinji watanabe\nMetadata:\nPaperid: 0c7018db4a00df1792a7b3de3cb0b48aa19ca041\nTitle: Integrating Pretrained ASR and LM to Perform Sequence Generation for Spoken Language Understanding\nYear: 2023\nAbstract: There has been an increased interest in the integration of pretrained speech recognition (ASR) and language models (LM) into the SLU framework. However, prior methods often struggle with a vocabulary mismatch between pretrained models, and LM cannot be directly utilized as they diverge from its NLU formulation. In this study, we propose a three-pass end-to-end (E2E) SLU system that effectively integrates ASR and LM subnetworks into the SLU formulation for sequence generation tasks. In the first pass, our architecture predicts ASR transcripts using the ASR subnetwork. This is followed by the LM subnetwork, which makes an initial SLU prediction. Finally, in the third pass, the deliberation subnetwork conditions on representations from the ASR and LM subnetworks to make the final prediction. \nDocument 1: Faculty Name: shinji watanabe\nMetadata:\nPaperid: 083cf10c0cbf75dd5755a6a2cd971f39e7da75c2\nTitle: UniverSLU: Universal Spoken Language Understanding for Diverse Classification and Sequence Generation Tasks with a Single Network\nYear: 2023\nAbstract: Recent studies have demonstrated promising outcomes by employing large language models with multi-tasking capabilities. They utilize prompts to guide the model's behavior and surpass performance of task-specific models. Motivated by this, we ask: can we build a single model that jointly perform various spoken language understanding (SLU) tasks? To address this, we utilize pre-trained automatic speech recognition (ASR) models and employ various task and dataset specifiers as discrete prompts. We demonstrate efficacy of our single multi-task learning (MTL) model""UniverSLU""for 12 different speech classification and sequence generation tasks across 17 datasets and 9 languages. Results show that UniverSLU achieves competitive performance and even surpasses task-specific models. \n\n"
"What year was the paper titled ""BotPercent: Estimating Bot Populations in Twitter Communities"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: What year was the paper titled ""BotPercent: Estimating Bot Populations in Twitter Communities"" published?\nContext: Document 0: Faculty Name: yulia tsvetkov\nMetadata:\nPaperid: 1bc0dc96d745325d89ec5bee1da1541255e6d1eb\nTitle: BotPercent: Estimating Twitter Bot Populations from Groups to Crowds\nYear: 2023\nAbstract: Twitter bot detection has become increasingly important in combating misinformation, identifying malicious online cam-paigns, and protecting the integrity of social media discourse. While existing bot detection literature mostly focuses on identifying individual bots, it remains underexplored how to estimate the proportion of bots within speciﬁc communities and social networks, which has great implications for both content moderators and day-to-day users. In this work, we propose community-level bot detection , a novel approach to estimating the amount of malicious interference in online communities by estimating the percentage of bot accounts. Speciﬁcally, we introduce BotPercent , an amalgamation of Twitter bot-detection datasets and feature, text, and graph-based models that overcome generalization issues in existing individual-level models, resulting in a more accurate community-level bot estimation. \nDocument 1: Faculty Name: yulia tsvetkov\nMetadata:\nPaperid: 5cd7c5f4e21cb541d7c553b04074335e858847c2\nTitle: BotPercent: Estimating Bot Populations in Twitter Communities\nYear: 2023\nAbstract: Twitter bot detection is vital in combating misinformation and safeguarding the integrity of social media discourse. While malicious bots are becoming more and more sophisticated and personalized, standard bot detection approaches are still agnostic to social environments (henceforth, communities) the bots operate at. In this work, we introduce community-specific bot detection, estimating the percentage of bots given the context of a community. Our method -- BotPercent -- is an amalgamation of Twitter bot detection datasets and feature-, text-, and graph-based models, adjusted to a particular community on Twitter. We introduce an approach that performs confidence calibration across bot detection models, which addresses generalization issues in existing community-agnostic models targeting individual bots and leads to more accurate community-level bot estimations. \n\n"
"Who are the authors of the paper titled ""When to generate hedges in peer-tutoring interactions""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Who are the authors of the paper titled ""When to generate hedges in peer-tutoring interactions""?\nContext: Document 0: List of 2023 Open Access papers by justine cassell are:\nWhen to generate hedges in peer-tutoring interactions\nHow About Kind of Generating Hedges using End-to-End Neural Models?\nBeyond Single-Mindedness: A Figure-Ground Reversal for the Cognitive Sciences\n""You might think about slightly revising the title”: Identifying Hedges in Peer-tutoring Interactions \nDocument 1: Faculty Name: justine cassell\nMetadata:\nPaperid: 24bff26f19051b1413d1e343322c1ae4bba05428\nTitle: When to generate hedges in peer-tutoring interactions\nYear: 2023\nAbstract: This paper explores the application of machine learning techniques to predict where hedging occurs in peer-tutoring interactions. The study uses a naturalistic face-to-face dataset annotated for natural language turns, conversational strategies, tutoring strategies, and nonverbal behaviors. These elements are processed into a vector representation of the previous turns, which serves as input to several machine learning models, including MLP and LSTM. The results show that embedding layers, capturing the semantic information of the previous turns, significantly improves the model’s performance. Additionally, the study provides insights into the importance of various features, such as interpersonal rapport and nonverbal behaviors, in predicting hedges by using Shapley values for feature explanation. We discover that the eye gaze of both the tutor and the tutee has a significant impact on hedge prediction. We further validate this observation through a follow-up ablation study. \n\n"
"In which venue was the paper titled ""Beyond Active Engagement: The Significance of Lurkers in a Polarized Twitter Debate"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: In which venue was the paper titled ""Beyond Active Engagement: The Significance of Lurkers in a Polarized Twitter Debate"" published?\nContext: Document 0: Faculty Name: fernando diaz\nMetadata:\nPaperid: c1b6e86b51df36f400a84c4fe8b1535c3f07f605\nTitle: Beyond Active Engagement: The Significance of Lurkers in a Polarized Twitter Debate\nYear: 2023\nAbstract: The emergence of new public forums in the shape of online social media has introduced unprecedented challenges to public discourse, including polarization, misinformation, and the emergence of echo chambers. While existing research has extensively studied the behavior of active users within echo chambers, little attention has been given to the hidden audience, also known as lurkers, who passively consume content without actively engaging. This study aims to estimate the share of the hidden audience and investigate their interplay with the echo chamber effect. Using Twitter as a case study, we analyze a polarized political debate to understand the engagement patterns and factors influencing the hidden audience's presence. Our findings reveal a relevant fraction of users that consume content without active interaction, which underscores the importance of considering their presence in online debates. \nDocument 1: Using Twitter as a case study, we analyze a polarized political debate to understand the engagement patterns and factors influencing the hidden audience's presence. Our findings reveal a relevant fraction of users that consume content without active interaction, which underscores the importance of considering their presence in online debates. Notably, our results indicate that the engagement of the hidden audience is primarily influenced by factors such as the reliability of media sources mentioned in tweets rather than the ideological stance of the user that produced the content. These findings highlight the need for a comprehensive understanding of the hidden audience's role in online debates and how they may influence public opinion.\nAuthors: Anees Baqir, Yijing Chen, Fernando Diaz-Diaz, Sercan Kiyak, Thomas Louf, Virginia Morini, Valentina Pansanella, M. Torricelli, Alessandro Galeazzi\nVenue: arXiv.org\nTldr: None \n\n"
"Who are the authors of the paper titled ""Population well-being and the COVID-19 vaccination program in Chile: evidence from Google Trends""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Who are the authors of the paper titled ""Population well-being and the COVID-19 vaccination program in Chile: evidence from Google Trends""?\nContext: Document 0: Faculty Name: fernando diaz\nMetadata:\nPaperid: cda03f3d8b1eff888174c0dc4262e1dc73be2d49\nTitle: Population well-being and the COVID-19 vaccination program in Chile: evidence from Google Trends\nYear: 2023\nAbstract: None\nAuthors: F. Díaz, Pablo A. Henríquez, Nicolás Hardy, D. Ponce\nVenue: Public Health\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is found that mental well-being responds positively to the percentage of inoculated people, and this phenomenon appears to be permanent and affected by socioeconomic status, with the wealthier population experiencing greater improvements than the less wealthy.'} \nDocument 1: List of 2023 Open Access papers by fernando diaz are:\nAmplification-free, highly sensitive electrochemical DNA-based sensor for simultaneous detection of stx1 and stx2 genes of Shiga toxin-producing E. coli (STEC)\nDiscordance Between Social Vulnerability and Cancer-Related Mortality in Border Counties - A Letter to the Editor Regarding “Local Social Vulnerability as a Predictor for Cancer-Related Mortality Among US Counties”\nCross-border utilization of cancer care by patients in the US and Mexico – a survey of Mexican oncologists\nFemales translate male mRNA transferred during mating\nTranscriptional Misexpression in Hybrids between Species Linked by Gene Flow Is Associated With Patterns of Sequence Divergence\nPopulation well-being and the COVID-19 vaccination program in Chile: evidence from Google Trends\nPre-vaccination CD56 dimCD16 +NK cell abundance and T h1/T h17 ratio predict responsiveness to conjugated pneumococcal vaccine in older adults\nBest-Case Retrieval Evaluation: Improving the Sensitivity of Reciprocal Rank with Lexicographic Precision\nFairness Through Domain Awareness: Mitigating Popularity Bias For Music Discovery\nOverview of the TREC 2021 Fair Ranking Track\nCost analysis of three-dimensional radiation \n\n"
"What year was the paper titled ""MRI Features for Predicting Microvascular Invasion and Postoperative Recurrence in Hepatocellular Carcinoma Without Peritumoral Hypointensity"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: What year was the paper titled ""MRI Features for Predicting Microvascular Invasion and Postoperative Recurrence in Hepatocellular Carcinoma Without Peritumoral Hypointensity"" published?\nContext: Document 0: Faculty Name: yang yiming\nMetadata:\nPaperid: f1a75a847c99ab399454c911235f0d5f7854c5a4\nTitle: MRI Features for Predicting Microvascular Invasion and Postoperative Recurrence in Hepatocellular Carcinoma Without Peritumoral Hypointensity\nYear: 2023\nAbstract: Purpose To identify MRI features of hepatocellular carcinoma (HCC) that predict microvascular invasion (MVI) and postoperative intrahepatic recurrence in patients without peritumoral hepatobiliary phase (HBP) hypointensity. Patients and Methods One hundred and thirty patients with HCC who underwent preoperative gadoxetate-enhanced MRI and curative hepatic resection were retrospectively reviewed. Two radiologists reviewed all preoperative MR images and assessed the radiological features of HCCs. The ability of peritumoral HBP hypointensity to identify MVI and intrahepatic recurrence was analyzed. We then assessed the MRI features of HCC that predicted the MVI and intrahepatic recurrence-free survival (RFS) in the subgroup without peritumoral HBP hypointensity. \nDocument 1: ratio and the risk of overall survival in advanced non-small cell lung cancer patients with anlotinib treatment: a retrospective cohort study\nAnalysis of Volatile Components in Dried Fruits and Branch Exudates of Schisandra chinensis with Different Fruit Colors Using GC-IMS Technology\nSecreted endogenous macrosomes reduce Aβ burden and ameliorate Alzheimer’s disease\nDIFUSCO: Graph-based Diffusion Solvers for Combinatorial Optimization\nBalancing Exploration and Exploitation in Hierarchical Reinforcement Learning via Latent Landmark Graphs\nAligning Large Multimodal Models with Factually Augmented RLHF\nAn Experimental Study on Secondary Transfer Performances of Prestress after Anchoring Failure of Steel Wire Strands\nMRI Features for Predicting Microvascular Invasion and Postoperative Recurrence in Hepatocellular Carcinoma Without Peritumoral Hypointensity\nImpact of local governments’ construction land allocation strategies on innovation-driven development of China\nSynergistic Interface Engineering of RuO2/Co3O4 Heterostructures for Enhanced Overall Water Splitting in Acidic Media\nNumerical Analysis on the Influence of Joint Density on the Stability of Complex Jointed Roadway Surrounding Rock\nExperimental Study on Secondary Anchorage Bond Performance \n\n"
"Who are the authors of the paper titled ""Towards Improving Harmonic Sensitivity and Prediction Stability for Singing Melody Extraction""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Who are the authors of the paper titled ""Towards Improving Harmonic Sensitivity and Prediction Stability for Singing Melody Extraction""?\nContext: Document 0: Faculty Name: berg kirkpatrick taylor\nMetadata:\nPaperid: 15b08595533bfc640f4dd470ca7a2273badec20a\nTitle: Towards Improving Harmonic Sensitivity and Prediction Stability for Singing Melody Extraction\nYear: 2023\nAbstract: In deep learning research, many melody extraction models rely on redesigning neural network architectures to improve performance. In this paper, we propose an input feature modification and a training objective modification based on two assumptions. First, harmonics in the spectrograms of audio data decay rapidly along the frequency axis. To enhance the model's sensitivity on the trailing harmonics, we modify the Combined Frequency and Periodicity (CFP) representation using discrete z-transform. Second, the vocal and non-vocal segments with extremely short duration are uncommon. To ensure a more stable melody contour, we design a differentiable loss function that prevents the model from predicting such segments. We apply these modifications to several models, including MSNet, FTANet, and a newly introduced model, PianoNet, modified from a piano transcription network. Our experimental results demonstrate that the proposed modifications are empirically effective for singing melody extraction. \nDocument 1: List of 2023 Open Access papers by berg kirkpatrick taylor are:\nSmaller Language Models are Better Black-box Machine-Generated Text Detectors\nTowards Improving Harmonic Sensitivity and Prediction Stability for Singing Melody Extraction\nJointly modeling products and resource pages for task-oriented recommendation\nMusicLDM: Enhancing Novelty in Text-to-Music Generation Using Beat-Synchronous Mixup Strategies\nUniversal Source Separation with Weakly Labelled Data\nCLIPSonic: Text-to-Audio Synthesis with Unlabeled Videos and Pretrained Language-Vision Models\nMembership Inference Attacks against Language Models via Neighbourhood Comparison\nContrastive Attention Networks for Attribution of Early Modern Print\nText Conditional Alt-Text Generation for Twitter Images\nExploring the Relationship Between Model Architecture and In-Context Learning Ability\nA Block Metropolis-Hastings Sampler for Controllable Energy-based Text Generation\nMisusing Tools in Large Language Models With Visual Adversarial Examples\nSimple Temporal Adaptation to Changing Label Sets: Hashtag Prediction via Dense KNN\nCuneiML: A Cuneiform Dataset for Machine Learning \n\n"
"Who are the authors of the paper titled ""It’s MBR All the Way Down: Modern Generation Techniques Through the Lens of Minimum Bayes Risk""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Who are the authors of the paper titled ""It’s MBR All the Way Down: Modern Generation Techniques Through the Lens of Minimum Bayes Risk""?\nContext: Document 0: List of 2023 Open Access papers by matt gormley are:\nIt’s MBR All the Way Down: Modern Generation Techniques Through the Lens of Minimum Bayes Risk\nUnlimiformer: Long-Range Transformers with Unlimited Length Input\nMDACE: MIMIC Documents Annotated with Code Evidence\nSummQA at MEDIQA-Chat 2023: In-Context Learning with GPT-4 for Medical Summarization \nDocument 1: Faculty Name: matt gormley\nMetadata:\nPaperid: d6ae4c0679bdceb029f652efd2a854ac5ade772f\nTitle: It’s MBR All the Way Down: Modern Generation Techniques Through the Lens of Minimum Bayes Risk\nYear: 2023\nAbstract: Minimum Bayes Risk (MBR) decoding is a method for choosing the outputs of a machine learning system based not on the output with the highest probability, but the output with the lowest risk (expected error) among multiple candidates. It is a simple but powerful method: for an additional cost at inference time, MBR provides reliable several-point improvements across metrics for a wide variety of tasks without any additional data or training. Despite this, MBR is not frequently applied in NLP works, and knowledge of the method itself is limited. We first provide an introduction to the method and the recent literature. We show that several recent methods that do not reference MBR can be written as special cases of MBR; this reformulation provides additional theoretical justification for the performance of these methods, explaining some results that were previously only empirical. \n\n"
"In which venue was the paper titled ""Effects of Coupling Constants on Chaos of Charged Particles in the Einstein–Æther Theory"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: In which venue was the paper titled ""Effects of Coupling Constants on Chaos of Charged Particles in the Einstein–Æther Theory"" published?\nContext: Document 0: Faculty Name: eric xing\nMetadata:\nPaperid: a3c4a5c18ef9bfffd9c8aac0dc2b75b8f18b9f7c\nTitle: Effects of Coupling Constants on Chaos of Charged Particles in the Einstein–Æther Theory\nYear: 2023\nAbstract: There are two free coupling parameters c13 and c14 in the Einstein–Æther metric describing a non-rotating black hole. This metric is the Reissner–Nordström black hole solution when 0≤2c13<c14<2, but it is not for 0≤c14<2c13<2. When the black hole is immersed in an external asymptotically uniform magnetic field, the Hamiltonian system describing the motion of charged particles around the black hole is not integrable; however, the Hamiltonian allows for the construction of explicit symplectic integrators. The proposed fourth-order explicit symplectic scheme is used to investigate the dynamics of charged particles because it exhibits excellent long-term performance in conserving the Hamiltonian. \nDocument 1: the next generation of GRB polarization detector\nMeasurement of Heavy Nulei beyond Iron in Cosmic Rays with the DAMPE Experiment\nRecent Advances in Decellularized Extracellular Matrix-Based Bioinks for 3D Bioprinting in Tissue Engineering\nEvaluation of thermal comfort in air-conditioned rooms based on structure/control-related parameters and data-mining method\nEffects of Coupling Constants on Chaos of Charged Particles in the Einstein–Æther Theory\nA PCA-based Method for Electron-Proton Discrimination of the DAMPE Experiment\nCosmic Ray Carbon and Oxygen Flux Measurements with the DAMPE Experiment\nErratum: New insight into the shape coexistence and shape evolution of \n<mml:math xmlns:mml=""http://www.w3.org/1998/Math/MathML""><mml:mmultiscripts><mml:mi>Yb</mml:mi><mml:mprescripts /><mml:none /><mml:mn>157</mml:mn></mml:mmultiscripts></mml:math>\n [Phys. Rev. \n\n"
"In which venue was the paper titled ""Enhancing student learning and achievement through orchestration of group processes and group composition"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: In which venue was the paper titled ""Enhancing student learning and achievement through orchestration of group processes and group composition"" published?\nContext: Document 0: Faculty Name: carolyn rosé\nMetadata:\nPaperid: 7ec990ab7362e8eac0c074830d44a58a1d89b4a6\nTitle: Enhancing student learning and achievement through orchestration of group processes and group composition\nYear: 2023\nAbstract: None\nAuthors: Carolyn P. Rosé, Sanna Järvelä\nVenue: International Journal of Computer-Supported Collaborative Learning\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This September issue of the International Journal of Computer-Supported Collaborative Learning reflects on the importance of productive collaborative processes, with an emphasis on feedback processes, and the scaffolding that upholds and promotes productive learning processes, whether it is explicit or implicit.'} \nDocument 1: List of 2023 Open Access papers by carolyn rosé are:\nEnhancing student learning and achievement through orchestration of group processes and group composition\nEditorial: Nine elements for robust collaborative learning analytics: A constructive collaborative critique\nHigh school students’ data modeling practices and processes: from modeling unstructured data to evaluating automated decisions\nLinguistic representations for fewer-shot relation extraction across domains\nUsing counterfactual contrast to improve compositional generalization for multi-step quantitative reasoning\nTowards Extracting and Understanding the Implicit Rubrics of Transformer Based Automatic Essay Scoring Models\nExploring Artificial Intelligence in English Language Arts with StoryQ\nSPEERLoom: An Open-Source Loom Kit for Interdisciplinary Engagement in Math, Engineering, and Textiles\nStudying Interdisciplinary Collaboration as a Core Skill \n\n"
"What year was the paper titled ""Cuttlefish: Low-Rank Model Training without All the Tuning"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: What year was the paper titled ""Cuttlefish: Low-Rank Model Training without All the Tuning"" published?\nContext: Document 0: Faculty Name: eric xing\nMetadata:\nPaperid: a06a4a38668c4737ab2ce80badc177ea3f520456\nTitle: Cuttlefish: Low-Rank Model Training without All the Tuning\nYear: 2023\nAbstract: Recent research has shown that training low-rank neural networks can effectively reduce the total number of trainable parameters without sacrificing predictive accuracy, resulting in end-to-end speedups. However, low-rank model training necessitates adjusting several additional factorization hyperparameters, such as the rank of the factorization at each layer. In this paper, we tackle this challenge by introducing Cuttlefish, an automated low-rank training approach that eliminates the need for tuning factorization hyperparameters. Cuttlefish leverages the observation that after a few epochs of full-rank training, the stable rank (i.e., an approximation of the true rank) of each layer stabilizes at a constant value. Cuttlefish switches from full-rank to low-rank training once the stable ranks of all layers have converged, setting the dimension of each factorization to its corresponding stable rank. \nDocument 1: Moreover, Cuttlefish outperforms state-of-the-art low-rank model training methods and other prominent baselines. The source code for our implementation can be found at: https://github.com/hwang595/Cuttlefish.\nAuthors: Hongyi Wang, Saurabh Agarwal, Pongsakorn U-chupala, Yoshiki Tanaka, Eric P. Xing, Dimitris Papailiopoulos\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper introduces Cuttlefish, an automated low-rank training approach that eliminates the need for tuning factorization hyperparameters, and generates models up to 5.6 times smaller than full-rank models, and attains up to a 1.2 times faster end-to-end training process while preserving comparable accuracy.'} \n\n"
"Who are the authors of the paper titled ""To Build Our Future, We Must Know Our Past: Contextualizing Paradigm Shifts in Natural Language Processing""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Who are the authors of the paper titled ""To Build Our Future, We Must Know Our Past: Contextualizing Paradigm Shifts in Natural Language Processing""?\nContext: Document 0: Faculty Name: emma strubell\nMetadata:\nPaperid: 1433b8d43d446fcc7f3e1370b22f744a4dd7c8e4\nTitle: To Build Our Future, We Must Know Our Past: Contextualizing Paradigm Shifts in Natural Language Processing\nYear: 2023\nAbstract: NLP is in a period of disruptive change that is impacting our methodologies, funding sources, and public perception. In this work, we seek to understand how to shape our future by better understanding our past. We study factors that shape NLP as a field, including culture, incentives, and infrastructure by conducting long-form interviews with 26 NLP researchers of varying seniority, research area, institution, and social identity. Our interviewees identify cyclical patterns in the field, as well as new shifts without historical parallel, including changes in benchmark culture and software infrastructure. We complement this discussion with quantitative analysis of citation, authorship, and language use in the ACL Anthology over time. We conclude by discussing shared visions, concerns, and hopes for the future of NLP. \nDocument 1: List of 2023 Open Access papers by emma strubell are:\nTo Build Our Future, We Must Know Our Past: Contextualizing Paradigm Shifts in Natural Language Processing\nUnderstanding the Effect of Model Compression on Social Bias in Large Language Models\nSurveying (Dis)Parities and Concerns of Compute Hungry NLP Research\nOn the Interactions of Structural Constraints and Data Resources for Structured Prediction\nEfficiency Pentathlon: A Standardized Arena for Efficiency Evaluation\nQueer People are People First: Deconstructing Sexual Identity Stereotypes in Large Language Models\nMaking Scalable Meta Learning Practical\nRegularizing Self-training for Unsupervised Domain Adaptation via Structural Constraints\nThe Framework Tax: Disparities Between Inference Efficiency in Research and Deployment\nData-efficient Active Learning for Structured Prediction with Partial Annotation and Self-Training \n\n"
"Can you provide the abstract of the paper titled ""491. Risk Factors for Severe Pediatric COVID-19: A Systematic Review""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Can you provide the abstract of the paper titled ""491. Risk Factors for Severe Pediatric COVID-19: A Systematic Review""?\nContext: Document 0: Faculty Name: bio\nMetadata:\nPaperid: 0b2db5968605bbce549f75928c1b5468782bc2ed\nTitle: 491. Risk Factors for Severe Pediatric COVID-19: A Systematic Review\nYear: 2023\nAbstract: Abstract Background Optimal management of COVID-19 in children requires risk stratification based on comorbidities and demographic factors that can predispose to severe disease. The Pediatric Infectious Diseases Society (PIDS) Pediatric COVID-19 Therapies Task Force, comprised of pediatric infectious diseases physicians, intensivists, and pharmacists from 29 US hospitals, develops clinical guidance for pediatric COVID-19 management. In support of these efforts, a systematic review of peer-reviewed literature was conducted to synthesize the evidence for risk factors for severe pediatric COVID-19. Methods Medline, EMBASE, and CDC databases were searched to identify all relevant publications before July 1, 2022. Titles and abstracts were reviewed to identify studies that assessed for potential predictors of severe COVID-19 disease in children < 21 years. \nDocument 1: List of 2023 Open Access papers by bio are:\n491. Risk Factors for Severe Pediatric COVID-19: A Systematic Review\nAntifungal stewardship in practice: Insights from a prospective audit and feedback program\n2945. Audit and Feedback Informed ASP Interventions Lead to Sustained Reductions in Suboptimal Antibiotic Prescribing at Hospital Discharge\nCharacterisation and Dynamics of an Emerging Seagrass Meadow\nNew Methodology for Intertidal Seaweed Biomass Estimation Using Multispectral Data Obtained with Unoccupied Aerial Vehicles\nApplication of a Multispectral UAS to Assess the Cover and Biomass of the Invasive Dune Species Carpobrotus edulis\nSea Level Rise Effects on the Sedimentary Dynamics of the Douro Estuary Sandspit (Portugal)\nDispensing of Antibiotics Without Prescription in Southern Benin, West Africa, 2018\nNonmedical Use of Prescription Psychotropic Drugs among Secondary School Students in Parakou, \n\n"
"In which venue was the paper titled ""Carbon Flux with DAMPE Using Machine Learning Methods"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: In which venue was the paper titled ""Carbon Flux with DAMPE Using Machine Learning Methods"" published?\nContext: Document 0: Faculty Name: lu jiang\nMetadata:\nPaperid: 3dc80cea6704a2bc1d714e3bbd502846f3498743\nTitle: Carbon Flux with DAMPE Using Machine Learning Methods\nYear: 2023\nAbstract: DAMPE space-borne cosmic ray experiment has been collecting data since December 2015. Many high-impact results on the ion, electron and photon fluxes were obtained. This submission presents the carbon flux analysis with DAMPE using machine learning techniques. The readout electronics would saturate at energy deposits above several TeV in a single BGO bar of the DAMPE calorimeter. The total energy loss per event due to saturation can sometimes reach over a hundred TeV. We present a convolutional neural network model which can accurately recover the energy lost due to saturation and thus significantly increase the dynamic range of DAMPE. Another machine learning model combines the resolution of the hodoscopic BGO calorimeter and the high-resolution tracker of DAMPE to provide the best possible prediction of the direction of the incoming particle. This allows measuring charges at energies up to several hundred TeV. In this work, we present the application of these methods to carbon flux analysis. \nDocument 1: Faculty Name: eric xing\nMetadata:\nPaperid: 3dc80cea6704a2bc1d714e3bbd502846f3498743\nTitle: Carbon Flux with DAMPE Using Machine Learning Methods\nYear: 2023\nAbstract: DAMPE space-borne cosmic ray experiment has been collecting data since December 2015. Many high-impact results on the ion, electron and photon fluxes were obtained. This submission presents the carbon flux analysis with DAMPE using machine learning techniques. The readout electronics would saturate at energy deposits above several TeV in a single BGO bar of the DAMPE calorimeter. The total energy loss per event due to saturation can sometimes reach over a hundred TeV. We present a convolutional neural network model which can accurately recover the energy lost due to saturation and thus significantly increase the dynamic range of DAMPE. Another machine learning model combines the resolution of the hodoscopic BGO calorimeter and the high-resolution tracker of DAMPE to provide the best possible prediction of the direction of the incoming particle. This allows measuring charges at energies up to several hundred TeV. \n\n"
"What year was the paper titled ""BAC Transgenic Expression of Human TREM2-R47H Remodels Amyloid Plaques but Unable to Reprogram Plaque-associated Microglial Reactivity in 5xFAD Mice"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: What year was the paper titled ""BAC Transgenic Expression of Human TREM2-R47H Remodels Amyloid Plaques but Unable to Reprogram Plaque-associated Microglial Reactivity in 5xFAD Mice"" published?\nContext: Document 0: Faculty Name: lu jiang\nMetadata:\nPaperid: e28b314bed6b71eb8f112b866ac77dbcb182bf0b\nTitle: BAC Transgenic Expression of Human TREM2-R47H Remodels Amyloid Plaques but Unable to Reprogram Plaque-associated Microglial Reactivity in 5xFAD Mice\nYear: 2023\nAbstract: Background Genetic study of late-onset Alzheimer’s disease (AD) reveals that a rare Arginine-to-Histamine mutation at amino acid residue 47 (R47H) in Triggering Receptor Expressed on Myeloid Cells 2 (TREM2) results in increased disease risk. TREM2 plays critical roles in regulating microglial response to amyloid plaques in AD, leading to their clustering and activation surrounding the plaques. We previously showed that increasing human TREM2 gene dosage exerts neuroprotective effects against AD-related deficits in amyloid depositing mouse models of AD. However, the in vivo effects of the R47H mutation on human TREM2-mediated microglial reprogramming and neuroprotection remains poorly understood. \nDocument 1: Rays with the DAMPE Experiment\nCosmic Ray Carbon and Oxygen Flux Measurements with the DAMPE Experiment\nStudy of hadronic cross-sections with cosmic ray Carbon from GeV to TeV by the DAMPE experiment\nLatest results on searching for fractionally charged particles with the DAMPE experiment\nAnalysis of cosmic lithium, beryllium and boron with the DAMPE mission\nMedian mandibular flexure—the unique physiological phenomenon of the mandible and its clinical significance in implant restoration\nBAC Transgenic Expression of Human TREM2-R47H Remodels Amyloid Plaques but Unable to Reprogram Plaque-associated Microglial Reactivity in 5xFAD Mice\nTMEM241 is a UDP-N-acetylglucosamine transporter required for M6P modification of NPC2 and cholesterol transport\nReduced electron relaxation time of perovskite films via g-C3N4 quantum dot doping for high-performance perovskite solar cells\nHow to drive corporate responsible innovation? \n\n"
"What year was the paper titled ""Ruffle&Riley: Towards the Automated Induction of Conversational Tutoring Systems"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: What year was the paper titled ""Ruffle&Riley: Towards the Automated Induction of Conversational Tutoring Systems"" published?\nContext: Document 0: Faculty Name: tom mitchell\nMetadata:\nPaperid: 5b7dcf469c285381a83b1bfd85d2b22da121e0cc\nTitle: Ruffle&Riley: Towards the Automated Induction of Conversational Tutoring Systems\nYear: 2023\nAbstract: Conversational tutoring systems (CTSs) offer learning experiences driven by natural language interaction. They are known to promote high levels of cognitive engagement and benefit learning outcomes, particularly in reasoning tasks. Nonetheless, the time and cost required to author CTS content is a major obstacle to widespread adoption. In this paper, we introduce a novel type of CTS that leverages the recent advances in large language models (LLMs) in two ways: First, the system induces a tutoring script automatically from a lesson text. Second, the system automates the script orchestration via two LLM-based agents (Ruffle&Riley) with the roles of a student and a professor in a learning-by-teaching format. The system allows a free-form conversation that follows the ITS-typical inner and outer loop structure. \nDocument 1: List of 2023 Open Access papers by tom mitchell are:\nPlan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents\nThe Roles of Symbols in Neural-based AI: They are Not What You Think!\nThe Internal State of an LLM Knows When its Lying\nNeuropilin-1 interacts with VE-cadherin and TGFBR2 to stabilize adherens junctions and prevent activation of endothelium under flow\nThe unconventional Myosin-1C augments endothelial secretion of von Willebrand factor by linking contractile actomyosin machinery to the plasma membrane\nRuffle&Riley: Towards the Automated Induction of Conversational Tutoring Systems\nSynthetic biology open language (SBOL) version 3.1.0\nRead and Reap the Rewards: Learning to Play Atari with the Help of Instruction Manuals\nLearning to Give Useful Hints: Assistance Action Evaluation and Policy Improvements\nGenitourinary Management and Follow-Up for Patients with Stevens-Johnson Syndrome/Toxic Epidermal Necrolysis\nFumarate induces vesicular release of mtDNA to drive innate immunity\nFLAIRR-Seq: A Method for Single-Molecule Resolution of Near Full-Length Antibody H Chain Repertoires. \n\n"
"What year was the paper titled ""Chinese EFL learners different from English natives in cataphora resolution: Evidence from eye-tracking studies"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: What year was the paper titled ""Chinese EFL learners different from English natives in cataphora resolution: Evidence from eye-tracking studies"" published?\nContext: Document 0: Faculty Name: yang yiming\nMetadata:\nPaperid: 915fef14d53ac91df037f7749e922d7ce568d91f\nTitle: Chinese EFL learners different from English natives in cataphora resolution: Evidence from eye-tracking studies\nYear: 2023\nAbstract: Previous studies on English natives have shown that encountering an English cataphoric pronoun triggers an active search for its antecedent and this searching process is modulated by syntactic constraints. It remains unknown whether the conclusion is universal to EFL (English as a Foreign Language) learners, particularly those with distinct L1 like Chinese in linguistic typology. Therefore, this study used two eye-tracking experiments to investigate how Chinese EFL learners resolve English cataphora. The experiments adopted the gender-mismatch paradigm. Experiment 1 investigated whether Chinese EFL learners with different proficiency would adopt the similar processing pattern to English natives and found that gender congruency elicited longer reading times than gender incongruency between the first potential antecedent and the cataphoric pronoun, the effect early observed in high-proficiency relative to low-proficiency learners. \nDocument 1: Experiment 2 explored whether the cataphora resolution process was modulated by Binding Principle B and revealed that longer first fixation durations and first pass reading times were observed in gender-mismatch than in gender-match conditions no matter the antecedents are binding-accessible or not while longer regression path durations occurred in gender-mismatch than in gender-match conditions only as the antecedents are binding-accessible. Taken together, these results indicate that Chinese EFL learners also adopt an active search mechanism to resolve cataphoric pronouns, yet along a processing path distinct from English natives’. Specifically, Chinese EFL learners predictively link a cataphoric pronoun to the first potential antecedent in the sentence but only a gender-matching antecedent can prompt them to engage in deep processing of the antecedent. Moreover, the processing time varies with the learners’ English proficiency. \n\n"
"Who are the authors of the paper titled ""Amortizing Pragmatic Program Synthesis with Rankings""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Who are the authors of the paper titled ""Amortizing Pragmatic Program Synthesis with Rankings""?\nContext: Document 0: Faculty Name: daniel fried\nMetadata:\nPaperid: 5016766c87982f5c62ef6580e120939ab155d776\nTitle: Amortizing Pragmatic Program Synthesis with Rankings\nYear: 2023\nAbstract: In program synthesis, an intelligent system takes in a set of user-generated examples and returns a program that is logically consistent with these examples. The usage of Rational Speech Acts (RSA) framework has been successful in building \emph{pragmatic} program synthesizers that return programs which -- in addition to being logically consistent -- account for the fact that a user chooses their examples informatively. However, the computational burden of running the RSA algorithm has restricted the application of pragmatic program synthesis to domains with a small number of possible programs. This work presents a novel method of amortizing the RSA algorithm by leveraging a \emph{global pragmatic ranking} -- a single, total ordering of all the hypotheses. We prove that for a pragmatic synthesizer that uses a single demonstration, our global ranking method exactly replicates RSA's ranked responses. We further empirically show that global rankings effectively approximate the full pragmatic synthesizer in an online, multi-demonstration setting. \nDocument 1: We prove that for a pragmatic synthesizer that uses a single demonstration, our global ranking method exactly replicates RSA's ranked responses. We further empirically show that global rankings effectively approximate the full pragmatic synthesizer in an online, multi-demonstration setting. Experiments on two program synthesis domains using our pragmatic ranking method resulted in orders of magnitudes of speed ups compared to the RSA synthesizer, while outperforming the standard, non-pragmatic synthesizer.\nAuthors: Yewen Pu, Saujas Vaduguru, Priyan Vaithilingam, Elena L. Glassman, Daniel Fried\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': ""This work presents a novel method of amortizing the RSA algorithm by leveraging a single, total ordering of all the hypotheses, and proves that for a pragmatic synthesizer that uses a single demonstration, the global ranking method exactly replicates RSA's ranked responses.""} \n\n"
"Who is the faculty member associated with the paper titled ""Enhancing the Generalization for Text Classification through Fusion of Backward Features""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Who is the faculty member associated with the paper titled ""Enhancing the Generalization for Text Classification through Fusion of Backward Features""?\nContext: Document 0: Faculty Name: eric xing\nMetadata:\nPaperid: d2c03c788ad3fbd6d783cbbc4393c31b1a260691\nTitle: Enhancing the Generalization for Text Classification through Fusion of Backward Features\nYear: 2023\nAbstract: Generalization has always been a keyword in deep learning. Pretrained models and domain adaptation technology have received widespread attention in solving the problem of generalization. They are all focused on finding features in data to improve the generalization ability and to prevent overfitting. Although they have achieved good results in various tasks, those models are unstable when classifying a sentence whose label is positive but still contains negative phrases. In this article, we analyzed the attention heat map of the benchmarks and found that previous models pay more attention to the phrase rather than to the semantic information of the whole sentence. Moreover, we proposed a method to scatter the attention away from opposite sentiment words to avoid a one-sided judgment. We designed a two-stream network and stacked the gradient reversal layer and feature projection layer within the auxiliary network. \nDocument 1: Metasurface Deflector Enhanced Grating Coupler for Perfectly Vertical Coupling\nForest Fire Smoke Detection Research Based on the Random Forest Algorithm and Sub-Pixel Mapping Method\nA Magnetically Controlled Guidewire Robot System with Steering and Propulsion Capabilities for Vascular Interventional Surgery\nMeasurement of the p+He energy spectrum with the DAMPE space mission\nStudy of hadronic cross-sections with cosmic ray Carbon from GeV to TeV by the DAMPE experiment\nLatest results on searching for fractionally charged particles with the DAMPE experiment\nEnhancing the Generalization for Text Classification through Fusion of Backward Features\nEvaluation of hydraulic fracturing of horizontal wells in tight reservoirs based on the deep neural network with physical constraints\nExploring Fundamental Particle Acceleration and Loss Processes in Heliophysics through an Orbiting X-ray Instrument in the Jovian System\nForest Cover Change Monitoring Using Sub-Pixel Mapping with Edge-Matching Correction\nAnalysis of cosmic lithium, beryllium and boron with the DAMPE mission\nEnergy-dependent polarization of Gamma-Ray Bursts' prompt emission with the POLAR and POLAR-2 instruments \n\n"
"Can you provide the abstract of the paper titled ""Genitourinary Management and Follow-Up for Patients with Stevens-Johnson Syndrome/Toxic Epidermal Necrolysis""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Can you provide the abstract of the paper titled ""Genitourinary Management and Follow-Up for Patients with Stevens-Johnson Syndrome/Toxic Epidermal Necrolysis""?\nContext: Document 0: Faculty Name: tom mitchell\nMetadata:\nPaperid: e98e4af918f3ad0f6ea65f2c68e2846a5b7eb333\nTitle: Genitourinary Management and Follow-Up for Patients with Stevens-Johnson Syndrome/Toxic Epidermal Necrolysis\nYear: 2023\nAbstract: None\nAuthors: Gina T. Baaklini, Tom Michael Mitchell, Jordan Davis, Kevin McGovern, J. Aden, L. Cancio\nVenue: Burns Open\nTldr: None \nDocument 1: List of 2023 Open Access papers by tom mitchell are:\nPlan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents\nThe Roles of Symbols in Neural-based AI: They are Not What You Think!\nThe Internal State of an LLM Knows When its Lying\nNeuropilin-1 interacts with VE-cadherin and TGFBR2 to stabilize adherens junctions and prevent activation of endothelium under flow\nThe unconventional Myosin-1C augments endothelial secretion of von Willebrand factor by linking contractile actomyosin machinery to the plasma membrane\nRuffle&Riley: Towards the Automated Induction of Conversational Tutoring Systems\nSynthetic biology open language (SBOL) version 3.1.0\nRead and Reap the Rewards: Learning to Play Atari with the Help of Instruction Manuals\nLearning to Give Useful Hints: Assistance Action Evaluation and Policy Improvements\nGenitourinary Management and Follow-Up for Patients with Stevens-Johnson Syndrome/Toxic Epidermal Necrolysis\nFumarate induces vesicular release of mtDNA to drive innate immunity\nFLAIRR-Seq: A Method for Single-Molecule Resolution of Near Full-Length Antibody H Chain Repertoires. \n\n"
"Who are the authors of the paper titled ""SigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Who are the authors of the paper titled ""SigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing""?\nContext: Document 0: Faculty Name: david mortensen\nMetadata:\nPaperid: 659be1ff350634f50cc066d258ee6a45e697e552\nTitle: SigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing\nYear: 2023\nAbstract: In our submission to the SIGMORPHON 2023 Shared Task on interlinear glossing (IGT), we explore approaches to data augmentation and modeling across seven low-resource languages. For data augmentation, we explore two approaches: creating artificial data from the provided training data and utilizing existing IGT resources in other languages. On the modeling side, we test an enhanced version of the provided token classification baseline as well as a pretrained multilingual seq2seq model. Additionally, we apply post-correction using a dictionary for Gitksan, the language with the smallest amount of data. We find that our token classification models are the best performing, with the highest word-level accuracy for Arapaho and highest morpheme-level accuracy for Gitksan out of all submissions. We also show that data augmentation is an effective strategy, though applying artificial data pretraining has very different effects across both models tested. \nDocument 1: Faculty Name: lori levin\nMetadata:\nPaperid: 659be1ff350634f50cc066d258ee6a45e697e552\nTitle: SigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing\nYear: 2023\nAbstract: In our submission to the SIGMORPHON 2023 Shared Task on interlinear glossing (IGT), we explore approaches to data augmentation and modeling across seven low-resource languages. For data augmentation, we explore two approaches: creating artificial data from the provided training data and utilizing existing IGT resources in other languages. On the modeling side, we test an enhanced version of the provided token classification baseline as well as a pretrained multilingual seq2seq model. Additionally, we apply post-correction using a dictionary for Gitksan, the language with the smallest amount of data. We find that our token classification models are the best performing, with the highest word-level accuracy for Arapaho and highest morpheme-level accuracy for Gitksan out of all submissions. We also show that data augmentation is an effective strategy, though applying artificial data pretraining has very different effects across both models tested. \n\n"
"What year was the paper titled ""Expression of ALCAM in Clinical Colon Cancer and Relationship With Patients’ Treatment Responses"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: What year was the paper titled ""Expression of ALCAM in Clinical Colon Cancer and Relationship With Patients’ Treatment Responses"" published?\nContext: Document 0: Faculty Name: yang yiming\nMetadata:\nPaperid: 3040fcdfec29d63f9c25663ac1d58a8b5fec34db\nTitle: Expression of ALCAM in Clinical Colon Cancer and Relationship With Patients’ Treatment Responses\nYear: 2023\nAbstract: Background/Aim: Activated leukocyte cell adhesion molecule (ALCAM) plays an important role in cancer via its homotypical and heterotypical interactions with ALCAM or other proteins and can also mediate cell-cell interactions. The present study investigated the expression of ALCAM in relation to epithelial–to–mesenchymal transition (EMT) markers and its downstream signal proteins including Ezrin-Moesin-Radixin (ERM), in clinical colon cancer and in the progression of the disease. Materials and Methods: Expression of ALCAM was determined in a clinical colon cancer cohort and assessed against the clinical pathological factors and outcome, together with the expression patterns of the ERM family and EMT markers. ALCAM protein was detected using immunohistochemistry. Cell line models, with ALCAM knock-down and over-expression, were established and used to test cells’ responses to drugs. \nDocument 1: List of 2023 Open Access papers by yang yiming are:\nFunctional targeted therapy for glioma based on platelet membrane-coated nanogels\nDual Responsive Magnetic Drug Delivery Nanomicelles with Tumor Targeting for Enhanced Cancer Chemo/Magnetothermal Synergistic Therapy\nExpression of ALCAM in Clinical Colon Cancer and Relationship With Patients’ Treatment Responses\nClaudin-10 in the Blood Brain Barrier Function of Cerebral Endothelial Cells and Transendothelial Invasion of Breast Cancer Cells\nAccelerating Diffusion-based Combinatorial Optimization Solvers by Progressive Distillation\nAutomatic synchrotron tomographic alignment schemes based on genetic algorithms and human-in-the-loop software\nHigh CD8+tumor-infiltrating lymphocytes indicate severe exhaustion and poor prognosis in angioimmunoblastic T-cell lymphoma\nNumerical Investigation of Fatigue Crack Propagation Behaviour of 550E High-Performance Steel\nAssociation between albumin-to-globulin ratio and the risk of overall survival in advanced non-small cell lung cancer patients with anlotinib treatment: a retrospective cohort study\nAnalysis of Volatile Components in Dried Fruits and Branch Exudates of Schisandra chinensis with Different Fruit Colors Using GC-IMS Technology\nSecreted \n\n"
"Who is the faculty member associated with the paper titled ""Evaluating Multilingual Speech Translation under Realistic Conditions with Resegmentation and Terminology""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Who is the faculty member associated with the paper titled ""Evaluating Multilingual Speech Translation under Realistic Conditions with Resegmentation and Terminology""?\nContext: Document 0: Faculty Name: mona diab\nMetadata:\nPaperid: c5849f406e8263806a84e1a407ec0e0fe131bd5c\nTitle: Evaluating Multilingual Speech Translation under Realistic Conditions with Resegmentation and Terminology\nYear: 2023\nAbstract: We present the ACL 60/60 evaluation sets for multilingual translation of ACL 2022 technical presentations into 10 target languages. This dataset enables further research into multilingual speech translation under realistic recording conditions with unsegmented audio and domain-specific terminology, applying NLP tools to text and speech in the technical domain, and evaluating and improving model robustness to diverse speaker demographics.\nAuthors: Elizabeth Salesky, Kareem Darwish, Mohamed Al-Badrashiny, Mona T. Diab, J. Niehues\nVenue: International Workshop on Spoken Language Translation\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This dataset enables further research into multilingual speech translation under realistic recording conditions with unsegmented audio and domain-specific terminology, applying NLP tools to text and speech in the technical domain, and evaluating and improving model robustness to diverse speaker demographics.'} \nDocument 1: Faculty Name: alexander waibel\nMetadata:\nPaperid: 610d9958390ab83515d0d81e19f8e5264faf8e9b\nTitle: KIT’s Multilingual Speech Translation System for IWSLT 2023\nYear: 2023\nAbstract: Many existing speech translation benchmarks focus on native-English speech in high-quality recording conditions, which often do not match the conditions in real-life use-cases. In this paper, we describe our speech translation system for the multilingual track of IWSLT 2023, which focuses on the translation of scientific conference talks. The test condition features accented input speech and terminology-dense contents. The tasks requires translation into 10 languages of varying amounts of resources. In absence of training data from the target domain, we use a retrieval-based approach (kNN-MT) for effective adaptation (+0.8 BLEU for speech translation). We also use adapters to easily integrate incremental training data from data augmentation, and show that it matches the performance of re-training. We observe that cascaded systems are more easily adaptable towards specific target domains, due to their separate modules. \n\n"
"Can you provide the abstract of the paper titled ""The response linearity of energy measurement up to TeV in the DAMPE experiment""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Can you provide the abstract of the paper titled ""The response linearity of energy measurement up to TeV in the DAMPE experiment""?\nContext: Document 0: Faculty Name: lu jiang\nMetadata:\nPaperid: 53a8712c48ddcd2bf1af30f9235f42b372f66980\nTitle: The response linearity of energy measurement up to TeV in the DAMPE experiment\nYear: 2023\nAbstract: The DArk Matter Particle Explorer (DAMPE) space mission is designed to measure cosmic rays and gamma rays. The key sub-detector of DAMPE is the Bismuth Germanium Oxide (BGO) Electromagnetic CALorimeter (ECAL), which measures the energies of electrons/gamma-rays ranging from 5 GeV - 10 TeV. A laser test carried out to study the response of the BGO ECAL to up to ∼ TeV energy deposition revealed that the BGO ﬂuorescence response retains linearity at laser energy deposition densities higher than that induced by a ∼ 10 TeV electromagnetic shower. The energy measurements obtained from on-orbit data were also compared with Monte Carlo simulation results. The present study conﬁrms that there is no ﬂuorescence quenching eﬀect in the DAMPE BGO ECAL. \nDocument 1: Faculty Name: eric xing\nMetadata:\nPaperid: 53a8712c48ddcd2bf1af30f9235f42b372f66980\nTitle: The response linearity of energy measurement up to TeV in the DAMPE experiment\nYear: 2023\nAbstract: The DArk Matter Particle Explorer (DAMPE) space mission is designed to measure cosmic rays and gamma rays. The key sub-detector of DAMPE is the Bismuth Germanium Oxide (BGO) Electromagnetic CALorimeter (ECAL), which measures the energies of electrons/gamma-rays ranging from 5 GeV - 10 TeV. A laser test carried out to study the response of the BGO ECAL to up to ∼ TeV energy deposition revealed that the BGO ﬂuorescence response retains linearity at laser energy deposition densities higher than that induced by a ∼ 10 TeV electromagnetic shower. The energy measurements obtained from on-orbit data were also compared with Monte Carlo simulation results. The present study conﬁrms that there is no ﬂuorescence quenching eﬀect in the DAMPE BGO ECAL. \n\n"
"Who is the faculty member associated with the paper titled ""AutoReply: Detecting Nonsense in Dialogue with Discriminative Replies""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Who is the faculty member associated with the paper titled ""AutoReply: Detecting Nonsense in Dialogue with Discriminative Replies""?\nContext: Document 0: Faculty Name: daniel fried\nMetadata:\nPaperid: f983cf75e368dcd07dd3a762721c095678514e56\nTitle: AutoReply: Detecting Nonsense in Dialogue with Discriminative Replies\nYear: 2023\nAbstract: None\nAuthors: Weiyan Shi, Emily Dinan, Adi Renduchintala, Daniel Fried, Athul Paul Jacob, Zhou Yu, Mike Lewis\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: None \nDocument 1: AutoReply: Detecting Nonsense in Dialogue with Discriminative Replies\nPragmatic Inference with a CLIP Listener for Contrastive Captioning\nSantaCoder: don't reach for the stars!\nGrounding Language Models to Images for Multimodal Generation\nStarCoder: may the source be with you!\nGenerating Images with Multimodal Language Models\nWebArena: A Realistic Web Environment for Building Autonomous Agents\nAmortizing Pragmatic Program Synthesis with Rankings \n\n"
"Can you provide the abstract of the paper titled ""Memory-adaptive Depth-wise Heterogenous Federated Learning""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Can you provide the abstract of the paper titled ""Memory-adaptive Depth-wise Heterogenous Federated Learning""?\nContext: Document 0: Faculty Name: eric xing\nMetadata:\nPaperid: fdf9f4c09451e847e0bd1b251621ca56e0eb491b\nTitle: Memory-adaptive Depth-wise Heterogenous Federated Learning\nYear: 2023\nAbstract: Federated learning is a promising paradigm that allows multiple clients to collaboratively train a model without sharing the local data. However, the presence of heterogeneous devices in federated learning, such as mobile phones and IoT devices with varying memory capabilities, would limit the scale and hence the performance of the model could be trained. The mainstream approaches to address memory limitations focus on width-slimming techniques, where different clients train subnetworks with reduced widths locally and then the server aggregates the subnetworks. The global model produced from these methods suffers from performance degradation due to the negative impact of the actions taken to handle the varying subnetwork widths in the aggregation phase. In this paper, we introduce a memory-adaptive depth-wise learning solution in FL called FeDepth, which adaptively decomposes the full model into blocks according to the memory budgets of each client and trains blocks sequentially to obtain a full inference model. \nDocument 1: In this paper, we introduce a memory-adaptive depth-wise learning solution in FL called FeDepth, which adaptively decomposes the full model into blocks according to the memory budgets of each client and trains blocks sequentially to obtain a full inference model. Our method outperforms state-of-the-art approaches, achieving 5% and more than 10% improvements in top-1 accuracy on CIFAR-10 and CIFAR-100, respectively. We also demonstrate the effectiveness of depth-wise fine-tuning on ViT. Our findings highlight the importance of memory-aware techniques for federated learning with heterogeneous devices and the success of depth-wise training strategy in improving the global model's performance.\nAuthors: Kai Zhang, Yutong Dai, Hongyi Wang, Eric P. Xing, Xun Chen, Lichao Sun\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A memory-adaptive depth-wise learning solution in FL called FeDepth, which adaptively decomposes the full model into blocks according to the memory budgets of each client and trains blocks sequentially to obtain a full inference model, which outperforms state-of-the-art approaches.'} \n\n"
"Who are the authors of the paper titled ""Analysis of the transparent surface layer formed at the surfaces of arrested enamel caries lesions with tomographic imaging methods""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Who are the authors of the paper titled ""Analysis of the transparent surface layer formed at the surfaces of arrested enamel caries lesions with tomographic imaging methods""?\nContext: Document 0: Faculty Name: daniel fried\nMetadata:\nPaperid: 0524230fb6da632043c714523b409431dc08edc9\nTitle: Analysis of the transparent surface layer formed at the surfaces of arrested enamel caries lesions with tomographic imaging methods\nYear: 2023\nAbstract: None\nAuthors: Nai-Yuan N. Chang, Morgan Ng, Tina Dillas, Yi-Ching Ho, Yihua Zhu, D. Fried\nVenue: JADA Foundational Science\nTldr: None \nDocument 1: List of 2023 Open Access papers by daniel fried are:\nAnalysis of the transparent surface layer formed at the surfaces of arrested enamel caries lesions with tomographic imaging methods\nExploratory Analysis of Objective Outcome Measures for the Clinical Assessment of Erosive Tooth Wear\nAssessment of the activity of secondary caries lesions with short-wavelength infrared, thermal, and optical coherence tomographic imaging\nMonitoring lesion activity on primary teeth with CP‐OCT and SWIR reflectance imaging\nActive Surveillance of Root Caries in Vivo with CP-OCT\nTime‐resolved SWIR imaging for the assessment of the activity of occlusal caries lesions\nDiagnostic Performance of Multispectral SWIR Transillumination and Reflectance Imaging for Caries Detection\nLongitudinal assessment of dental erosion-abrasion by cross-polarization optical coherence tomography in vitro.\nAutoReply: Detecting Nonsense in Dialogue with Discriminative Replies\nPragmatic Inference with a CLIP Listener for Contrastive Captioning\nSantaCoder: don't reach for the stars!\nGrounding Language Models to Images for Multimodal Generation\nStarCoder: may the source be with you! \n\n"
"Who is the faculty member associated with the paper titled ""Exploring Speech Recognition, Translation, and Understanding with Discrete Speech Units: A Comparative Study""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Who is the faculty member associated with the paper titled ""Exploring Speech Recognition, Translation, and Understanding with Discrete Speech Units: A Comparative Study""?\nContext: Document 0: Faculty Name: shinji watanabe\nMetadata:\nPaperid: bb4c59fc93d5be6b3d85dfde9d08e3dab80db9b7\nTitle: Exploring Speech Recognition, Translation, and Understanding with Discrete Speech Units: A Comparative Study\nYear: 2023\nAbstract: Speech signals, typically sampled at rates in the tens of thousands per second, contain redundancies, evoking inefficiencies in sequence modeling. High-dimensional speech features such as spectrograms are often used as the input for the subsequent model. However, they can still be redundant. Recent investigations proposed the use of discrete speech units derived from self-supervised learning representations, which significantly compresses the size of speech data. Applying various methods, such as de-duplication and subword modeling, can further compress the speech sequence length. Hence, training time is significantly reduced while retaining notable performance. In this study, we undertake a comprehensive and systematic exploration into the application of discrete units within end-to-end speech processing models. \nDocument 1: February to March 2023\nExploring Speech Recognition, Translation, and Understanding with Discrete Speech Units: A Comparative Study\nJoint Modelling of Spoken Language Understanding Tasks with Integrated Dialog History\nEnhancing End-to-End Conversational Speech Translation Through Target Language Context Utilization\nChallenges of Corporate Alliance CLOMA toward Plastic Litter\nThe Multimodal Information Based Speech Processing (MISP) 2023 Challenge: Audio-Visual Target Speaker Extraction\nReproducing Whisper-Style Training Using An Open-Source Toolkit And Publicly Available Data\nThe CHiME-7 DASR Challenge: Distant Meeting Transcription with Multiple Devices in Diverse Scenarios\nCross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing\nESPnet-ST-v2: Multipurpose Spoken Language Translation Toolkit\nMulti-Channel Target Speaker Extraction with Refinement: The WavLab Submission to the Second Clarity Enhancement Challenge\nFully Unsupervised Topic Clustering of Unlabelled Spoken Audio Using Self-Supervised Representation Learning and Topic Model\nTAPLoss: A Temporal Acoustic Parameter Loss for Speech Enhancement\nEnd-to-End Speech Recognition: A Survey\nThe Multimodal Information Based Speech Processing (Misp) \n\n"
"What year was the paper titled ""Zero-Shot and Few-Shot Stance Detection on Varied Topics via Conditional Generation"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: What year was the paper titled ""Zero-Shot and Few-Shot Stance Detection on Varied Topics via Conditional Generation"" published?\nContext: Document 0: Faculty Name: alexander hauptmann\nMetadata:\nPaperid: 2107b867cb8f8afa30a9a940288d7c8b657f8aa5\nTitle: Zero-Shot and Few-Shot Stance Detection on Varied Topics via Conditional Generation\nYear: 2023\nAbstract: Zero-shot and few-shot stance detection identify the polarity of text with regard to a certain target when we have only limited or no training resources for the target. Previous work generally formulates the problem into a classification setting, ignoring the potential use of label text. In this paper, we instead utilize a conditional generation framework and formulate the problem as denoising from partially-filled templates, which can better utilize the semantics among input, label, and target texts. We further propose to jointly train an auxiliary task, target prediction, and to incorporate manually constructed incorrect samples with unlikelihood training to improve the representations for both target and label texts. We also verify the effectiveness of target-related Wikipedia knowledge with the generation framework. Experiments show that our proposed method significantly outperforms several strong baselines on VAST, and achieves new state-of-the-art performance. \nDocument 1: List of 2023 Open Access papers by alexander hauptmann are:\nTowards Open-Domain Twitter User Profile Inference\nZero-Shot and Few-Shot Stance Detection on Varied Topics via Conditional Generation\nSPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs\nSTMT: A Spatial-Temporal Mesh Transformer for MoCap-Based Action Recognition\nDocumentNet: Bridging the Data Gap in Document Pre-training\nLanguage Model Beats Diffusion - Tokenizer is Key to Visual Generation\nHyperbolic vs Euclidean Embeddings in Few-Shot Learning: Two Sides of the Same Coin \n\n"
"Who are the authors of the paper titled ""Hence, Socrates is mortal: A Benchmark for Natural Language Syllogistic Reasoning""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Who are the authors of the paper titled ""Hence, Socrates is mortal: A Benchmark for Natural Language Syllogistic Reasoning""?\nContext: Document 0: Faculty Name: lei li\nMetadata:\nPaperid: 56de9c4c63ee74757be1b203d2ea852690087ded\nTitle: Hence, Socrates is mortal: A Benchmark for Natural Language Syllogistic Reasoning\nYear: 2023\nAbstract: Syllogistic reasoning, a typical form of deductive reasoning, is a critical capability widely required in natural language understanding tasks, such as text entailment and question answering. To better facilitate research on syllogis-tic reasoning, we develop a benchmark called S YLLO B ASE that differs from existing syllo-gistic datasets in three aspects: (1) Covering a complete taxonomy of syllogism reasoning patterns; (2) Containing both automatically and manually constructed samples; and (3) Involving both the generation and understanding tasks. We automatically construct 50k template-based syllogism samples by mining syllogism patterns from Wikidata and ConceptNet. To improve our dataset’s naturalness and challenge, we apply GPT-3 to paraphrase the template-based data and further manually rewrite 1,000 samples as the test set. \nDocument 1: Socrates is mortal: A Benchmark for Natural Language Syllogistic Reasoning\nProvable Robust Watermarking for AI-Generated Text\nMCM6 is a Poor Prognostic Biomarker and Promotes Progression in Breast Cancer.\np53 deacetylation alleviates calcium oxalate deposition-induced renal fibrosis by inhibiting ferroptosis.\nGut microbiota in patients with kidney stones: a systematic review and meta-analysis\nEffect of instant surgery compared with traditional management on paediatric complicated acute appendicitis post‐surgery wound: A meta‐analysis\nProtecting Language Generation Models via Invisible Watermarking\nComprehensive Analysis of Cuproptosis Genes and Identification of Cuproptosis Subtypes in Breast Cancer\nLong-tailed Extreme Multi-label Text Classification by the Retrieval of Generated Pseudo Label Descriptions \n\n"
"Who is the faculty member associated with the paper titled ""PWESuite: Phonetic Word Embeddings and Tasks They Facilitate""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Who is the faculty member associated with the paper titled ""PWESuite: Phonetic Word Embeddings and Tasks They Facilitate""?\nContext: Document 0: Faculty Name: david mortensen\nMetadata:\nPaperid: db14d05b18ec852f8afcd6d2d10bbd9eeaef8325\nTitle: PWESuite: Phonetic Word Embeddings and Tasks They Facilitate\nYear: 2023\nAbstract: Mapping words into a fixed-dimensional vector space is the backbone of modern NLP. While most word embedding methods successfully encode semantic information, they overlook phonetic information that is crucial for many tasks. We develop three methods that use articulatory features to build phonetically informed word embeddings. To address the inconsistent evaluation of existing phonetic word embedding methods, we also contribute a task suite to fairly evaluate past, current, and future methods. We evaluate both (1) intrinsic aspects of phonetic word embeddings, such as word retrieval and correlation with sound similarity, and (2) extrinsic performance on tasks such as rhyme and cognate detection and sound analogies. We hope our task suite will promote reproducibility and inspire future phonetic embedding research. \nDocument 1: List of 2023 Open Access papers by david mortensen are:\nChatGPT MT: Competitive for High- (but Not Low-) Resource Languages\nDo All Languages Cost the Same? Tokenization in the Era of Commercial Language Models\nSigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing\nConstruction Grammar Provides Unique Insight into Neural Language Models\nGeneralized Glossing Guidelines: An Explicit, Human- and Machine-Readable, Item-and-Process Convention for Morphological Annotation\nTransformed Protoform Reconstruction\nPWESuite: Phonetic Word Embeddings and Tasks They Facilitate\nKuki-Chin Phonology: An Overview \n\n"
"Who are the authors of the paper titled ""Evaluating emotional labor from a career management perspective""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Who are the authors of the paper titled ""Evaluating emotional labor from a career management perspective""?\nContext: Document 0: Faculty Name: eric xing\nMetadata:\nPaperid: 83aa9762c0fa099e6f893bb895e287a18b482d7e\nTitle: Evaluating emotional labor from a career management perspective\nYear: 2023\nAbstract: Emotional labor claims its significance as the key indicator both of the psychological health of contemporary employees, and the productivity of service-based businesses depending upon genuine emotional input of employees. By far, research on emotional labor of employees in an organizational context is still lacking. This study aims to explore the relationships among emotional labor, organizational support, career competences and career commitment to investigate how emotional labor interacts with the organizational context and affects the career management of the employee. Data were collected from a sample of 387 frontline employees working at two luxury hotel brands in China. Structural equation modeling (SEM) was utilized to estimate the relationships among the constructs. It is demonstrated by the findings that organizational support mediates positively on emotional labor, which exerts positive influences on career competences and career commitment. Sound handling of emotional labor, boosted by a supportive organizational environment, has been ascertained to positively predict long-term career paths of the employees at the company. \nDocument 1: It is demonstrated by the findings that organizational support mediates positively on emotional labor, which exerts positive influences on career competences and career commitment. Sound handling of emotional labor, boosted by a supportive organizational environment, has been ascertained to positively predict long-term career paths of the employees at the company. This study provides insights into how the tourism and hospitality industry can optimize the functions of emotional labor for in enhancing service quality and customer satisfaction, as well as promoting the psychological well-being of the employees.\nAuthors: Yunhong Hu, Wei Tu, Li Zhou, Xin Wu, Qi Yan\nVenue: Frontiers in Psychology\nTldr: None \n\n"
"What year was the paper titled ""End-to-End Evaluation for Low-Latency Simultaneous Speech Translation"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: What year was the paper titled ""End-to-End Evaluation for Low-Latency Simultaneous Speech Translation"" published?\nContext: Document 0: Faculty Name: alexander waibel\nMetadata:\nPaperid: f524f119afc13cc07ca15998c10b9509e9e9b0b5\nTitle: End-to-End Evaluation for Low-Latency Simultaneous Speech Translation\nYear: 2023\nAbstract: The challenge of low-latency speech translation has recently draw significant interest in the research community as shown by several publications and shared tasks. Therefore, it is essential to evaluate these different approaches in realistic scenarios. However, currently only specific aspects of the systems are evaluated and often it is not possible to compare different approaches. In this work, we propose the first framework to perform and evaluate the various aspects of low-latency speech translation under realistic conditions. The evaluation is carried out in an end-to-end fashion. This includes the segmentation of the audio as well as the run-time of the different components. Secondly, we compare different approaches to low-latency speech translation using this framework. We evaluate models with the option to revise the output as well as methods with fixed output. Furthermore, we directly compare state-of-the-art cascaded as well as end-to-end systems. \nDocument 1: List of 2023 Open Access papers by alexander waibel are:\nAdapITN: A Fast, Reliable, and Dynamic Adaptive Inverse Text Normalization\nTrain Global, Tailor Local: Minimalist Multilingual Translation into Endangered Languages\nTowards Efficient Simultaneous Speech Translation: CUNI-KIT System for Simultaneous Track at IWSLT 2023\nSYNTACC : Synthesizing Multi-Accent Speech By Weight Factorization\nKIT’s Multilingual Speech Translation System for IWSLT 2023\nConvoifilter: A case study of doing cocktail party speech recognition\nContinually learning new languages\nIncremental Blockwise Beam Search for Simultaneous Speech Translation with Controllable Quality-Latency Tradeoff\nEnd-to-End Evaluation for Low-Latency Simultaneous Speech Translation\nFINDINGS OF THE IWSLT 2023 EVALUATION CAMPAIGN\nIncremental Learning of Humanoid Robot Behavior from Natural Interaction and Large Language Models \n\n"
"Who is the faculty member associated with the paper titled ""CMU’s IWSLT 2023 Simultaneous Speech Translation System""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Who is the faculty member associated with the paper titled ""CMU’s IWSLT 2023 Simultaneous Speech Translation System""?\nContext: Document 0: Faculty Name: shinji watanabe\nMetadata:\nPaperid: 3c01b59cd923192913bb96849a892c5732c40d3d\nTitle: CMU’s IWSLT 2023 Simultaneous Speech Translation System\nYear: 2023\nAbstract: This paper describes CMU’s submission to the IWSLT 2023 simultaneous speech translation shared task for translating English speech to both German text and speech in a streaming fashion. We first build offline speech-to-text (ST) models using the joint CTC/attention framework. These models also use WavLM front-end features and mBART decoder initialization. We adapt our offline ST models for simultaneous speech-to-text translation (SST) by 1) incrementally encoding chunks of input speech, re-computing encoder states for each new chunk and 2) incrementally decoding output text, pruning beam search hypotheses to 1-best after processing each chunk. We then build text-to-speech (TTS) models using the VITS framework and achieve simultaneous speech-to-speech translation (SS2ST) by cascading our SST and TTS models. \nDocument 1: Faculty Name: alexander waibel\nMetadata:\nPaperid: f547c7ec86cbc0989e87f0e23f7e0b2cfc5259c3\nTitle: Towards Efficient Simultaneous Speech Translation: CUNI-KIT System for Simultaneous Track at IWSLT 2023\nYear: 2023\nAbstract: In this paper, we describe our submission to the Simultaneous Track at IWSLT 2023. This year, we continue with the successful setup from the last year, however, we adopt the latest methods that further improve the translation quality. Additionally, we propose a novel online policy for attentional encoder-decoder models. The policy prevents the model to generate translation beyond the current speech input by using an auxiliary CTC output layer. We show that the proposed simultaneous policy can be applied to both streaming blockwise models and offline encoder-decoder models. We observe significant improvements in quality (up to 1.1 BLEU) and the computational footprint (up to 45% relative RTF). \n\n"
"What year was the paper titled ""A Combination of Ruthenium Complexes and Photosensitizers to Treat Colorectal Cancer"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: What year was the paper titled ""A Combination of Ruthenium Complexes and Photosensitizers to Treat Colorectal Cancer"" published?\nContext: Document 0: Faculty Name: mona diab\nMetadata:\nPaperid: e818b74b7415fb43deeb80c1a33ffd5be76abed4\nTitle: A Combination of Ruthenium Complexes and Photosensitizers to Treat Colorectal Cancer\nYear: 2023\nAbstract: Treatment regimens are regularly evolving alongside novel therapies and drugs. Such evolution is necessary to circumvent resistance mechanisms and to give patients the best possible health care. When dealing with cancer, most regimens involve multiple treatments (surgery, radiation therapy, chemotherapy, immunotherapy, etc.). The purpose of this study was to associate in a single compound metal-based drugs and photosensitizers to combine chemotherapy and photodynamic therapy. Two arene–ruthenium tetrapyridylporphyrin compounds (2H-TPyP-arene-Ru and Zn-TPyP-arene-Ru) have been synthesized and evaluated on two colorectal cancer cell lines (HCT116 and HT-29). Their cytotoxicity and phototoxicity have been evaluated. In addition, the anticancer mechanism and the cell death process mediated by the two compounds were studied. \nDocument 1: Their cytotoxicity and phototoxicity have been evaluated. In addition, the anticancer mechanism and the cell death process mediated by the two compounds were studied. The results showed that the two arene–ruthenium photosensitizer-containing complexes have a strong phototoxic effect after photoactivation. The 2H-TPyP-arene-Ru complex induced outstanding cytotoxicity when compared to the Zn-TPyP-arene-Ru analogue. Moreover, under light, these two arene–ruthenium photosensitizers induce an apoptotic process in human colorectal cancer cell lines.\nAuthors: Jacquie Massoud, A. Pinon, M. Gallardo-Villagrán, L. Paulus, Catherine Ouk, Claire Carrion, Sayed Antoun, Mona Diab-Assaf, Bruno Therrien, B. Liagre\nVenue: Inorganics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Results showed that the two arene–ruthenium photosensitizer-containing complexes have a strong phototoxic effect after photoactivation, and induce an apoptotic process in human colorectal cancer cell lines.'} \n\n"
"Who are the authors of the paper titled ""Transformed Protoform Reconstruction""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Who are the authors of the paper titled ""Transformed Protoform Reconstruction""?\nContext: Document 0: Faculty Name: david mortensen\nMetadata:\nPaperid: c5c6d006e399386c99068daba138021a62d6cc17\nTitle: Transformed Protoform Reconstruction\nYear: 2023\nAbstract: Protoform reconstruction is the task of inferring what morphemes or words appeared like in the ancestral languages of a set of daughter languages. Meloni et al (2021) achieved the state-of-the-art on Latin protoform reconstruction with an RNN-based encoder-decoder with attention model. We update their model with the state-of-the-art seq2seq model: the Transformer. Our model outperforms their model on a suite of different metrics on two different datasets: their Romance data of 8,000 cognates spanning 5 languages and a Chinese dataset (Hou 2004) of 800+ cognates spanning 39 varieties. We also probe our model for potential phylogenetic signal contained in the model. Our code is publicly available at https://github.com/cmu-llab/acl-2023. \nDocument 1: List of 2023 Open Access papers by david mortensen are:\nChatGPT MT: Competitive for High- (but Not Low-) Resource Languages\nDo All Languages Cost the Same? Tokenization in the Era of Commercial Language Models\nSigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing\nConstruction Grammar Provides Unique Insight into Neural Language Models\nGeneralized Glossing Guidelines: An Explicit, Human- and Machine-Readable, Item-and-Process Convention for Morphological Annotation\nTransformed Protoform Reconstruction\nPWESuite: Phonetic Word Embeddings and Tasks They Facilitate\nKuki-Chin Phonology: An Overview \n\n"
"What year was the paper titled ""Population pharmacokinetic analysis and dosing regimen optimization of teicoplanin in critically ill patients with sepsis"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: What year was the paper titled ""Population pharmacokinetic analysis and dosing regimen optimization of teicoplanin in critically ill patients with sepsis"" published?\nContext: Document 0: Faculty Name: lei li\nMetadata:\nPaperid: 81a0ff93d7a3678330c0fb362fab427217bf2483\nTitle: Population pharmacokinetic analysis and dosing regimen optimization of teicoplanin in critically ill patients with sepsis\nYear: 2023\nAbstract: Objectives: Teicoplanin has been extensively used in the treatment for infections caused by gram-positive bacteria including methicillin-resistant Staphylococcus aureus (MRSA). However, current teicoplanin treatment is challenging due to relatively low and variable concentrations under standard dosage regimens. This study aimed to investigate the population pharmacokinetics (PPK) characteristics of teicoplanin in adult sepsis patients and provide recommendations for optimal teicoplanin dosing regimens. Methods: A total of 249 serum concentration samples from 59 septic patients were prospectively collected in the intensive care unit (ICU). Teicoplanin concentrations were detected, and patients’ clinical data were recorded. PPK analysis was performed using a non-linear, mixed-effect modeling approach. Monte Carlo simulations were performed to evaluate currently recommended dosing and other dosage regimens. \nDocument 1: List of 2023 Open Access papers by lei li are:\nEstablishment of a N1-methyladenosine-related risk signature for breast carcinoma by bioinformatics analysis and experimental validation\nPopulation pharmacokinetic analysis and dosing regimen optimization of teicoplanin in critically ill patients with sepsis\nThe effects of pharmaceutical interventions on potentially inappropriate medications in older patients: a systematic review and meta-analysis\nP53 protein and the diseases in central nervous system\nCorrection: Polydopamine-functionalized selenium nanoparticles as an efficient photoresponsive antibacterial platform\nEditorial: Strategies for functional polymeric nanocomposites and its multifunctional applications\nPolydopamine-functionalized selenium nanoparticles as an efficient photoresponsive antibacterial platform\nAntimicrobial properties of heterojunction BiSnSbO_6-ZnO composites in wastewater treatment\nResearch on torsional stiffness of flexspline-flexible bearing contact pair in harmonic drive based on macro-micro scale modeling\nIntegrated Valve Product Fluid Simulation and Test Verification\nFailure Analysis and Improvement of Check Valve Reverse Cut-off Seal\nA Study of Yuediao Folk Music Knowledge Development in Zhoukou, Henan Province, \n\n"
"Who is the faculty member associated with the paper titled ""Functional targeted therapy for glioma based on platelet membrane-coated nanogels""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Who is the faculty member associated with the paper titled ""Functional targeted therapy for glioma based on platelet membrane-coated nanogels""?\nContext: Document 0: Faculty Name: yang yiming\nMetadata:\nPaperid: aab67be24b412216ee3a048b20af146459d3c406\nTitle: Functional targeted therapy for glioma based on platelet membrane-coated nanogels\nYear: 2023\nAbstract: None\nAuthors: Qin Li, Jing-Jing Shen, Lingling Wu, S. Lei, Yiming Yang, Weide Xu, Ke Hao, Yi Zhang, Fei Kong, Wei-Qiong Yang, Yaling Wang, Lina Peng, Kai-qiang Li, Zhen Wang\nVenue: Cancer nanotechnology\nTldr: {'model': 'tldr@v2.0.0', 'text': 'DOX@PNGs increased drug penetration and prolonged mouse survival time during the treatment of orthotopic gliomas, indicating this biomimetic drug delivery system to be promising for glioma treatment and may be clinically translated in the future.'} \nDocument 1: List of 2023 Open Access papers by yang yiming are:\nFunctional targeted therapy for glioma based on platelet membrane-coated nanogels\nDual Responsive Magnetic Drug Delivery Nanomicelles with Tumor Targeting for Enhanced Cancer Chemo/Magnetothermal Synergistic Therapy\nExpression of ALCAM in Clinical Colon Cancer and Relationship With Patients’ Treatment Responses\nClaudin-10 in the Blood Brain Barrier Function of Cerebral Endothelial Cells and Transendothelial Invasion of Breast Cancer Cells\nAccelerating Diffusion-based Combinatorial Optimization Solvers by Progressive Distillation\nAutomatic synchrotron tomographic alignment schemes based on genetic algorithms and human-in-the-loop software\nHigh CD8+tumor-infiltrating lymphocytes indicate severe exhaustion and poor prognosis in angioimmunoblastic T-cell lymphoma\nNumerical Investigation of Fatigue Crack Propagation Behaviour of 550E High-Performance Steel\nAssociation between albumin-to-globulin ratio and the risk of overall survival in advanced non-small cell lung cancer patients with anlotinib treatment: a retrospective cohort study\nAnalysis of Volatile Components in Dried Fruits and Branch Exudates of Schisandra chinensis with Different Fruit Colors Using GC-IMS Technology\nSecreted \n\n"
"In which venue was the paper titled ""A Combination of Ruthenium Complexes and Photosensitizers to Treat Colorectal Cancer"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: In which venue was the paper titled ""A Combination of Ruthenium Complexes and Photosensitizers to Treat Colorectal Cancer"" published?\nContext: Document 0: Faculty Name: mona diab\nMetadata:\nPaperid: e818b74b7415fb43deeb80c1a33ffd5be76abed4\nTitle: A Combination of Ruthenium Complexes and Photosensitizers to Treat Colorectal Cancer\nYear: 2023\nAbstract: Treatment regimens are regularly evolving alongside novel therapies and drugs. Such evolution is necessary to circumvent resistance mechanisms and to give patients the best possible health care. When dealing with cancer, most regimens involve multiple treatments (surgery, radiation therapy, chemotherapy, immunotherapy, etc.). The purpose of this study was to associate in a single compound metal-based drugs and photosensitizers to combine chemotherapy and photodynamic therapy. Two arene–ruthenium tetrapyridylporphyrin compounds (2H-TPyP-arene-Ru and Zn-TPyP-arene-Ru) have been synthesized and evaluated on two colorectal cancer cell lines (HCT116 and HT-29). Their cytotoxicity and phototoxicity have been evaluated. In addition, the anticancer mechanism and the cell death process mediated by the two compounds were studied. \nDocument 1: Their cytotoxicity and phototoxicity have been evaluated. In addition, the anticancer mechanism and the cell death process mediated by the two compounds were studied. The results showed that the two arene–ruthenium photosensitizer-containing complexes have a strong phototoxic effect after photoactivation. The 2H-TPyP-arene-Ru complex induced outstanding cytotoxicity when compared to the Zn-TPyP-arene-Ru analogue. Moreover, under light, these two arene–ruthenium photosensitizers induce an apoptotic process in human colorectal cancer cell lines.\nAuthors: Jacquie Massoud, A. Pinon, M. Gallardo-Villagrán, L. Paulus, Catherine Ouk, Claire Carrion, Sayed Antoun, Mona Diab-Assaf, Bruno Therrien, B. Liagre\nVenue: Inorganics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Results showed that the two arene–ruthenium photosensitizer-containing complexes have a strong phototoxic effect after photoactivation, and induce an apoptotic process in human colorectal cancer cell lines.'} \n\n"
"Who are the authors of the paper titled ""Fumarate induces vesicular release of mtDNA to drive innate immunity""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Who are the authors of the paper titled ""Fumarate induces vesicular release of mtDNA to drive innate immunity""?\nContext: Document 0: Faculty Name: tom mitchell\nMetadata:\nPaperid: f456c96e97252f0f567d61f154ad59552621fc6a\nTitle: Fumarate induces vesicular release of mtDNA to drive innate immunity\nYear: 2023\nAbstract: None\nAuthors: V. Zecchini, Vincent Paupe, Irene Herranz-Montoya, Joëlle J E Janssen, Inge M. N. Wortel, Jordan L. Morris, Ashley N. Ferguson, Suvagata Roy Chowdury, Marc Segarra-Mondejar, Ana S. H. Costa, Gonçalo C. Pereira, L. Tronci, T. Young, Efterpi Nikitopoulou, Ming Yang, D. Bihary, F. Caicci, Shun Nagashima, Alyson Speed, K. Bokea, Zara Baig, S. Samarajiwa, M. Tran, T. Mitchell, Mark H. Johnson, J. Prudent, C. Frezza\nVenue: Nature\nTldr: {'model': 'tldr@v2.0.0', \nDocument 1: List of 2023 Open Access papers by tom mitchell are:\nPlan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents\nThe Roles of Symbols in Neural-based AI: They are Not What You Think!\nThe Internal State of an LLM Knows When its Lying\nNeuropilin-1 interacts with VE-cadherin and TGFBR2 to stabilize adherens junctions and prevent activation of endothelium under flow\nThe unconventional Myosin-1C augments endothelial secretion of von Willebrand factor by linking contractile actomyosin machinery to the plasma membrane\nRuffle&Riley: Towards the Automated Induction of Conversational Tutoring Systems\nSynthetic biology open language (SBOL) version 3.1.0\nRead and Reap the Rewards: Learning to Play Atari with the Help of Instruction Manuals\nLearning to Give Useful Hints: Assistance Action Evaluation and Policy Improvements\nGenitourinary Management and Follow-Up for Patients with Stevens-Johnson Syndrome/Toxic Epidermal Necrolysis\nFumarate induces vesicular release of mtDNA to drive innate immunity\nFLAIRR-Seq: A Method for Single-Molecule Resolution of Near Full-Length Antibody H Chain Repertoires. \n\n"
"Who is the faculty member associated with the paper titled ""SALMON: Self-Alignment with Principle-Following Reward Models""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Who is the faculty member associated with the paper titled ""SALMON: Self-Alignment with Principle-Following Reward Models""?\nContext: Document 0: Faculty Name: yang yiming\nMetadata:\nPaperid: 24df244bf7a6e8c93c5f183d3f62d39c0f773c68\nTitle: SALMON: Self-Alignment with Principle-Following Reward Models\nYear: 2023\nAbstract: Supervised Fine-Tuning (SFT) on response demonstrations combined with Reinforcement Learning from Human Feedback (RLHF) constitutes a powerful paradigm for aligning LLM-based AI agents. However, a significant limitation of such an approach is its dependency on high-quality human annotations, making its application to intricate tasks challenging due to difficulties in obtaining consistent response demonstrations and in-distribution response preferences. This paper presents a novel approach, namely SALMON (Self-ALignMent with principle-fOllowiNg reward models), to align base language models with minimal human supervision, using only a small set of human-defined principles, yet achieving superior performance. Central to our approach is a principle-following reward model. Trained on synthetic preference data, this model can generate reward scores based on arbitrary human-defined principles. \nDocument 1: We have open-sourced the code and model weights to encourage further research into aligning LLM-based AI agents with enhanced supervision efficiency, improved controllability, and scalable oversight.\nAuthors: Zhiqing Sun, Yikang Shen, Hongxin Zhang, Qinhong Zhou, Zhenfang Chen, David D. Cox, Yiming Yang, Chuang Gan\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A novel approach, namely SALMON (Self-ALignMent with principle-fOllowiNg reward models), to align base language models with minimal human supervision, using only a small set of human-defined principles, yet achieving superior performance.'} \n\n"
"Can you provide the abstract of the paper titled ""Incremental Learning of Humanoid Robot Behavior from Natural Interaction and Large Language Models""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Can you provide the abstract of the paper titled ""Incremental Learning of Humanoid Robot Behavior from Natural Interaction and Large Language Models""?\nContext: Document 0: Faculty Name: alexander waibel\nMetadata:\nPaperid: 807abb9c185ce233e2c8a2fcee49be851a1c968f\nTitle: Incremental Learning of Humanoid Robot Behavior from Natural Interaction and Large Language Models\nYear: 2023\nAbstract: Natural-language dialog is key for intuitive human-robot interaction. It can be used not only to express humans' intents, but also to communicate instructions for improvement if a robot does not understand a command correctly. Of great importance is to endow robots with the ability to learn from such interaction experience in an incremental way to allow them to improve their behaviors or avoid mistakes in the future. In this paper, we propose a system to achieve incremental learning of complex behavior from natural interaction, and demonstrate its implementation on a humanoid robot. Building on recent advances, we present a system that deploys Large Language Models (LLMs) for high-level orchestration of the robot's behavior, based on the idea of enabling the LLM to generate Python statements in an interactive console to invoke both robot perception and action. \nDocument 1: Building on recent advances, we present a system that deploys Large Language Models (LLMs) for high-level orchestration of the robot's behavior, based on the idea of enabling the LLM to generate Python statements in an interactive console to invoke both robot perception and action. The interaction loop is closed by feeding back human instructions, environment observations, and execution results to the LLM, thus informing the generation of the next statement. Specifically, we introduce incremental prompt learning, which enables the system to interactively learn from its mistakes. For that purpose, the LLM can call another LLM responsible for code-level improvements of the current interaction based on human feedback. The improved interaction is then saved in the robot's memory, and thus retrieved on similar requests. We integrate the system in the robot cognitive architecture of the humanoid robot ARMAR-6 and evaluate our methods both quantitatively (in simulation) and qualitatively (in simulation and real-world) by demonstrating generalized incrementally-learned knowledge. \n\n"
"In which venue was the paper titled ""Long-tailed Extreme Multi-label Text Classification by the Retrieval of Generated Pseudo Label Descriptions"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: In which venue was the paper titled ""Long-tailed Extreme Multi-label Text Classification by the Retrieval of Generated Pseudo Label Descriptions"" published?\nContext: Document 0: Faculty Name: lei li\nMetadata:\nPaperid: 3c92fd24ea2a49aeba4b368abe3ef13cbce40987\nTitle: Long-tailed Extreme Multi-label Text Classification by the Retrieval of Generated Pseudo Label Descriptions\nYear: 2023\nAbstract: Extreme Multi-label Text Classification (XMTC) has been a tough challenge in machine learning research and applications due to the sheer sizes of the label spaces and the severe data scarcity problem associated with the long tail of rare labels in highly skewed distributions. This paper addresses the challenge of tail label prediction by leveraging the power of dense neural retrieval model in mapping input documents (as queries) to relevant label descriptions. To further enhance the quality of label descriptions, we propose to generate pseudo label descriptions from a trained bag-of-words (BoW) classifier, which demonstrates better classification performance under severe scarce data conditions.The proposed approach achieves the state-of-the-art (SOTA) performance of overall label prediction on XMTC benchmark datasets and especially outperforms the SOTA models in the tail label prediction. We also provide a theoretical analysis for relating the BoW and neural models w.r.t. performance lower bound. \nDocument 1: Faculty Name: yang yiming\nMetadata:\nPaperid: 3c92fd24ea2a49aeba4b368abe3ef13cbce40987\nTitle: Long-tailed Extreme Multi-label Text Classification by the Retrieval of Generated Pseudo Label Descriptions\nYear: 2023\nAbstract: Extreme Multi-label Text Classification (XMTC) has been a tough challenge in machine learning research and applications due to the sheer sizes of the label spaces and the severe data scarcity problem associated with the long tail of rare labels in highly skewed distributions. This paper addresses the challenge of tail label prediction by leveraging the power of dense neural retrieval model in mapping input documents (as queries) to relevant label descriptions. To further enhance the quality of label descriptions, we propose to generate pseudo label descriptions from a trained bag-of-words (BoW) classifier, which demonstrates better classification performance under severe scarce data conditions.The proposed approach achieves the state-of-the-art (SOTA) performance of overall label prediction on XMTC benchmark datasets and especially outperforms the SOTA models in the tail label prediction. We also provide a theoretical analysis for relating the BoW and neural models w.r.t. performance lower bound. \n\n"
"Can you provide the abstract of the paper titled ""The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Can you provide the abstract of the paper titled ""The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment""?\nContext: Document 0: Faculty Name: emma strubell\nMetadata:\nPaperid: b777aa86b5a1d49ce8eababc5c2ee56d3562801e\nTitle: The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment\nYear: 2023\nAbstract: Increased focus on the computational efficiency of NLP systems has motivated the design of efficient model architectures and improvements to underlying hardware accelerators. However, the resulting increases in computational throughput and reductions in floating point operations have not directly translated to improvements in wall-clock inference latency. We demonstrate that these discrepancies can be largely attributed to bottlenecks introduced by deep learning frameworks. We denote this phenomenon as the \textit{framework tax}, and observe that the disparity is growing as hardware speed increases over time. In this work, we examine this phenomenon through a series of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency. Code is available at https://github.com/JaredFern/Framework-Tax. \nDocument 1: Faculty Name: yonatan bisk\nMetadata:\nPaperid: b777aa86b5a1d49ce8eababc5c2ee56d3562801e\nTitle: The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment\nYear: 2023\nAbstract: Increased focus on the computational efficiency of NLP systems has motivated the design of efficient model architectures and improvements to underlying hardware accelerators. However, the resulting increases in computational throughput and reductions in floating point operations have not directly translated to improvements in wall-clock inference latency. We demonstrate that these discrepancies can be largely attributed to bottlenecks introduced by deep learning frameworks. We denote this phenomenon as the \textit{framework tax}, and observe that the disparity is growing as hardware speed increases over time. In this work, we examine this phenomenon through a series of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency. Code is available at https://github.com/JaredFern/Framework-Tax. \n\n"
"In which venue was the paper titled ""The role of novelty stimuli in second language acquisition: evidence from the optimized training by the Pinyin Tutor at TalkBank"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: In which venue was the paper titled ""The role of novelty stimuli in second language acquisition: evidence from the optimized training by the Pinyin Tutor at TalkBank"" published?\nContext: Document 0: Faculty Name: brian macwhinney\nMetadata:\nPaperid: 283dbaa4da4beafa5e5719095bcc88e63d17815e\nTitle: The role of novelty stimuli in second language acquisition: evidence from the optimized training by the Pinyin Tutor at TalkBank\nYear: 2023\nAbstract: None\nAuthors: Yanhui Zhang, B. MacWhinney\nVenue: Smart Learning Environments\nTldr: None \nDocument 1: List of 2023 Open Access papers by brian macwhinney are:\nAssessment and Therapy Goal Planning Using Free Computerized Language Analysis Software.\nAutomation of Language Sample Analysis\nThe role of novelty stimuli in second language acquisition: evidence from the optimized training by the Pinyin Tutor at TalkBank\nUsing diagnostic feedback to enhance the development of phonetic knowledge of an L2: a CALL design based on the unified competition model and the implementation with the Pinyin Tutor\nA New Benchmark of Aphasia Speech Recognition and Detection Based on E-Branchformer and Multi-task Learning\nCollaborative Commentary for Understanding Communication Disorders.\nEstablishing the DementiaBank Delaware Corpus: An Online Multimedia Database for the Study of Language and Cognition in Dementia\nEvaluating Picture Description Speech for Dementia Detection using Image-text Alignment\nMultilingual Alzheimer’s Dementia Recognition through Spontaneous Speech: A Signal Processing Grand Challenge\nDementiaBank: Theoretical Rationale, Protocol, and Illustrative Analyses \n\n"
"Can you provide the abstract of the paper titled ""Riveter: Measuring Power and Social Dynamics Between Entities""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Can you provide the abstract of the paper titled ""Riveter: Measuring Power and Social Dynamics Between Entities""?\nContext: Document 0: Faculty Name: maarten sap\nMetadata:\nPaperid: 27553f8bd9cbee90f6e65b9cdecadff0e7cc55ee\nTitle: Riveter: Measuring Power and Social Dynamics Between Entities\nYear: 2023\nAbstract: Riveter provides a complete easy-to-use pipeline for analyzing verb connotations associated with entities in text corpora. We prepopulate the package with connotation frames of sentiment, power, and agency, which have demonstrated usefulness for capturing social phenomena, such as gender bias, in a broad range of corpora. For decades, lexical frameworks have been foundational tools in computational social science, digital humanities, and natural language processing, facilitating multifaceted analysis of text corpora. But working with verb-centric lexica specifically requires natural language processing skills, reducing their accessibility to other researchers. By organizing the language processing pipeline, providing complete lexicon scores and visualizations for all entities in a corpus, and providing functionality for users to target specific research questions, Riveter greatly improves the accessibility of verb lexica and can facilitate a broad range of future research. \nDocument 1: List of 2023 Open Access papers by maarten sap are:\nModeling Empathic Similarity in Personal Narratives\nCOBRA Frames: Contextual Reasoning about Effects and Harms of Offensive Statements\nRiveter: Measuring Power and Social Dynamics Between Entities\nDon't Take This Out of Context!: On the Need for Contextual Models and Evaluations for Stylistic Rewriting\nBiasX: ""Thinking Slow"" in Toxic Content Moderation with Explanations of Implied Social Biases\nImproving Language Models with Advantage-based Offline Policy Gradients\nFrom Dogwhistles to Bullhorns: Unveiling Coded Rhetoric with Language Models\nNLPositionality: Characterizing Design Biases of Datasets and Models\nDon't Take This Out of Context! On the Need for Contextual Models and Evaluations for Stylistic Rewriting\nQueer In AI: A Case Study in Community-Led Participatory AI\nValue Kaleidoscope: Engaging AI with Pluralistic Human Values, Rights, and Duties\nClever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in Large Language Models\nTowards Countering Essentialism through Social Bias Reasoning \n\n"
"In which venue was the paper titled ""Qualitative study of the association between psychosocial health and physical activity/sleep quality in toddlers"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: In which venue was the paper titled ""Qualitative study of the association between psychosocial health and physical activity/sleep quality in toddlers"" published?\nContext: Document 0: Faculty Name: lu jiang\nMetadata:\nPaperid: 6f84a90299847f661a0b6a1fa8e71425b304b945\nTitle: Qualitative study of the association between psychosocial health and physical activity/sleep quality in toddlers\nYear: 2023\nAbstract: None\nAuthors: Chisa Tsuyuki, Koya Suzuki, Kanako Seo, Dandan Ke, Kyoko Tsuge, Pengyu Deng, Dajiang Lu, Hisashi Naito\nVenue: Scientific Reports\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A retrospective cohort study in 3-year-old children in Shanghai, China indicated that current physical activity had a direct and moderate impact on current psychosocial health evaluated using the Strength and Difficulties Questionnaire, and past sleep quality had slight impact on current psychosocial health.'} \nDocument 1: Impact of Varicella Immunization and Public Health and Social Measures on Varicella Incidence: Insights from Surveillance Data in Shanghai, 2013–2022\nCoverage and impact of influenza vaccination among children in Minhang District, China, 2013–2020\nAssociations of Morphological Changes in Skeletal Muscles of Preschool Children in China Following Physical Activity\nQualitative study of the association between psychosocial health and physical activity/sleep quality in toddlers\nEstimability study on the age of toddlers’ gait development based on gait parameters\nAdvances in gene therapy hold promise for treating hereditary hearing loss. \n\n"
"Who is the faculty member associated with the paper titled ""Grounding Language Models to Images for Multimodal Generation""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Who is the faculty member associated with the paper titled ""Grounding Language Models to Images for Multimodal Generation""?\nContext: Document 0: Faculty Name: daniel fried\nMetadata:\nPaperid: 2b2d9ee18507aa89a7f1ecba0bf68844c7d9aa75\nTitle: Grounding Language Models to Images for Multimodal Generation\nYear: 2023\nAbstract: We propose an efﬁcient method to ground pre-trained text-only language models to the visual domain, enabling them to process and generate arbitrarily interleaved image-and-text data. Our method leverages the abilities of language models learnt from large scale text-only pretraining, such as in-context learning and free-form text generation. We keep the language model frozen, and ﬁnetune input and output linear layers to enable cross-modality interactions. This allows our model to process arbitrarily interleaved image-and-text inputs, and generate free-form text inter-leaved with retrieved images. We achieve strong zero-shot performance on grounded tasks such as contextual image retrieval and multimodal dialogue, and showcase compelling interactive abilities. Our approach works with any off-the-shelf language model and paves the way towards an effective, general solution for leveraging pretrained language models in visually grounded settings. \nDocument 1: Faculty Name: daniel fried\nMetadata:\nPaperid: 6fb5c0eff3696ef252aca9638e10176ecce7cecb\nTitle: Generating Images with Multimodal Language Models\nYear: 2023\nAbstract: We propose a method to fuse frozen text-only large language models (LLMs) with pre-trained image encoder and decoder models, by mapping between their embedding spaces. Our model demonstrates a wide suite of multimodal capabilities: image retrieval, novel image generation, and multimodal dialogue. Ours is the first approach capable of conditioning on arbitrarily interleaved image and text inputs to generate coherent image (and text) outputs. To achieve strong performance on image generation, we propose an efficient mapping network to ground the LLM to an off-the-shelf text-to-image generation model. This mapping network translates hidden representations of text into the embedding space of the visual models, enabling us to leverage the strong text representations of the LLM for visual outputs. Our approach outperforms baseline generation models on tasks with longer and more complex language. In addition to novel image generation, our model is also capable of image retrieval from a prespecified dataset, and decides whether to retrieve or generate at inference time. \n\n"
"What year was the paper titled ""Hence, Socrates is mortal: A Benchmark for Natural Language Syllogistic Reasoning"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: What year was the paper titled ""Hence, Socrates is mortal: A Benchmark for Natural Language Syllogistic Reasoning"" published?\nContext: Document 0: Faculty Name: lei li\nMetadata:\nPaperid: 56de9c4c63ee74757be1b203d2ea852690087ded\nTitle: Hence, Socrates is mortal: A Benchmark for Natural Language Syllogistic Reasoning\nYear: 2023\nAbstract: Syllogistic reasoning, a typical form of deductive reasoning, is a critical capability widely required in natural language understanding tasks, such as text entailment and question answering. To better facilitate research on syllogis-tic reasoning, we develop a benchmark called S YLLO B ASE that differs from existing syllo-gistic datasets in three aspects: (1) Covering a complete taxonomy of syllogism reasoning patterns; (2) Containing both automatically and manually constructed samples; and (3) Involving both the generation and understanding tasks. We automatically construct 50k template-based syllogism samples by mining syllogism patterns from Wikidata and ConceptNet. To improve our dataset’s naturalness and challenge, we apply GPT-3 to paraphrase the template-based data and further manually rewrite 1,000 samples as the test set. \nDocument 1: Socrates is mortal: A Benchmark for Natural Language Syllogistic Reasoning\nProvable Robust Watermarking for AI-Generated Text\nMCM6 is a Poor Prognostic Biomarker and Promotes Progression in Breast Cancer.\np53 deacetylation alleviates calcium oxalate deposition-induced renal fibrosis by inhibiting ferroptosis.\nGut microbiota in patients with kidney stones: a systematic review and meta-analysis\nEffect of instant surgery compared with traditional management on paediatric complicated acute appendicitis post‐surgery wound: A meta‐analysis\nProtecting Language Generation Models via Invisible Watermarking\nComprehensive Analysis of Cuproptosis Genes and Identification of Cuproptosis Subtypes in Breast Cancer\nLong-tailed Extreme Multi-label Text Classification by the Retrieval of Generated Pseudo Label Descriptions \n\n"
"Who are the authors of the paper titled ""Fully Unsupervised Topic Clustering of Unlabelled Spoken Audio Using Self-Supervised Representation Learning and Topic Model""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Who are the authors of the paper titled ""Fully Unsupervised Topic Clustering of Unlabelled Spoken Audio Using Self-Supervised Representation Learning and Topic Model""?\nContext: Document 0: Faculty Name: shinji watanabe\nMetadata:\nPaperid: debb65ab30ceef2faef0e4af560a67f2abd03d14\nTitle: Fully Unsupervised Topic Clustering of Unlabelled Spoken Audio Using Self-Supervised Representation Learning and Topic Model\nYear: 2023\nAbstract: Unsupervised topic clustering of spoken audio is an important research topic for zero-resourced unwritten languages. A classical approach is to find a set of spoken terms from only the audio based on dynamic time warping or generative modeling (e.g., hidden Markov model), and apply a topic model to classify topics. The spoken term discovery is the most important and difficult part. In this paper, we propose to combine self-supervised representation learning (SSRL) methods as a component of spoken term discovery and probabilistic topic models. Most SSRL methods pre-train a model which predicts high-quality pseudo labels generated from an audio-only corpus. These pseudo labels can be used to produce a sequence of pseudo subwords by applying deduplication and a subword model. \nDocument 1: Challenge\nFully Unsupervised Topic Clustering of Unlabelled Spoken Audio Using Self-Supervised Representation Learning and Topic Model\nTAPLoss: A Temporal Acoustic Parameter Loss for Speech Enhancement\nEnd-to-End Speech Recognition: A Survey\nThe Multimodal Information Based Speech Processing (Misp) 2022 Challenge: Audio-Visual Diarization And Recognition\nDPHuBERT: Joint Distillation and Pruning of Self-Supervised Speech Models\nAn external quality assessment feasibility study; \n\n"
"What year was the paper titled ""Characterisation and Dynamics of an Emerging Seagrass Meadow"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: What year was the paper titled ""Characterisation and Dynamics of an Emerging Seagrass Meadow"" published?\nContext: Document 0: Faculty Name: bio\nMetadata:\nPaperid: 0312627ed2ce0f5327d8588c2f9d65afd61e53d3\nTitle: Characterisation and Dynamics of an Emerging Seagrass Meadow\nYear: 2023\nAbstract: Seagrasses are habitat-forming species that support biodiversity and a wide range of associated ecosystem services, from blue carbon capture to providing nursery areas for a variety of organisms. Their decline has been documented worldwide and is attributed to human impacts ranging from habitat loss and eutrophication to the effects of climate change. However, recent recovery trends have also been documented due to reductions in stressors, passive and active restoration, and even changes in environmental conditions owing to local management. In this study, we document for the first time the occurrence of Zostera noltei in the downstream area of the River Minho Estuary. This occurrence was unexpected given the hydrological conditions of the estuary, characterised by dredging and siltation. We reconstructed the occurrence and historical distribution of seagrass beds, and showed that they have existed in the region for more than a decade. \nDocument 1: List of 2023 Open Access papers by bio are:\n491. Risk Factors for Severe Pediatric COVID-19: A Systematic Review\nAntifungal stewardship in practice: Insights from a prospective audit and feedback program\n2945. Audit and Feedback Informed ASP Interventions Lead to Sustained Reductions in Suboptimal Antibiotic Prescribing at Hospital Discharge\nCharacterisation and Dynamics of an Emerging Seagrass Meadow\nNew Methodology for Intertidal Seaweed Biomass Estimation Using Multispectral Data Obtained with Unoccupied Aerial Vehicles\nApplication of a Multispectral UAS to Assess the Cover and Biomass of the Invasive Dune Species Carpobrotus edulis\nSea Level Rise Effects on the Sedimentary Dynamics of the Douro Estuary Sandspit (Portugal)\nDispensing of Antibiotics Without Prescription in Southern Benin, West Africa, 2018\nNonmedical Use of Prescription Psychotropic Drugs among Secondary School Students in Parakou, \n\n"
"Who are the authors of the paper titled ""MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Who are the authors of the paper titled ""MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception""?\nContext: Document 0: Faculty Name: yonatan bisk\nMetadata:\nPaperid: 69b8cd15966c4c9c3e44e71769e557f1c87fb3f9\nTitle: MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception\nYear: 2023\nAbstract: A holistic understanding of object properties across diverse sensory modalities (e.g., visual, audio, and haptic) is essential for tasks ranging from object categorization to complex manipulation. Drawing inspiration from cognitive science studies that emphasize the significance of multi-sensory integration in human perception, we introduce MOSAIC (Multimodal Object property learning with Self-Attention and Interactive Comprehension), a novel framework designed to facilitate the learning of unified multi-sensory object property representations. While it is undeniable that visual information plays a prominent role, we acknowledge that many fundamental object properties extend beyond the visual domain to encompass attributes like texture, mass distribution, or sounds, which significantly influence how we interact with objects. In MOSAIC, we leverage this profound insight by distilling knowledge from multimodal foundation models and aligning these representations not only across vision but also haptic and auditory sensory modalities. \nDocument 1: List of 2023 Open Access papers by yonatan bisk are:\nSPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs\nHomeRobot: Open-Vocabulary Mobile Manipulation\nPlan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents\nMOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception\nReasoning about the Unseen for Efficient Outdoor Object Navigation\nThe Framework Tax: Disparities Between Inference Efficiency in Research and Deployment\nWebArena: A Realistic Web Environment for Building Autonomous Agents\nComputational Language Acquisition with Theory of Mind \n\n"
"Who is the faculty member associated with the paper titled ""FINDINGS OF THE IWSLT 2023 EVALUATION CAMPAIGN""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Who is the faculty member associated with the paper titled ""FINDINGS OF THE IWSLT 2023 EVALUATION CAMPAIGN""?\nContext: Document 0: Faculty Name: alexander waibel\nMetadata:\nPaperid: f7e995c3cae465963ecaa8c9b4ce8b9b4323a71b\nTitle: FINDINGS OF THE IWSLT 2023 EVALUATION CAMPAIGN\nYear: 2023\nAbstract: This paper reports on the shared tasks organized by the 20th IWSLT Conference. The shared tasks address 9 scientific challenges in spoken language translation: simultaneous and offline translation, automatic subtitling and dubbing, speech-to-speech translation, multilingual, dialect and low-resource speech translation, and formality control. The shared tasks attracted a total of 38 submissions by 31 teams. The growing interest towards spoken language translation is also witnessed by the constantly increasing number of shared task organizers and contributors to the overview paper, almost evenly distributed across industry and academia. \nDocument 1: Faculty Name: shinji watanabe\nMetadata:\nPaperid: f7e995c3cae465963ecaa8c9b4ce8b9b4323a71b\nTitle: FINDINGS OF THE IWSLT 2023 EVALUATION CAMPAIGN\nYear: 2023\nAbstract: This paper reports on the shared tasks organized by the 20th IWSLT Conference. The shared tasks address 9 scientific challenges in spoken language translation: simultaneous and offline translation, automatic subtitling and dubbing, speech-to-speech translation, multilingual, dialect and low-resource speech translation, and formality control. The shared tasks attracted a total of 38 submissions by 31 teams. The growing interest towards spoken language translation is also witnessed by the constantly increasing number of shared task organizers and contributors to the overview paper, almost evenly distributed across industry and academia. \n\n"
"Who are the authors of the paper titled ""Methods for Measuring, Updating, and Visualizing Factual Beliefs in Language Models""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Who are the authors of the paper titled ""Methods for Measuring, Updating, and Visualizing Factual Beliefs in Language Models""?\nContext: Document 0: Faculty Name: mona diab\nMetadata:\nPaperid: f727f928e7e179307d8d4a1da2387393f2bd7915\nTitle: Methods for Measuring, Updating, and Visualizing Factual Beliefs in Language Models\nYear: 2023\nAbstract: Language models can memorize a considerable amount of factual information during pretraining that can be elicited through prompting or finetuning models on tasks like question answering. In this paper, we discuss approaches to measuring model factual beliefs, updating incorrect factual beliefs in models, and visualizing graphical relationships between factual beliefs. Our main contributions include: (1) new metrics for evaluating belief-updating methods focusing on the logical consistency of beliefs, (2) a training objective for Sequential, Local, and Generalizing updates (SLAG) that improves the performance of existing hypernetwork approaches, and (3) the introduction of the belief graph, a new form of visualization for language models that shows relationships between stored model beliefs. Our experiments suggest that models show only limited consistency between factual beliefs, but update methods can both fix incorrect model beliefs and greatly improve their consistency. \nDocument 1: Our experiments suggest that models show only limited consistency between factual beliefs, but update methods can both fix incorrect model beliefs and greatly improve their consistency. Although off-the-shelf optimizers are surprisingly strong belief-updating baselines, our learned optimizers can outperform them in more difficult settings than have been considered in past work.\nAuthors: Peter Hase, Mona T. Diab, Asli Celikyilmaz, Xian Li, Zornitsa Kozareva, Veselin Stoyanov, Mohit Bansal, Srini Iyer\nVenue: Conference of the European Chapter of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The experiments suggest that models show only limited consistency between factual beliefs, but update methods can both fix incorrect model beliefs and greatly improve their consistency, and off-the-shelf optimizers can outperform them in more difficult settings than have been considered in past work.'} \n\n"
"Can you provide the abstract of the paper titled ""Self-Refine: Iterative Refinement with Self-Feedback""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Can you provide the abstract of the paper titled ""Self-Refine: Iterative Refinement with Self-Feedback""?\nContext: Document 0: Faculty Name: yang yiming\nMetadata:\nPaperid: 3aaf6a2cbad5850ad81ab5c163599cb3d523436f\nTitle: Self-Refine: Iterative Refinement with Self-Feedback\nYear: 2023\nAbstract: Like humans, large language models (LLMs) do not always generate the best output on their first try. Motivated by how humans refine their written text, we introduce Self-Refine, an approach for improving initial outputs from LLMs through iterative feedback and refinement. The main idea is to generate an initial output using an LLMs; then, the same LLMs provides feedback for its output and uses it to refine itself, iteratively. Self-Refine does not require any supervised training data, additional training, or reinforcement learning, and instead uses a single LLM as the generator, refiner, and feedback provider. We evaluate Self-Refine across 7 diverse tasks, ranging from dialog response generation to mathematical reasoning, using state-of-the-art (GPT-3.5, ChatGPT, and GPT-4) LLMs. \nDocument 1: Faculty Name: sean welleck\nMetadata:\nPaperid: 3aaf6a2cbad5850ad81ab5c163599cb3d523436f\nTitle: Self-Refine: Iterative Refinement with Self-Feedback\nYear: 2023\nAbstract: Like humans, large language models (LLMs) do not always generate the best output on their first try. Motivated by how humans refine their written text, we introduce Self-Refine, an approach for improving initial outputs from LLMs through iterative feedback and refinement. The main idea is to generate an initial output using an LLMs; then, the same LLMs provides feedback for its output and uses it to refine itself, iteratively. Self-Refine does not require any supervised training data, additional training, or reinforcement learning, and instead uses a single LLM as the generator, refiner, and feedback provider. We evaluate Self-Refine across 7 diverse tasks, ranging from dialog response generation to mathematical reasoning, using state-of-the-art (GPT-3.5, ChatGPT, and GPT-4) LLMs. \n\n"
"What year was the paper titled ""Measurement of Heavy Nulei beyond Iron in Cosmic Rays with the DAMPE Experiment"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: What year was the paper titled ""Measurement of Heavy Nulei beyond Iron in Cosmic Rays with the DAMPE Experiment"" published?\nContext: Document 0: Faculty Name: eric xing\nMetadata:\nPaperid: 96d6fc4281e739c0e5bc1ea4b7b14ea1ab3bce52\nTitle: Measurement of Heavy Nulei beyond Iron in Cosmic Rays with the DAMPE Experiment\nYear: 2023\nAbstract: None\nAuthors: Haoran Sun, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, F. de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, \nDocument 1: Faculty Name: lu jiang\nMetadata:\nPaperid: 96d6fc4281e739c0e5bc1ea4b7b14ea1ab3bce52\nTitle: Measurement of Heavy Nulei beyond Iron in Cosmic Rays with the DAMPE Experiment\nYear: 2023\nAbstract: None\nAuthors: Haoran Sun, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, F. de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, \n\n"
"What year was the paper titled ""PAMR1 negatively impacts cell proliferation and migration of Human Colon Cancer HT29 Cell Line"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: What year was the paper titled ""PAMR1 negatively impacts cell proliferation and migration of Human Colon Cancer HT29 Cell Line"" published?\nContext: Document 0: Faculty Name: mona diab\nMetadata:\nPaperid: 4674d83e0c54a9a7b6833121cc2f40cd21f2579c\nTitle: PAMR1 negatively impacts cell proliferation and migration of Human Colon Cancer HT29 Cell Line\nYear: 2023\nAbstract: Colorectal cancer (CRC) is becoming one of the most prevalent cancers worldwide. Among cancers, it ranks the third place in terms of incidence and the second in terms of mortality. Even though immunological test allows fast and easy diagnostic method, there is no specific and reliable methods for early detection of CRC. Despite different treatments, high risk of re-occurrence is associated with advanced and metastatic CRC stages. An exhaustive knowledge on specific biomarkers or molecular actors involved in CRC could help to eradicate tumors or limit cancer recurrence. In this study, we focused on PAMR1 (Peptidase Domain Containing Associated with Muscle Regeneration 1), which is already considered as a tumor suppressor in breast and cervical cancers. \nDocument 1: Quantification, and Prescriptive Remediations\nOPT-R: Exploring the Role of Explanations in Finetuning and Prompting for Reasoning Skills of Large Language Models\nMethods for Measuring, Updating, and Visualizing Factual Beliefs in Language Models\nComparison of the structures and topologies of plasma extracted circulating nuclear and mitochondrial cell-free DNA\nCytomegalovirus at the crossroads of immunosenescence and oncogenesis\nAspalathus linearis (Rooibos) Targets Adipocytes and Obesity-Associated Inflammation\nEmerging Therapeutic Approaches to Target the Dark Side of Senescent Cells: New Hopes to Treat Aging as a Disease and to Delay Age-Related Pathologies\nCrosstalk of Inflammatory Cytokines within the Breast Tumor Microenvironment\nAuthor Correction: Arabic natural language processing for Qur’anic research: a systematic review\nEvaluating Multilingual Speech Translation under Realistic Conditions with Resegmentation and Terminology\nA bleeding bite: crotalinae snake envonamation\nPAMR1 negatively impacts cell proliferation and migration of Human Colon Cancer HT29 Cell Line\nA Combination of Ruthenium Complexes and Photosensitizers to Treat Colorectal Cancer \n\n"
"What year was the paper titled ""Claudin-10 in the Blood Brain Barrier Function of Cerebral Endothelial Cells and Transendothelial Invasion of Breast Cancer Cells"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: What year was the paper titled ""Claudin-10 in the Blood Brain Barrier Function of Cerebral Endothelial Cells and Transendothelial Invasion of Breast Cancer Cells"" published?\nContext: Document 0: Faculty Name: yang yiming\nMetadata:\nPaperid: ca5d6ee5ce52d039c109fe44b0c68b1fe1f0198a\nTitle: Claudin-10 in the Blood Brain Barrier Function of Cerebral Endothelial Cells and Transendothelial Invasion of Breast Cancer Cells\nYear: 2023\nAbstract: Background/Aim: Claudin-10 (CLDN10) is a membrane integral protein. It is one of the widely expressed tight junctional claudins with functions not well defined. In the present study, the expression profile and its role in cerebral endothelial cells and in the interaction between breast cancer and endothelial cells were investigated. Materials and Methods: CLDN10 expression was examined in a wide range of cell types. Brain endothelial cell models with or without CLDN10 expression were generated using the hCMEC/D3 cell line and used to test the barrier and permeability functions. Transendothelial drug delivery and invasion were also evaluated. \nDocument 1: List of 2023 Open Access papers by yang yiming are:\nFunctional targeted therapy for glioma based on platelet membrane-coated nanogels\nDual Responsive Magnetic Drug Delivery Nanomicelles with Tumor Targeting for Enhanced Cancer Chemo/Magnetothermal Synergistic Therapy\nExpression of ALCAM in Clinical Colon Cancer and Relationship With Patients’ Treatment Responses\nClaudin-10 in the Blood Brain Barrier Function of Cerebral Endothelial Cells and Transendothelial Invasion of Breast Cancer Cells\nAccelerating Diffusion-based Combinatorial Optimization Solvers by Progressive Distillation\nAutomatic synchrotron tomographic alignment schemes based on genetic algorithms and human-in-the-loop software\nHigh CD8+tumor-infiltrating lymphocytes indicate severe exhaustion and poor prognosis in angioimmunoblastic T-cell lymphoma\nNumerical Investigation of Fatigue Crack Propagation Behaviour of 550E High-Performance Steel\nAssociation between albumin-to-globulin ratio and the risk of overall survival in advanced non-small cell lung cancer patients with anlotinib treatment: a retrospective cohort study\nAnalysis of Volatile Components in Dried Fruits and Branch Exudates of Schisandra chinensis with Different Fruit Colors Using GC-IMS Technology\nSecreted \n\n"
"Who are the authors of the paper titled ""Improving Cascaded Unsupervised Speech Translation with Denoising Back-translation""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Who are the authors of the paper titled ""Improving Cascaded Unsupervised Speech Translation with Denoising Back-translation""?\nContext: Document 0: Faculty Name: shinji watanabe\nMetadata:\nPaperid: ef8b095292a8e38e9b8f56c54cbf3c67c3ed425d\nTitle: Improving Cascaded Unsupervised Speech Translation with Denoising Back-translation\nYear: 2023\nAbstract: Most of the speech translation models heavily rely on parallel data, which is hard to collect especially for low-resource languages. To tackle this issue, we propose to build a cascaded speech translation system without leveraging any kind of paired data. We use fully unpaired data to train our unsupervised systems and evaluate our results on CoVoST 2 and CVSS. The results show that our work is comparable with some other early supervised methods in some language pairs. While cascaded systems always suffer from severe error propagation problems, we proposed denoising back-translation (DBT), a novel approach to building robust unsupervised neural machine translation (UNMT). DBT successfully increases the BLEU score by 0.7--0.9 in all three translation directions. \nDocument 1: DBT successfully increases the BLEU score by 0.7--0.9 in all three translation directions. Moreover, we simplified the pipeline of our cascaded system to reduce inference latency and conducted a comprehensive analysis of every part of our work. We also demonstrate our unsupervised speech translation results on the established website.\nAuthors: Yu-Kuan Fu, Liang-Hsuan Tseng, Jiatong Shi, Chen-An Li, Tsung-Yuan Hsu, Shinji Watanabe, Hung-yi Lee\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposed denoising back-translation (DBT), a novel approach to building robust unsupervised neural machine translation (UNMT), which successfully increases the BLEU score by 0.7--0.9 in all three translation directions.'} \n\n"
"Who is the faculty member associated with the paper titled ""Imaging Field‐Driven Melting of a Molecular Solid at the Atomic Scale""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Who is the faculty member associated with the paper titled ""Imaging Field‐Driven Melting of a Molecular Solid at the Atomic Scale""?\nContext: Document 0: Faculty Name: yang yiming\nMetadata:\nPaperid: 70a6d974580a272e724936b6bc9cd27064098604\nTitle: Imaging Field‐Driven Melting of a Molecular Solid at the Atomic Scale\nYear: 2023\nAbstract: Solid–liquid phase transitions are basic physical processes, but atomically resolved microscopy has yet to capture their full dynamics. A new technique is developed for controlling the melting and freezing of self‐assembled molecular structures on a graphene field‐effect transistor (FET) that allows phase‐transition behavior to be imaged using atomically resolved scanning tunneling microscopy. This is achieved by applying electric fields to 2,3,5,6‐tetrafluoro‐7,7,8,8‐tetracyanoquinodimethane‐decorated FETs to induce reversible transitions between molecular solid and liquid phases at the FET surface. Nonequilibrium melting dynamics are visualized by rapidly heating the graphene substrate with an electrical current and imaging the resulting evolution toward new 2D equilibrium states. An analytical model is developed that explains observed mixed‐state phases based on spectroscopic measurement of solid and liquid molecular energy levels. \nDocument 1: Nonequilibrium melting dynamics are visualized by rapidly heating the graphene substrate with an electrical current and imaging the resulting evolution toward new 2D equilibrium states. An analytical model is developed that explains observed mixed‐state phases based on spectroscopic measurement of solid and liquid molecular energy levels. The observed nonequilibrium melting dynamics are consistent with Monte Carlo simulations.\nAuthors: Franklin Liou, H. Tsai, Zachary A H Goodwin, Andrew S. Aikawa, Ethan Ha, Michael Hu, Yiming Yang, Kenji Watanabe, T. Taniguchi, A. Zettl, J. Lischner, M. Crommie\nVenue: Advances in Materials\nTldr: None \n\n"
"Can you provide the abstract of the paper titled ""InPars-Light: Cost-Effective Unsupervised Training of Efficient Rankers""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Can you provide the abstract of the paper titled ""InPars-Light: Cost-Effective Unsupervised Training of Efficient Rankers""?\nContext: Document 0: Faculty Name: eric nyberg\nMetadata:\nPaperid: 3a30217c4115777fb30c182c97cc77d34d065556\nTitle: InPars-Light: Cost-Effective Unsupervised Training of Efficient Rankers\nYear: 2023\nAbstract: We carried out a reproducibility study of InPars, which is a method for unsupervised training of neural rankers (Bonifacio et al., 2022). As a by-product, we developed InPars-light, which is a simple-yet-effective modification of InPars. Unlike InPars, InPars-light uses 7x-100x smaller ranking models and only a freely available language model BLOOM, which -- as we found out -- produced more accurate rankers compared to a proprietary GPT-3 model. On all five English retrieval collections (used in the original InPars study) we obtained substantial (7%-30%) and statistically significant improvements over BM25 (in nDCG and MRR) using only a 30M parameter six-layer MiniLM-30M ranker and a single three-shot prompt. \nDocument 1: List of 2023 Open Access papers by eric nyberg are:\nGameQA: Gamified Mobile App Platform for Building Multiple-Domain Question-Answering Datasets\nInPars-Light: Cost-Effective Unsupervised Training of Efficient Rankers\nLanguage-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA\nChain-of-Skills: A Configurable Model for Open-Domain Question Answering\nA super wear-resistant coating for Mg alloys achieved by plasma electrolytic oxidation and discontinuous deposition\nDifference-Masking: Choosing What to Mask in Continued Pretraining\nUsing Implicit Feedback to Improve Question Generation \n\n"
"What year was the paper titled ""Are aligned neural networks adversarially aligned?"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: What year was the paper titled ""Are aligned neural networks adversarially aligned?"" published?\nContext: Document 0: Faculty Name: daphne ippolito\nMetadata:\nPaperid: 8724579d3f126e753a0451d98ff57b165f722e72\nTitle: Are aligned neural networks adversarially aligned?\nYear: 2023\nAbstract: Large language models are now tuned to align with the goals of their creators, namely to be""helpful and harmless.""These models should respond helpfully to user questions, but refuse to answer requests that could cause harm. However, adversarial users can construct inputs which circumvent attempts at alignment. In this work, we study to what extent these models remain aligned, even when interacting with an adversarial user who constructs worst-case inputs (adversarial examples). These inputs are designed to cause the model to emit harmful content that would otherwise be prohibited. We show that existing NLP-based optimization attacks are insufficiently powerful to reliably attack aligned text models: even when current NLP-based attacks fail, we can find adversarial inputs with brute force. As a result, the failure of current attacks should not be seen as proof that aligned text models remain aligned under adversarial inputs. \nDocument 1: List of 2023 Open Access papers by daphne ippolito are:\nReverse-Engineering Decoding Strategies Given Blackbox Access to a Language Generation System\nA Pretrainer's Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, & Toxicity\nExtracting Training Data from Diffusion Models\nAre aligned neural networks adversarially aligned? \n\n"
"Who is the faculty member associated with the paper titled ""Purpose in the Machine: Do Traffic Simulators Produce Distributionally Equivalent Outcomes for Reinforcement Learning Applications?""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Who is the faculty member associated with the paper titled ""Purpose in the Machine: Do Traffic Simulators Produce Distributionally Equivalent Outcomes for Reinforcement Learning Applications?""?\nContext: Document 0: Faculty Name: norman sadeh\nMetadata:\nPaperid: 3625207ac4fcdf8aa091a589dd6efc996062e3fb\nTitle: Purpose in the Machine: Do Traffic Simulators Produce Distributionally Equivalent Outcomes for Reinforcement Learning Applications?\nYear: 2023\nAbstract: Traffic simulators are used to generate data for learning in intelligent transportation systems (ITSs). A key question is to what extent their modelling assumptions affect the capabilities of ITSs to adapt to various scenarios when deployed in the real world. This work focuses on two simulators commonly used to train reinforcement learning (RL) agents for traffic applications, CityFlow and SUMO. A controlled virtual experiment varying driver behavior and simulation scale finds evidence against distributional equivalence in RL-relevant measures from these simulators, with the root mean squared error and KL divergence being significantly greater than 0 for all assessed measures. While granular real-world validation generally remains infeasible, these findings suggest that traffic simulators are not a deus ex machina for RL training: understanding the impacts of inter-simulator differences is necessary to train and deploy RL-based ITSs. \nDocument 1: List of 2023 Open Access papers by norman sadeh are:\nDo Privacy Labels Answer Users' Privacy Questions?\nExploring Smart Commercial Building Occupants’ Perceptions and Notification Preferences of Internet of Things Data Collection in the United States\nComparing Privacy Label Disclosures of Apps Published in both the App Store and Google Play Stores\nATLAS: Automatically Detecting Discrepancies Between Privacy Policies and Privacy Labels\nPurpose in the Machine: Do Traffic Simulators Produce Distributionally Equivalent Outcomes for Reinforcement Learning Applications?\nUnderstanding How to Inform Blind and Low-Vision Users about Data Privacy through Privacy Question Answering Assistants \n\n"
"What year was the paper titled ""Self-Refine: Iterative Refinement with Self-Feedback"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: What year was the paper titled ""Self-Refine: Iterative Refinement with Self-Feedback"" published?\nContext: Document 0: Faculty Name: sean welleck\nMetadata:\nPaperid: 3aaf6a2cbad5850ad81ab5c163599cb3d523436f\nTitle: Self-Refine: Iterative Refinement with Self-Feedback\nYear: 2023\nAbstract: Like humans, large language models (LLMs) do not always generate the best output on their first try. Motivated by how humans refine their written text, we introduce Self-Refine, an approach for improving initial outputs from LLMs through iterative feedback and refinement. The main idea is to generate an initial output using an LLMs; then, the same LLMs provides feedback for its output and uses it to refine itself, iteratively. Self-Refine does not require any supervised training data, additional training, or reinforcement learning, and instead uses a single LLM as the generator, refiner, and feedback provider. We evaluate Self-Refine across 7 diverse tasks, ranging from dialog response generation to mathematical reasoning, using state-of-the-art (GPT-3.5, ChatGPT, and GPT-4) LLMs. \nDocument 1: Faculty Name: yang yiming\nMetadata:\nPaperid: 3aaf6a2cbad5850ad81ab5c163599cb3d523436f\nTitle: Self-Refine: Iterative Refinement with Self-Feedback\nYear: 2023\nAbstract: Like humans, large language models (LLMs) do not always generate the best output on their first try. Motivated by how humans refine their written text, we introduce Self-Refine, an approach for improving initial outputs from LLMs through iterative feedback and refinement. The main idea is to generate an initial output using an LLMs; then, the same LLMs provides feedback for its output and uses it to refine itself, iteratively. Self-Refine does not require any supervised training data, additional training, or reinforcement learning, and instead uses a single LLM as the generator, refiner, and feedback provider. We evaluate Self-Refine across 7 diverse tasks, ranging from dialog response generation to mathematical reasoning, using state-of-the-art (GPT-3.5, ChatGPT, and GPT-4) LLMs. \n\n"
"Who is the faculty member associated with the paper titled ""Ruffle&Riley: Towards the Automated Induction of Conversational Tutoring Systems""?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: Who is the faculty member associated with the paper titled ""Ruffle&Riley: Towards the Automated Induction of Conversational Tutoring Systems""?\nContext: Document 0: Faculty Name: tom mitchell\nMetadata:\nPaperid: 5b7dcf469c285381a83b1bfd85d2b22da121e0cc\nTitle: Ruffle&Riley: Towards the Automated Induction of Conversational Tutoring Systems\nYear: 2023\nAbstract: Conversational tutoring systems (CTSs) offer learning experiences driven by natural language interaction. They are known to promote high levels of cognitive engagement and benefit learning outcomes, particularly in reasoning tasks. Nonetheless, the time and cost required to author CTS content is a major obstacle to widespread adoption. In this paper, we introduce a novel type of CTS that leverages the recent advances in large language models (LLMs) in two ways: First, the system induces a tutoring script automatically from a lesson text. Second, the system automates the script orchestration via two LLM-based agents (Ruffle&Riley) with the roles of a student and a professor in a learning-by-teaching format. The system allows a free-form conversation that follows the ITS-typical inner and outer loop structure. \nDocument 1: List of 2023 Open Access papers by tom mitchell are:\nPlan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents\nThe Roles of Symbols in Neural-based AI: They are Not What You Think!\nThe Internal State of an LLM Knows When its Lying\nNeuropilin-1 interacts with VE-cadherin and TGFBR2 to stabilize adherens junctions and prevent activation of endothelium under flow\nThe unconventional Myosin-1C augments endothelial secretion of von Willebrand factor by linking contractile actomyosin machinery to the plasma membrane\nRuffle&Riley: Towards the Automated Induction of Conversational Tutoring Systems\nSynthetic biology open language (SBOL) version 3.1.0\nRead and Reap the Rewards: Learning to Play Atari with the Help of Instruction Manuals\nLearning to Give Useful Hints: Assistance Action Evaluation and Policy Improvements\nGenitourinary Management and Follow-Up for Patients with Stevens-Johnson Syndrome/Toxic Epidermal Necrolysis\nFumarate induces vesicular release of mtDNA to drive innate immunity\nFLAIRR-Seq: A Method for Single-Molecule Resolution of Near Full-Length Antibody H Chain Repertoires. \n\n"
"What year was the paper titled ""Convoifilter: A case study of doing cocktail party speech recognition"" published?","\nSystem : You are an expert extraction algorithm. Only extract relevant information from the given context. \nInstruction : Answer using 1 sentence only. If you do not know the answer for the question, return ""I don't know"" as the answer.\nQuestion: What year was the paper titled ""Convoifilter: A case study of doing cocktail party speech recognition"" published?\nContext: Document 0: Faculty Name: alexander waibel\nMetadata:\nPaperid: 7e13fcb7b7bae202fb9087e87abaa71a4b19a3e3\nTitle: Convoifilter: A case study of doing cocktail party speech recognition\nYear: 2023\nAbstract: This paper presents an end-to-end model designed to improve automatic speech recognition (ASR) for a particular speaker in a crowded, noisy environment. The model utilizes a single-channel speech enhancement module that isolates the speaker's voice from background noise (ConVoiFilter) and an ASR module. The model can decrease ASR's word error rate (WER) from 80% to 26.4% through this approach. Typically, these two components are adjusted independently due to variations in data requirements. However, speech enhancement can create anomalies that decrease ASR efficiency. By implementing a joint fine-tuning strategy, the model can reduce the WER from 26.4% in separate tuning to 14.5% in joint tuning. We openly share our pre-trained model to foster further research hf.co/nguyenvulebinh/voice-filter. \nDocument 1: List of 2023 Open Access papers by alexander waibel are:\nAdapITN: A Fast, Reliable, and Dynamic Adaptive Inverse Text Normalization\nTrain Global, Tailor Local: Minimalist Multilingual Translation into Endangered Languages\nTowards Efficient Simultaneous Speech Translation: CUNI-KIT System for Simultaneous Track at IWSLT 2023\nSYNTACC : Synthesizing Multi-Accent Speech By Weight Factorization\nKIT’s Multilingual Speech Translation System for IWSLT 2023\nConvoifilter: A case study of doing cocktail party speech recognition\nContinually learning new languages\nIncremental Blockwise Beam Search for Simultaneous Speech Translation with Controllable Quality-Latency Tradeoff\nEnd-to-End Evaluation for Low-Latency Simultaneous Speech Translation\nFINDINGS OF THE IWSLT 2023 EVALUATION CAMPAIGN\nIncremental Learning of Humanoid Robot Behavior from Natural Interaction and Large Language Models \n\n"
