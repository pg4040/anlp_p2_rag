[
  "Faculty Name: alexander hauptmann\nPaperid: 2107b867cb8f8afa30a9a940288d7c8b657f8aa5\nTitle: Zero-Shot and Few-Shot Stance Detection on Varied Topics via Conditional Generation\nYear: 2023\nAbstract: Zero-shot and few-shot stance detection identify the polarity of text with regard to a certain target when we have only limited or no training resources for the target. Previous work generally formulates the problem into a classification setting, ignoring the potential use of label text. In this paper, we instead utilize a conditional generation framework and formulate the problem as denoising from partially-filled templates, which can better utilize the semantics among input, label, and target texts. We further propose to jointly train an auxiliary task, target prediction, and to incorporate manually constructed incorrect samples with unlikelihood training to improve the representations for both target and label texts. We also verify the effectiveness of target-related Wikipedia knowledge with the generation framework. Experiments show that our proposed method significantly outperforms several strong baselines on VAST, and achieves new state-of-the-art performance.",
  "We also verify the effectiveness of target-related Wikipedia knowledge with the generation framework. Experiments show that our proposed method significantly outperforms several strong baselines on VAST, and achieves new state-of-the-art performance.\nAuthors: Haoyang Wen, A. Hauptmann\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper utilizes a conditional generation framework and formulates the zero-shot and few-shot stance detection problem as denoising from partially-filled templates, which can better utilize the semantics among input, label, and target texts.'}\nUrl: https://aclanthology.org/2023.acl-short.127.pdf",
  "Faculty Name: alexander hauptmann\nPaperid: 376f494126d1ea4f571ea0263c43ac2b6331800a\nTitle: SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs\nYear: 2023\nAbstract: In this work, we introduce Semantic Pyramid AutoEncoder (SPAE) for enabling frozen LLMs to perform both understanding and generation tasks involving non-linguistic modalities such as images or videos. SPAE converts between raw pixels and interpretable lexical tokens (or words) extracted from the LLM's vocabulary. The resulting tokens capture both the semantic meaning and the fine-grained details needed for visual reconstruction, effectively translating the visual content into a language comprehensible to the LLM, and empowering it to perform a wide array of multimodal tasks. Our approach is validated through in-context learning experiments with frozen PaLM 2 and GPT 3.5 on a diverse set of image understanding and generation tasks. Our method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%.",
  "Our method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%.\nAuthors: Lijun Yu, Yong Cheng, Zhiruo Wang, Vivek Kumar, Wolfgang Macherey, Yanping Huang, David A. Ross, Irfan Essa, Yonatan Bisk, Ming Yang, K. Murphy, A. Hauptmann, Lu Jiang\nVenue: Neural Information Processing Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%.'}\nUrl: http://arxiv.org/pdf/2306.17842",
  "Faculty Name: alexander hauptmann\nPaperid: 405e3910e06c9efe7e660b8697bcb4bab4e92f48\nTitle: STMT: A Spatial-Temporal Mesh Transformer for MoCap-Based Action Recognition\nYear: 2023\nAbstract: We study the problem of human action recognition using motion capture (MoCap) sequences. Unlike existing techniques that take multiple manual steps to derive standard-ized skeleton representations as model input, we propose a novel Spatial-Temporal Mesh Transformer (STMT) to directly model the mesh sequences. The model uses a hierarchical transformer with intra-frame off-set attention and inter-frame self-attention. The attention mechanism allows the model to freely attend between any two vertex patches to learn nonlocal relationships in the spatial-temporal domain. Masked vertex modeling and future frame prediction are used as two self-supervised tasks to fully activate the bi-directional and auto-regressive attention in our hierarchical transformer. The proposed method achieves state-of-the-art performance compared to skeleton-based and point-cloud-based models on common MoCap benchmarks. Code is available at https://github.com/zgzxy001/STMT.",
  "The proposed method achieves state-of-the-art performance compared to skeleton-based and point-cloud-based models on common MoCap benchmarks. Code is available at https://github.com/zgzxy001/STMT.\nAuthors: Xiaoyu Zhu, Po-Yao (Bernie) Huang, Junwei Liang, Celso M. de Melo, A. Hauptmann\nVenue: Computer Vision and Pattern Recognition\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A novel Spatial-Temporal Mesh Transformer (STMT) is proposed to directly model the mesh sequences using motion capture sequences to achieve state-of-the-art performance compared to skeleton-based and point-cloud-based models on common MoCap benchmarks.'}\nUrl: https://arxiv.org/pdf/2303.18177",
  "Faculty Name: alexander hauptmann\nPaperid: 72cce47fd053bf916314d89a8174726c58c05e02\nTitle: Towards Open-Domain Twitter User Profile Inference\nYear: 2023\nAbstract: ,\nAuthors: Haoyang Wen, Zhenxin Xiao, E. Hovy, Alexander Hauptmann\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': None}\nUrl: https://aclanthology.org/2023.findings-acl.198.pdf",
  "Faculty Name: alexander hauptmann\nPaperid: 8ccda6de0223bcd897d5dc0efc8f33222a899d0d\nTitle: DocumentNet: Bridging the Data Gap in Document Pre-training\nYear: 2023\nAbstract: Document understanding tasks, in particular, Visually-rich Document Entity Retrieval (VDER), have gained significant attention in recent years thanks to their broad applications in enterprise AI. However, publicly available data have been scarce for these tasks due to strict privacy constraints and high annotation costs. To make things worse, the non-overlapping entity spaces from different datasets hinder the knowledge transfer between document types. In this paper, we propose a method to collect massive-scale and weakly labeled data from the web to benefit the training of VDER models. The collected dataset, named DocumentNet, does not depend on specific document types or entity sets, making it universally applicable to all VDER tasks. The current DocumentNet consists of 30M documents spanning nearly 400 document types organized in a four-level ontology.",
  "The collected dataset, named DocumentNet, does not depend on specific document types or entity sets, making it universally applicable to all VDER tasks. The current DocumentNet consists of 30M documents spanning nearly 400 document types organized in a four-level ontology. Experiments on a set of broadly adopted VDER tasks show significant improvements when DocumentNet is incorporated into the pre-training for both classic and few-shot learning settings. With the recent emergence of large language models (LLMs), DocumentNet provides a large data source to extend their multi-modal capabilities for VDER.\nAuthors: Lijun Yu, Jin Miao, Xiaoyu Sun, Jiayi Chen, A. Hauptmann, H. Dai, Wei Wei\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper proposes a method to collect massive-scale and weakly labeled data from the web to benefit the training of VDER models, and provides a large data source to extend their multi-modal capabilities for VDER.'}\nUrl: https://aclanthology.org/2023.emnlp-industry.66.pdf",
  "Faculty Name: alexander hauptmann\nPaperid: 985f0c89c5a607742ec43c1fdc2cbfe54541cbad\nTitle: Language Model Beats Diffusion - Tokenizer is Key to Visual Generation\nYear: 2023\nAbstract: While Large Language Models (LLMs) are the dominant models for generative tasks in language, they do not perform as well as diffusion models on image and video generation. To effectively use LLMs for visual generation, one crucial component is the visual tokenizer that maps pixel-space inputs to discrete tokens appropriate for LLM learning. In this paper, we introduce MAGVIT-v2, a video tokenizer designed to generate concise and expressive tokens for both videos and images using a common token vocabulary. Equipped with this new tokenizer, we show that LLMs outperform diffusion models on standard image and video generation benchmarks including ImageNet and Kinetics. In addition, we demonstrate that our tokenizer surpasses the previously top-performing video tokenizer on two more tasks: (1) video compression comparable to the next-generation video codec (VCC) according to human evaluations, and (2) learning effective representations for action recognition tasks.",
  "In addition, we demonstrate that our tokenizer surpasses the previously top-performing video tokenizer on two more tasks: (1) video compression comparable to the next-generation video codec (VCC) according to human evaluations, and (2) learning effective representations for action recognition tasks.\nAuthors: Lijun Yu, Jos'e Lezama, Nitesh B. Gundavarapu, Luca Versari, Kihyuk Sohn, David C. Minnen, Yong Cheng, Agrim Gupta, Xiuye Gu, Alexander G. Hauptmann, Boqing Gong, Ming-Hsuan Yang, Irfan Essa, David A. Ross, Lu Jiang\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': None}\nUrl: https://arxiv.org/pdf/2310.05737",
  "Faculty Name: alexander hauptmann\nPaperid: e371d10dd65c8bb25375f3c09d1c0cac777cca65\nTitle: Hyperbolic vs Euclidean Embeddings in Few-Shot Learning: Two Sides of the Same Coin\nYear: 2023\nAbstract: Recent research in representation learning has shown that hierarchical data lends itself to low-dimensional and highly informative representations in hyperbolic space. However, even if hyperbolic embeddings have gathered attention in image recognition, their optimization is prone to numerical hurdles. Further, it remains unclear which applications stand to benefit the most from the implicit bias imposed by hyperbolicity, when compared to traditional Euclidean features. In this paper, we focus on prototypical hyperbolic neural networks. In particular, the tendency of hyperbolic embeddings to converge to the boundary of the Poincar\\'e ball in high dimensions and the effect this has on few-shot classification. We show that the best few-shot results are attained for hyperbolic embeddings at a common hyperbolic radius.",
  "In particular, the tendency of hyperbolic embeddings to converge to the boundary of the Poincar\\'e ball in high dimensions and the effect this has on few-shot classification. We show that the best few-shot results are attained for hyperbolic embeddings at a common hyperbolic radius. In contrast to prior benchmark results, we demonstrate that better performance can be achieved by a fixed-radius encoder equipped with the Euclidean metric, regardless of the embedding dimension.\nAuthors: Gabriel Moreira, Manuel Marques, J. Costeira, Alexander Hauptmann\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is demonstrated that better performance can be achieved by a fixed-radius encoder equipped with the Euclidean metric, regardless of the embedding dimension, and that the best few-shot results are attained for hyperbolic embeddings at a commonhyperbolic radius.'}\nUrl: https://arxiv.org/pdf/2309.10013",
  "List of 2023 Open Access papers by alexander hauptmann are:\nTowards Open-Domain Twitter User Profile Inference\nZero-Shot and Few-Shot Stance Detection on Varied Topics via Conditional Generation\nSPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs\nSTMT: A Spatial-Temporal Mesh Transformer for MoCap-Based Action Recognition\nDocumentNet: Bridging the Data Gap in Document Pre-training\nLanguage Model Beats Diffusion - Tokenizer is Key to Visual Generation\nHyperbolic vs Euclidean Embeddings in Few-Shot Learning: Two Sides of the Same Coin",
  "Faculty Name: alexander rudnicky\nPaperid: 06a8f2e3c4266196b008851f1ec7ef9f340809da\nTitle: Advancing Regular Language Reasoning in Linear Recurrent Neural Networks\nYear: 2023\nAbstract: In recent studies, linear recurrent neural networks (LRNNs) have achieved Transformer-level performance in natural language modeling and long-range modeling while offering rapid parallel training and constant inference costs. With the resurged interest in LRNNs, we study whether they can learn the hidden rules in training sequences, such as the grammatical structures of regular language. We theoretically analyze some existing LRNNs and discover their limitations on regular language. Motivated by the analysis, we propose a new LRNN equipped with a block-diagonal and input-dependent transition matrix. Experiments suggest that the proposed model is the only LRNN that can perform length extrapolation on regular language tasks such as Sum, Even Pair, and Modular Arithmetic.",
  "Motivated by the analysis, we propose a new LRNN equipped with a block-diagonal and input-dependent transition matrix. Experiments suggest that the proposed model is the only LRNN that can perform length extrapolation on regular language tasks such as Sum, Even Pair, and Modular Arithmetic.\nAuthors: Ting-Han Fan, Ta-Chung Chi, Alexander I. Rudnicky\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work theoretically analyze some existing LRNNs and proposes a new LRNN equipped with a block-diagonal and input-dependent transition matrix that is the only LRNN that can perform length extrapolation on regular language tasks such as Sum, Even Pair, and Modular Arithmetic.'}\nUrl: https://arxiv.org/pdf/2309.07412",
  "Faculty Name: alexander rudnicky\nPaperid: 161bf3f0705ef8e088f53b383363338daac9af44\nTitle: Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings\nYear: 2023\nAbstract: The use of positional embeddings in transformer language models is widely accepted. However, recent research has called into question the necessity of such embeddings. We further extend this inquiry by demonstrating that a randomly initialized and frozen transformer language model, devoid of positional embeddings, inherently encodes strong positional information through the shrinkage of self-attention variance. To quantify this variance, we derive the underlying distribution of each step within a transformer layer. Through empirical validation using a fully pretrained model, we show that the variance shrinkage effect still persists after extensive gradient updates. Our findings serve to justify the decision to discard positional embeddings and thus facilitate more efficient pretraining of transformer language models.",
  "Through empirical validation using a fully pretrained model, we show that the variance shrinkage effect still persists after extensive gradient updates. Our findings serve to justify the decision to discard positional embeddings and thus facilitate more efficient pretraining of transformer language models.\nAuthors: Ta-Chung Chi, Ting-Han Fan, Li-Wei Chen, A. Rudnicky, P. Ramadge\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work demonstrates that a randomly initialized and frozen transformer language model, devoid of positional embeddings, inherently encodes strong positional information through the shrinkage of self-attention variance, and derives the underlying distribution of each step within a transformer layer.'}\nUrl: http://arxiv.org/pdf/2305.13571",
  "Faculty Name: alexander rudnicky\nPaperid: 2670612b5e11297cd9b98f4d7ff796725f77fe35\nTitle: Structured Dialogue Discourse Parsing\nYear: 2023\nAbstract: Dialogue discourse parsing aims to uncover the internal structure of a multi-participant conversation by finding all the discourse links and corresponding relations. Previous work either treats this task as a series of independent multiple-choice problems, in which the link existence and relations are decoded separately, or the encoding is restricted to only local interaction, ignoring the holistic structural information. In contrast, we propose a principled method that improves upon previous work from two perspectives: encoding and decoding. From the encoding side, we perform structured encoding on the adjacency matrix followed by the matrix-tree learning algorithm, where all discourse links and relations in the dialogue are jointly optimized based on latent tree-level distribution. From the decoding side, we perform structured inference using the modified Chiu-Liu-Edmonds algorithm, which explicitly generates the labeled multi-root non-projective spanning tree that best captures the discourse structure. In addition, unlike in previous work, we do not rely on hand-crafted features; this improves the model\u2019s robustness.",
  "In addition, unlike in previous work, we do not rely on hand-crafted features; this improves the model\u2019s robustness. Experiments show that our method achieves new state-of-the-art, surpassing the previous model by 2.3 on STAC and 1.5 on Molweni (F1 scores).\nAuthors: Ta-Chung Chi, Alexander I. Rudnicky\nVenue: SIGDIAL Conferences\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes a principled method that improves upon previous work from two perspectives: encoding and decoding and achieves new state-of-the-art results, surpassing the previous model by 2.3 on STAC and 1.5 on Molweni (F1 scores).'}\nUrl: http://arxiv.org/pdf/2306.15103",
  "Faculty Name: alexander rudnicky\nPaperid: 465ec2212d865e875e64638b3dd1ecaac21c5ddd\nTitle: Transformer Working Memory Enables Regular Language Reasoning and Natural Language Length Extrapolation\nYear: 2023\nAbstract: Unlike recurrent models, conventional wisdom has it that Transformers cannot perfectly model regular languages. Inspired by the notion of working memory, we propose a new Transformer variant named RegularGPT. With its novel combination of Weight-Sharing, Adaptive-Depth, and Sliding-Dilated-Attention, RegularGPT constructs working memory along the depth dimension, thereby enabling efficient and successful modeling of regular languages such as PARITY. We further test RegularGPT on the task of natural language length extrapolation and surprisingly find that it rediscovers the local windowed attention effect deemed necessary in prior work for length extrapolation.",
  "We further test RegularGPT on the task of natural language length extrapolation and surprisingly find that it rediscovers the local windowed attention effect deemed necessary in prior work for length extrapolation.\nAuthors: Ta-Chung Chi, Ting-Han Fan, A. Rudnicky, P. Ramadge\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Inspired by the notion of working memory, a new Transformer variant named RegularGPT is proposed, which constructs working memory along the depth dimension, thereby enabling efficient and successful modeling of regular languages such as PARITY.'}\nUrl: http://arxiv.org/pdf/2305.03796",
  "Faculty Name: alexander rudnicky\nPaperid: 4b8d3ede673ddeab9dfb5184da6b748d7a526754\nTitle: A Vector Quantized Approach for Text to Speech Synthesis on Real-World Spontaneous Speech\nYear: 2023\nAbstract: Recent Text-to-Speech (TTS) systems trained on reading or acted corpora have achieved near human-level naturalness. The diversity of human speech, however, often goes beyond the coverage of these corpora. We believe the ability to handle such diversity is crucial for AI systems to achieve human-level communication. Our work explores the use of more abundant real-world data for building speech synthesizers. We train TTS systems using real-world speech from YouTube and podcasts. We observe the mismatch between training and inference alignments in mel-spectrogram based autoregressive models, leading to unintelligible synthesis, and demonstrate that learned discrete codes within multiple code groups effectively resolves this issue. We introduce our MQTTS system whose architecture is designed for multiple code generation and monotonic alignment, along with the use of a clean silence prompt to improve synthesis quality.",
  "We introduce our MQTTS system whose architecture is designed for multiple code generation and monotonic alignment, along with the use of a clean silence prompt to improve synthesis quality. We conduct ablation analyses to identify the efficacy of our methods. We show that MQTTS outperforms existing TTS systems in several objective and subjective measures.\nAuthors: Li-Wei Chen, Shinji Watanabe, Alexander I. Rudnicky\nVenue: AAAI Conference on Artificial Intelligence\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work introduces the MQTTS system, a Text-to-Speech system whose architecture is designed for multiple code generation and monotonic alignment, along with the use of a clean silence prompt to improve synthesis quality, and shows that MqTTS outperforms existing TTS systems in several objective and subjective measures.'}\nUrl: http://arxiv.org/pdf/2302.04215",
  "Faculty Name: alexander rudnicky\nPaperid: 9799c17fd287bb9e8d231fe032c6dbf9c0c9d675\nTitle: Overview of Robust and Multilingual Automatic Evaluation Metrics\n\nfor Open-Domain Dialogue Systems at DSTC 11 Track 4\nYear: 2023\nAbstract: The advent and fast development of neural networks have revolutionized the research on dialogue systems and subsequently have triggered various challenges regarding their automatic evaluation. Automatic evaluation of open-domain dialogue systems as an open challenge has been the center of the attention of many researchers. Despite the consistent efforts to improve automatic metrics\u2019 correlations with human evaluation, there have been very few attempts to assess their robustness over multiple domains and dimensions. Also, their focus is mainly on the English language. All of these challenges prompt the development of automatic evaluation metrics that are reliable in various domains, dimensions, and languages. This track in the 11th Dialogue System Technology Challenge (DSTC11) is part of the ongoing effort to promote robust and multilingual automatic evaluation metrics. This article describes the datasets and baselines provided to participants and discusses the submission and result details of the two proposed subtasks.",
  "This track in the 11th Dialogue System Technology Challenge (DSTC11) is part of the ongoing effort to promote robust and multilingual automatic evaluation metrics. This article describes the datasets and baselines provided to participants and discusses the submission and result details of the two proposed subtasks.\nAuthors: Mario Rodr'iguez-Cantelar, Chen Zhang, Chengguang Tang, Ke Shi, Sarik Ghazarian, Jo\u00e3o Sedoc, L. F. D\u2019Haro, Alexander I. Rudnicky\nVenue: DSTC\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The datasets and baselines provided to participants are described and the submission and result details of the two proposed subtasks are discussed, which promote robust and multilingual automatic evaluation metrics.'}\nUrl: https://arxiv.org/pdf/2306.12794",
  "Faculty Name: alexander rudnicky\nPaperid: f743324682d5d50db9b114fa60b908f09c10c9a0\nTitle: Learning to Ask Questions for Zero-shot Dialogue State Tracking\nYear: 2023\nAbstract: We present a method for performing zero-shot Dialogue State Tracking (DST) by casting the task as a learning-to-ask-questions framework. The framework learns to pair the best question generation (QG) strategy with in-domain question answering (QA) methods to extract slot values from a dialogue without any human intervention. A novel self-supervised QA pretraining step using in-domain data is essential to learn the structure without requiring any slot-filling annotations. Moreover, we show that QG methods need to be aligned with the same grammatical person used in the dialogue. Empirical evaluation on the MultiWOZ 2.1 dataset demonstrates that our approach, when used alongside robust QA models, outperforms existing zero-shot methods in the challenging task of zero-shot cross domain adaptation-given a comparable amount of domain knowledge during data creation.",
  "Empirical evaluation on the MultiWOZ 2.1 dataset demonstrates that our approach, when used alongside robust QA models, outperforms existing zero-shot methods in the challenging task of zero-shot cross domain adaptation-given a comparable amount of domain knowledge during data creation. Finally, we analyze the impact of the types of questions used, and demonstrate that the algorithmic approach outperforms template-based question generation.\nAuthors: Diogo Tavares, David Semedo, Alexander I. Rudnicky, Jo\u00e3o Magalh\u00e3es\nVenue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work presents a method for performing zero-shot Dialogue State Tracking by casting the task as a learning-to-ask-questions framework that outperforms template-based question generation and shows that QG methods need to be aligned with the same grammatical person used in the dialogue.'}\nUrl: https://dl.acm.org/doi/pdf/10.1145/3539618.3592010",
  "List of 2023 Open Access papers by alexander rudnicky are:\nAdvancing Regular Language Reasoning in Linear Recurrent Neural Networks\nStructured Dialogue Discourse Parsing\nA Vector Quantized Approach for Text to Speech Synthesis on Real-World Spontaneous Speech\nOverview of Robust and Multilingual Automatic Evaluation Metrics\n\nfor Open-Domain Dialogue Systems at DSTC 11 Track 4\nLearning to Ask Questions for Zero-shot Dialogue State Tracking\nLatent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings\nTransformer Working Memory Enables Regular Language Reasoning and Natural Language Length Extrapolation",
  "List of 2023 Open Access papers by alexander waibel are:\nAdapITN: A Fast, Reliable, and Dynamic Adaptive Inverse Text Normalization\nTrain Global, Tailor Local: Minimalist Multilingual Translation into Endangered Languages\nTowards Efficient Simultaneous Speech Translation: CUNI-KIT System for Simultaneous Track at IWSLT 2023\nSYNTACC : Synthesizing Multi-Accent Speech By Weight Factorization\nKIT\u2019s Multilingual Speech Translation System for IWSLT 2023\nConvoifilter: A case study of doing cocktail party speech recognition\nContinually learning new languages\nIncremental Blockwise Beam Search for Simultaneous Speech Translation with Controllable Quality-Latency Tradeoff\nEnd-to-End Evaluation for Low-Latency Simultaneous Speech Translation\nFINDINGS OF THE IWSLT 2023 EVALUATION CAMPAIGN\nIncremental Learning of Humanoid Robot Behavior from Natural Interaction and Large Language Models",
  "Alexander Hauptmann\nResearch Professor, Language Technologies Institute\nResearch Area\nInformation Extraction, Summarization and Question Answering, Information Retrieval, Text Mining and Analytics, Machine Learning, Multimodal Computing and Interaction\nResearch\nMy research interests revolve around the integration of text, image, video, and audio analysis. In the Informedia Project we built the News-on-Demand application, which is an instantiation of the Informedia Digital Video Library idea, based completely on automatic methods for processing television and radio news. Through the combination of the strengths of speech recognition, natural language processing, information retrieval and interface design, the system is able to overcome some of the shortfalls inherent in each of the component technologies.My goal is to utilize large corpora of \"found data\", i.e., data that is already available through the Internet or other readily accessible open sources, to improve speech and natural language processing by exploiting advantages across different modalities. It has become clear in recent years that large volumes of text, image, video, and audio can be easily stored and made available for research and applications. However, most of these sources were not produced with computer processing in mind.",
  "It has become clear in recent years that large volumes of text, image, video, and audio can be easily stored and made available for research and applications. However, most of these sources were not produced with computer processing in mind. My intention is to design and build intelligent, understanding programs that help process data from these sources and make the data useful for other applications. This data can be used to improve speech recognition, image understanding, natural language processing, machine learning as well as information retrieval. The challenge is to find the right data, process it into suitable form for training, learning or re-use and build mechanisms that can successfully utilize this data.Speech and multimedia technology are about to make a major impact on our daily interaction with computers. What is needed at this point are clear demonstrations of the advantages of integrated speech and multimedia interfaces.\nCV (brief) https://lti.cmu.edu/people/faculty/faculty-bio-images/alexanderhauptmann_cv_short_jul2017.pdf\nContact 5519 \u2014Gates & Hillman Centers\nEmail alex@cs.cmu.edu\n412-268-1448",
  "Alexander Rudnicky\nResearch Professor Emeritus, Language Technologies Institute\nContact\n6511 \u2014Gates & Hillman Centers\nEmail alex.rudnicky@cs.cmu.edu\n412-268-2622\nResearch Area\nMultimodal Computing and Interaction, Speech Processing, Spoken Interfaces and Dialogue Processing\n\nResearch\nMy research centers on interactive systems that use speech. I am currently interested in the following problems:\n\nImplicit Learning : Human-computer interaction generates information that the system could use to modify its behavior. For example, a speech recognition error that is repaired leaves information about a misclassification that could be used to improve subsequent accuracy. Exploiting such situations (and in fact contriving to create them) can provide a rich set of experiences that drive self-improving systems\n\nAutomatic detection and recovery from error: Humans easily detect and recover from breakdowns in communication. Automatic systems are less successful at this, however we can use features of recognition, understanding and dialog to predict the likelihood of misunderstanding at a given point in an interaction, and then apply heuristic strategies for guiding the conversation back onto track.",
  "Automatic systems are less successful at this, however we can use features of recognition, understanding and dialog to predict the likelihood of misunderstanding at a given point in an interaction, and then apply heuristic strategies for guiding the conversation back onto track.\n\nA theory of language design for speech-based interactive systems: Speech-mode communication predisposes the user to make certain word choices and to exhibit certain grammatical preferences. An understanding of the principles that underlie these preferences (and how these can be influenced by the system's language) leads to better language design for interactive systems.\n\nThe role of speech in the computer interface: Speech is an effective means of communication, but it is not always suitable for all types of interaction. Ideally we can analyze an interface in terms of the task(s) it will be used for, the costs of specific interactions and the value perceived by the user. To date we've studied models based on time, system error and task structure. These models turn out to be useful for simple systems and appear to be extensible to more complex systems.",
  "To date we've studied models based on time, system error and task structure. These models turn out to be useful for simple systems and appear to be extensible to more complex systems. Many of these issues are being explored in the context of working systems, for example a language interface for a team of humans and robots working together (Treasure Hunt) or a information access for conferences (ConQuest) or for scheduling court time (Let\u2019s Play).\n\nPersonal Website http://www.cs.cmu.edu/~air/",
  "Alexander Waibel\nProfessor (On Leave), Language Technologies Institute\nContact\n205 \u2014407 South Craig Street\nEmail waibel@cs.cmu.edu\n412-268-7676\nResearch Area\nMachine Learning, Machine Translation, Multimodal Computing and Interaction, Neural Networks, Speech Processing, Spoken Interfaces and Dialogue Processing, Spoken Language Translation\n\nBio\nDr. Alexander Waibel is a Professor of Computer Science at Carnegie Mellon University, Pittsburgh and at the Karlsruhe Institute of Technology, Germany. He is the director of the International Center for Advanced Communication Technologies (interACT). The Center works in a network with eight of the world\u2019s top research institutions. The Center\u2019s mission is to develop advanced machine learning algorithms to improve human-human and human-machine communication technologies.  Prof. Waibel and his team developed many statistical and neural network learning  algorithms that made such communication breakthroughs possible. Most notably, the \u201cTime-Delay Neural Network\u201d (1987) (the first \u201cconvolutional\u201d neural network) now is at the heart of many of today\u2019s AI technologies.",
  "Waibel and his team developed many statistical and neural network learning  algorithms that made such communication breakthroughs possible. Most notably, the \u201cTime-Delay Neural Network\u201d (1987) (the first \u201cconvolutional\u201d neural network) now is at the heart of many of today\u2019s AI technologies. System breakthroughs at Waibel\u2019s lab included early multimodal interfaces, speech and language interfaces, the first speech translation system in Europe & USA (1990/1991), the first simultaneous lecture translation system (2005), and Jibbigo, the first commercial speech translator on a phone (2009).\n\nDr. Waibel founded and served as chairmen of C-STAR, the Consortium for Speech Translation Advanced Research in 1991. He directed many research programs in speech, translation, multimodal interfaces and machine learning in the US, Europe and Asia. He served as director of EU-Bridge (2012-2015) and CHIL (2004-2007), two large European multi-site Integrated Project initiatives on intelligent assistants and speech translation services. He also was co-director of IMMI, a joint venture between KIT, CNRS & RWTH.\n\nDr.",
  "He also was co-director of IMMI, a joint venture between KIT, CNRS & RWTH.\n\nDr. Waibel is an IEEE Fellow and received many awards for his work on multilingual and multimodal communication  and translation. He published extensively (>750 publications, >25,000 citations, h-index 80) in the field and received/filed numerous patents. Waibel was elected to the National Academy of Sciences of Germany in 2017, and was named Honorary Senator of the Hochschulrektorenkonferenz (Representation of German Universities).\n\nDuring his career, Dr. Waibel founded and built ten successful companies. Following the acquisition of Jibbigo by Facebook, Waibel served as founding director of the Language Technology Group at FB. He also deployed speech translation technologies in humanitarian and disaster relief missions. His team recently deployed the first simultaneous interpretation service for lectures at Universities and interpretation tools at the European Parliament. \n\nEducation\nDr. Waibel received his BS, MS and PhD degrees at Massachusetts Institute of Technology and CMU, respectively.\nPersonal Website https://www.cs.cmu.edu/~ahw/",
  "Faculty Name: bhiksha raj\nPaperid: 078f86c6a691806cc71bbef1e734f75690db0ffc\nTitle: FREDOM: Fairness Domain Adaptation Approach to Semantic Scene Understanding\nYear: 2023\nAbstract: Although Domain Adaptation in Semantic Scene Segmentation has shown impressive improvement in recent years, the fairness concerns in the domain adaptation have yet to be well defined and addressed. In addition, fairness is one of the most critical aspects when deploying the segmentation models into human-related real-world applications, e.g., autonomous driving, as any unfair predictions could influence human safety. In this paper, we propose a novel Fairness Domain Adaptation (FREDOM) approach to semantic scene segmentation. In particular, from the proposed formulated fairness objective, a new adaptation framework will be introduced based on the fair treatment of class distributions. Moreover, to generally model the context of structural dependency, a new conditional structural constraint is introduced to impose the consistency of predicted segmentation. Thanks to the proposed Conditional Structure Network, the self-attention mechanism has sufficiently modeled the structural information of segmentation.",
  "Moreover, to generally model the context of structural dependency, a new conditional structural constraint is introduced to impose the consistency of predicted segmentation. Thanks to the proposed Conditional Structure Network, the self-attention mechanism has sufficiently modeled the structural information of segmentation. Through the ablation studies, the proposed method has shown the performance improvement of the segmentation models and promoted fairness in the model predictions. The experimental results on the two standard benchmarks, i.e., SYNTHIA $\\rightarrow$ Cityscapes and GTA5 $\\rightarrow$ Cityscapes, have shown that our method achieved State-of-the-Art (SOTA) performance11The implementation of FREDOM is available at https://github.com/uark-cviu/FREDOM\nAuthors: Thanh-Dat Truong, Ngan T. H. Le, B. Raj, J. Cothren, Khoa Luu\nVenue: Computer Vision and Pattern Recognition\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper proposes a novel Fairness Domain Adaptation (FREDOM) approach to semantic scene segmentation, where a new adaptation framework will be introduced based on the fair treatment of class distributions to generally model the context of structural dependency.'}",
  "Url: https://arxiv.org/pdf/2304.02135",
  "Faculty Name: bhiksha raj\nPaperid: 0a8d38686b18f28aae1222529e6b9e8a60cab1c2\nTitle: UTOPIA: Unconstrained Tracking Objects without Preliminary Examination via Cross-Domain Adaptation\nYear: 2023\nAbstract: Multiple Object Tracking (MOT) aims to find bounding boxes and identities of targeted objects in consecutive video frames. While fully-supervised MOT methods have achieved high accuracy on existing datasets, they cannot generalize well on a newly obtained dataset or a new unseen domain. In this work, we first address the MOT problem from the cross-domain point of view, imitating the process of new data acquisition in practice. Then, a new cross-domain MOT adaptation from existing datasets is proposed without any pre-defined human knowledge in understanding and modeling objects. It can also learn and update itself from the target data feedback. The intensive experiments are designed on four challenging settings, including MOTSynth to MOT17, MOT17 to MOT20, MOT17 to VisDrone, and MOT17 to DanceTrack. We then prove the adaptability of the proposed self-supervised learning strategy.",
  "The intensive experiments are designed on four challenging settings, including MOTSynth to MOT17, MOT17 to MOT20, MOT17 to VisDrone, and MOT17 to DanceTrack. We then prove the adaptability of the proposed self-supervised learning strategy. The experiments also show superior performance on tracking metrics MOTA and IDF1, compared to fully supervised, unsupervised, and self-supervised state-of-the-art methods.\nAuthors: Pha Nguyen, Kha Gia Quach, J. Gauch, S. Khan, B. Raj, Khoa Luu\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A new cross-domain MOT adaptation from existing datasets is proposed without any pre-defined human knowledge in understanding and modeling objects, and it can also learn and update itself from the target data feedback.'}\nUrl: http://arxiv.org/pdf/2306.09613",
  "Faculty Name: bhiksha raj\nPaperid: 100da279ee981960884a12dfc5a0697c24ed315a\nTitle: SoftMatch: Addressing the Quantity-Quality Trade-off in Semi-supervised Learning\nYear: 2023\nAbstract: The critical challenge of Semi-Supervised Learning (SSL) is how to effectively leverage the limited labeled data and massive unlabeled data to improve the model's generalization performance. In this paper, we first revisit the popular pseudo-labeling methods via a unified sample weighting formulation and demonstrate the inherent quantity-quality trade-off problem of pseudo-labeling with thresholding, which may prohibit learning. To this end, we propose SoftMatch to overcome the trade-off by maintaining both high quantity and high quality of pseudo-labels during training, effectively exploiting the unlabeled data. We derive a truncated Gaussian function to weight samples based on their confidence, which can be viewed as a soft version of the confidence threshold. We further enhance the utilization of weakly-learned classes by proposing a uniform alignment approach. In experiments, SoftMatch shows substantial improvements across a wide variety of benchmarks, including image, text, and imbalanced classification.",
  "We further enhance the utilization of weakly-learned classes by proposing a uniform alignment approach. In experiments, SoftMatch shows substantial improvements across a wide variety of benchmarks, including image, text, and imbalanced classification.\nAuthors: Hao Chen, R. Tao, Yue Fan, Yidong Wang, Jindong Wang, B. Schiele, Xingxu Xie, B. Raj, M. Savvides\nVenue: International Conference on Learning Representations\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper revisits the popular pseudo-labeling methods via a unified sample weighting formulation and demonstrates the inherent quantity-quality trade-off problem of pseudo-labels with thresholding, which may prohibit learning.'}\nUrl: http://arxiv.org/pdf/2301.10921",
  "Faculty Name: bhiksha raj\nPaperid: 11c50900f50036fb3247be7c83849a8774a4ba60\nTitle: Fixed Inter-Neuron Covariability Induces Adversarial Robustness\nYear: 2023\nAbstract: The vulnerability to adversarial perturbations is a major flaw of Deep Neural Networks (DNNs) that raises question about their reliability when in real-world scenarios. On the other hand, human perception, which DNNs are supposed to emulate, is highly robust to such perturbations, indicating that there may be certain features of the human perception that make it robust but are not represented in the current class of DNNs. One such feature is that the activity of biological neurons is correlated and the structure of this correlation tends to be rather rigid over long spans of times, even if it hampers performance and learning.",
  "One such feature is that the activity of biological neurons is correlated and the structure of this correlation tends to be rather rigid over long spans of times, even if it hampers performance and learning. We hypothesize that integrating such constraints on the activations of a DNN would improve its adversarial robustness, and, to test this hypothesis, we have developed the Self-Consistent Activation (SCA) layer, which comprises of neurons whose activations are consistent with each other, as they conform to a fixed, but learned, covariability pattern.",
  "When evaluated on image and sound recognition tasks, the models with a SCA layer achieved high accuracy, and exhibited significantly greater robustness than multi-layer perceptron models to state-of-the-art Auto-PGD adversarial attacks \\textit{without being trained on adversarially perturbed data\nAuthors: Muhammad A Shah, B. Raj\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The SCA layer is developed, which comprises of neurons whose activations are consistent with each other, as they conform to a fixed, but learned, covariability pattern, and exhibited significantly greater robustness than multi-layer perceptron models to state-of-the-art Auto-PGD adversarial attacks.'}\nUrl: https://arxiv.org/pdf/2308.03956",
  "Faculty Name: bhiksha raj\nPaperid: 1de2dcb5de694920f50f000a3795eb0ca54d57ab\nTitle: LoFT: Local Proxy Fine-tuning For Improving Transferability Of Adversarial Attacks Against Large Language Model\nYear: 2023\nAbstract: It has been shown that Large Language Model (LLM) alignments can be circumvented by appending specially crafted attack suffixes with harmful queries to elicit harmful responses. To conduct attacks against private target models whose characterization is unknown, public models can be used as proxies to fashion the attack, with successful attacks being transferred from public proxies to private target models. The success rate of attack depends on how closely the proxy model approximates the private model. We hypothesize that for attacks to be transferrable, it is sufficient if the proxy can approximate the target model in the neighborhood of the harmful query. Therefore, in this paper, we propose \\emph{Local Fine-Tuning (LoFT)}, \\textit{i.e.}, fine-tuning proxy models on similar queries that lie in the lexico-semantic neighborhood of harmful queries to decrease the divergence between the proxy and target models.",
  "Therefore, in this paper, we propose \\emph{Local Fine-Tuning (LoFT)}, \\textit{i.e.}, fine-tuning proxy models on similar queries that lie in the lexico-semantic neighborhood of harmful queries to decrease the divergence between the proxy and target models. First, we demonstrate three approaches to prompt private target models to obtain similar queries given harmful queries. Next, we obtain data for local fine-tuning by eliciting responses from target models for the generated similar queries. Then, we optimize attack suffixes to generate attack prompts and evaluate the impact of our local fine-tuning on the attack's success rate. Experiments show that local fine-tuning of proxy models improves attack transferability and increases attack success rate by $39\\%$, $7\\%$, and $0.5\\%$ (absolute) on target models ChatGPT, GPT-4, and Claude respectively.",
  "Experiments show that local fine-tuning of proxy models improves attack transferability and increases attack success rate by $39\\%$, $7\\%$, and $0.5\\%$ (absolute) on target models ChatGPT, GPT-4, and Claude respectively.\nAuthors: Muhammad Ahmed Shah, Roshan Sharma, Hira Dhamyal, R. Olivier, Ankit Shah, Dareen Alharthi, Hazim T Bukhari, Massa Baali, Soham Deshmukh, Michael Kuhlmann, Bhiksha Raj, Rita Singh\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Local fine-tuning of proxy models improves attack transferability and increases attack success rate by $39, $7, and $0.5$ (absolute) on target models ChatGPT, GPT-4, and Claude respectively.'}\nUrl: https://arxiv.org/pdf/2310.04445",
  "Faculty Name: bhiksha raj\nPaperid: 22c9eb4868c5cabb26d132e0a160b9a093579f08\nTitle: Understanding political polarization using language models: A dataset and method\nYear: 2023\nAbstract: Our paper aims to analyze political polarization in US political system using language models, and thereby help candidates make an informed decision. The availability of this information will help voters understand their candidates' views on the economy, healthcare, education, and other social issues. Our main contributions are a dataset extracted from Wikipedia that spans the past 120 years and a language model\u2010based method that helps analyze how polarized a candidate is. Our data are divided into two parts, background information and political information about a candidate, since our hypothesis is that the political views of a candidate should be based on reason and be independent of factors such as birthplace, alma mater, and so forth. We further split this data into four phases chronologically, to help understand if and how the polarization amongst candidates changes. This data has been cleaned to remove biases. To understand the polarization, we begin by showing results from some classical language models in Word2Vec and Doc2Vec.",
  "We further split this data into four phases chronologically, to help understand if and how the polarization amongst candidates changes. This data has been cleaned to remove biases. To understand the polarization, we begin by showing results from some classical language models in Word2Vec and Doc2Vec. And then use more powerful techniques like the Longformer, a transformer\u2010based encoder, to assimilate more information and find the nearest neighbors of each candidate based on their political view and their background. The code and data for the project will be available here: \u201chttps://github.com/samirangode/Understanding_Polarization\u201d\nAuthors: Samiran Gode, Supreeth Bare, B. Raj, H. Yoo\nVenue: The AI Magazine\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The main contributions are a dataset extracted from Wikipedia that spans the past 120 years and a language model\u2010based method that helps analyze how polarized a candidate is.'}\nUrl: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/aaai.12104",
  "Faculty Name: bhiksha raj\nPaperid: 255bad49d29202e2d255926ab0983c125dcce835\nTitle: Evaluating Speech Synthesis by Training Recognizers on Synthetic Speech\nYear: 2023\nAbstract: Modern speech synthesis systems have improved significantly, with synthetic speech being indistinguishable from real speech. However, efficient and holistic evaluation of synthetic speech still remains a significant challenge. Human evaluation using Mean Opinion Score (MOS) is ideal, but inefficient due to high costs. Therefore, researchers have developed auxiliary automatic metrics like Word Error Rate (WER) to measure intelligibility. Prior works focus on evaluating synthetic speech based on pre-trained speech recognition models, however, this can be limiting since this approach primarily measures speech intelligibility. In this paper, we propose an evaluation technique involving the training of an ASR model on synthetic speech and assessing its performance on real speech. Our main assumption is that by training the ASR model on the synthetic speech, the WER on real speech reflects the similarity between distributions, a broader assessment of synthetic speech quality beyond intelligibility.",
  "Our main assumption is that by training the ASR model on the synthetic speech, the WER on real speech reflects the similarity between distributions, a broader assessment of synthetic speech quality beyond intelligibility. Our proposed metric demonstrates a strong correlation with both MOS naturalness and MOS intelligibility when compared to SpeechLMScore and MOSNet on three recent Text-to-Speech (TTS) systems: MQTTS, StyleTTS, and YourTTS.\nAuthors: Dareen Alharthi, Roshan Sharma, Hira Dhamyal, Soumi Maiti, Bhiksha Raj, Rita Singh\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper proposes an evaluation technique involving the training of an ASR model on synthetic speech and assessing its performance on real speech, and demonstrates a strong correlation with both MOS naturalness and MOS intelligibility when compared to SpeechLMScore and MosNet on three recent Text-to-Speech systems.'}\nUrl: https://arxiv.org/pdf/2310.00706",
  "Faculty Name: bhiksha raj\nPaperid: 2a8f592c31d8de9906183b081095b9842025f792\nTitle: Rethinking Audiovisual Segmentation with Semantic Quantization and Decomposition\nYear: 2023\nAbstract: Audiovisual segmentation (AVS) is a challenging task that aims to segment visual objects in videos based on their associated acoustic cues. With multiple sound sources involved, establishing robust correspondences between audio and visual contents poses unique challenges due to its (1) intricate entanglement across sound sources and (2) frequent shift among sound events. Assuming sound events occur independently, the multi-source semantic space (which encompasses all possible semantic categories) can be represented as the Cartesian product of single-source sub-spaces. This motivates us to decompose the multi-source audio semantics into single-source semantics, enabling more effective interaction with visual content. Specifically, we propose a semantic decomposition method based on product quantization, where the multi-source semantics can be decomposed and represented by several quantized single-source semantics.",
  "This motivates us to decompose the multi-source audio semantics into single-source semantics, enabling more effective interaction with visual content. Specifically, we propose a semantic decomposition method based on product quantization, where the multi-source semantics can be decomposed and represented by several quantized single-source semantics. Furthermore, we introduce a global-to-local quantization mechanism, which distills knowledge from stable global (clip-level) features into local (frame-level) ones, to handle the constant shift of audio semantics. Extensive experiments demonstrate that semantically quantized and decomposed audio representation significantly improves AVS performance, e.g., +21.2% mIoU on the most challenging AVS-Semantic benchmark.\nAuthors: Xiang Li, Jinglu Wang, Xiaohao Xu, Xiulian Peng, Rita Singh, Yan Lu, Bhiksha Raj\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes a semantic decomposition method based on product quantization, where the multi-source semantics can be decomposed and represented by several quantized single-source semantics, enabling more effective interaction with visual content.'}",
  "Url: https://arxiv.org/pdf/2310.00132",
  "Faculty Name: bhiksha raj\nPaperid: 35a8802facb4441787017ac5c630a8fa0f2413bd\nTitle: Prolonged school closure during the pandemic time in successive waves of COVID-19- vulnerability of children to sexual abuses \u2013 A case study in Tamil Nadu, India\nYear: 2023\nAbstract: None\nAuthors: Kandaswamy Paramasivan, B. Raj, Nandan Sudarasanam, R. Subburaj\nVenue: Heliyon\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Considering that the median delay in filing CSA complaints was above 30 days in the mild and post-intervention periods, the upsurge of cases in the more relaxed phases indicates increased occurrences of CSA during strict lockdowns.'}\nUrl: http://www.cell.com/article/S2405844023050739/pdf",
  "Faculty Name: bhiksha raj\nPaperid: 37e8e07d3ecfa43a1e64d48202c73f597e6f9fee\nTitle: Towards Noise-Tolerant Speech-Referring Video Object Segmentation: Bridging Speech and Text\nYear: 2023\nAbstract: None\nAuthors: Xiang Li, Jinglu Wang, Xiaohao Xu, Muqiao Yang, Fan Yang, Yizhou Zhao, Rita Singh, Bhiksha Raj\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: None\nUrl: https://aclanthology.org/2023.emnlp-main.140.pdf",
  "Faculty Name: bhiksha raj\nPaperid: 3bd320ddb25886417ae90011b00f13f5d558097b\nTitle: BASS: Block-wise Adaptation for Speech Summarization\nYear: 2023\nAbstract: End-to-end speech summarization has been shown to improve performance over cascade baselines. However, such models are difficult to train on very large inputs (dozens of minutes or hours) owing to compute restrictions and are hence trained with truncated model inputs. Truncation leads to poorer models, and a solution to this problem rests in block-wise modeling, i.e., processing a portion of the input frames at a time. In this paper, we develop a method that allows one to train summarization models on very long sequences in an incremental manner. Speech summarization is realized as a streaming process, where hypothesis summaries are updated every block based on new acoustic information. We devise and test strategies to pass semantic context across the blocks. Experiments on the How2 dataset demonstrate that the proposed block-wise training method improves by 3 points absolute on ROUGE-L over a truncated input baseline.",
  "We devise and test strategies to pass semantic context across the blocks. Experiments on the How2 dataset demonstrate that the proposed block-wise training method improves by 3 points absolute on ROUGE-L over a truncated input baseline.\nAuthors: Roshan Sharma, Kenneth Zheng, Siddhant Arora, Shinji Watanabe, Rita Singh, B. Raj\nVenue: Interspeech\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper develops a method that allows one to train summarization models on very long sequences in an incremental manner and devise and test strategies to pass semantic context across the blocks.'}\nUrl: https://arxiv.org/pdf/2307.08217",
  "Faculty Name: bhiksha raj\nPaperid: 4628f0c28a8ed231168d1a27a93ddb938da4102d\nTitle: Psychoacoustic Challenges Of Speech Enhancement On VoIP Platforms\nYear: 2023\nAbstract: Within the ambit of VoIP (Voice over Internet Protocol) telecommunications, the complexities introduced by acoustic transformations merit rigorous analysis. This research, rooted in the exploration of proprietary sender-side denoising effects, meticulously evaluates platforms such as Google Meets and Zoom. The study draws upon the Deep Noise Suppression (DNS) 2020 dataset, ensuring a structured examination tailored to various denoising settings and receiver interfaces. A methodological novelty is introduced via the Oaxaca decomposition, traditionally an econometric tool, repurposed herein to analyze acoustic-phonetic perturbations within VoIP systems. To further ground the implications of these transformations, psychoacoustic metrics, specifically PESQ and STOI, were harnessed to furnish a comprehensive understanding of speech alterations. Cumulatively, the insights garnered underscore the intricate landscape of VoIP-influenced acoustic dynamics.",
  "To further ground the implications of these transformations, psychoacoustic metrics, specifically PESQ and STOI, were harnessed to furnish a comprehensive understanding of speech alterations. Cumulatively, the insights garnered underscore the intricate landscape of VoIP-influenced acoustic dynamics. In addition to the primary findings, a multitude of metrics are reported, extending the research purview. Moreover, out-of-domain benchmarking for both time and time-frequency domain speech enhancement models is included, thereby enhancing the depth and applicability of this inquiry. Repository: github.com/deepology/VoIP-DNS-Challenge\nAuthors: Joseph Konan, Ojas Bhargave, Shikhar Agnihotri, Shuo Han, YUNYANG ZENG, Ankit Shah, Bhiksha Raj\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This research, rooted in the exploration of proprietary sender-side denoising effects, meticulously evaluates platforms such as Google Meets and Zoom, and draws upon the Deep Noise Suppression (DNS) 2020 dataset, ensuring a structured examination tailored to various denoised settings and receiver interfaces.'}",
  "Url: https://arxiv.org/pdf/2310.07161",
  "Faculty Name: bhiksha raj\nPaperid: 4e6a004e4f9a3b489004a2efb5b25b0bcd0f48b5\nTitle: Understanding Political Polarisation using Language Models: A dataset and method\nYear: 2023\nAbstract: Our paper aims to analyze political polarization in US political system using Language Models, and thereby help candidates make an informed decision. The availability of this information will help voters understand their candidates views on the economy, healthcare, education and other social issues. Our main contributions are a dataset extracted from Wikipedia that spans the past 120 years and a Language model based method that helps analyze how polarized a candidate is. Our data is divided into 2 parts, background information and political information about a candidate, since our hypothesis is that the political views of a candidate should be based on reason and be independent of factors such as birthplace, alma mater, etc. We further split this data into 4 phases chronologically, to help understand if and how the polarization amongst candidates changes. This data has been cleaned to remove biases.",
  "We further split this data into 4 phases chronologically, to help understand if and how the polarization amongst candidates changes. This data has been cleaned to remove biases. To understand the polarization we begin by showing results from some classical language models in Word2Vec and Doc2Vec. And then use more powerful techniques like the Longformer, a transformer based encoder, to assimilate more information and find the nearest neighbors of each candidate based on their political view and their background.\nAuthors: Samiran Gode, Supreeth Bare, B. Raj, H. Yoo\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A dataset extracted from Wikipedia that spans the past 120 years and a Language model based method that helps analyze how polarized a candidate is are used to understand the polarization.'}\nUrl: http://arxiv.org/pdf/2301.00891",
  "Faculty Name: bhiksha raj\nPaperid: 593a603354c09d151440ae044de1d80324a2ab01\nTitle: An Approach to Ontological Learning from Weak Labels\nYear: 2023\nAbstract: Ontologies encompass a formal representation of knowledge through the definition of concepts or properties of a domain, and the relationships between those concepts. In this work, we seek to investigate whether using this ontological information will improve learning from weakly labeled data, which are easier to collect since it requires only the presence or absence of an event to be known. We use the AudioSet ontology and dataset, which contains audio clips weakly labeled with the ontology concepts and the ontology providing the \"Is A\" relations between the concepts. We first re-implemented the model proposed by [1] with modifications to fit the multi-label scenario and then expand on that idea by using a Graph Convolutional Network (GCN) to model the ontology information to learn the concepts. We find that the baseline Twin Neural Network (TNN) does not perform better by incorporating ontology information in the weak and multi-label scenario, but that the GCN does capture the ontology knowledge better for weak, multi-labeled data.",
  "We find that the baseline Twin Neural Network (TNN) does not perform better by incorporating ontology information in the weak and multi-label scenario, but that the GCN does capture the ontology knowledge better for weak, multi-labeled data. We also investigate how different modules can tolerate noises introduced from weak labels and better incorporate ontology information. Our best TNN-GCN model achieves mAP=0.45 and AUC=0.87 for lower-level concepts and mAP=0.72 and AUC=0.86 for higher-level concepts, which is an improvement over the baseline TNN but about the same as our models that do not use ontology information.\nAuthors: Ankit Shah, Larry Tang, Po Hao Chou, Yilun Zheng, Ziqian Ge, B. Raj\nVenue: IEEE International Conference on Acoustics, Speech, and Signal Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work re-implements the model proposed by [1] with modifications to fit the multi-label scenario and expands on that idea by using a Graph Convolutional Network (GCN) to model the ontology information to learn the concepts.'}\nUrl: N/A",
  "Faculty Name: bhiksha raj\nPaperid: 5a3307b2e64bbcaff1202e261b8a83f7d03418a8\nTitle: Rethinking Voice-Face Correlation: A Geometry View\nYear: 2023\nAbstract: Previous works on voice-face matching and voice-guided face synthesis demonstrate strong correlations between voice and face, but mainly rely on coarse semantic cues such as gender, age, and emotion. In this paper, we aim to investigate the capability of reconstructing the 3D facial shape from voice from a geometry perspective without any semantic information. We propose a voice-anthropometric measurement (AM)-face paradigm, which identifies predictable facial AMs from the voice and uses them to guide 3D face reconstruction. By leveraging AMs as a proxy to link the voice and face geometry, we can eliminate the influence of unpredictable AMs and make the face geometry tractable. Our approach is evaluated on our proposed dataset with ground-truth 3D face scans and corresponding voice recordings, and we find significant correlations between voice and specific parts of the face geometry, such as the nasal cavity and cranium.",
  "Our approach is evaluated on our proposed dataset with ground-truth 3D face scans and corresponding voice recordings, and we find significant correlations between voice and specific parts of the face geometry, such as the nasal cavity and cranium. Our work offers a new perspective on voice-face correlation and can serve as a good empirical study for anthropometry science.\nAuthors: Xiang Li, Yandong Wen, Muqiao Yang, Jinglu Wang, Rita Singh, B. Raj\nVenue: ACM Multimedia\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes a voice-anthropometric measurement (AM)-face paradigm, which identifies predictable facial AMs from the voice and uses them to guide 3D face reconstruction and finds significant correlations between voice and specific parts of the face geometry, such as the nasal cavity and cranium.'}\nUrl: https://arxiv.org/pdf/2307.13948",
  "Faculty Name: bhiksha raj\nPaperid: 611f9ee6eef0936462cd78f371798d0699951c59\nTitle: Paaploss: A Phonetic-Aligned Acoustic Parameter Loss for Speech Enhancement\nYear: 2023\nAbstract: Despite rapid advancement in recent years, current speech enhancement models often produce speech that differs in perceptual quality from real clean speech. We propose a learning objective that formalizes differences in perceptual quality, by using domain knowledge of acoustic-phonetics. We identify temporal acoustic parameters \u2013 such as spectral tilt, spectral flux, shimmer, etc. \u2013 that are non-differentiable, and we develop a neural network estimator that can accurately predict their time-series values across an utterance. We also model phoneme-specific weights for each feature, as the acoustic parameters are known to show different behavior in different phonemes. We can add this criterion as an auxiliary loss to any model that produces speech, to optimize speech outputs to match the values of clean speech in these features. Experimentally we show that it improves speech enhancement workflows in both time-domain and time-frequency domain, as measured by standard evaluation metrics.",
  "We can add this criterion as an auxiliary loss to any model that produces speech, to optimize speech outputs to match the values of clean speech in these features. Experimentally we show that it improves speech enhancement workflows in both time-domain and time-frequency domain, as measured by standard evaluation metrics. We also provide an analysis of phoneme-dependent improvement on acoustic parameters, demonstrating the additional interpretability that our method provides. This analysis can suggest which features are currently the bottleneck for improvement.\nAuthors: Muqiao Yang, Joseph Konan, David Bick, YUNYANG ZENG, Shuo Han, Anurag Kumar, Shinji Watanabe, B. Raj\nVenue: IEEE International Conference on Acoustics, Speech, and Signal Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A learning objective is proposed that formalizes differences in perceptual quality, by using domain knowledge of acoustic-phonetics, and a neural network estimator is developed that can accurately predict their time-series values across an utterance.'}\nUrl: https://arxiv.org/pdf/2302.08095",
  "Faculty Name: bhiksha raj\nPaperid: 6ca2caa4edecc5f08949756266db241ef5e51fc1\nTitle: uSee: Unified Speech Enhancement and Editing with Conditional Diffusion Models\nYear: 2023\nAbstract: Speech enhancement aims to improve the quality of speech signals in terms of quality and intelligibility, and speech editing refers to the process of editing the speech according to specific user needs. In this paper, we propose a Unified Speech Enhancement and Editing (uSee) model with conditional diffusion models to handle various tasks at the same time in a generative manner. Specifically, by providing multiple types of conditions including self-supervised learning embeddings and proper text prompts to the score-based diffusion model, we can enable controllable generation of the unified speech enhancement and editing model to perform corresponding actions on the source speech. Our experiments show that our proposed uSee model can achieve superior performance in both speech denoising and dereverberation compared to other related generative speech enhancement models, and can perform speech editing given desired environmental sound text description, signal-to-noise ratios (SNR), and room impulse responses (RIR).",
  "Our experiments show that our proposed uSee model can achieve superior performance in both speech denoising and dereverberation compared to other related generative speech enhancement models, and can perform speech editing given desired environmental sound text description, signal-to-noise ratios (SNR), and room impulse responses (RIR). Demos of the generated speech are available at https://muqiaoy.github.io/usee.\nAuthors: Muqiao Yang, Chunlei Zhang, Yong Xu, Zhongweiyang Xu, Heming Wang, Bhiksha Raj, Dong Yu\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The proposed uSee model can achieve superior performance in both speech denoising and dereverberation compared to other related generative speech enhancement models, and can perform speech editing given desired environmental sound text description, signal-to-noise ratios (SNR), and room impulse responses (RIR).'}\nUrl: https://arxiv.org/pdf/2310.00900",
  "Faculty Name: bhiksha raj\nPaperid: 7333be530df311b3148e9857ce9f481975cf0a9b\nTitle: Improving Perceptual Quality, Intelligibility, and Acoustics on VoIP Platforms\nYear: 2023\nAbstract: In this paper, we present a method for fine-tuning models trained on the Deep Noise Suppression (DNS) 2020 Challenge to improve their performance on Voice over Internet Protocol (VoIP) applications. Our approach involves adapting the DNS 2020 models to the specific acoustic characteristics of VoIP communications, which includes distortion and artifacts caused by compression, transmission, and platform-specific processing. To this end, we propose a multi-task learning framework for VoIP-DNS that jointly optimizes noise suppression and VoIP-specific acoustics for speech enhancement. We evaluate our approach on a diverse VoIP scenarios and show that it outperforms both industry performance and state-of-the-art methods for speech enhancement on VoIP applications.",
  "We evaluate our approach on a diverse VoIP scenarios and show that it outperforms both industry performance and state-of-the-art methods for speech enhancement on VoIP applications. Our results demonstrate the potential of models trained on DNS-2020 to be improved and tailored to different VoIP platforms using VoIP-DNS, whose findings have important applications in areas such as speech recognition, voice assistants, and telecommunication.\nAuthors: Joseph Konan, Ojas Bhargave, Shikhar Agnihotri, Hojeong Lee, Ankit Shah, Shuo Han, YUNYANG ZENG, Amanda Shu, Haohui Liu, Xuankai Chang, Hamza Khalid, Minseon Gwak, Kawon Lee, Minjeong Kim, B. Raj\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A multi-task learning framework forVoIP-DNS that jointly optimizes noise suppression and VoIP-specific acoustics for speech enhancement and outperforms both industry performance and state-of-the-art methods for speech Enhancement on VoIP applications is proposed.'}\nUrl: http://arxiv.org/pdf/2303.09048",
  "Faculty Name: bhiksha raj\nPaperid: 740488982dee323d559f2dae70b1f4b3aa5f7171\nTitle: Approach to Learning Generalized Audio Representation Through Batch Embedding Covariance Regularization and Constant-Q Transforms\nYear: 2023\nAbstract: General-purpose embedding is highly desirable for few-shot even zero-shot learning in many application scenarios, including audio tasks. In order to understand representations better, we conducted a thorough error analysis and visualization of HEAR 2021 submission results. Inspired by the analysis, this work experiments with different front-end audio preprocessing methods, including Constant-Q Transform (CQT) and Short-time Fourier transform (STFT), and proposes a Batch Embedding Covariance Regularization (BECR) term to uncover a more holistic simulation of the frequency information received by the human auditory system. We tested the models on the suite of HEAR 2021 tasks, which encompass a broad category of tasks.",
  "We tested the models on the suite of HEAR 2021 tasks, which encompass a broad category of tasks. Preliminary results show (1) the proposed BECR can incur a more dispersed embedding on the test set, (2) BECR improves the PaSST model without extra computation complexity, and (3) STFT preprocessing outperforms CQT in all tasks we tested. Github:https://github.com/ankitshah009/general_audio_embedding_hear_2021\nAuthors: Ankit Shah, Shuyi Chen, Kejun Zhou, Yue Chen, B. Raj\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Experiments with different front-end audio preprocessing methods are experiments, and a Batch Embedding Covariance Regularization (BECR) term is proposed to uncover a more holistic simulation of the frequency information received by the human auditory system.'}\nUrl: http://arxiv.org/pdf/2303.03591",
  "Faculty Name: bhiksha raj\nPaperid: 74664618ad3b44eb191ba96fdff5b93f27a29ced\nTitle: Training on Foveated Images Improves Robustness to Adversarial Attacks\nYear: 2023\nAbstract: Deep neural networks (DNNs) have been shown to be vulnerable to adversarial attacks -- subtle, perceptually indistinguishable perturbations of inputs that change the response of the model. In the context of vision, we hypothesize that an important contributor to the robustness of human visual perception is constant exposure to low-fidelity visual stimuli in our peripheral vision. To investigate this hypothesis, we develop \\RBlur, an image transform that simulates the loss in fidelity of peripheral vision by blurring the image and reducing its color saturation based on the distance from a given fixation point. We show that compared to DNNs trained on the original images, DNNs trained on images transformed by \\RBlur are substantially more robust to adversarial attacks, as well as other, non-adversarial, corruptions, achieving up to 25\\% higher accuracy on perturbed data.",
  "We show that compared to DNNs trained on the original images, DNNs trained on images transformed by \\RBlur are substantially more robust to adversarial attacks, as well as other, non-adversarial, corruptions, achieving up to 25\\% higher accuracy on perturbed data.\nAuthors: Muhammad A Shah, B. Raj\nVenue: Neural Information Processing Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'DNNs trained on images transformed by \\\\RBlur are substantially more robust to adversarial attacks, as well as other, non-adversarial, corruptions, achieving up to 25\\\\% higher accuracy on perturbed data.'}\nUrl: https://arxiv.org/pdf/2308.00854",
  "Faculty Name: bhiksha raj\nPaperid: 7a25aa397ae2a7f82df87a936ce6ff7f03b7ac4c\nTitle: Token Prediction as Implicit Classification to Identify LLM-Generated Text\nYear: 2023\nAbstract: This paper introduces a novel approach for identifying the possible large language models (LLMs) involved in text generation. Instead of adding an additional classification layer to a base LM, we reframe the classification task as a next-token prediction task and directly fine-tune the base LM to perform it. We utilize the Text-to-Text Transfer Transformer (T5) model as the backbone for our experiments. We compared our approach to the more direct approach of utilizing hidden states for classification. Evaluation shows the exceptional performance of our method in the text classification task, highlighting its simplicity and efficiency. Furthermore, interpretability studies on the features extracted by our model reveal its ability to differentiate distinctive writing styles among various LLMs even in the absence of an explicit classifier.",
  "Evaluation shows the exceptional performance of our method in the text classification task, highlighting its simplicity and efficiency. Furthermore, interpretability studies on the features extracted by our model reveal its ability to differentiate distinctive writing styles among various LLMs even in the absence of an explicit classifier. We also collected a dataset named OpenLLMText, containing approximately 340k text samples from human and LLMs, including GPT3.5, PaLM, LLaMA, and GPT2.\nAuthors: Yutian Chen, Hao Kang, Vivian Zhai, Liangze Li, Rita Singh, Bhiksha Raj\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Evaluation shows the exceptional performance of the method in the text classification task, highlighting its simplicity and efficiency, and interpretability studies on the features extracted by the model reveal its ability to differentiate distinctive writing styles among various LLMs even in the absence of an explicit classifier.'}\nUrl: https://aclanthology.org/2023.emnlp-main.810.pdf",
  "Faculty Name: bhiksha raj\nPaperid: 8665c864d71df1e918d2010778fc06712f4e5550\nTitle: Imprecise Label Learning: A Unified Framework for Learning with Various Imprecise Label Configurations\nYear: 2023\nAbstract: Learning with reduced labeling standards, such as noisy label, partial label, and multiple label candidates, which we generically refer to as \\textit{imprecise} labels, is a commonplace challenge in machine learning tasks. Previous methods tend to propose specific designs for every emerging imprecise label configuration, which is usually unsustainable when multiple configurations of imprecision coexist. In this paper, we introduce imprecise label learning (ILL), a framework for the unification of learning with various imprecise label configurations. ILL leverages expectation-maximization (EM) for modeling the imprecise label information, treating the precise labels as latent variables.Instead of approximating the correct labels for training, it considers the entire distribution of all possible labeling entailed by the imprecise information.",
  "ILL leverages expectation-maximization (EM) for modeling the imprecise label information, treating the precise labels as latent variables.Instead of approximating the correct labels for training, it considers the entire distribution of all possible labeling entailed by the imprecise information. We demonstrate that ILL can seamlessly adapt to partial label learning, semi-supervised learning, noisy label learning, and, more importantly, a mixture of these settings. Notably, ILL surpasses the existing specified techniques for handling imprecise labels, marking the first unified framework with robust and effective performance across various challenging settings. We hope our work will inspire further research on this topic, unleashing the full potential of ILL in wider scenarios where precise labels are expensive and complicated to obtain.",
  "We hope our work will inspire further research on this topic, unleashing the full potential of ILL in wider scenarios where precise labels are expensive and complicated to obtain.\nAuthors: Hao Chen, Ankit Shah, Jindong Wang, R. Tao, Yidong Wang, Xingxu Xie, Masashi Sugiyama, Rita Singh, B. Raj\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Imprecise label learning (ILL) is introduced, a framework for the unification of learning with various imprecise label configurations, marking the first unified framework with robust and effective performance across various challenging settings.'}\nUrl: https://arxiv.org/pdf/2305.12715",
  "Faculty Name: bhiksha raj\nPaperid: 9f9cdced51568c623ec447bf0ea9709b383b5a0f\nTitle: Understanding and Mitigating the Label Noise in Pre-training on Downstream Tasks\nYear: 2023\nAbstract: Pre-training on large-scale datasets and then fine-tuning on downstream tasks have become a standard practice in deep learning. However, pre-training data often contain label noise that may adversely affect the generalization of the model. This paper aims to understand the nature of noise in pre-training datasets and to mitigate its impact on downstream tasks. More specifically, through extensive experiments of supervised pre-training models on synthetic noisy ImageNet-1K and YFCC15M datasets, we demonstrate that while slight noise in pre-training can benefit in-domain (ID) transfer performance, where the training and testing data share the same distribution, it always deteriorates out-of-domain (OOD) performance, where training and testing data distribution are different. We empirically verify that the reason behind is noise in pre-training shapes the feature space differently.",
  "We empirically verify that the reason behind is noise in pre-training shapes the feature space differently. We then propose a lightweight black-box tuning method (NMTune) to affine the feature space to mitigate the malignant effect of noise and improve generalization on both ID and OOD tasks, considering one may not be able to fully fine-tune or even access the pre-trained models. We conduct practical experiments on popular vision and language models that are pre-trained on noisy data for evaluation of our approach. Our analysis and results show the importance of this interesting and novel research direction, which we term Noisy Model Learning.\nAuthors: Hao Chen, Jindong Wang, Ankit Shah, Ran Tao, Hongxin Wei, Xingxu Xie, Masashi Sugiyama, Bhiksha Raj\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A lightweight black-box tuning method (NMTune) is proposed to affine the feature space to mitigate the malignant effect of noise and improve generalization on both ID and OOD tasks, considering one may not be able to fully fine-tune or even access the pre-trained models.'}",
  "Url: https://arxiv.org/pdf/2309.17002",
  "Faculty Name: bhiksha raj\nPaperid: a6e3a10a6286967413e3406374bbeea533640030\nTitle: The Hidden Dance of Phonemes and Visage: Unveiling the Enigmatic Link between Phonemes and Facial Features\nYear: 2023\nAbstract: This work unveils the enigmatic link between phonemes and facial features. Traditional studies on voice-face correlations typically involve using a long period of voice input, including generating face images from voices and reconstructing 3D face meshes from voices. However, in situations like voice-based crimes, the available voice evidence may be short and limited. Additionally, from a physiological perspective, each segment of speech -- phoneme -- corresponds to different types of airflow and movements in the face. Therefore, it is advantageous to discover the hidden link between phonemes and face attributes. In this paper, we propose an analysis pipeline to help us explore the voice-face relationship in a fine-grained manner, i.e., phonemes v.s. facial anthropometric measurements (AM). We build an estimator for each phoneme-AM pair and evaluate the correlation through hypothesis testing.",
  "In this paper, we propose an analysis pipeline to help us explore the voice-face relationship in a fine-grained manner, i.e., phonemes v.s. facial anthropometric measurements (AM). We build an estimator for each phoneme-AM pair and evaluate the correlation through hypothesis testing. Our results indicate that AMs are more predictable from vowels compared to consonants, particularly with plosives. Additionally, we observe that if a specific AM exhibits more movement during phoneme pronunciation, it is more predictable. Our findings support those in physiology regarding correlation and lay the groundwork for future research on speech-face multimodal learning.\nAuthors: Liao Qu, X. Zou, Xiang Li, Yandong Wen, Rita Singh, B. Raj\nVenue: Interspeech\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes an analysis pipeline to help explore the voice-face relationship in a fine-grained manner, i.s. phonemes v. facial anthropometric measurements (AM), and indicates that AMs are more predictable from vowels compared to consonants, particularly with plosives.'}\nUrl: https://arxiv.org/pdf/2307.13953",
  "Faculty Name: bhiksha raj\nPaperid: ac856b6b7b3f32fb34320b7170526d3ab15ba5f3\nTitle: Fairness Continual Learning Approach to Semantic Scene Understanding in Open-World Environments\nYear: 2023\nAbstract: Continual semantic segmentation aims to learn new classes while maintaining the information from the previous classes. Although prior studies have shown impressive progress in recent years, the fairness concern in the continual semantic segmentation needs to be better addressed. Meanwhile, fairness is one of the most vital factors in deploying the deep learning model, especially in human-related or safety applications. In this paper, we present a novel Fairness Continual Learning approach to the semantic segmentation problem. In particular, under the fairness objective, a new fairness continual learning framework is proposed based on class distributions. Then, a novel Prototypical Contrastive Clustering loss is proposed to address the significant challenges in continual learning, i.e., catastrophic forgetting and background shift. Our proposed loss has also been proven as a novel, generalized learning paradigm of knowledge distillation commonly used in continual learning. Moreover, the proposed Conditional Structural Consistency loss further regularized the structural constraint of the predicted segmentation.",
  "Our proposed loss has also been proven as a novel, generalized learning paradigm of knowledge distillation commonly used in continual learning. Moreover, the proposed Conditional Structural Consistency loss further regularized the structural constraint of the predicted segmentation. Our proposed approach has achieved State-of-the-Art performance on three standard scene understanding benchmarks, i.e., ADE20K, Cityscapes, and Pascal VOC, and promoted the fairness of the segmentation model.\nAuthors: Thanh-Dat Truong, Hoang-Quan Nguyen, B. Raj, Khoa Luu\nVenue: Neural Information Processing Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A novel Fairness Continual Learning approach to the semantic segmentation problem is presented, in particular, a new fairness continual learning framework is proposed based on class distributions and a novel Prototypical Contrastive Clustering loss is proposed to address the significant challenges in continual learning.'}\nUrl: https://arxiv.org/pdf/2305.15700",
  "Faculty Name: bhiksha raj\nPaperid: b7e2074934985b6112b6bce8c3680b14e621fdfe\nTitle: Importance of negative sampling in weak label learning\nYear: 2023\nAbstract: Weak-label learning is a challenging task that requires learning from data\"bags\"containing positive and negative instances, but only the bag labels are known. The pool of negative instances is usually larger than positive instances, thus making selecting the most informative negative instance critical for performance. Such a selection strategy for negative instances from each bag is an open problem that has not been well studied for weak-label learning. In this paper, we study several sampling strategies that can measure the usefulness of negative instances for weak-label learning and select them accordingly. We test our method on CIFAR-10 and AudioSet datasets and show that it improves the weak-label classification performance and reduces the computational cost compared to random sampling methods. Our work reveals that negative instances are not all equally irrelevant, and selecting them wisely can benefit weak-label learning.",
  "We test our method on CIFAR-10 and AudioSet datasets and show that it improves the weak-label classification performance and reduces the computational cost compared to random sampling methods. Our work reveals that negative instances are not all equally irrelevant, and selecting them wisely can benefit weak-label learning.\nAuthors: Ankit Shah, Fuyu Tang, Zelin Ye, Rita Singh, Bhiksha Raj\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work reveals that negative instances are not all equally irrelevant, and selecting them wisely can benefit weak-label learning, and reduces the computational cost compared to random sampling methods.'}\nUrl: https://arxiv.org/pdf/2309.13227",
  "Faculty Name: bhiksha raj\nPaperid: d7911ff6f80bd9f053ef8d304f15791f510f5cda\nTitle: Completing Visual Objects via Bridging Generation and Segmentation\nYear: 2023\nAbstract: This paper presents a novel approach to object completion, with the primary goal of reconstructing a complete object from its partially visible components. Our method, named MaskComp, delineates the completion process through iterative stages of generation and segmentation. In each iteration, the object mask is provided as an additional condition to boost image generation, and, in return, the generated images can lead to a more accurate mask by fusing the segmentation of images. We demonstrate that the combination of one generation and one segmentation stage effectively functions as a mask denoiser. Through alternation between the generation and segmentation stages, the partial object mask is progressively refined, providing precise shape guidance and yielding superior object completion results. Our experiments demonstrate the superiority of MaskComp over existing approaches, e.g., ControlNet and Stable Diffusion, establishing it as an effective solution for object completion.",
  "Through alternation between the generation and segmentation stages, the partial object mask is progressively refined, providing precise shape guidance and yielding superior object completion results. Our experiments demonstrate the superiority of MaskComp over existing approaches, e.g., ControlNet and Stable Diffusion, establishing it as an effective solution for object completion.\nAuthors: Xiang Li, Yinpeng Chen, Chung-Ching Lin, Rita Singh, Bhiksha Raj, Zicheng Liu\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The method, named MaskComp, delineates the completion process through iterative stages of generation and segmentation, and demonstrates that the combination of one generation and one segmentation stage effectively functions as a mask denoiser.'}\nUrl: https://arxiv.org/pdf/2310.00808",
  "Faculty Name: bhiksha raj\nPaperid: dc157eba8bdb4cfe6ee65566d8295939ac5b4b37\nTitle: PaintSeg: Training-free Segmentation via Painting\nYear: 2023\nAbstract: The paper introduces PaintSeg, a new unsupervised method for segmenting objects without any training. We propose an adversarial masked contrastive painting (AMCP) process, which creates a contrast between the original image and a painted image in which a masked area is painted using off-the-shelf generative models. During the painting process, inpainting and outpainting are alternated, with the former masking the foreground and filling in the background, and the latter masking the background while recovering the missing part of the foreground object. Inpainting and outpainting, also referred to as I-step and O-step, allow our method to gradually advance the target segmentation mask toward the ground truth without supervision or training. PaintSeg can be configured to work with a variety of prompts, e.g. coarse masks, boxes, scribbles, and points.",
  "PaintSeg can be configured to work with a variety of prompts, e.g. coarse masks, boxes, scribbles, and points. Our experimental results demonstrate that PaintSeg outperforms existing approaches in coarse mask-prompt, box-prompt, and point-prompt segmentation tasks, providing a training-free solution suitable for unsupervised segmentation.\nAuthors: Xiang Li, Chung-Ching Lin, Yinpeng Chen, Zicheng Liu, Jinglu Wang, B. Raj\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'An adversarial masked contrastive painting process, which creates a contrast between the original image and a painted image in which a masked area is painted using off-the-shelf generative models, providing a training-free solution suitable for unsupervised segmentation.'}\nUrl: http://arxiv.org/pdf/2305.19406",
  "Faculty Name: bhiksha raj\nPaperid: e146e5221c124d93f69516c5ae7e1b7b1822848e\nTitle: TAPLoss: A Temporal Acoustic Parameter Loss for Speech Enhancement\nYear: 2023\nAbstract: Speech enhancement models have greatly progressed in recent years, but still show limits in perceptual quality of their speech outputs. We propose an objective for perceptual quality based on temporal acoustic parameters. These are fundamental speech features that play an essential role in various applications, including speaker recognition and paralinguistic analysis. We provide a differentiable estimator for four categories of low-level acoustic descriptors involving: frequency-related parameters, energy or amplitude-related parameters, spectral balance parameters, and temporal features. Un-like prior work that looks at aggregated acoustic parameters or a few categories of acoustic parameters, our temporal acoustic parameter (TAP) loss enables auxiliary optimization and improvement of many fine-grained speech characteristics in enhancement workflows. We show that adding TAPLoss as an auxiliary objective in speech enhancement produces speech with improved perceptual quality and intelligibility.",
  "We show that adding TAPLoss as an auxiliary objective in speech enhancement produces speech with improved perceptual quality and intelligibility. We use data from the Deep Noise Suppression 2020 Challenge to demonstrate that both time-domain models and time-frequency domain models can benefit from our method.\nAuthors: YUNYANG ZENG, Joseph Konan, Shuo Han, David Bick, Muqiao Yang, Anurag Kumar, Shinji Watanabe, B. Raj\nVenue: IEEE International Conference on Acoustics, Speech, and Signal Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work shows that adding TAPLoss as an auxiliary objective in speech enhancement produces speech with improved perceptual quality and intelligibility and uses data from the Deep Noise Suppression 2020 Challenge to demonstrate that both time-domain models and time-frequency domain models can benefit from the method.'}\nUrl: https://arxiv.org/pdf/2302.08088",
  "Faculty Name: bhiksha raj\nPaperid: e2572e0adacfb116b19b25691e7f6b3749490a88\nTitle: Training Audio Captioning Models without Audio\nYear: 2023\nAbstract: Automated Audio Captioning (AAC) is the task of generating natural language descriptions given an audio stream. A typical AAC system requires manually curated training data of audio segments and corresponding text caption annotations. The creation of these audio-caption pairs is costly, resulting in general data scarcity for the task. In this work, we address this major limitation and propose an approach to train AAC systems using only text. Our approach leverages the multimodal space of contrastively trained audio-text models, such as CLAP. During training, a decoder generates captions conditioned on the pretrained CLAP text encoder. During inference, the text encoder is replaced with the pretrained CLAP audio encoder. To bridge the modality gap between text and audio embeddings, we propose the use of noise injection or a learnable adapter, during training. We find that the proposed text-only framework performs competitively with state-of-the-art models trained with paired audio, showing that efficient text-to-audio transfer is possible.",
  "To bridge the modality gap between text and audio embeddings, we propose the use of noise injection or a learnable adapter, during training. We find that the proposed text-only framework performs competitively with state-of-the-art models trained with paired audio, showing that efficient text-to-audio transfer is possible. Finally, we showcase both stylized audio captioning and caption enrichment while training without audio or human-created text captions.\nAuthors: Soham Deshmukh, Benjamin Elizalde, Dimitra Emmanouilidou, Bhiksha Raj, Rita Singh, Huaming Wang\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes an approach to train AAC systems using only text, and finds that the proposed text-only framework performs competitively with state-of-the-art models trained with paired audio, showing that efficient text-to-audio transfer is possible.'}\nUrl: https://arxiv.org/pdf/2309.07372",
  "Faculty Name: bhiksha raj\nPaperid: f5a7a4fda49c657742072a2758f43b1cbcde3886\nTitle: Continual Contrastive Spoken Language Understanding\nYear: 2023\nAbstract: Recently, neural networks have shown impressive progress across diverse fields, with speech processing being no exception. However, recent breakthroughs in this area require extensive offline training using large datasets and tremendous computing resources. Unfortunately, these models struggle to retain their previously acquired knowledge when learning new tasks continually, and retraining from scratch is almost always impractical. In this paper, we investigate the problem of learning sequence-to-sequence models for spoken language understanding in a class-incremental learning (CIL) setting and we propose COCONUT, a CIL method that relies on the combination of experience replay and contrastive learning. Through a modified version of the standard supervised contrastive loss applied only to the rehearsal samples, COCONUT preserves the learned representations by pulling closer samples from the same class and pushing away the others. Moreover, we leverage a multimodal contrastive loss that helps the model learn more discriminative representations of the new data by aligning audio and text features.",
  "Moreover, we leverage a multimodal contrastive loss that helps the model learn more discriminative representations of the new data by aligning audio and text features. We also investigate different contrastive designs to combine the strengths of the contrastive loss with teacher-student architectures used for distillation. Experiments on two established SLU datasets reveal the effectiveness of our proposed approach and significant improvements over the baselines. We also show that COCONUT can be combined with methods that operate on the decoder side of the model, resulting in further metrics improvements.\nAuthors: Umberto Cappellazzo, Enrico Fini, Muqiao Yang, Daniele Falavigna, A. Brutti, Bhiksha Raj\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper investigates the problem of learning sequence-to-sequence models for spoken language understanding in a class-incremental learning (CIL) setting and proposes COCONUT, a CIL method that relies on the combination of experience replay and contrastive learning.'}\nUrl: https://arxiv.org/pdf/2310.02699",
  "Faculty Name: bhiksha raj\nPaperid: f5b88ca9d74e8ddc679adcd07a292bd8481062fa\nTitle: Prompting Audios Using Acoustic Properties For Emotion Representation\nYear: 2023\nAbstract: Emotions lie on a continuum, but current models treat emotions as a finite valued discrete variable. This representation does not capture the diversity in the expression of emotion. To better represent emotions we propose the use of natural language descriptions (or prompts). In this work, we address the challenge of automatically generating these prompts and training a model to better learn emotion representations from audio and prompt pairs. We use acoustic properties that are correlated to emotion like pitch, intensity, speech rate, and articulation rate to automatically generate prompts i.e. 'acoustic prompts'. We use a contrastive learning objective to map speech to their respective acoustic prompts. We evaluate our model on Emotion Audio Retrieval and Speech Emotion Recognition. Our results show that the acoustic prompts significantly improve the model's performance in EAR, in various Precision@K metrics. In SER, we observe a 3.8% relative accuracy improvement on the Ravdess dataset.",
  "We evaluate our model on Emotion Audio Retrieval and Speech Emotion Recognition. Our results show that the acoustic prompts significantly improve the model's performance in EAR, in various Precision@K metrics. In SER, we observe a 3.8% relative accuracy improvement on the Ravdess dataset.\nAuthors: Hira Dhamyal, Benjamin Elizalde, Soham Deshmukh, Huaming Wang, Bhiksha Raj, Rita Singh\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work addresses the challenge of automatically generating prompts and training a model to better learn emotion representations from audio and prompt pairs by using acoustic properties that are correlated to emotion like pitch, intensity, speech rate, and articulation rate to automatically generate prompts.'}\nUrl: https://arxiv.org/pdf/2310.02298",
  "Faculty Name: bhiksha raj\nPaperid: f969f059b01be02f9995396b6cc397959b574635\nTitle: Pairwise Similarity Learning is SimPLE\nYear: 2023\nAbstract: In this paper, we focus on a general yet important learning problem, pairwise similarity learning (PSL). PSL subsumes a wide range of important applications, such as open-set face recognition, speaker verification, image retrieval and person re-identification. The goal of PSL is to learn a pairwise similarity function assigning a higher similarity score to positive pairs (i.e., a pair of samples with the same label) than to negative pairs (i.e., a pair of samples with different label). We start by identifying a key desideratum for PSL, and then discuss how existing methods can achieve this desideratum. We then propose a surprisingly simple proxy-free method, called SimPLE, which requires neither feature/proxy normalization nor angular margin and yet is able to generalize well in open-set recognition. We apply the proposed method to three challenging PSL tasks: open-set face recognition, image retrieval and speaker verification.",
  "We then propose a surprisingly simple proxy-free method, called SimPLE, which requires neither feature/proxy normalization nor angular margin and yet is able to generalize well in open-set recognition. We apply the proposed method to three challenging PSL tasks: open-set face recognition, image retrieval and speaker verification. Comprehensive experimental results on large-scale benchmarks show that our method performs significantly better than current state-of-the-art methods. Our project page is available at simple.is.tue.mpg.de.\nAuthors: Yandong Wen, Weiyang Liu, Yao Feng, Bhiksha Raj, Rita Singh, Adrian Weller, Michael J. Black, Bernhard Sch\u00f6lkopf\nVenue: IEEE International Conference on Computer Vision\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work identifies a key desideratum for PSL, and proposes a surprisingly simple proxy-free method, called SimPLE, which requires neither feature/proxy normalization nor angular margin and yet is able to generalize well in open-set recognition.'}\nUrl: https://arxiv.org/pdf/2310.09449",
  "Faculty Name: bhiksha raj\nPaperid: feecd2cfb7871a818ba514e8b4b3f9da482f17bc\nTitle: Synergy between human and machine approaches to sound/scene recognition and processing: An overview of ICASSP special session\nYear: 2023\nAbstract: Machine Listening, as usually formalized, attempts to perform a task that is, from our perspective, fundamentally human-performable, and performed by humans. Current automated models of Machine Listening vary from purely data-driven approaches to approaches imitating human systems. In recent years, the most promising approaches have been hybrid in that they have used data-driven approaches informed by models of the perceptual, cognitive, and semantic processes of the human system. Not only does the guidance provided by models of human perception and domain knowledge enable better, and more generalizable Machine Listening, in the converse, the lessons learned from these models may be used to verify or improve our models of human perception themselves. This paper summarizes advances in the development of such hybrid approaches, ranging from Machine Listening models that are informed by models of peripheral (human) auditory processes, to those that employ or derive semantic information encoded in relations between sounds.",
  "This paper summarizes advances in the development of such hybrid approaches, ranging from Machine Listening models that are informed by models of peripheral (human) auditory processes, to those that employ or derive semantic information encoded in relations between sounds. The research described herein was presented in a special session on\"Synergy between human and machine approaches to sound/scene recognition and processing\"at the 2023 ICASSP meeting.\nAuthors: L. Heller, Benjamin Elizalde, B. Raj, Soham Deshmukh\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Advances in the development of hybrid approaches to Machine Listening models that are informed by models of peripheral (human) auditory processes, to those that employ or derive semantic information encoded in relations between sounds are summarized.'}\nUrl: http://arxiv.org/pdf/2302.09719",
  "List of 2023 Open Access papers by bhiksha raj are:\nFREDOM: Fairness Domain Adaptation Approach to Semantic Scene Understanding\nUTOPIA: Unconstrained Tracking Objects without Preliminary Examination via Cross-Domain Adaptation\nSoftMatch: Addressing the Quantity-Quality Trade-off in Semi-supervised Learning\nFixed Inter-Neuron Covariability Induces Adversarial Robustness\nUnderstanding political polarization using language models: A dataset and method\nProlonged school closure during the pandemic time in successive waves of COVID-19- vulnerability of children to sexual abuses \u2013 A case study in Tamil Nadu, India\nBASS: Block-wise Adaptation for Speech Summarization\nUnderstanding Political Polarisation using Language Models: A dataset and method\nAn Approach to Ontological Learning from Weak Labels\nRethinking Voice-Face Correlation: A Geometry View\nPaaploss: A Phonetic-Aligned Acoustic Parameter Loss for Speech Enhancement\nImproving Perceptual Quality, Intelligibility, and Acoustics on VoIP Platforms\nApproach to Learning Generalized Audio Representation Through Batch Embedding Covariance Regularization and Constant-Q Transforms\nTraining on Foveated Images Improves Robustness to Adversarial",
  "Intelligibility, and Acoustics on VoIP Platforms\nApproach to Learning Generalized Audio Representation Through Batch Embedding Covariance Regularization and Constant-Q Transforms\nTraining on Foveated Images Improves Robustness to Adversarial Attacks\nImprecise Label Learning: A Unified Framework for Learning with Various Imprecise Label Configurations\nThe Hidden Dance of Phonemes and Visage: Unveiling the Enigmatic Link between Phonemes and Facial Features\nFairness Continual Learning Approach to Semantic Scene Understanding in Open-World Environments\nPaintSeg: Training-free Segmentation via Painting\nTAPLoss: A Temporal Acoustic Parameter Loss for Speech Enhancement\nSynergy between human and machine approaches to sound/scene recognition and processing: An overview of ICASSP special session\nLoFT: Local Proxy Fine-tuning For Improving Transferability Of Adversarial Attacks Against Large Language Model\nEvaluating Speech Synthesis by Training Recognizers on Synthetic Speech\nRethinking Audiovisual Segmentation with Semantic Quantization and Decomposition\nTowards Noise-Tolerant Speech-Referring Video Object Segmentation: Bridging Speech and Text\nPsychoacoustic Challenges Of Speech Enhancement On VoIP Platforms\nuSee: Unified Speech Enhancement and Editing with",
  "Training Recognizers on Synthetic Speech\nRethinking Audiovisual Segmentation with Semantic Quantization and Decomposition\nTowards Noise-Tolerant Speech-Referring Video Object Segmentation: Bridging Speech and Text\nPsychoacoustic Challenges Of Speech Enhancement On VoIP Platforms\nuSee: Unified Speech Enhancement and Editing with Conditional Diffusion Models\nToken Prediction as Implicit Classification to Identify LLM-Generated Text\nUnderstanding and Mitigating the Label Noise in Pre-training on Downstream Tasks\nImportance of negative sampling in weak label learning\nCompleting Visual Objects via Bridging Generation and Segmentation\nTraining Audio Captioning Models without Audio\nContinual Contrastive Spoken Language Understanding\nPrompting Audios Using Acoustic Properties For Emotion Representation\nPairwise Similarity Learning is SimPLE",
  "Bhiksha Raj\nProfessor, Language Technologies Institute\nContact\n6705 \u2014Gates & Hillman Centers\nEmail bhiksha@cs.cmu.edu\n412-268-9826\nResearch Area\nMachine Learning, Multimodal Computing and Interaction, Privacy and Security, Speech Processing, Spoken Interfaces and Dialogue Processing\n\nhttp://mlsp.cs.cmu.edu/people/bhiksha/index.php",
  "Faculty Name: carolyn rose\nPaperid: 06dc7b3d8cbc40fb4e39b42de1bc664deaacca74\nTitle: High school students\u2019 data modeling practices and processes: from modeling unstructured data to evaluating automated decisions\nYear: 2023\nAbstract: ABSTRACT It\u2019s critical to foster artificial intelligence (AI) literacy for high school students, the first generation to grow up surrounded by AI, to understand working mechanism of data-driven AI technologies and critically evaluate automated decisions from predictive models. While efforts have been made to engage youth in understanding AI through developing machine learning models, few provided in-depth insights into the nuanced learning processes. In this study, we examined high school students\u2019 data modeling practices and processes. Twenty-eight students developed machine learning models with text data for classifying negative and positive reviews of ice cream stores. We identified nine data modeling practices that describe students\u2019 processes of model exploration, development, and testing and two themes about evaluating automated decisions from data technologies. The results provide implications for designing accessible data modeling experiences for students to understand data justice as well as the role and responsibility of data modelers in creating AI technologies.",
  "We identified nine data modeling practices that describe students\u2019 processes of model exploration, development, and testing and two themes about evaluating automated decisions from data technologies. The results provide implications for designing accessible data modeling experiences for students to understand data justice as well as the role and responsibility of data modelers in creating AI technologies.\nAuthors: Shiyan Jiang, Hengtao Tang, Can Tatar, C. Ros\u00e9, J. Chao\nVenue: Journal of Educational Media\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It\u2019s critical to foster artificial intelligence literacy for high school students to understand working mechanism of data-driven AI technologies and critically evaluate automated decisions from predictive models.'}\nUrl: https://www.tandfonline.com/doi/pdf/10.1080/17439884.2023.2189735?needAccess=true&role=button",
  "Faculty Name: carolyn rose\nPaperid: 0c0d8ea1c1745e7b56bc3b1513a715ae3df30c44\nTitle: Linguistic representations for fewer-shot relation extraction across domains\nYear: 2023\nAbstract: Recent work has demonstrated the positive impact of incorporating linguistic representations as additional context and scaffolds on the in-domain performance of several NLP tasks. We extend this work by exploring the impact of linguistic representations on cross-domain performance in a few-shot transfer setting. An important question is whether linguistic representations enhance generalizability by providing features that function as cross-domain pivots. We focus on the task of relation extraction on three datasets of procedural text in two domains, cooking and materials science. Our approach augments a popular transformer-based architecture by alternately incorporating syntactic and semantic graphs constructed by freely available off-the-shelf tools. We examine their utility for enhancing generalization, and investigate whether earlier findings, e.g. that semantic representations can be more helpful than syntactic ones, extend to relation extraction in multiple domains.",
  "We examine their utility for enhancing generalization, and investigate whether earlier findings, e.g. that semantic representations can be more helpful than syntactic ones, extend to relation extraction in multiple domains. We find that while the inclusion of these graphs results in significantly higher performance in few-shot transfer, both types of graph exhibit roughly equivalent utility.\nAuthors: Sireesh Gururaja, Ritam Dutt, Ting-gen Liao, C. Ros\u00e9\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work explores the impact of linguistic representations on cross-domain performance in a few-shot transfer setting, and investigates whether earlier findings, e.g. that semantic representations can be more helpful than syntactic ones, extend to relation extraction in multiple domains.'}\nUrl: https://arxiv.org/pdf/2307.03823",
  "Faculty Name: carolyn rose\nPaperid: 117e1323677cb5d78ece0fd07b5cfa81618f4866\nTitle: Using counterfactual contrast to improve compositional generalization for multi-step quantitative reasoning\nYear: 2023\nAbstract: In quantitative question answering, compositional generalization is one of the main challenges of state of the art models, especially when longer sequences of reasoning steps are required. In this paper we propose CounterComp, a method that uses counterfactual scenarios to generate samples with compositional contrast. Instead of a data augmentation approach, CounterComp is based on metric learning, which allows for direct sampling from the training set and circumvents the need for additional human labels. Our proposed auxiliary metric learning loss improves the performance of three state of the art models on four recently released datasets. We also show how the approach can improve OOD performance on unseen domains, as well as unseen compositions. Lastly, we demonstrate how the method can lead to better compositional attention patterns during training.",
  "Our proposed auxiliary metric learning loss improves the performance of three state of the art models on four recently released datasets. We also show how the approach can improve OOD performance on unseen domains, as well as unseen compositions. Lastly, we demonstrate how the method can lead to better compositional attention patterns during training.\nAuthors: Armineh Nourbakhsh, Sameena Shah, C. Ros\u00e9\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper proposes CounterComp, a method that uses counterfactual scenarios to generate samples with compositional contrast based on metric learning, which allows for direct sampling from the training set and circumvents the need for additional human labels.'}\nUrl: https://aclanthology.org/2023.acl-long.834.pdf",
  "Faculty Name: carolyn rose\nPaperid: 15d85036b15388bcb0199c83c01ba833e6095a31\nTitle: Towards Extracting and Understanding the Implicit Rubrics of Transformer Based Automatic Essay Scoring Models\nYear: 2023\nAbstract: By aligning the functional components derived from the activations of transformer models trained for AES with external knowledge such as human-understandable feature groups, the proposed method improves the interpretability of a Longformer Automatic Essay Scoring (AES) system and provides tools for performing such analyses on further neural AES systems. The analysis focuses on models trained to score essays based on organization, main idea, support, and language. The findings provide insights into the models\u2019 decision-making processes, biases, and limitations, contributing to the development of more transparent and reliable AES systems.",
  "The analysis focuses on models trained to score essays based on organization, main idea, support, and language. The findings provide insights into the models\u2019 decision-making processes, biases, and limitations, contributing to the development of more transparent and reliable AES systems.\nAuthors: James Fiacco, David Adamson, C. Ros\u00e9\nVenue: Workshop on Innovative Use of NLP for Building Educational Applications\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The proposed method improves the interpretability of a Longformer Automatic Essay Scoring (AES) system and provides tools for performing such analyses on further neural AES systems.'}\nUrl: https://aclanthology.org/2023.bea-1.20.pdf",
  "Faculty Name: carolyn rose\nPaperid: 27ca2d927421035e10b48c96a96db32224f1f8e6\nTitle: Exploring Artificial Intelligence in English Language Arts with StoryQ\nYear: 2023\nAbstract: Exploring Artificial Intelligence (AI) in English Language Arts (ELA) with StoryQ is a 10-hour curriculum module designed for high school ELA classes. The module introduces students to fundamental AI concepts and essential machine learning workflow using StoryQ, a web-based GUI environment for Grades 6-12 learners. In this module, students work with unstructured text data and learn to train, test, and improve text classification models such as intent recognition, clickbait filter, and sentiment analysis. As they interact with machine-learning language models deeply, students also gain a nuanced understanding of language and how to wield it, not just as a data structure, but as a tool in our human-human encounters as well. The current version contains eight lessons, all delivered through a full-featured online learning and teaching platform. Computers and Internet access are required to implement the module.",
  "The current version contains eight lessons, all delivered through a full-featured online learning and teaching platform. Computers and Internet access are required to implement the module. The module was piloted in an ELA class in the Spring of 2022, and the student learning outcomes were positive. The module is currently undergoing revision and will be further tested and improved in Fall 2022.\nAuthors: J. Chao, Rebecca Ellis, Shiyan Jiang, C. Ros\u00e9, W. Finzer, Can Tatar, James Fiacco, Kenia Wiedemann\nVenue: AAAI Conference on Artificial Intelligence\nTldr: {'model': 'tldr@v2.0.0', 'text': None}\nUrl: https://ojs.aaai.org/index.php/AAAI/article/download/26899/26671",
  "Faculty Name: carolyn rose\nPaperid: 41646e0908c7e5086b868ca9dd3e74fe56894368\nTitle: Can a family caregiver provide an evidence\u2010based falls prevention intervention to the person with cognitive impairment or dementia they care for?\nYear: 2023\nAbstract: Falls are a common reason that persons with cognitive impairment or dementia (PwCID) cannot remain at home. FallsTalk is a one\u2010month evidence\u2010based falls prevention program that focuses attention on the individual causes of losses of balance or falls. FallsTalk encourages new falls prevention behaviors, which have been shown to decrease falls. We adapted FallsTalk for family Caregiver (FCG) administration to a PwCID with a recent history of falls to determine if FallsTalk\u2010Caregiver could influence the number of new falls prevention behaviors reported by the FCG or the number of falls.",
  "We adapted FallsTalk for family Caregiver (FCG) administration to a PwCID with a recent history of falls to determine if FallsTalk\u2010Caregiver could influence the number of new falls prevention behaviors reported by the FCG or the number of falls.\nAuthors: V. Panzer, Veronica Smith, Dorothy Wakefield, J. Maher, C. Ham, R. Fortinsky\nVenue: Alzheimer's &amp; Dementia\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work adapted FallsTalk for family Caregiver administration to a PwCID with a recent history of falls to determine if FallsTalk\u2010Caregiver could influence the number of new falls prevention behaviors reported by the FCG or the numberof falls.'}\nUrl: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/alz.066371",
  "Faculty Name: carolyn rose\nPaperid: 7ec990ab7362e8eac0c074830d44a58a1d89b4a6\nTitle: Enhancing student learning and achievement through orchestration of group processes and group composition\nYear: 2023\nAbstract: None\nAuthors: Carolyn P. Ros\u00e9, Sanna J\u00e4rvel\u00e4\nVenue: International Journal of Computer-Supported Collaborative Learning\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This September issue of the International Journal of Computer-Supported Collaborative Learning reflects on the importance of productive collaborative processes, with an emphasis on feedback processes, and the scaffolding that upholds and promotes productive learning processes, whether it is explicit or implicit.'}\nUrl: https://link.springer.com/content/pdf/10.1007/s11412-023-09408-x.pdf",
  "Faculty Name: carolyn rose\nPaperid: 914c32500ac858c0f849996a2887892e8bba8fb6\nTitle: Hypermutator emergence in experimental Escherichia coli populations is stress-type dependent\nYear: 2023\nAbstract: Abstract Genotypes exhibiting an increased mutation rate, called hypermutators, can propagate in microbial populations because they can have an advantage due to the higher supply of beneficial mutations needed for adaptation. Although this is a frequently observed phenomenon in natural and laboratory populations, little is known about the influence of parameters such as the degree of maladaptation, stress intensity, and the genetic architecture for adaptation on the emergence of hypermutators. To address this knowledge gap, we measured the emergence of hypermutators over ~1,000 generations in experimental Escherichia coli populations exposed to different levels of osmotic or antibiotic stress. Our stress types were chosen based on the assumption that the genetic architecture for adaptation differs between them. Indeed, we show that the size of the genetic basis for adaptation is larger for osmotic stress compared to antibiotic stress.",
  "Our stress types were chosen based on the assumption that the genetic architecture for adaptation differs between them. Indeed, we show that the size of the genetic basis for adaptation is larger for osmotic stress compared to antibiotic stress. During our experiment, we observed an increased emergence of hypermutators in populations exposed to osmotic stress but not in those exposed to antibiotic stress, indicating that hypermutator emergence rates are stress type dependent. These results support our hypothesis that hypermutator emergence is linked to the size of the genetic basis for adaptation. In addition, we identified other parameters that covaried with stress type (stress level and IS transposition rates) that might have contributed to an increased hypermutator provision and selection. Our results provide a first comparison of hypermutator emergence rates under varying stress conditions and point towards complex interactions of multiple stress-related factors on the evolution of mutation rates.",
  "Our results provide a first comparison of hypermutator emergence rates under varying stress conditions and point towards complex interactions of multiple stress-related factors on the evolution of mutation rates.\nAuthors: M. Callens, C. Rose, Michaela L Finnegan, Fran\u00e7ois Gatchitch, L\u00e9na Simon, J. Hamet, L\u00e9a Pradier, M. Dubois, S. Bedhomme\nVenue: Evolution Letters\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The results provide a first comparison of hypermutator emergence rates under varying stress conditions and point towards complex interactions of multiple stress-related factors on the evolution of mutation rates.'}\nUrl: https://academic.oup.com/evlett/advance-article-pdf/doi/10.1093/evlett/qrad019/50248143/qrad019.pdf",
  "Faculty Name: carolyn rose\nPaperid: bc936884d358d73d6b514f7e5899e67ad09690d8\nTitle: Editorial: Nine elements for robust collaborative learning analytics: A constructive collaborative critique\nYear: 2023\nAbstract: None\nAuthors: A. Wise, Carolyn P. Ros\u00e9, Sanna J\u00e4rvel\u00e4\nVenue: International Journal of Computer-Supported Collaborative Learning\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The four full articles of this March issue offer a view of the kind of work that the CSCL community is engaging in to capture meaningful traces of learning, map them onto valued learning constructs, and discover useful ways to present them back to teachers, students and other educational stakeholders.'}\nUrl: https://link.springer.com/content/pdf/10.1007/s11412-023-09389-x.pdf",
  "List of 2023 Open Access papers by carolyn rose are:\nEnhancing student learning and achievement through orchestration of group processes and group composition\nEditorial: Nine elements for robust collaborative learning analytics: A constructive collaborative critique\nHigh school students\u2019 data modeling practices and processes: from modeling unstructured data to evaluating automated decisions\nLinguistic representations for fewer-shot relation extraction across domains\nUsing counterfactual contrast to improve compositional generalization for multi-step quantitative reasoning\nTowards Extracting and Understanding the Implicit Rubrics of Transformer Based Automatic Essay Scoring Models\nExploring Artificial Intelligence in English Language Arts with StoryQ\nCan a family caregiver provide an evidence\u2010based falls prevention intervention to the person with cognitive impairment or dementia they care for?\nHypermutator emergence in experimental Escherichia coli populations is stress-type dependent",
  "Carolyn Ros\u00e9\nProfessor, Language Technologies Institute\nHuman-Computer Interaction Institute\nContact\n5415 \u2014Gates & Hillman Centers\nEmail\n412-268-7130\nResearch Area\nComputer-Supported Collaborative Learning/MOOCs, Information Retrieval, Text Mining and Analytics, Language Technologies for Education, Natural Language Processing and Computational Linguistics\n\nEducation\nPh.D. in Language and Information Technology\n1997\nEmployer Upon Graduation: \nFaculty, LTI CMU\nResearch\nMy research focuses on better understanding the social and pragmatic nature of conversation, and using this understanding to build computational systems that improve the efficacy of conversation both between people, and between people and computers. In order to pursue these goals, I invoke approaches from computational discourse analysis and text mining, conversational agents, and computer-supported collaborative learning. I ground my research in the fields of language technologies and human-computer interaction, and am fortunate to work closely with students and post-docs from the LTI and the Human-Computer Interaction Institute, as well as to direct my own lab, TELEDIA.",
  "I ground my research in the fields of language technologies and human-computer interaction, and am fortunate to work closely with students and post-docs from the LTI and the Human-Computer Interaction Institute, as well as to direct my own lab, TELEDIA. My group\u2019s highly interdisciplinary work, published in 160 peer-reviewed publications, is represented in the top venues in five fields: language technologies, learning sciences, cognitive science, educational technology and human-computer interaction.\n\nAn exciting direction of my group's work is spearheading a satellite working group to support social interaction for learning in MOOCs with EdX called DANCE. My research toward this end has birthed and substantially contributed to the growth of two thriving interrelated research areas: automated analysis of collaborative learning processes and dynamic support for collaborative learning. Both areas use intelligent conversational agents to support collaborative learning in a context-sensitive way.\n\nAll of my work draws insight from rich theoretical models from sociolinguistics and discourse analysis, and pares them down to precise operationalizations that capture the most important essence for achieving impact.",
  "Both areas use intelligent conversational agents to support collaborative learning in a context-sensitive way.\n\nAll of my work draws insight from rich theoretical models from sociolinguistics and discourse analysis, and pares them down to precise operationalizations that capture the most important essence for achieving impact. I always start by investigating how conversation works and formalizing this understanding in models that are precise enough to be reproducible and that demonstrate explanatory power in connection with outcomes with real-world value. The next step is to adapt, extend and apply machine learning and text mining technologies that leverage this deep understanding to build computational models capable of automatically applying these constructs to naturally occurring language interactions. Finally, with the technology to automatically monitor naturalistic language communication in place, we can build interventions with real-world benefits.\n\nThis approach leads to three aspects included in each project:\n\nBasic research on discourse analysis to identify conversational constructs that predict important group outcomes such as learning, knowledge transfer or motivation.\nBasic research on text classification technology for automated analysis of conversational constructs identified under research on discourse analysis, as well as tools to enable other researchers to do the same.",
  "Basic research on text classification technology for automated analysis of conversational constructs identified under research on discourse analysis, as well as tools to enable other researchers to do the same.\nBasic research on conversational agent technology and summarization that eases development of interventions triggered by automatic analyses from basic research on text classification that either enables human facilitators to offer support, directly provide feedback to groups or influence group participation in positive ways.\nHuman-Computer Interaction Institute https://hcii.cmu.edu/\nPersonal Website http://www.cs.cmu.edu/~cprose/",
  "Faculty Name: chenyan xiong\nPaperid: 105759bdb5e3bddc1d3244df2eff2d5c997a1d84\nTitle: Improving Multitask Retrieval by Promoting Task Specialization\nYear: 2023\nAbstract: Abstract In multitask retrieval, a single retriever is trained to retrieve relevant contexts for multiple tasks. Despite its practical appeal, naive multitask retrieval lags behind task-specific retrieval, in which a separate retriever is trained for each task. We show that it is possible to train a multitask retriever that outperforms task-specific retrievers by promoting task specialization. The main ingredients are: (1) a better choice of pretrained model\u2014one that is explicitly optimized for multitasking\u2014along with compatible prompting, and (2) a novel adaptive learning method that encourages each parameter to specialize in a particular task. The resulting multitask retriever is highly performant on the KILT benchmark.",
  "The resulting multitask retriever is highly performant on the KILT benchmark. Upon analysis, we find that the model indeed learns parameters that are more task-specialized compared to naive multitasking without prompting or adaptive learning.1\nAuthors: Wenzheng Zhang, Chenyan Xiong, K. Stratos, Arnold Overwijk\nVenue: Transactions of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is shown that it is possible to train a multitask retriever that outperforms task-specific retrievers by promoting task specialization, and the model indeed learns parameters that are more task-specialized compared to naive multitasking without prompting or adaptive learning.'}\nUrl: https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl_a_00597/2159628/tacl_a_00597.pdf",
  "Faculty Name: chenyan xiong\nPaperid: 159100c8323fc558e4073a3a006f3f243aca3a60\nTitle: Text Matching Improves Sequential Recommendation by Reducing Popularity Biases\nYear: 2023\nAbstract: This paper proposes Text mAtching based SequenTial rEcommenda-tion model (TASTE), which maps items and users in an embedding space and recommends items by matching their text representations. TASTE verbalizes items and user-item interactions using identifiers and attributes of items. To better characterize user behaviors, TASTE additionally proposes an attention sparsity method, which enables TASTE to model longer user-item interactions by reducing the self-attention computations during encoding. Our experiments show that TASTE outperforms the state-of-the-art methods on widely used sequential recommendation datasets. TASTE alleviates the cold start problem by representing long-tail items using full-text modeling and bringing the benefits of pretrained language models to recommendation systems. Our further analyses illustrate that TASTE significantly improves the recommendation accuracy by reducing the popularity bias of previous item id based recommendation models and returning more appropriate and text-relevant items to satisfy users.",
  "Our further analyses illustrate that TASTE significantly improves the recommendation accuracy by reducing the popularity bias of previous item id based recommendation models and returning more appropriate and text-relevant items to satisfy users. All codes are available at https://github.com/OpenMatch/TASTE.\nAuthors: Zhenghao Liu, Senkun Mei, Chenyan Xiong, Xiaohua Li, Shi Yu, Zhiyuan Liu, Yu Gu, Ge Yu\nVenue: International Conference on Information and Knowledge Management\nTldr: {'model': 'tldr@v2.0.0', 'text': None}\nUrl: https://arxiv.org/pdf/2308.14029",
  "Faculty Name: chenyan xiong\nPaperid: 1fe3a802efdc4f1a3e5c8187547f38a3ec65750b\nTitle: Unsupervised Dense Retrieval Training with Web Anchors\nYear: 2023\nAbstract: In this work, we present an unsupervised retrieval method with contrastive learning on web anchors. The anchor text describes the content that is referenced from the linked page. This shows similarities to search queries that aim to retrieve pertinent information from relevant documents. Based on their commonalities, we train an unsupervised dense retriever, Anchor-DR, with a contrastive learning task that matches the anchor text and the linked document. To filter out uninformative anchors (such as \"homepage\" or other functional anchors), we present a novel filtering technique to only select anchors that contain similar types of information as search queries. Experiments show that Anchor-DR outperforms state-of-the-art methods on unsupervised dense retrieval by a large margin (e.g., by 5.3% NDCG@10 on MSMARCO). The gain of our method is especially significant for search and question answering tasks.",
  "Experiments show that Anchor-DR outperforms state-of-the-art methods on unsupervised dense retrieval by a large margin (e.g., by 5.3% NDCG@10 on MSMARCO). The gain of our method is especially significant for search and question answering tasks. Our analysis further reveals that the pattern of anchor-document pairs is similar to that of search query-document pairs. Code available at https://github.com/Veronicium/AnchorDR.\nAuthors: Yiqing Xie, X. Liu, Chenyan Xiong\nVenue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work trains an unsupervised dense retriever, Anchor-DR, with a contrastive learning task that matches the anchor text and the linked document, and presents a novel filtering technique to only select anchors that contain similar types of information as search queries.'}\nUrl: https://dl.acm.org/doi/pdf/10.1145/3539618.3592080",
  "Faculty Name: chenyan xiong\nPaperid: 24811cadf16519910f643b6084107164e6ca4219\nTitle: Augmentation-Adapted Retriever Improves Generalization of Language Models as Generic Plug-In\nYear: 2023\nAbstract: Retrieval augmentation can aid language models (LMs) in knowledge-intensive tasks by supplying them with external information. Prior works on retrieval augmentation usually jointly fine-tune the retriever and the LM, making them closely coupled. In this paper, we explore the scheme of generic retrieval plug-in: the retriever is to assist target LMs that may not be known beforehand or are unable to be fine-tuned together. To retrieve useful documents for unseen target LMs, we propose augmentation-adapted retriever (AAR), which learns LM\u2019s preferences obtained from a known source LM. Experiments on the MMLU and PopQA datasets demonstrate that our AAR trained with a small source LM is able to significantly improve the zero-shot generalization of larger target LMs ranging from 250M Flan-T5 to 175B InstructGPT.",
  "Experiments on the MMLU and PopQA datasets demonstrate that our AAR trained with a small source LM is able to significantly improve the zero-shot generalization of larger target LMs ranging from 250M Flan-T5 to 175B InstructGPT. Further analysis indicates that the preferences of different LMs overlap, enabling AAR trained with a single source LM to serve as a generic plug-in for various target LMs. Our code is open-sourced at https://github.com/OpenMatch/Augmentation-Adapted-Retriever.\nAuthors: Zichun Yu, Chenyan Xiong, S. Yu, Zhiyuan Liu\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper proposes augmentation-adapted retriever (AAR), which learns LM\u2019s preferences obtained from a known source LM to assist target LMs that may not be known beforehand or are unable to be fine-tuned together in a generic retrieval plug-in.'}\nUrl: http://arxiv.org/pdf/2305.17331",
  "Faculty Name: chenyan xiong\nPaperid: 275da3802142fc42f6fab2ce2104223b2e0ef40d\nTitle: Fusion-in-T5: Unifying Document Ranking Signals for Improved Information Retrieval\nYear: 2023\nAbstract: Common IR pipelines are typically cascade systems that may involve multiple rankers and/or fusion models to integrate different information step-by-step. In this paper, we propose a novel re-ranker named Fusion-in-T5 (FiT5), which integrates document text information, retrieval features, and global document information into a single unified model using templated-based input and global attention. Experiments on passage ranking benchmarks MS MARCO and TREC DL show that FiT5 significantly improves ranking performance over prior pipelines. Analyses find that through global attention, FiT5 is able to jointly utilize the ranking features via gradually attending to related documents, and thus improve the detection of subtle nuances between them. Our code will be open-sourced.",
  "Analyses find that through global attention, FiT5 is able to jointly utilize the ranking features via gradually attending to related documents, and thus improve the detection of subtle nuances between them. Our code will be open-sourced.\nAuthors: S. Yu, Cheng-Chung Fan, Chenyan Xiong, David Jin, Zhiyuan Liu, Zhenghao Liu Tsinghua University, Huazhong University of Science, Technology, Microsoft Research, M. I. O. Technology, N. University\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A novel re-ranker named Fusion-in-T5 (FiT5), which integrates document text information, retrieval features, and global document information into a single unified model using templated-based input and global attention, is proposed.'}\nUrl: http://arxiv.org/pdf/2305.14685",
  "Faculty Name: chenyan xiong\nPaperid: 38aaf8a29df6deeff0bf64cc835d242a25b10337\nTitle: Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers\nYear: 2023\nAbstract: This paper explores the effectiveness of model-generated signals in improving zero-shot generalization of text-to-text Transformers such as T5. We study various designs to pretrain T5 using an auxiliary model to construct more challenging token replacements for the main model to denoise. Key aspects under study include the decoding target, the location of the RTD head, and the masking pattern. Based on these studies, we develop a new model, METRO-T0, which is pretrained using the redesigned ELECTRA-Style pretraining strategies and then prompt-finetuned on a mixture of NLP tasks. METRO-T0 outperforms all similar-sized baselines on prompted NLP benchmarks, such as _T0 Eval_ and MMLU, and rivals the state-of-the-art T0-11B model with only **8%** of its parameters.",
  "METRO-T0 outperforms all similar-sized baselines on prompted NLP benchmarks, such as _T0 Eval_ and MMLU, and rivals the state-of-the-art T0-11B model with only **8%** of its parameters. Our analysis on model\u2019s neural activation and parameter sensitivity reveals that the effectiveness of METRO-T0 stems from more balanced contribution of parameters and better utilization of their capacity. The code and model checkpoints are available at [https://github.com/gonglinyuan/metro_t0](https://github.com/gonglinyuan/metro_t0).",
  "The code and model checkpoints are available at [https://github.com/gonglinyuan/metro_t0](https://github.com/gonglinyuan/metro_t0).\nAuthors: Linyuan Gong, Chenyan Xiong, Xiaodong Liu, Payal Bajaj, Yiqing Xie, Alvin Cheung, Jianfeng Gao, Xia Song\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A new model, METRO-T0 is developed, which is pretrained using the redesigned ELECTRA-Style pretraining strategies and then prompt-finetuned on a mixture of NLP tasks and rivals the state-of-the-art T0-11B model with only **8%** of its parameters.'}\nUrl: https://aclanthology.org/2023.acl-long.724.pdf",
  "Faculty Name: chenyan xiong\nPaperid: a57b90cfc2eab46b773e65240d4ff910f05f989e\nTitle: Structure-Aware Language Model Pretraining Improves Dense Retrieval on Structured Data\nYear: 2023\nAbstract: This paper presents Structure Aware Dense Retrieval (SANTA) model, which encodes user queries and structured data in one universal embedding space for retrieving structured data. SANTA proposes two pretraining methods to make language models structure-aware and learn effective representations for structured data: 1) Structured Data Alignment, which utilizes the natural alignment relations between structured data and unstructured data for structure-aware pretraining. It contrastively trains language models to represent multi-modal text data and teaches models to distinguish matched structured data for unstructured texts. 2) Masked Entity Prediction, which designs an entity-oriented mask strategy and asks language models to fill in the masked entities. Our experiments show that SANTA achieves state-of-the-art on code search and product search and conducts convincing results in the zero-shot setting.",
  "2) Masked Entity Prediction, which designs an entity-oriented mask strategy and asks language models to fill in the masked entities. Our experiments show that SANTA achieves state-of-the-art on code search and product search and conducts convincing results in the zero-shot setting. SANTA learns tailored representations for multi-modal text data by aligning structured and unstructured data pairs and capturing structural semantics by masking and predicting entities in the structured data. All codes are available at https://github.com/OpenMatch/OpenMatch.\nAuthors: Xinze Li, Zhenghao Liu, Chenyan Xiong, Shi Yu, Yu Gu, Zhiyuan Liu, Ge Yu\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': None}\nUrl: http://arxiv.org/pdf/2305.19912",
  "Faculty Name: chenyan xiong\nPaperid: b9e8b62bcc019f47a0a015568f70039b3b7c1196\nTitle: Toolink: Linking Toolkit Creation and Using through Chain-of-Solving on Open-Source Model\nYear: 2023\nAbstract: Large Language Models (LLMs) have demonstrated remarkable progress in utilizing tools, but their closed-source nature and high inference costs pose limitations on their adaptability, necessitating a valid method that leverages smaller, open-sourced models. In this paper, we introduce Toolink, a comprehensive framework that performs task-solving by first creating a toolkit and then integrating the planning and calling of tools through a chain-of-solving (CoS) approach. We first validate the efficacy of Toolink in harnessing the model's creativity and CoS ability on ChatGPT. Subsequently, we curate CoS-GPT, a chain-of-solving dataset designed for tool-using, and finetune the LLaMA-7B model. It results in LLaMA-CoS, a powerful open-source model with advanced tool-planning and tool-calling capabilities.",
  "Subsequently, we curate CoS-GPT, a chain-of-solving dataset designed for tool-using, and finetune the LLaMA-7B model. It results in LLaMA-CoS, a powerful open-source model with advanced tool-planning and tool-calling capabilities. Evaluation on diverse tasks from BIG-bench demonstrates its CoS ability matches that of ChatGPT while its performance surpasses the chain-of-thought approach. Further studies highlight the generalization of LLaMA-CoS to unseen tasks and showcase its capability in using toolkits not explicitly tailored for the target task, affirming its robustness in real-world scenarios. All codes and data are released.",
  "Further studies highlight the generalization of LLaMA-CoS to unseen tasks and showcase its capability in using toolkits not explicitly tailored for the target task, affirming its robustness in real-world scenarios. All codes and data are released.\nAuthors: Cheng Qian, Chenyan Xiong, Zhenghao Liu, Zhiyuan Liu\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper introduces Toolink, a comprehensive framework that performs task-solving by first creating a toolkit and then integrating the planning and calling of tools through a chain-of-s solving (CoS) approach, and results in LLaMA-CoS, a powerful open-source model with advanced tool-planning and tool-calling capabilities.'}\nUrl: https://arxiv.org/pdf/2310.05155",
  "Faculty Name: chenyan xiong\nPaperid: bfa7f7bec1c4553c6c382ec2dbf4f889d7fa6e4f\nTitle: CompleQA: Benchmarking the Impacts of Knowledge Graph Completion Methods on Question Answering\nYear: 2023\nAbstract: None\nAuthors: Donghan Yu, Yu Gu, Chenyan Xiong, Yiming Yang\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: None\nUrl: https://aclanthology.org/2023.findings-emnlp.849.pdf",
  "Faculty Name: chenyan xiong\nPaperid: cdfd0926ad26c3c95a02db2ae891b7d4a457429c\nTitle: OpenMatch-v2: An All-in-one Multi-Modality PLM-based Information Retrieval Toolkit\nYear: 2023\nAbstract: Pre-trained language models (PLMs) have emerged as the foundation of the most advanced Information Retrieval (IR) models. Powered by PLMs, the latest IR research has proposed novel models, new domain adaptation algorithms as well as enlarged datasets. In this paper, we present a Python-based IR toolkit OpenMatch-v2. As a full upgrade of OpenMatch proposed in 2021, OpenMatch-v2 incorporates the most recent advancements of PLM-based IR research, providing support for new, cross-modality models and enhanced domain adaptation techniques with a streamlined, optimized infrastructure. The code of OpenMatch is publicly available at https://github.com/OpenMatch/OpenMatch.",
  "The code of OpenMatch is publicly available at https://github.com/OpenMatch/OpenMatch.\nAuthors: Shi Yu, Zhenghao Liu, Chenyan Xiong, Zhiyuan Liu\nVenue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\nTldr: {'model': 'tldr@v2.0.0', 'text': 'As a full upgrade of OpenMatch proposed in 2021, OpenMatch-v2 incorporates the most recent advancements of PLM-based IR research, providing support for new, cross-modality models and enhanced domain adaptation techniques with a streamlined, optimized infrastructure.'}\nUrl: https://dl.acm.org/doi/pdf/10.1145/3539618.3591813",
  "Faculty Name: chenyan xiong\nPaperid: e0401ca2d4fd6d0ed55130a4a24b33ed90111479\nTitle: Augmenting Zero-Shot Dense Retrievers with Plug-in Mixture-of-Memories\nYear: 2023\nAbstract: In this paper we improve the zero-shot generalization ability of language models via Mixture-Of-Memory Augmentation (MoMA), a mechanism that retrieves augmentation documents from multiple information corpora (\"external memories\"), with the option to\"plug in\"new memory at inference time. We develop a joint learning mechanism that trains the augmentation component with latent labels derived from the end retrieval task, paired with hard negatives from the memory mixture. We instantiate the model in a zero-shot dense retrieval setting by augmenting a strong T5-based retriever with MoMA. Our model, MoMA, obtains strong zero-shot retrieval accuracy on the eighteen tasks included in the standard BEIR benchmark. It outperforms systems that seek generalization from increased model parameters and computation steps.",
  "Our model, MoMA, obtains strong zero-shot retrieval accuracy on the eighteen tasks included in the standard BEIR benchmark. It outperforms systems that seek generalization from increased model parameters and computation steps. Our analysis further illustrates the necessity of augmenting with mixture-of-memory for robust generalization, the benefits of augmentation learning, and how MoMA utilizes the plug-in memory at inference time without changing its parameters. We plan to open source our code.\nAuthors: Suyu Ge, Chenyan Xiong, Corby Rosset, Arnold Overwijk, Jiawei Han, Paul N. Bennett\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': None}\nUrl: http://arxiv.org/pdf/2302.03754",
  "List of 2023 Open Access papers by chenyan xiong are:\nText Matching Improves Sequential Recommendation by Reducing Popularity Biases\nFusion-in-T5: Unifying Document Ranking Signals for Improved Information Retrieval\nOpenMatch-v2: An All-in-one Multi-Modality PLM-based Information Retrieval Toolkit\nCompleQA: Benchmarking the Impacts of Knowledge Graph Completion Methods on Question Answering\nImproving Multitask Retrieval by Promoting Task Specialization\nUnsupervised Dense Retrieval Training with Web Anchors\nAugmentation-Adapted Retriever Improves Generalization of Language Models as Generic Plug-In\nModel-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers\nStructure-Aware Language Model Pretraining Improves Dense Retrieval on Structured Data\nToolink: Linking Toolkit Creation and Using through Chain-of-Solving on Open-Source Model\nAugmenting Zero-Shot Dense Retrievers with Plug-in Mixture-of-Memories",
  "Chenyan Xiong\nAssociate Professor, Language Technologies Institute\nContact\nEmail cx@andrew.cmu.edu\nAddress\n5000 Forbes Avenue\nPittsburgh, PA 15213",
  "Faculty Name: daniel fried\nPaperid: 0524230fb6da632043c714523b409431dc08edc9\nTitle: Analysis of the transparent surface layer formed at the surfaces of arrested enamel caries lesions with tomographic imaging methods\nYear: 2023\nAbstract: None\nAuthors: Nai-Yuan N. Chang, Morgan Ng, Tina Dillas, Yi-Ching Ho, Yihua Zhu, D. Fried\nVenue: JADA Foundational Science\nTldr: None\nUrl: N/A",
  "Faculty Name: daniel fried\nPaperid: 19f59c14b3d79e3203c696128a135d33eb35e468\nTitle: Pragmatic Inference with a CLIP Listener for Contrastive Captioning\nYear: 2023\nAbstract: We propose a simple yet effective and robust method for contrastive captioning: generating discriminative captions that distinguish target images from very similar alternative distractor images. Our approach is built on a pragmatic inference procedure that formulates captioning as a reference game between a speaker, which produces possible captions describing the target, and a listener, which selects the target given the caption. Unlike previous methods that derive both speaker and listener distributions from a single captioning model, we leverage an off-the-shelf CLIP model to parameterize the listener. Compared with captioner-only pragmatic models, our method benefits from rich vision language alignment representations from CLIP when reasoning over distractors. Like previous methods for discriminative captioning, our method uses a hyperparameter to control the tradeoff between the informativity (how likely captions are to allow a human listener to discriminate the target image) and the fluency of the captions.",
  "Like previous methods for discriminative captioning, our method uses a hyperparameter to control the tradeoff between the informativity (how likely captions are to allow a human listener to discriminate the target image) and the fluency of the captions. However, we find that our method is substantially more robust to the value of this hyperparameter than past methods, which allows us to automatically optimize the captions for informativity - outperforming past methods for discriminative captioning by 11% to 15% accuracy in human evaluations\nAuthors: Jiefu Ou, Benno Krojer, Daniel Fried\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes a simple yet effective and robust method for contrastive captioning: generating discriminative captions that distinguish target images from very similar alternative distractor images by leveraging an off-the-shelf CLIP model to parameterize the listener.'}\nUrl: http://arxiv.org/pdf/2306.08818",
  "Faculty Name: daniel fried\nPaperid: 1bf21dabbdfc81fd4f9e92b1201ecce744cabb6a\nTitle: SantaCoder: don't reach for the stars!\nYear: 2023\nAbstract: The BigCode project is an open-scientific collaboration working on the responsible development of large language models for code. This tech report describes the progress of the collaboration until December 2022, outlining the current state of the Personally Identifiable Information (PII) redaction pipeline, the experiments conducted to de-risk the model architecture, and the experiments investigating better preprocessing methods for the training data. We train 1.1B parameter models on the Java, JavaScript, and Python subsets of The Stack and evaluate them on the MultiPL-E text-to-code benchmark. We find that more aggressive filtering of near-duplicates can further boost performance and, surprisingly, that selecting files from repositories with 5+ GitHub stars deteriorates performance significantly.",
  "We find that more aggressive filtering of near-duplicates can further boost performance and, surprisingly, that selecting files from repositories with 5+ GitHub stars deteriorates performance significantly. Our best model outperforms previous open-source multilingual code generation models (InCoder-6.7B and CodeGen-Multi-2.7B) in both left-to-right generation and infilling on the Java, JavaScript, and Python portions of MultiPL-E, despite being a substantially smaller model. All models are released under an OpenRAIL license at https://hf.co/bigcode.\nAuthors: Loubna Ben Allal, Raymond Li, Denis Kocetkov, Chenghao Mou, Christopher Akiki, Carlos Mu\u00f1oz Ferrandis, Niklas Muennighoff, Mayank Mishra, A. Gu, Manan Dey, Logesh Kumar Umapathi, Carolyn Jane Anderson, Yangtian Zi, J. Poirier, Hailey Schoelkopf, S. Troshin, Dmitry Abulkhanov, M. Romero, M. Lappert, F. Toni, Bernardo Garc'ia del R'io, Qian Liu, Shamik Bose, Urvashi Bhattacharyya,",
  "Poirier, Hailey Schoelkopf, S. Troshin, Dmitry Abulkhanov, M. Romero, M. Lappert, F. Toni, Bernardo Garc'ia del R'io, Qian Liu, Shamik Bose, Urvashi Bhattacharyya, Terry Yue Zhuo, I. Yu, Paulo Villegas, Marco Zocca, Sourab Mangrulkar, D. Lansky, Huu Nguyen, Danish Contractor, Luisa Villa, Jia Li, Dzmitry Bahdanau, Yacine Jernite, S. Hughes, Daniel Fried, Arjun Guha, H. D. Vries, Leandro von Werra\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The current state of the Personally Identifiable Information (PII) redaction pipeline is outlined, the experiments conducted to de-risk the model architecture, and the experiments investigating better preprocessing methods for the training data are outlined.'}\nUrl: http://arxiv.org/pdf/2301.03988",
  "Faculty Name: daniel fried\nPaperid: 2b2d9ee18507aa89a7f1ecba0bf68844c7d9aa75\nTitle: Grounding Language Models to Images for Multimodal Generation\nYear: 2023\nAbstract: We propose an ef\ufb01cient method to ground pre-trained text-only language models to the visual domain, enabling them to process and generate arbitrarily interleaved image-and-text data. Our method leverages the abilities of language models learnt from large scale text-only pretraining, such as in-context learning and free-form text generation. We keep the language model frozen, and \ufb01netune input and output linear layers to enable cross-modality interactions. This allows our model to process arbitrarily interleaved image-and-text inputs, and generate free-form text inter-leaved with retrieved images. We achieve strong zero-shot performance on grounded tasks such as contextual image retrieval and multimodal dialogue, and showcase compelling interactive abilities. Our approach works with any off-the-shelf language model and paves the way towards an effective, general solution for leveraging pretrained language models in visually grounded settings.",
  "We achieve strong zero-shot performance on grounded tasks such as contextual image retrieval and multimodal dialogue, and showcase compelling interactive abilities. Our approach works with any off-the-shelf language model and paves the way towards an effective, general solution for leveraging pretrained language models in visually grounded settings.\nAuthors: Jing Yu Koh, R. Salakhutdinov, Daniel Fried\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': None}\nUrl: http://arxiv.org/pdf/2301.13823",
  "Faculty Name: daniel fried\nPaperid: 3dc7c209b772baaf3cca527ac3c5deca330f7b2e\nTitle: Exploratory Analysis of Objective Outcome Measures for the Clinical Assessment of Erosive Tooth Wear\nYear: 2023\nAbstract: This study proposed using enamel surface texture and thickness for the objective detection and monitoring of erosive tooth wear (ETW), comparing them to the standard subjective Basic Erosive Wear Evaluation (BEWE). Thirty-two subjects (n = 597 teeth) were enrolled in this longitudinal observational clinical study. Enamel thickness (by cross-polarization optical coherence tomography, CP-OCT) and 3D dental microwear parameters, i.e., area-scale fractal complexity (Asfc), anisotropy (Str), and roughness (Sa) (by white-light scanning confocal profilometry), were obtained from buccal surfaces. Buccal, occlusal, and lingual surfaces were scored for BEWE and the maximum score per tooth (BEWEMax) was determined at baseline and 12 months (M12). Data outcome relationships were evaluated (alpha = 0.05).",
  "Buccal, occlusal, and lingual surfaces were scored for BEWE and the maximum score per tooth (BEWEMax) was determined at baseline and 12 months (M12). Data outcome relationships were evaluated (alpha = 0.05). Enamel thickness decreased (p < 0.001), BEWE scores, Sa, and Str increased (p < 0.001), while Asfc did not change at M12. Baseline BEWEBuccal correlated strongly with BEWEMax (r = 0.86, p < 0.001) and moderately with BEWELingual (r = 0.42, p < 0.001), but not with enamel thickness (r = 0.03, p = 0.43). Change (\u0394) in surface texture outcomes correlated poorly but significantly with \u0394BEWEBuccal (r = \u22120.15\u20130.16, p < 0.001) and did not correlate with \u0394enamel thickness (r = 0.02\u20130.09, p > 0.06). Teeth with BEWE progression revealed a greater increase in \u0394Sa and \u0394Str.",
  "Teeth with BEWE progression revealed a greater increase in \u0394Sa and \u0394Str. These findings suggest that enamel surface roughness can potentially determine ETW severity, and CP-OCT may be relevant for clinically monitoring enamel thickness.\nAuthors: M. J. R. Romero, P. Ungar, D. Fried, F. Lippert, D. Zero, S. Zunt, G. Eckert, A. Gossweiler, D. Elkington-Stauss, Guillermo Tamayo-Cabeza, A. Kelly, Troy Bartels, Camille Kita, Elizabeth Wewers, A. Hara\nVenue: Diagnostics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is suggested that enamel surface roughness can potentially determine ETW severity, and CP-OCT may be relevant for clinically monitoring enamel thickness.'}\nUrl: https://www.mdpi.com/2075-4418/13/15/2568/pdf?version=1690945777",
  "Faculty Name: daniel fried\nPaperid: 3e4085e5869f1b7959707a1e1d7d273b6057eb4e\nTitle: StarCoder: may the source be with you!\nYear: 2023\nAbstract: The BigCode community, an open-scientific collaboration working on the responsible development of Large Language Models for Code (Code LLMs), introduces StarCoder and StarCoderBase: 15.5B parameter models with 8K context length, infilling capabilities and fast large-batch inference enabled by multi-query attention. StarCoderBase is trained on 1 trillion tokens sourced from The Stack, a large collection of permissively licensed GitHub repositories with inspection tools and an opt-out process. We fine-tuned StarCoderBase on 35B Python tokens, resulting in the creation of StarCoder. We perform the most comprehensive evaluation of Code LLMs to date and show that StarCoderBase outperforms every open Code LLM that supports multiple programming languages and matches or outperforms the OpenAI code-cushman-001 model.",
  "We perform the most comprehensive evaluation of Code LLMs to date and show that StarCoderBase outperforms every open Code LLM that supports multiple programming languages and matches or outperforms the OpenAI code-cushman-001 model. Furthermore, StarCoder outperforms every model that is fine-tuned on Python, can be prompted to achieve 40\\% pass@1 on HumanEval, and still retains its performance on other programming languages. We take several important steps towards a safe open-access model release, including an improved PII redaction pipeline and a novel attribution tracing tool, and make the StarCoder models publicly available under a more commercially viable version of the Open Responsible AI Model license.\nAuthors: Raymond Li, Loubna Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov, Chenghao Mou, Marc Marone, Christopher Akiki, Jia Li, Jenny Chim, Qian Liu, Evgenii Zheltonozhskii, Terry Yue Zhuo, Thomas Wang, Olivier Dehaene, Mishig Davaadorj, J. Lamy-Poirier, Jo\u00e3o Monteiro, Oleh Shliazhko, Nicolas Gontier,",
  "Jenny Chim, Qian Liu, Evgenii Zheltonozhskii, Terry Yue Zhuo, Thomas Wang, Olivier Dehaene, Mishig Davaadorj, J. Lamy-Poirier, Jo\u00e3o Monteiro, Oleh Shliazhko, Nicolas Gontier, Nicholas Meade, Armel Zebaze, Ming-Ho Yee, Logesh Kumar Umapathi, Jian Zhu, Benjamin Lipkin, Muhtasham Oblokulov, Zhiruo Wang, Rudra Murthy, J. Stillerman, S. Patel, Dmitry Abulkhanov, Marco Zocca, Manan Dey, Zhihan Zhang, N. Fahmy, Urvashi Bhattacharyya, W. Yu, Swayam Singh, Sasha Luccioni, Paulo Villegas, M. Kunakov, Fedor Zhdanov, Manuel Romero, Tony Lee, Nadav Timor, Jennifer Ding, Claire Schlesinger, Hailey Schoelkopf, Jana Ebert, Tri Dao, Mayank Mishra, A. Gu, Jennifer Robinson, Carolyn Jane Anderson, Brendan Dolan-Gavitt, Danish Contractor, Siva Reddy, Daniel Fried,",
  "Nadav Timor, Jennifer Ding, Claire Schlesinger, Hailey Schoelkopf, Jana Ebert, Tri Dao, Mayank Mishra, A. Gu, Jennifer Robinson, Carolyn Jane Anderson, Brendan Dolan-Gavitt, Danish Contractor, Siva Reddy, Daniel Fried, Dzmitry Bahdanau, Yacine Jernite, Carlos Mu\u00f1oz Ferrandis, Sean M. Hughes, Thomas Wolf, Arjun Guha, Leandro von Werra, H. D. Vries\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work performs the most comprehensive evaluation of Code LLMs to date and shows that StarCoderBase outperforms every open Code LLM that supports multiple programming languages and matches or outperforms the OpenAI code-cushman-001 model.'}\nUrl: http://arxiv.org/pdf/2305.06161",
  "Faculty Name: daniel fried\nPaperid: 4a48291d52be0ef4e399270eb029fe03ca2ed831\nTitle: Assessment of the activity of secondary caries lesions with short-wavelength infrared, thermal, and optical coherence tomographic imaging\nYear: 2023\nAbstract: Abstract. Significance: Leakage in the interfaces between restorative materials and tooth structure allows for fluid and bacterial acid infiltration, causing restoration failure due to secondary caries. Dentists spend more time replacing composite restorations than placing new ones. Previous in vitro and in vivo studies on enamel and root surfaces using shortwave-infrared (SWIR) and thermal imaging during dehydration with forced air have been promising for assessing lesion activity. Aim: We hypothesized that SWIR reflectance and thermal imaging methods can be used to monitor the activity of secondary caries lesions around composite restorations. The objective of this study was to employ these methods to measure the rate of fluid loss from lesions during dehydration with forced air to assess lesion activity. Approach: Sixty-three extracted human teeth with total of 109 suspected secondary lesions were examined using SWIR and thermal imaging during dehydration.",
  "The objective of this study was to employ these methods to measure the rate of fluid loss from lesions during dehydration with forced air to assess lesion activity. Approach: Sixty-three extracted human teeth with total of 109 suspected secondary lesions were examined using SWIR and thermal imaging during dehydration. The thickness of the highly mineralized transparent surface layer (TSL) at lesion interfaces indicative of lesion activity was measured by optical coherence tomography (OCT). Micro-computed tomography (MicroCT) was used to further confirm lesion severity and structure. OCT and MicroCT measurements of lesion structure, depth, and severity were correlated with fluid loss rates measured with SWIR reflectance and thermal imaging. Results: TSL thickness measured with OCT correlated with both SWIR reflectance and thermal measurements of rates of fluid loss (p\u2009\u2009<\u2009\u20090.05). Increasing TSL thickness led to decreased permeability of lesions, potentially indicating full lesion arrest at TSL\u2009\u2009\u2265\u2009\u200970\u2009\u2009\u03bcm. SWIR performed better than thermal imaging for secondary lesion activity assessment, although both methods performed best on smooth surface lesions.",
  "Increasing TSL thickness led to decreased permeability of lesions, potentially indicating full lesion arrest at TSL\u2009\u2009\u2265\u2009\u200970\u2009\u2009\u03bcm. SWIR performed better than thermal imaging for secondary lesion activity assessment, although both methods performed best on smooth surface lesions. Conclusions: Nondestructive SWIR reflectance and OCT imaging methods are promising for clinically monitoring the activity of secondary caries lesions.\nAuthors: Nai-Yuan N. Chang, Tina Dillas, Yihua Zhu, D. Fried\nVenue: Journal of Biomedical Optics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Nondestructive SWIR reflectance and OCT imaging methods are promising for clinically monitoring the activity of secondary caries lesions.'}\nUrl: https://www.spiedigitallibrary.org/journals/journal-of-biomedical-optics/volume-28/issue-9/094801/Assessment-of-the-activity-of-secondary-caries-lesions-with-short/10.1117/1.JBO.28.9.094801.pdf",
  "Faculty Name: daniel fried\nPaperid: 5016766c87982f5c62ef6580e120939ab155d776\nTitle: Amortizing Pragmatic Program Synthesis with Rankings\nYear: 2023\nAbstract: In program synthesis, an intelligent system takes in a set of user-generated examples and returns a program that is logically consistent with these examples. The usage of Rational Speech Acts (RSA) framework has been successful in building \\emph{pragmatic} program synthesizers that return programs which -- in addition to being logically consistent -- account for the fact that a user chooses their examples informatively. However, the computational burden of running the RSA algorithm has restricted the application of pragmatic program synthesis to domains with a small number of possible programs. This work presents a novel method of amortizing the RSA algorithm by leveraging a \\emph{global pragmatic ranking} -- a single, total ordering of all the hypotheses. We prove that for a pragmatic synthesizer that uses a single demonstration, our global ranking method exactly replicates RSA's ranked responses. We further empirically show that global rankings effectively approximate the full pragmatic synthesizer in an online, multi-demonstration setting.",
  "We prove that for a pragmatic synthesizer that uses a single demonstration, our global ranking method exactly replicates RSA's ranked responses. We further empirically show that global rankings effectively approximate the full pragmatic synthesizer in an online, multi-demonstration setting. Experiments on two program synthesis domains using our pragmatic ranking method resulted in orders of magnitudes of speed ups compared to the RSA synthesizer, while outperforming the standard, non-pragmatic synthesizer.\nAuthors: Yewen Pu, Saujas Vaduguru, Priyan Vaithilingam, Elena L. Glassman, Daniel Fried\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': \"This work presents a novel method of amortizing the RSA algorithm by leveraging a single, total ordering of all the hypotheses, and proves that for a pragmatic synthesizer that uses a single demonstration, the global ranking method exactly replicates RSA's ranked responses.\"}\nUrl: https://arxiv.org/pdf/2309.03225",
  "Faculty Name: daniel fried\nPaperid: 52b9ab94b9a4be203031bbc1fa61251513b1d5f7\nTitle: Monitoring lesion activity on primary teeth with CP\u2010OCT and SWIR reflectance imaging\nYear: 2023\nAbstract: The purpose of this study was to use cross polarization optical coherence tomography (CP\u2010OCT) and short wavelength infrared imaging (SWIR) reflectance imaging to monitor changes in the structure and activity of early occlusal caries on primary teeth over a period of 6 months during intervention with fluoride.\nAuthors: Yihua Zhu, Jungsoo Kim, B. Lin, D. Fried\nVenue: Lasers in Surgery and Medicine\nTldr: {'model': 'tldr@v2.0.0', 'text': None}\nUrl: https://escholarship.org/content/qt24z290zt/qt24z290zt.pdf?t=rvf4ji",
  "Faculty Name: daniel fried\nPaperid: 6aedce6dc4e6c9a218bbc95fc4ae4d4de8d424ac\nTitle: Active Surveillance of Root Caries in Vivo with CP-OCT\nYear: 2023\nAbstract: The active surveillance of root caries lesions to monitor potential remineralization or decay progression is challenging for the clinician, due to unreliable diagnostic information. The conventional visual and tactile methods for assessing the lesion activity are not reliable, and the clinician is often unable to determine if the lesion is progressing or has been arrested. An important marker of an arrested lesion is a highly mineralized transparent surface zone (TSL) that forms when the mineral is deposited in the outer layer of the lesion. The purpose of this study was to determine if cross-polarization optical coherence tomography (CP-OCT) could be used to detect changes in the lesion severity and activity during active monitoring. In total, 18 subjects with 22 suspected active root caries lesions were evaluated using CP-OCT at the baseline, 3 months, and 6 months. All subjects were instructed to use a high fluoride dentifrice at the baseline.",
  "In total, 18 subjects with 22 suspected active root caries lesions were evaluated using CP-OCT at the baseline, 3 months, and 6 months. All subjects were instructed to use a high fluoride dentifrice at the baseline. The results showed that CP-OCT was able to discriminate the active from the arrested lesions by identifying the presence of a TSL on arrested lesions. The results also indicated that the mean TSL thickness increased significantly (p < 0.05) for the nine lesion areas. In addition, CP-OCT was able to show the progression of demineralization, erosion, and changes in gingival contours in scanned areas. CP-OCT was valuable for monitoring the activity and severity of root caries lesions in vivo. CP-OCT can be used to assess the activity of root caries lesions at a single time point by detecting the presence of a TSL at the lesion surface indicative of the lesion arrest.",
  "CP-OCT was valuable for monitoring the activity and severity of root caries lesions in vivo. CP-OCT can be used to assess the activity of root caries lesions at a single time point by detecting the presence of a TSL at the lesion surface indicative of the lesion arrest.\nAuthors: Yihua Zhu, Minyoung Kim, D. Curtis, Jing Wang, O. Le, D. Fried\nVenue: Diagnostics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'CP-OCT was valuable for monitoring the activity and severity of root caries lesions in vivo and was able to show the progression of demineralization, erosion, and changes in gingival contours in scanned areas.'}\nUrl: https://www.mdpi.com/2075-4418/13/3/465/pdf?version=1674821027",
  "Faculty Name: daniel fried\nPaperid: 6fb5c0eff3696ef252aca9638e10176ecce7cecb\nTitle: Generating Images with Multimodal Language Models\nYear: 2023\nAbstract: We propose a method to fuse frozen text-only large language models (LLMs) with pre-trained image encoder and decoder models, by mapping between their embedding spaces. Our model demonstrates a wide suite of multimodal capabilities: image retrieval, novel image generation, and multimodal dialogue. Ours is the first approach capable of conditioning on arbitrarily interleaved image and text inputs to generate coherent image (and text) outputs. To achieve strong performance on image generation, we propose an efficient mapping network to ground the LLM to an off-the-shelf text-to-image generation model. This mapping network translates hidden representations of text into the embedding space of the visual models, enabling us to leverage the strong text representations of the LLM for visual outputs. Our approach outperforms baseline generation models on tasks with longer and more complex language. In addition to novel image generation, our model is also capable of image retrieval from a prespecified dataset, and decides whether to retrieve or generate at inference time.",
  "Our approach outperforms baseline generation models on tasks with longer and more complex language. In addition to novel image generation, our model is also capable of image retrieval from a prespecified dataset, and decides whether to retrieve or generate at inference time. This is done with a learnt decision module which conditions on the hidden representations of the LLM. Our model exhibits a wider range of capabilities compared to prior multimodal language models. It can process image-and-text inputs, and produce retrieved images, generated images, and generated text -- outperforming non-LLM based generation models across several text-to-image tasks that measure context dependence.\nAuthors: Jing Yu Koh, Daniel Fried, R. Salakhutdinov\nVenue: Neural Information Processing Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes a method to fuse frozen text-only large language models (LLMs) with pre-trained image encoder and decoder models, by mapping between their embedding spaces, and exhibits a wider range of capabilities compared to prior multimodal language models.'}\nUrl: https://arxiv.org/pdf/2305.17216",
  "Faculty Name: daniel fried\nPaperid: aa705ba5294ed9d06978fe6a08ab2f2b5dd08e1e\nTitle: Time\u2010resolved SWIR imaging for the assessment of the activity of occlusal caries lesions\nYear: 2023\nAbstract: The aim of this study was to develop a clinical SWIR reflectance handpiece to assess the activity of lesions on the occlusal surfaces. The time\u2010resolved reflectivity of 10 active and 10 arrested occlusal caries lesions on extracted teeth was monitored at 1470\u2009nm using a benchtop system and a modified clinical prototype during forced air drying. The presence of a highly mineralized surface layer measured with microcomputed tomography (microCT) was used to indicate lesion activity. Multiple kinetic parameters were extracted from the acquired SWIR time versus intensity dehydration curves and used to assess lesion activity. Three parameters: delay, %Ifin, and rate calculated from the SWIR dehydration curves were significantly different (p\u2009<\u20090.05) between active and arrested lesions.",
  "Multiple kinetic parameters were extracted from the acquired SWIR time versus intensity dehydration curves and used to assess lesion activity. Three parameters: delay, %Ifin, and rate calculated from the SWIR dehydration curves were significantly different (p\u2009<\u20090.05) between active and arrested lesions. The modified clinical probe was able to completely dehydrate all the active lesion areas in the occlusal pits and fissures in less than 30\u2009s.\nAuthors: Morgan Ng, Spencer Wycoff, Yihua Zhu, Yi-Ching Ho, Hannah Takasuka, D. Fried\nVenue: Journal of Biophotonics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A clinical SWIR reflectance handpiece to assess the activity of lesions on the occlusal surfaces was developed and was able to completely dehydrate all the active lesion areas in the Occlusal pits and fissures in less than 30\\u2009s.'}\nUrl: N/A",
  "Faculty Name: daniel fried\nPaperid: bebca5d54374c83a7489638d3b45d2b006d559f0\nTitle: Diagnostic Performance of Multispectral SWIR Transillumination and Reflectance Imaging for Caries Detection\nYear: 2023\nAbstract: The aim of this clinical study was to compare the diagnostic performance of dual short wavelength infrared (SWIR) occlusal transillumination and reflectance multispectral imaging with conventional visual assessment and radiography for caries detection on premolars scheduled for extraction for orthodontics reasons. Polarized light microscopy (PLM) and micro-computed tomography (microCT) performed after tooth extraction were used as gold standards. The custom-fabricated imaging probe was 3D-printed and the imaging system employed a SWIR camera and fiber-optic light sources emitting light at 1300 nm for occlusal transillumination and 1600 nm for reflectance measurements. Teeth (n = 135) on 40 test subjects were imaged in vivo using the SWIR imaging prototype in the study and teeth were extracted after imaging.",
  "Teeth (n = 135) on 40 test subjects were imaged in vivo using the SWIR imaging prototype in the study and teeth were extracted after imaging. Our study demonstrates for the first time that near-simultaneous real-time transillumination and reflectance video can be successfully acquired for caries detection. Both SWIR imaging modalities had markedly higher sensitivity for lesions on proximal and occlusal surfaces compared to conventional methods (visual and radiographic). Reflectance imaging at 1600 nm had higher sensitivity and specificity than transillumination at 1300 nm. The combined SWIR methods yielded higher specificity but the combined sensitivity was lower than for each individual method.\nAuthors: Yihua Zhu, C. Ng, O. Le, Yi-Ching Ho, D. Fried\nVenue: Diagnostics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This study demonstrates for the first time that near-simultaneous real-time transillumination and reflectance video can be successfully acquired for caries detection.'}\nUrl: https://www.mdpi.com/2075-4418/13/17/2824/pdf?version=1693538243",
  "Faculty Name: daniel fried\nPaperid: e41482f4ee984f17382f6cdd900df094d928be06\nTitle: WebArena: A Realistic Web Environment for Building Autonomous Agents\nYear: 2023\nAbstract: With advances in generative AI, there is now potential for autonomous agents to manage daily tasks via natural language commands. However, current agents are primarily created and tested in simplified synthetic environments, leading to a disconnect with real-world scenarios. In this paper, we build an environment for language-guided agents that is highly realistic and reproducible. Specifically, we focus on agents that perform tasks on the web, and create an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management. Our environment is enriched with tools (e.g., a map) and external knowledge bases (e.g., user manuals) to encourage human-like task-solving. Building upon our environment, we release a set of benchmark tasks focusing on evaluating the functional correctness of task completions. The tasks in our benchmark are diverse, long-horizon, and designed to emulate tasks that humans routinely perform on the internet.",
  "Building upon our environment, we release a set of benchmark tasks focusing on evaluating the functional correctness of task completions. The tasks in our benchmark are diverse, long-horizon, and designed to emulate tasks that humans routinely perform on the internet. We experiment with several baseline agents, integrating recent techniques such as reasoning before acting. The results demonstrate that solving complex tasks is challenging: our best GPT-4-based agent only achieves an end-to-end task success rate of 14.41%, significantly lower than the human performance of 78.24%. These results highlight the need for further development of robust agents, that current state-of-the-art large language models are far from perfect performance in these real-life tasks, and that WebArena can be used to measure such progress.",
  "These results highlight the need for further development of robust agents, that current state-of-the-art large language models are far from perfect performance in these real-life tasks, and that WebArena can be used to measure such progress.\nAuthors: Shuyan Zhou, Frank F. Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, Yonatan Bisk, Daniel Fried, Uri Alon, Graham Neubig\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper builds an environment for language-guided agents that is highly realistic and reproducible, and creates an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management.'}\nUrl: https://arxiv.org/pdf/2307.13854",
  "Faculty Name: daniel fried\nPaperid: eafc0e6504514650753207108f15e62e09008950\nTitle: Longitudinal assessment of dental erosion-abrasion by cross-polarization optical coherence tomography in vitro.\nYear: 2023\nAbstract: This study tested a novel in vitro dental erosion-abrasion model and the performance of cross-polarization optical coherence tomography (CP-OCT) in longitudinally monitoring the simulated lesions. Thirty human enamel specimens were prepared and randomized to receive three dental erosion-abrasion (EA) protocols: severe (s-EA, lemon juice/pH:2.5/4.25%w/v citric acid), moderate (m-EA, grapefruit juice/pH:3.5/1.03%w/v citric acid) and no-EA (water, control). EA challenge was performed by exposing the specimens to acidic solutions 4x/day and to brushing 2x/day with 1:3 fluoridated toothpaste slurry, for 14 days.",
  "EA challenge was performed by exposing the specimens to acidic solutions 4x/day and to brushing 2x/day with 1:3 fluoridated toothpaste slurry, for 14 days. Enamel thickness measurements were obtained using CP-OCT at baseline (D0), 7 (D7) and 14 days (D14) and micro-computed tomography (micro-CT) at D14. Enamel surface loss was measured with both CP-OCT and optical profilometry at D0, D7 and D14. Data was analyzed with repeated-measures ANOVA and Pearson's correlation (r) (\u03b1 = 0.05). CP-OCT enamel thickness decreased over time in the s-EA group (D0 >D7 > D14, p < 0.001) and m-EA group (D0 > D14, p = 0.019) but did not change in the no-EA group (p = 0.30). Overall, CP-OCT and micro-CT results at D14 correlated moderately (r = 0.73).",
  "Overall, CP-OCT and micro-CT results at D14 correlated moderately (r = 0.73). CP-OCT surface loss was highest for s-EA (p <0.001) but did not differ between moderate and no-EA (p = 0.25). Enamel surface loss with profilometry increased with severity (no-EA>m-EA>s-EA, p < 0.001). D14 surface loss was higher than D7 for both methods except for the no-EA group with profilometry. CP-OCT and profilometry had moderate overall correlation (r = 0.70). Our results revealed that the currently proposed in vitro dental erosion-abrasion model is valid and could simulate lesions of different severities over time. CP-OCT was a suitable method for monitoring the EA lesions.",
  "CP-OCT and profilometry had moderate overall correlation (r = 0.70). Our results revealed that the currently proposed in vitro dental erosion-abrasion model is valid and could simulate lesions of different severities over time. CP-OCT was a suitable method for monitoring the EA lesions.\nAuthors: M. J. R. Romero, S. J. Bezerra, Daniel Fried, F. Lippert, G. Eckert, A. Hara\nVenue: Brazilian Oral Research\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The results revealed that the currently proposed in vitro dental erosion-abrasion model is valid and could simulate lesions of different severities over time and CP-OCT was a suitable method for monitoring the EA lesions.'}\nUrl: https://www.scielo.br/j/bor/a/J8Zw4RyWJFHJxhwCjntTzdK/?lang=en&format=pdf",
  "Faculty Name: daniel fried\nPaperid: f983cf75e368dcd07dd3a762721c095678514e56\nTitle: AutoReply: Detecting Nonsense in Dialogue with Discriminative Replies\nYear: 2023\nAbstract: None\nAuthors: Weiyan Shi, Emily Dinan, Adi Renduchintala, Daniel Fried, Athul Paul Jacob, Zhou Yu, Mike Lewis\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: None\nUrl: https://aclanthology.org/2023.findings-emnlp.23.pdf",
  "List of 2023 Open Access papers by daniel fried are:\nAnalysis of the transparent surface layer formed at the surfaces of arrested enamel caries lesions with tomographic imaging methods\nExploratory Analysis of Objective Outcome Measures for the Clinical Assessment of Erosive Tooth Wear\nAssessment of the activity of secondary caries lesions with short-wavelength infrared, thermal, and optical coherence tomographic imaging\nMonitoring lesion activity on primary teeth with CP\u2010OCT and SWIR reflectance imaging\nActive Surveillance of Root Caries in Vivo with CP-OCT\nTime\u2010resolved SWIR imaging for the assessment of the activity of occlusal caries lesions\nDiagnostic Performance of Multispectral SWIR Transillumination and Reflectance Imaging for Caries Detection\nAutoReply: Detecting Nonsense in Dialogue with Discriminative Replies\nLongitudinal assessment of dental erosion-abrasion by cross-polarization optical coherence tomography in vitro.\nPragmatic Inference with a CLIP Listener for Contrastive Captioning\nSantaCoder: don't reach for the stars!\nGrounding Language Models to Images for Multimodal Generation\nStarCoder: may the source be with you!",
  "Pragmatic Inference with a CLIP Listener for Contrastive Captioning\nSantaCoder: don't reach for the stars!\nGrounding Language Models to Images for Multimodal Generation\nStarCoder: may the source be with you!\nGenerating Images with Multimodal Language Models\nWebArena: A Realistic Web Environment for Building Autonomous Agents\nAmortizing Pragmatic Program Synthesis with Rankings",
  "Daniel Fried\nAssistant Professor, Language Technologies Institute\nResearch Area\nConversational AI, Discourse and Pragmatics, Intelligent Agents and Dialogue, Multimodal AI, Natural Language Processing and Computational Linguistics\nEducation\nMaster of Science in Intelligent Information Systems\nPersonal Website https://dpfried.github.io/\nContact 6411 \u2014Gates & Hillman Centers\nEmail dfried@andrew.cmu.edu",
  "Faculty Name: daphne ippolito\nPaperid: 03fb535de5cfcf435705a079334ac60f501226ab\nTitle: Reverse-Engineering Decoding Strategies Given Blackbox Access to a Language Generation System\nYear: 2023\nAbstract: Neural language models are increasingly deployed into APIs and websites that allow a user to pass in a prompt and receive generated text. Many of these systems do not reveal generation parameters. In this paper, we present methods to reverse-engineer the decoding method used to generate text (i.e., top-_k_ or nucleus sampling). Our ability to discover which decoding strategy was used has implications for detecting generated text. Additionally, the process of discovering the decoding strategy can reveal biases caused by selecting decoding settings which severely truncate a model\u2019s predicted distributions. We perform our attack on several families of open-source language models, as well as on production systems (e.g., ChatGPT).",
  "Additionally, the process of discovering the decoding strategy can reveal biases caused by selecting decoding settings which severely truncate a model\u2019s predicted distributions. We perform our attack on several families of open-source language models, as well as on production systems (e.g., ChatGPT).\nAuthors: Daphne Ippolito, Nicholas Carlini, Katherine Lee, Milad Nasr, Yun William Yu\nVenue: International Conference on Natural Language Generation\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Methods to reverse-engineer the decoding method used to generate text (i.e., top-_k_ or nucleus sampling) are presented, which has implications for detecting generated text.'}\nUrl: https://arxiv.org/pdf/2309.04858",
  "Faculty Name: daphne ippolito\nPaperid: 1567bcac0ab09269c9d0ff33c9a406132417fab9\nTitle: A Pretrainer's Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, & Toxicity\nYear: 2023\nAbstract: Pretraining is the preliminary and fundamental step in developing capable language models (LM). Despite this, pretraining data design is critically under-documented and often guided by empirically unsupported intuitions. To address this, we pretrain 28 1.5B parameter decoder-only models, training on data curated (1) at different times, (2) with varying toxicity and quality filters, and (3) with different domain compositions. First, we quantify the effect of pretraining data age. A temporal shift between evaluation data and pretraining data leads to performance degradation, which is not overcome by finetuning. Second, we explore the effect of quality and toxicity filters, showing a trade-off between performance on standard benchmarks and risk of toxic generations. Our findings indicate there does not exist a one-size-fits-all solution to filtering training data.",
  "Second, we explore the effect of quality and toxicity filters, showing a trade-off between performance on standard benchmarks and risk of toxic generations. Our findings indicate there does not exist a one-size-fits-all solution to filtering training data. We also find that the effects of different types of filtering are not predictable from text domain characteristics. Lastly, we empirically validate that the inclusion of heterogeneous data sources, like books and web, is broadly beneficial and warrants greater prioritization. These findings constitute the largest set of experiments to validate, quantify, and expose many undocumented intuitions about text pretraining, which we hope will help support more informed data-centric decisions in LM development.",
  "These findings constitute the largest set of experiments to validate, quantify, and expose many undocumented intuitions about text pretraining, which we hope will help support more informed data-centric decisions in LM development.\nAuthors: S. Longpre, Gregory Yauney, Emily Reif, Katherine Lee, Adam Roberts, Barret Zoph, Denny Zhou, Jason Wei, Kevin Robinson, David M. Mimno, Daphne Ippolito\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'These findings constitute the largest set of experiments to validate, quantify, and expose many undocumented intuitions about text pretraining, which are hoped to help support more informed data-centric decisions in LM development.'}\nUrl: http://arxiv.org/pdf/2305.13169",
  "Faculty Name: daphne ippolito\nPaperid: 2e965b5d97c2d6fb4af284307735be39283792ba\nTitle: Extracting Training Data from Diffusion Models\nYear: 2023\nAbstract: Image diffusion models such as DALL-E 2, Imagen, and Stable Diffusion have attracted significant attention due to their ability to generate high-quality synthetic images. In this work, we show that diffusion models memorize individual images from their training data and emit them at generation time. With a generate-and-filter pipeline, we extract over a thousand training examples from state-of-the-art models, ranging from photographs of individual people to trademarked company logos. We also train hundreds of diffusion models in various settings to analyze how different modeling and data decisions affect privacy. Overall, our results show that diffusion models are much less private than prior generative models such as GANs, and that mitigating these vulnerabilities may require new advances in privacy-preserving training.",
  "We also train hundreds of diffusion models in various settings to analyze how different modeling and data decisions affect privacy. Overall, our results show that diffusion models are much less private than prior generative models such as GANs, and that mitigating these vulnerabilities may require new advances in privacy-preserving training.\nAuthors: Nicholas Carlini, Jamie Hayes, Milad Nasr, Matthew Jagielski, Vikash Sehwag, Florian Tram\u00e8r, B. Balle, Daphne Ippolito, Eric Wallace\nVenue: USENIX Security Symposium\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The results show that diffusion models are much less private than prior generative models such as GANs, and that mitigating these vulnerabilities may require new advances in privacy-preserving training.'}\nUrl: http://arxiv.org/pdf/2301.13188",
  "Faculty Name: daphne ippolito\nPaperid: 8724579d3f126e753a0451d98ff57b165f722e72\nTitle: Are aligned neural networks adversarially aligned?\nYear: 2023\nAbstract: Large language models are now tuned to align with the goals of their creators, namely to be\"helpful and harmless.\"These models should respond helpfully to user questions, but refuse to answer requests that could cause harm. However, adversarial users can construct inputs which circumvent attempts at alignment. In this work, we study to what extent these models remain aligned, even when interacting with an adversarial user who constructs worst-case inputs (adversarial examples). These inputs are designed to cause the model to emit harmful content that would otherwise be prohibited. We show that existing NLP-based optimization attacks are insufficiently powerful to reliably attack aligned text models: even when current NLP-based attacks fail, we can find adversarial inputs with brute force. As a result, the failure of current attacks should not be seen as proof that aligned text models remain aligned under adversarial inputs.",
  "As a result, the failure of current attacks should not be seen as proof that aligned text models remain aligned under adversarial inputs. However the recent trend in large-scale ML models is multimodal models that allow users to provide images that influence the text that is generated. We show these models can be easily attacked, i.e., induced to perform arbitrary un-aligned behavior through adversarial perturbation of the input image. We conjecture that improved NLP attacks may demonstrate this same level of adversarial control over text-only models.\nAuthors: Nicholas Carlini, Milad Nasr, Christopher A. Choquette-Choo, Matthew Jagielski, Irena Gao, Anas Awadalla, Pang Wei Koh, Daphne Ippolito, Katherine Lee, Florian Tram\u00e8r, Ludwig Schmidt\nVenue: Neural Information Processing Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is shown that existing NLP-based optimization attacks are insufficiently powerful to reliably attack aligned text models, and conjecture that improved NLP attacks may demonstrate this same level of adversarial control over text-only models.'}\nUrl: http://arxiv.org/pdf/2306.15447",
  "List of 2023 Open Access papers by daphne ippolito are:\nReverse-Engineering Decoding Strategies Given Blackbox Access to a Language Generation System\nA Pretrainer's Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, & Toxicity\nExtracting Training Data from Diffusion Models\nAre aligned neural networks adversarially aligned?",
  "Daphne Ippolito\nAssistant Professor, Language Technologies Institute\nResearch Area\nCreativity, Language Technology Application Areas/Issues, Natural Language Generation, Privacy and Security\nPersonal Website https://daphnei.com/\nContact 3525 \u2014Newell-Simon Hall\nEmail daphnei@cmu.edu",
  "Faculty Name: david mortensen\nPaperid: 11a571eaab42a6ffb1d938635a093315e392756d\nTitle: ChatGPT MT: Competitive for High- (but Not Low-) Resource Languages\nYear: 2023\nAbstract: Large language models (LLMs) implicitly learn to perform a range of language tasks, including machine translation (MT). Previous studies explore aspects of LLMs\u2019 MT capabilities. However, there exist a wide variety of languages for which recent LLM MT performance has never before been evaluated. Without published experimental evidence on the matter, it is difficult for speakers of the world\u2019s diverse languages to know how and whether they can use LLMs for their languages. We present the first experimental evidence for an expansive set of 204 languages, along with MT cost analysis, using the FLORES-200 benchmark. Trends reveal that GPT models approach or exceed traditional MT model performance for some high-resource languages (HRLs) but consistently lag for low-resource languages (LRLs), under-performing traditional MT for 84.1% of languages we covered.",
  "Trends reveal that GPT models approach or exceed traditional MT model performance for some high-resource languages (HRLs) but consistently lag for low-resource languages (LRLs), under-performing traditional MT for 84.1% of languages we covered. Our analysis reveals that a language\u2019s resource level is the most important feature in determining ChatGPT\u2019s relative ability to translate it, and suggests that ChatGPT is especially disadvantaged for LRLs and African languages.\nAuthors: Nathaniel R. Robinson, Perez Ogayo, David R. Mortensen, Graham Neubig\nVenue: Conference on Machine Translation\nTldr: {'model': 'tldr@v2.0.0', 'text': \"This work presents the first experimental evidence for an expansive set of 204 languages, along with MT cost analysis, using the FLORES-200 benchmark, and reveals that a language\u2019s resource level is the most important feature in determining ChatGPT's relative ability to translate it, and suggests thatChatGPT is especially disadvantaged for LRLs and African languages.\"}\nUrl: https://arxiv.org/pdf/2309.07423",
  "Faculty Name: david mortensen\nPaperid: 17fbffb05fa14e21d1c506fd5f0f568b955fe983\nTitle: Do All Languages Cost the Same? Tokenization in the Era of Commercial Language Models\nYear: 2023\nAbstract: Language models have graduated from being research prototypes to commercialized products offered as web APIs, and recent works have highlighted the multilingual capabilities of these products. The API vendors charge their users based on usage, more specifically on the number of ``tokens'' processed or generated by the underlying language models. What constitutes a token, however, is training data and model dependent with a large variance in the number of tokens required to convey the same information in different languages. In this work, we analyze the effect of this non-uniformity on the fairness of an API's pricing policy across languages. We conduct a systematic analysis of the cost and utility of OpenAI's language model API on multilingual benchmarks in 22 typologically diverse languages. We show evidence that speakers of a large number of the supported languages are overcharged while obtaining poorer results. These speakers tend to also come from regions where the APIs are less affordable to begin with.",
  "We show evidence that speakers of a large number of the supported languages are overcharged while obtaining poorer results. These speakers tend to also come from regions where the APIs are less affordable to begin with. Through these analyses, we aim to increase transparency around language model APIs' pricing policies and encourage the vendors to make them more equitable.\nAuthors: Orevaoghene Ahia, Sachin Kumar, Hila Gonen, Jungo Kasai, David R. Mortensen, Noah A. Smith, Yulia Tsvetkov\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': \"This work conducts a systematic analysis of the cost and utility of OpenAI's language model API on multilingual benchmarks in 22 typologically diverse languages and shows evidence that speakers of a large number of the supported languages are overcharged while obtaining poorer results.\"}\nUrl: http://arxiv.org/pdf/2305.13707",
  "Faculty Name: david mortensen\nPaperid: 1d343a435c8b27b986cbeac1708e2b76abf2f9bc\nTitle: Kuki-Chin Phonology: An Overview\nYear: 2023\nAbstract: None\nAuthors: David R Mortensen\nVenue: Himalayan Linguistics\nTldr: None\nUrl: https://escholarship.org/content/qt1d326124/qt1d326124.pdf?t=s7jt1o",
  "Faculty Name: david mortensen\nPaperid: 659be1ff350634f50cc066d258ee6a45e697e552\nTitle: SigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing\nYear: 2023\nAbstract: In our submission to the SIGMORPHON 2023 Shared Task on interlinear glossing (IGT), we explore approaches to data augmentation and modeling across seven low-resource languages. For data augmentation, we explore two approaches: creating artificial data from the provided training data and utilizing existing IGT resources in other languages. On the modeling side, we test an enhanced version of the provided token classification baseline as well as a pretrained multilingual seq2seq model. Additionally, we apply post-correction using a dictionary for Gitksan, the language with the smallest amount of data. We find that our token classification models are the best performing, with the highest word-level accuracy for Arapaho and highest morpheme-level accuracy for Gitksan out of all submissions. We also show that data augmentation is an effective strategy, though applying artificial data pretraining has very different effects across both models tested.",
  "We find that our token classification models are the best performing, with the highest word-level accuracy for Arapaho and highest morpheme-level accuracy for Gitksan out of all submissions. We also show that data augmentation is an effective strategy, though applying artificial data pretraining has very different effects across both models tested.\nAuthors: Taiqi He, Lindia Tjuatja, Nathaniel R. Robinson, Shinji Watanabe, David R. Mortensen, Graham Neubig, L. Levin\nVenue: Special Interest Group on Computational Morphology and Phonology Workshop\nTldr: {'model': 'tldr@v2.0.0', 'text': 'In this submission to the SIGMORPHON 2023 Shared Task on interlinear glossing (IGT), approaches to data augmentation and modeling across seven low-resource languages are explored and token classification models are found to be the best performing.'}\nUrl: https://aclanthology.org/2023.sigmorphon-1.22.pdf",
  "Faculty Name: david mortensen\nPaperid: 7a08051aac75a809737096e39820bf836908d4e1\nTitle: Construction Grammar Provides Unique Insight into Neural Language Models\nYear: 2023\nAbstract: Construction Grammar (CxG) has recently been used as the basis for probing studies that have investigated the performance of large pretrained language models (PLMs) with respect to the structure and meaning of constructions. In this position paper, we make suggestions for the continuation and augmentation of this line of research. We look at probing methodology that was not designed with CxG in mind, as well as probing methodology that was designed for specific constructions. We analyse selected previous work in detail, and provide our view of the most important challenges and research questions that this promising new field faces.",
  "We look at probing methodology that was not designed with CxG in mind, as well as probing methodology that was designed for specific constructions. We analyse selected previous work in detail, and provide our view of the most important challenges and research questions that this promising new field faces.\nAuthors: Leonie Weissweiler, Taiqi He, Naoki Otani, David R. Mortensen, L. Levin, Hinrich Sch\u00fctze\nVenue: CXGSNLP\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The view of the most important challenges and research questions that this promising new field of research faces is provided, and an analysis of selected previous work in detail is provided.'}\nUrl: http://arxiv.org/pdf/2302.02178",
  "Faculty Name: david mortensen\nPaperid: bf42c0462d1415cdde877c90d58da11545407b8a\nTitle: Generalized Glossing Guidelines: An Explicit, Human- and Machine-Readable, Item-and-Process Convention for Morphological Annotation\nYear: 2023\nAbstract: Interlinear glossing provides a vital type of morphosyntactic annotation, both for linguists and language revitalists, and numerous conventions exist for representing it formally and computationally. Some of these formats are human readable; others are machine readable. Some are easy to edit with general-purpose tools. Few represent non-concatentative processes like infixation, reduplication, mutation, truncation, and tonal overwriting in a consistent and formally rigorous way (on par with affixation). We propose an annotation convention\u00e2\u20ac\u201dGeneralized Glossing Guidelines (GGG) that combines all of these positive properties using an Item-and-Process (IP) framework. We describe the format, demonstrate its linguistic adequacy, and compare it with two other interlinear glossed text annotation schemes.",
  "We propose an annotation convention\u00e2\u20ac\u201dGeneralized Glossing Guidelines (GGG) that combines all of these positive properties using an Item-and-Process (IP) framework. We describe the format, demonstrate its linguistic adequacy, and compare it with two other interlinear glossed text annotation schemes.\nAuthors: David R. Mortensen, Ela Gulsen, Taiqi He, Nathaniel R. Robinson, Jonathan D. Amith, Lindia Tjuatja, L. Levin\nVenue: Special Interest Group on Computational Morphology and Phonology Workshop\nTldr: {'model': 'tldr@v2.0.0', 'text': 'An annotation convention is proposed that combines all of these positive properties using an Item-and-Process (IP) framework, and its linguistic adequacy is demonstrated, and it is compared with two other interlinear glossed text annotation schemes.'}\nUrl: https://aclanthology.org/2023.sigmorphon-1.7.pdf",
  "Faculty Name: david mortensen\nPaperid: c5c6d006e399386c99068daba138021a62d6cc17\nTitle: Transformed Protoform Reconstruction\nYear: 2023\nAbstract: Protoform reconstruction is the task of inferring what morphemes or words appeared like in the ancestral languages of a set of daughter languages. Meloni et al (2021) achieved the state-of-the-art on Latin protoform reconstruction with an RNN-based encoder-decoder with attention model. We update their model with the state-of-the-art seq2seq model: the Transformer. Our model outperforms their model on a suite of different metrics on two different datasets: their Romance data of 8,000 cognates spanning 5 languages and a Chinese dataset (Hou 2004) of 800+ cognates spanning 39 varieties. We also probe our model for potential phylogenetic signal contained in the model. Our code is publicly available at https://github.com/cmu-llab/acl-2023.",
  "We also probe our model for potential phylogenetic signal contained in the model. Our code is publicly available at https://github.com/cmu-llab/acl-2023.\nAuthors: Young Min Kim, Kalvin Chang, Chenxuan Cui, David R. Mortensen\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The Meloni et al (2021) model is updated with the state-of-the-art seq2seq model: the Transformer, which outperforms their model on a suite of different metrics on two different datasets: their Romance data of 8,000 cognate spanning 5 languages and a Chinese dataset (Hou 2004) of 800+ cognates spanning 39 varieties.'}\nUrl: https://arxiv.org/pdf/2307.01896",
  "Faculty Name: david mortensen\nPaperid: db14d05b18ec852f8afcd6d2d10bbd9eeaef8325\nTitle: PWESuite: Phonetic Word Embeddings and Tasks They Facilitate\nYear: 2023\nAbstract: Mapping words into a fixed-dimensional vector space is the backbone of modern NLP. While most word embedding methods successfully encode semantic information, they overlook phonetic information that is crucial for many tasks. We develop three methods that use articulatory features to build phonetically informed word embeddings. To address the inconsistent evaluation of existing phonetic word embedding methods, we also contribute a task suite to fairly evaluate past, current, and future methods. We evaluate both (1) intrinsic aspects of phonetic word embeddings, such as word retrieval and correlation with sound similarity, and (2) extrinsic performance on tasks such as rhyme and cognate detection and sound analogies. We hope our task suite will promote reproducibility and inspire future phonetic embedding research.",
  "We evaluate both (1) intrinsic aspects of phonetic word embeddings, such as word retrieval and correlation with sound similarity, and (2) extrinsic performance on tasks such as rhyme and cognate detection and sound analogies. We hope our task suite will promote reproducibility and inspire future phonetic embedding research.\nAuthors: Vil\u00e9m Zouhar, Kalvin Chang, Chenxuan Cui, Nathaniel Carlson, Nathaniel R. Robinson, Mrinmaya Sachan, David R. Mortensen\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Three methods that use articulatory features to build phonetically informed word embeddings are developed that address the inconsistent evaluation of existing phonetic word embedding methods and contribute a task suite to fairly evaluate past, current, and future methods.'}\nUrl: http://arxiv.org/pdf/2304.02541",
  "List of 2023 Open Access papers by david mortensen are:\nChatGPT MT: Competitive for High- (but Not Low-) Resource Languages\nDo All Languages Cost the Same? Tokenization in the Era of Commercial Language Models\nSigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing\nConstruction Grammar Provides Unique Insight into Neural Language Models\nGeneralized Glossing Guidelines: An Explicit, Human- and Machine-Readable, Item-and-Process Convention for Morphological Annotation\nTransformed Protoform Reconstruction\nPWESuite: Phonetic Word Embeddings and Tasks They Facilitate\nKuki-Chin Phonology: An Overview",
  "David Mortensen\nAssistant Research Professor, Language Technologies Institute\nResearch Area\nCorpus Annotation and Resources, Natural Language Processing and Computational Linguistics\nEducation\nMaster of Science in Intelligent Information Systems\nhttps://www.cs.cmu.edu/~dmortens/\n5707 \u2014Gates & Hillman Centers\ndmortens@cs.cmu.edu\ntel:412-268-2894",
  "Faculty Name: emma strubell\nPaperid: 1433b8d43d446fcc7f3e1370b22f744a4dd7c8e4\nTitle: To Build Our Future, We Must Know Our Past: Contextualizing Paradigm Shifts in Natural Language Processing\nYear: 2023\nAbstract: NLP is in a period of disruptive change that is impacting our methodologies, funding sources, and public perception. In this work, we seek to understand how to shape our future by better understanding our past. We study factors that shape NLP as a field, including culture, incentives, and infrastructure by conducting long-form interviews with 26 NLP researchers of varying seniority, research area, institution, and social identity. Our interviewees identify cyclical patterns in the field, as well as new shifts without historical parallel, including changes in benchmark culture and software infrastructure. We complement this discussion with quantitative analysis of citation, authorship, and language use in the ACL Anthology over time. We conclude by discussing shared visions, concerns, and hopes for the future of NLP.",
  "We complement this discussion with quantitative analysis of citation, authorship, and language use in the ACL Anthology over time. We conclude by discussing shared visions, concerns, and hopes for the future of NLP. We hope that this study of our field's past and present can prompt informed discussion of our community's implicit norms and more deliberate action to consciously shape the future.\nAuthors: Sireesh Gururaja, Amanda Bertsch, Clara Na, D. Widder, Emma Strubell\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work conducts long-form interviews with 26 NLP researchers of varying seniority, research area, institution, and social identity to study factors that shape NLP as a field, including culture, incentives, and infrastructure.'}\nUrl: https://arxiv.org/pdf/2310.07715",
  "Faculty Name: emma strubell\nPaperid: 45e50baac4d341f0cf1a40af096bfa9c3f555235\nTitle: Understanding the Effect of Model Compression on Social Bias in Large Language Models\nYear: 2023\nAbstract: Large Language Models (LLMs) trained with self-supervision on vast corpora of web text fit to the social biases of that text. Without intervention, these social biases persist in the model's predictions in downstream tasks, leading to representational harm. Many strategies have been proposed to mitigate the effects of inappropriate social biases learned during pretraining. Simultaneously, methods for model compression have become increasingly popular to reduce the computational burden of LLMs. Despite the popularity and need for both approaches, little work has been done to explore the interplay between these two. We perform a carefully controlled study of the impact of model compression via quantization and knowledge distillation on measures of social bias in LLMs. Longer pretraining and larger models led to higher social bias, and quantization showed a regularizer effect with its best trade-off around 20% of the original pretraining time.",
  "Longer pretraining and larger models led to higher social bias, and quantization showed a regularizer effect with its best trade-off around 20% of the original pretraining time.\nAuthors: Gustavo Gon\u00e7alves, Emma Strubell\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A carefully controlled study of the impact of model compression via quantization and knowledge distillation on measures of social bias in LLMs finds that longer pretraining and larger models led to higher social bias, and quantization showed a regularizer effect with its best trade-off around 20% of the original pretraining time.'}\nUrl: https://aclanthology.org/2023.emnlp-main.161.pdf",
  "Faculty Name: emma strubell\nPaperid: 667ba2e8f1933b6c32e9672012526904b4c5dc31\nTitle: Surveying (Dis)Parities and Concerns of Compute Hungry NLP Research\nYear: 2023\nAbstract: Many recent improvements in NLP stem from the development and use of large pre-trained language models (PLMs) with billions of parameters. Large model sizes makes computational cost one of the main limiting factors for training and evaluating such models; and has raised severe concerns about the sustainability, reproducibility, and inclusiveness for researching PLMs. These concerns are often based on personal experiences and observations. However, there had not been any large-scale surveys that investigate them. In this work, we provide a first attempt to quantify these concerns regarding three topics, namely, environmental impact, equity, and impact on peer reviewing. By conducting a survey with 312 participants from the NLP community, we capture existing (dis)parities between different and within groups with respect to seniority, academia, and industry; and their impact on the peer reviewing process.",
  "By conducting a survey with 312 participants from the NLP community, we capture existing (dis)parities between different and within groups with respect to seniority, academia, and industry; and their impact on the peer reviewing process. For each topic, we provide an analysis and devise recommendations to mitigate found disparities, some of which already successfully implemented. Finally, we discuss additional concerns raised by many participants in free-text responses.\nAuthors: Ji-Ung Lee, Haritz Puerto, Betty van Aken, Yuki Arase, J. Forde, Leon Derczynski, Andreas Ruckl'e, Iryna Gurevych, Roy Schwartz, Emma Strubell, Jesse Dodge\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work captures existing (dis)parities between different and within groups with respect to seniority, academia, and industry; and their impact on the peer reviewing process; and provides an analysis and devise recommendations to mitigate found disparities.'}\nUrl: http://arxiv.org/pdf/2306.16900",
  "Faculty Name: emma strubell\nPaperid: 71debf888acd57bb1baa4c146f31e58c66ea51af\nTitle: On the Interactions of Structural Constraints and Data Resources for Structured Prediction\nYear: 2023\nAbstract: ,\nAuthors: Zhisong Zhang, Emma Strubell, E. Hovy\nVenue: SUSTAINLP\nTldr: {'model': 'tldr@v2.0.0', 'text': None}\nUrl: https://aclanthology.org/2023.sustainlp-1.10.pdf",
  "Faculty Name: emma strubell\nPaperid: 84d20ad9f42d80dfd5130a6362d5422be8a6bdc3\nTitle: Efficiency Pentathlon: A Standardized Arena for Efficiency Evaluation\nYear: 2023\nAbstract: Rising computational demands of modern natural language processing (NLP) systems have increased the barrier to entry for cutting-edge research while posing serious environmental concerns. Yet, progress on model efficiency has been impeded by practical challenges in model evaluation and comparison. For example, hardware is challenging to control due to disparate levels of accessibility across different institutions. Moreover, improvements in metrics such as FLOPs often fail to translate to progress in real-world applications. In response, we introduce Pentathlon, a benchmark for holistic and realistic evaluation of model efficiency. Pentathlon focuses on inference, which accounts for a majority of the compute in a model's lifecycle. It offers a strictly-controlled hardware platform, and is designed to mirror real-world applications scenarios. It incorporates a suite of metrics that target different aspects of efficiency, including latency, throughput, memory overhead, and energy consumption.",
  "It offers a strictly-controlled hardware platform, and is designed to mirror real-world applications scenarios. It incorporates a suite of metrics that target different aspects of efficiency, including latency, throughput, memory overhead, and energy consumption. Pentathlon also comes with a software library that can be seamlessly integrated into any codebase and enable evaluation. As a standardized and centralized evaluation platform, Pentathlon can drastically reduce the workload to make fair and reproducible efficiency comparisons. While initially focused on natural language processing (NLP) models, Pentathlon is designed to allow flexible extension to other fields. We envision Pentathlon will stimulate algorithmic innovations in building efficient models, and foster an increased awareness of the social and environmental implications in the development of future-generation NLP models.",
  "While initially focused on natural language processing (NLP) models, Pentathlon is designed to allow flexible extension to other fields. We envision Pentathlon will stimulate algorithmic innovations in building efficient models, and foster an increased awareness of the social and environmental implications in the development of future-generation NLP models.\nAuthors: Hao Peng, Qingqing Cao, Jesse Dodge, Matthew E. Peters, Jared Fernandez, Tom Sherborne, Kyle Lo, Sam Skjonsberg, Emma Strubell, Darrell Plessas, Iz Beltagy, Pete Walsh, Noah A. Smith, Hannaneh Hajishirzi\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': \"Pentathlon is a benchmark for holistic and realistic evaluation of model efficiency, which focuses on inference, which accounts for a majority of the compute in a model's lifecycle, and is designed to mirror real-world applications scenarios.\"}\nUrl: https://arxiv.org/pdf/2307.09701",
  "Faculty Name: emma strubell\nPaperid: 88549b4f48b9709acdfb8b9e41656b6d133c5390\nTitle: Queer People are People First: Deconstructing Sexual Identity Stereotypes in Large Language Models\nYear: 2023\nAbstract: Large Language Models (LLMs) are trained primarily on minimally processed web text, which exhibits the same wide range of social biases held by the humans who created that content. Consequently, text generated by LLMs can inadvertently perpetuate stereotypes towards marginalized groups, like the LGBTQIA+ community. In this paper, we perform a comparative study of how LLMs generate text describing people with different sexual identities. Analyzing bias in the text generated by an LLM using regard score shows measurable bias against queer people. We then show that a post-hoc method based on chain-of-thought prompting using SHAP analysis can increase the regard of the sentence, representing a promising approach towards debiasing the output of LLMs in this setting.",
  "We then show that a post-hoc method based on chain-of-thought prompting using SHAP analysis can increase the regard of the sentence, representing a promising approach towards debiasing the output of LLMs in this setting.\nAuthors: Harnoor Dhingra, Preetiha Jayashanker, Sayali S. Moghe, Emma Strubell\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is shown that a post-hoc method based on chain-of-thought prompting using SHAP analysis can increase the regard of the sentence, representing a promising approach towards debiasing the output of LLMs in this setting.'}\nUrl: http://arxiv.org/pdf/2307.00101",
  "Faculty Name: emma strubell\nPaperid: a815c3209e7baff4466dbf6e129129511f842b7e\nTitle: Making Scalable Meta Learning Practical\nYear: 2023\nAbstract: Despite its flexibility to learn diverse inductive biases in machine learning programs, meta learning (i.e., learning to learn) has long been recognized to suffer from poor scalability due to its tremendous compute/memory costs, training instability, and a lack of efficient distributed training support. In this work, we focus on making scalable meta learning practical by introducing SAMA, which combines advances in both implicit differentiation algorithms and systems. Specifically, SAMA is designed to flexibly support a broad range of adaptive optimizers in the base level of meta learning programs, while reducing computational burden by avoiding explicit computation of second-order gradient information, and exploiting efficient distributed training techniques implemented for first-order gradients. Evaluated on multiple large-scale meta learning benchmarks, SAMA showcases up to 1.7/4.8x increase in throughput and 2.0/3.8x decrease in memory consumption respectively on single-/multi-GPU setups compared to other baseline meta learning algorithms.",
  "Evaluated on multiple large-scale meta learning benchmarks, SAMA showcases up to 1.7/4.8x increase in throughput and 2.0/3.8x decrease in memory consumption respectively on single-/multi-GPU setups compared to other baseline meta learning algorithms. Furthermore, we show that SAMA-based data optimization leads to consistent improvements in text classification accuracy with BERT and RoBERTa large language models, and achieves state-of-the-art results in both small- and large-scale data pruning on image classification tasks, demonstrating the practical applicability of scalable meta learning across language and vision domains.\nAuthors: Sang Keun Choe, Sanket Vaibhav Mehta, Hwijeen Ahn, W. Neiswanger, Pengtao Xie, Emma Strubell, Eric P. Xing\nVenue: Neural Information Processing Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'SAMA is designed to flexibly support a broad range of adaptive optimizers in the base level of meta learning programs, while reducing computational burden by avoiding explicit computation of second-order gradient information, and exploiting efficient distributed training techniques implemented for first-order gradients.'}",
  "Url: https://arxiv.org/pdf/2310.05674",
  "Faculty Name: emma strubell\nPaperid: b13da1161d65a8de7a96051b5bc68d5eaa8eb37b\nTitle: Regularizing Self-training for Unsupervised Domain Adaptation via Structural Constraints\nYear: 2023\nAbstract: Self-training based on pseudo-labels has emerged as a dominant approach for addressing conditional distribution shifts in unsupervised domain adaptation (UDA) for semantic segmentation problems. A notable drawback, however, is that this family of approaches is susceptible to erroneous pseudo labels that arise from confirmation biases in the source domain and that manifest as nuisance factors in the target domain. A possible source for this mismatch is the reliance on only photometric cues provided by RGB image inputs, which may ultimately lead to sub-optimal adaptation. To mitigate the effect of mismatched pseudo-labels, we propose to incorporate structural cues from auxiliary modalities, such as depth, to regularise conventional self-training objectives. Specifically, we introduce a contrastive pixel-level objectness constraint that pulls the pixel representations within a region of an object instance closer, while pushing those from different object categories apart.",
  "Specifically, we introduce a contrastive pixel-level objectness constraint that pulls the pixel representations within a region of an object instance closer, while pushing those from different object categories apart. To obtain object regions consistent with the true underlying object, we extract information from both depth maps and RGB-images in the form of multimodal clustering. Crucially, the objectness constraint is agnostic to the ground-truth semantic labels and, hence, appropriate for unsupervised domain adaptation. In this work, we show that our regularizer significantly improves top performing self-training methods (by up to $2$ points) in various UDA benchmarks for semantic segmentation. We include all code in the supplementary.\nAuthors: Rajshekhar Das, Jonathan M Francis, Sanket Vaibhav Mehta, Jean Oh, Emma Strubell, Jose Moura\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The regularizer significantly improves top performing self-training methods in various UDA benchmarks for semantic segmentation and introduces a contrastive pixel-level objectness constraint that pulls the pixel representations within a region of an object instance closer, while pushing those from different object categories apart.'}",
  "Url: http://arxiv.org/pdf/2305.00131",
  "Faculty Name: emma strubell\nPaperid: b777aa86b5a1d49ce8eababc5c2ee56d3562801e\nTitle: The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment\nYear: 2023\nAbstract: Increased focus on the computational efficiency of NLP systems has motivated the design of efficient model architectures and improvements to underlying hardware accelerators. However, the resulting increases in computational throughput and reductions in floating point operations have not directly translated to improvements in wall-clock inference latency. We demonstrate that these discrepancies can be largely attributed to bottlenecks introduced by deep learning frameworks. We denote this phenomenon as the \\textit{framework tax}, and observe that the disparity is growing as hardware speed increases over time. In this work, we examine this phenomenon through a series of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency. Code is available at https://github.com/JaredFern/Framework-Tax.",
  "In this work, we examine this phenomenon through a series of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency. Code is available at https://github.com/JaredFern/Framework-Tax.\nAuthors: Jared Fernandez, Jacob Kahn, Clara Na, Yonatan Bisk, Emma Strubell\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work examines the effects of model design decisions, framework paradigms, and hardware platforms on total model latency through a series of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency.'}\nUrl: http://arxiv.org/pdf/2302.06117",
  "Faculty Name: emma strubell\nPaperid: ba31ccac5fe5ea151727e8427e78bb300c35f899\nTitle: Data-efficient Active Learning for Structured Prediction with Partial Annotation and Self-Training\nYear: 2023\nAbstract: In this work we propose a pragmatic method that reduces the annotation cost for structured label spaces using active learning. Our approach leverages partial annotation, which reduces labeling costs for structured outputs by selecting only the most informative sub-structures for annotation. We also utilize self-training to incorporate the current model's automatic predictions as pseudo-labels for un-annotated sub-structures. A key challenge in effectively combining partial annotation with self-training to reduce annotation cost is determining which sub-structures to select to label. To address this challenge, we adopt an error estimator to adaptively decide the partial selection ratio according to the current model's capability. In evaluations spanning four structured prediction tasks, we show that our combination of partial annotation and self-training using an adaptive selection ratio reduces annotation cost over strong full annotation baselines under a fair comparison scheme that takes reading time into consideration.",
  "In evaluations spanning four structured prediction tasks, we show that our combination of partial annotation and self-training using an adaptive selection ratio reduces annotation cost over strong full annotation baselines under a fair comparison scheme that takes reading time into consideration.\nAuthors: Zhisong Zhang, Emma Strubell, E. Hovy\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': \"This work proposes a pragmatic method that reduces the annotation cost for structured label spaces using active learning by adopting an error estimator to adaptively decide the partial selection ratio according to the current model's capability.\"}\nUrl: http://arxiv.org/pdf/2305.12634",
  "List of 2023 Open Access papers by emma strubell are:\nTo Build Our Future, We Must Know Our Past: Contextualizing Paradigm Shifts in Natural Language Processing\nUnderstanding the Effect of Model Compression on Social Bias in Large Language Models\nSurveying (Dis)Parities and Concerns of Compute Hungry NLP Research\nOn the Interactions of Structural Constraints and Data Resources for Structured Prediction\nEfficiency Pentathlon: A Standardized Arena for Efficiency Evaluation\nQueer People are People First: Deconstructing Sexual Identity Stereotypes in Large Language Models\nMaking Scalable Meta Learning Practical\nRegularizing Self-training for Unsupervised Domain Adaptation via Structural Constraints\nThe Framework Tax: Disparities Between Inference Efficiency in Research and Deployment\nData-efficient Active Learning for Structured Prediction with Partial Annotation and Self-Training",
  "Emma Strubell\nAssistant Professor, Language Technologies Institute\nContact\n6709 \u2014Gates Hillman \nEmail estrubel@andrew.cmu.edu\nPersonal Website https://strubell.github.io/",
  "Faculty Name: eric nyberg\nPaperid: 0f008e07d601e8f21d1df5db3d36e85484840083\nTitle: GameQA: Gamified Mobile App Platform for Building Multiple-Domain Question-Answering Datasets\nYear: 2023\nAbstract: The methods used to create many of the well-known Question-Answering (QA) datasets are hard to replicate for low-resource languages. A commonality amongst these methods is hiring annotators to source answers from the internet by querying a single answer source, such as Wikipedia. Applying these methods for low-resource languages can be problematic since there is no single large answer source for these languages. Consequently, this can result in a high ratio of unanswered questions, since the amount of information in any single source is limited. To address this problem, we developed a novel crowd-sourcing platform to gather multiple-domain QA data for low-resource languages. Our platform, which consists of a mobile app and a web API, gamifies the data collection process.",
  "To address this problem, we developed a novel crowd-sourcing platform to gather multiple-domain QA data for low-resource languages. Our platform, which consists of a mobile app and a web API, gamifies the data collection process. We successfully released the app for Icelandic (a low-resource language with about 350,000 native speakers) to build a dataset which rivals large QA datasets for high-resource languages both in terms of size and ratio of answered questions. We have made the platform open source with instructions on how to localize and deploy it to gather data for other low-resource languages.",
  "We have made the platform open source with instructions on how to localize and deploy it to gather data for other low-resource languages.\nAuthors: Njall Skarphedinsson, Breki Gudmundsson, Steinar Smari, M. L\u00e1rusd\u00f3ttir, H. Einarsson, Abuzar Khan, Eric Nyberg, H. Loftsson\nVenue: Conference of the European Chapter of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work developed a novel crowd-sourcing platform to gather multiple-domain QA data for low-resource languages and successfully released the app for Icelandic to build a dataset which rivals large QA datasets for high- resource languages both in terms of size and ratio of answered questions.'}\nUrl: https://aclanthology.org/2023.eacl-demo.18.pdf",
  "Faculty Name: eric nyberg\nPaperid: 3a30217c4115777fb30c182c97cc77d34d065556\nTitle: InPars-Light: Cost-Effective Unsupervised Training of Efficient Rankers\nYear: 2023\nAbstract: We carried out a reproducibility study of InPars, which is a method for unsupervised training of neural rankers (Bonifacio et al., 2022). As a by-product, we developed InPars-light, which is a simple-yet-effective modification of InPars. Unlike InPars, InPars-light uses 7x-100x smaller ranking models and only a freely available language model BLOOM, which -- as we found out -- produced more accurate rankers compared to a proprietary GPT-3 model. On all five English retrieval collections (used in the original InPars study) we obtained substantial (7%-30%) and statistically significant improvements over BM25 (in nDCG and MRR) using only a 30M parameter six-layer MiniLM-30M ranker and a single three-shot prompt.",
  "On all five English retrieval collections (used in the original InPars study) we obtained substantial (7%-30%) and statistically significant improvements over BM25 (in nDCG and MRR) using only a 30M parameter six-layer MiniLM-30M ranker and a single three-shot prompt. In contrast, in the InPars study only a 100x larger monoT5-3B model consistently outperformed BM25, whereas their smaller monoT5-220M model (which is still 7x larger than our MiniLM ranker) outperformed BM25 only on MS MARCO and TREC DL 2020. In the same three-shot prompting scenario, our 435M parameter DeBERTA v3 ranker was at par with the 7x larger monoT5-3B (average gain over BM25 of 1.3 vs 1.32): In fact, on three out of five datasets, DeBERTA slightly outperformed monoT5-3B. Finally, these good results were achieved by re-ranking only 100 candidate documents compared to 1000 used by Bonifacio et al. (2022).",
  "Finally, these good results were achieved by re-ranking only 100 candidate documents compared to 1000 used by Bonifacio et al. (2022). We believe that InPars-light is the first truly cost-effective prompt-based unsupervised recipe to train and deploy neural ranking models that outperform BM25. Our code and data is publicly available. https://github.com/searchivarius/inpars_light/\nAuthors: Leonid Boytsov, Preksha Patel, Vivek Sourabh, Riddhi Nisar, Sayan Kundu, R. Ramanathan, Eric Nyberg\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'InPars-light is the first truly cost-effective prompt-based unsupervised recipe to train and deploy neural ranking models that outperform BM25.'}\nUrl: http://arxiv.org/pdf/2301.02998",
  "Faculty Name: eric nyberg\nPaperid: 444737639aeea4e1e616509e368afb0bae8f89d6\nTitle: Language-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA\nYear: 2023\nAbstract: The DialDoc 2023 shared task has expanded the document-grounded dialogue task to encompass multiple languages, despite having limited annotated data. This paper assesses the effectiveness of both language-agnostic and language-aware paradigms for multilingual pre-trained transformer models in a bi-encoder-based dense passage retriever (DPR), concluding that the language-agnostic approach is superior. Additionally, the study investigates the impact of query rewriting techniques using large language models, such as ChatGPT, on multilingual, document-grounded question-answering systems. The experiments conducted demonstrate that, for the examples examined, query rewriting does not enhance performance compared to the original queries. This failure is due to topic switching in final dialogue turns and irrelevant topics being considered for query rewriting.",
  "The experiments conducted demonstrate that, for the examples examined, query rewriting does not enhance performance compared to the original queries. This failure is due to topic switching in final dialogue turns and irrelevant topics being considered for query rewriting.\nAuthors: Srinivas Gowriraj, Soham Dinesh Tiwari, Mitali Potnis, Srijan Bansal, T. Mitamura, Eric Nyberg\nVenue: Workshop on Document-grounded Dialogue and Conversational Question Answering\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper assesses the effectiveness of both language-agnostic and language-aware paradigms for multilingual pre-trained transformer models in a bi-encoder-based dense passage retriever (DPR), concluding that the language-gnostic approach is superior.'}\nUrl: https://aclanthology.org/2023.dialdoc-1.11.pdf",
  "Faculty Name: eric nyberg\nPaperid: 61354e45bca908ad08f24e44bd507b4e1c958e6f\nTitle: Chain-of-Skills: A Configurable Model for Open-Domain Question Answering\nYear: 2023\nAbstract: The retrieval model is an indispensable component for real-world knowledge-intensive tasks, e.g., open-domain question answering (ODQA). As separate retrieval skills are annotated for different datasets, recent work focuses on customized methods, limiting the model transfer- ability and scalability. In this work, we propose a modular retriever where individual modules correspond to key skills that can be reused across datasets. Our approach supports flexible skill configurations based on the target domain to boost performance. To mitigate task interference, we design a novel modularization parameterization inspired by sparse Transformer. We demonstrate that our model can benefit from self-supervised pretraining on Wikipedia and fine-tuning using multiple ODQA datasets, both in a multi-task fashion. Our approach outperforms recent self-supervised retrievers in zero-shot evaluations and achieves state-of-the-art fine-tuned retrieval performance on NQ, HotpotQA and OTT-QA.",
  "Our approach outperforms recent self-supervised retrievers in zero-shot evaluations and achieves state-of-the-art fine-tuned retrieval performance on NQ, HotpotQA and OTT-QA.\nAuthors: Kaixin Ma, Hao Cheng, Yu Zhang, Xiaodong Liu, Eric Nyberg, Jianfeng Gao\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes a modular retriever where individual modules correspond to key skills that can be reused across datasets and achieves state-of-the-art fine-tuned retrieval performance on NQ, HotpotQA and OTT-QA.'}\nUrl: http://arxiv.org/pdf/2305.03130",
  "Faculty Name: eric nyberg\nPaperid: 8d0c37eee7162f33178979b4183f0211e2dcae0d\nTitle: Difference-Masking: Choosing What to Mask in Continued Pretraining\nYear: 2023\nAbstract: The self-supervised objective of masking-and-predicting has led to promising performance gains on a variety of downstream tasks. However, while most approaches randomly mask tokens, there is strong intuition that deciding what to mask can substantially improve learning outcomes. We investigate this in continued pretraining setting in which pretrained models continue to pretrain on domain-specific data before performing some downstream task. We introduce Difference-Masking, a masking strategy that automatically chooses what to mask during continued pretraining by considering what makes a task domain different from the pretraining domain. Empirically, we find that Difference-Masking outperforms baselines on continued pretraining settings across four diverse language-only and multimodal video tasks.",
  "Empirically, we find that Difference-Masking outperforms baselines on continued pretraining settings across four diverse language-only and multimodal video tasks.\nAuthors: Alex Wilf, Syeda Nahida Akter, Leena Mathur, P. Liang, Sheryl Mathew, Mengrou Shou, Eric Nyberg, Louis-Philippe Morency\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Difference-Masking is introduced, a masking strategy that automatically chooses what to mask during continued pretraining by considering what makes a task domain different from the pretraining domain.'}\nUrl: http://arxiv.org/pdf/2305.14577",
  "Faculty Name: eric nyberg\nPaperid: c251d929c2e54a61366c02c7052f055d408072a1\nTitle: A super wear-resistant coating for Mg alloys achieved by plasma electrolytic oxidation and discontinuous deposition\nYear: 2023\nAbstract: None\nAuthors: Xixi Dong, Mingxu Xia, Feng Wang, Hailin Yang, G. Ji, E. Nyberg, S. Ji\nVenue: Journal of Magnesium and Alloys\nTldr: None\nUrl: N/A",
  "Faculty Name: eric nyberg\nPaperid: daf657e9dc60e104827b6f574d3946c489188e69\nTitle: Using Implicit Feedback to Improve Question Generation\nYear: 2023\nAbstract: Question Generation (QG) is a task of Natural Language Processing (NLP) that aims at automatically generating questions from text. Many applications can benefit from automatically generated questions, but often it is necessary to curate those questions, either by selecting or editing them. This task is informative on its own, but it is typically done post-generation, and, thus, the effort is wasted. In addition, most existing systems cannot incorporate this feedback back into them easily. In this work, we present a system, GEN, that learns from such (implicit) feedback. Following a pattern-based approach, it takes as input a small set of sentence/question pairs and creates patterns which are then applied to new unseen sentences. Each generated question, after being corrected by the user, is used as a new seed in the next iteration, so more patterns are created each time. We also take advantage of the corrections made by the user to score the patterns and therefore rank the generated questions.",
  "Each generated question, after being corrected by the user, is used as a new seed in the next iteration, so more patterns are created each time. We also take advantage of the corrections made by the user to score the patterns and therefore rank the generated questions. Results show that GEN is able to improve by learning from both levels of implicit feedback when compared to the version with no learning, considering the top 5, 10, and 20 questions. Improvements go up from 10%, depending on the metric and strategy used.\nAuthors: Hugo Rodrigues, Eric Nyberg, Lu\u00edsa Coheur\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A system that learns from both levels of implicit feedback when compared to the version with no learning, considering the top 5, 10, and 20 questions, and improvements go up from 10%, depending on the metric and strategy used.'}\nUrl: http://arxiv.org/pdf/2304.13664",
  "List of 2023 Open Access papers by eric nyberg are:\nGameQA: Gamified Mobile App Platform for Building Multiple-Domain Question-Answering Datasets\nInPars-Light: Cost-Effective Unsupervised Training of Efficient Rankers\nLanguage-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA\nChain-of-Skills: A Configurable Model for Open-Domain Question Answering\nA super wear-resistant coating for Mg alloys achieved by plasma electrolytic oxidation and discontinuous deposition\nDifference-Masking: Choosing What to Mask in Continued Pretraining\nUsing Implicit Feedback to Improve Question Generation",
  "Faculty Name: eric xing\nPaperid: 043512db27dbb03eb05eb5f5679b5bd5f59d18ca\nTitle: Research on the Training Path of Live E-commerce Talents Oriented by Industry Development\nYear: 2023\nAbstract: The growth of user scale and application popularization of live streaming e-commerce promote the transformation of live streaming stores to store live streaming, live streaming scene to scene live streaming, and the transformation of web celebrity staff to staff web celebrity. The stock talents of live streaming e-commerce can no longer meet the development of the industry. Long-term training of applied talents in higher vocational colleges can provide human resources to the industry and promote the development of local industries. However, the rapid development of live-streaming e-commerce industry leads to the shortage of industrial development and talent supply, the dislocation of industrial demand and talent training, the disconnect between practical training conditions and training requirements, and the lack of complementarity between higher vocational teachers and industries.",
  "However, the rapid development of live-streaming e-commerce industry leads to the shortage of industrial development and talent supply, the dislocation of industrial demand and talent training, the disconnect between practical training conditions and training requirements, and the lack of complementarity between higher vocational teachers and industries. According to the new in April 2022, the revision of \"vocational education law\" requirements to promote enterprise depth to participate in vocational education, education fusion is live electricity talent training, talent training to adhere to the industry development, post, class, competition, and training process, college teachers and industry mentor complementary development, jointly promote live electricity talent training.\nAuthors: Shouhui Xia, Xili Rao, Xin Wu\nVenue: Academic Journal of Management and Social Sciences\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The rapid development of live-streaming e-commerce industry leads to the shortage of industrial development and talent supply, the dislocation of industrial demand and talent training, the disconnect between practical training conditions and training requirements, and the lack of complementarity between higher vocational teachers and industries.'}\nUrl: https://drpress.org/ojs/index.php/ajmss/article/download/8754/8528",
  "Faculty Name: eric xing\nPaperid: 05916c0933cb6cc434d4fcc469f928e13ae57689\nTitle: Recent progresses on the gamma-ray observations of DAMPE\nYear: 2023\nAbstract: None\nAuthors: Z. Shen, K. Duan, Zunlei Xu, Wei Jiang, Xiang Li, Xiao Yuan Huang, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, F. de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, J. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng,",
  "de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, J. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Y. Huang, M. Ionica, Luyao Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A.",
  "Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, H. Su, Meng Su, H. Sun, Zhiyu Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Yuanzhu Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu, G. Xue,",
  "Yuanzhu Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hong-yun Zhao, Xu Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: None\nUrl: https://pos.sissa.it/444/670/pdf",
  "Faculty Name: eric xing\nPaperid: 06eb9ad79cf76007e6847c771a4645f1dab6c36d\nTitle: US residents' preferences for sharing of electronic health record and genetic information: a discrete choice experiment.\nYear: 2023\nAbstract: None\nAuthors: A. Wagner, Felicia Zhang, Kerry A Ryan, Eric Xing, Paige Nong, Sharon L. R. Kardia, Jodyn E. Platt\nVenue: Value in Health\nTldr: {'model': 'tldr@v2.0.0', 'text': 'For both genetic and EHR information, patients strongly prefer their data to be de-identified and to have the choice to opt out of sharing information with commercial companies.'}\nUrl: http://www.valueinhealthjournal.com/article/S1098301523000220/pdf",
  "Faculty Name: eric xing\nPaperid: 075b751201f549daeba9840f78768f4ceb507e17\nTitle: Identification of Nonlinear Latent Hierarchical Models\nYear: 2023\nAbstract: Identifying latent variables and causal structures from observational data is essential to many real-world applications involving biological data, medical data, and unstructured data such as images and languages. However, this task can be highly challenging, especially when observed variables are generated by causally related latent variables and the relationships are nonlinear. In this work, we investigate the identification problem for nonlinear latent hierarchical causal models in which observed variables are generated by a set of causally related latent variables, and some latent variables may not have observed children. We show that the identifiability of causal structures and latent variables (up to invertible transformations) can be achieved under mild assumptions: on causal structures, we allow for multiple paths between any pair of variables in the graph, which relaxes latent tree assumptions in prior work; on structural functions, we permit general nonlinearity and multi-dimensional continuous variables, alleviating existing work's parametric assumptions.",
  "Specifically, we first develop an identification criterion in the form of novel identifiability guarantees for an elementary latent variable model. Leveraging this criterion, we show that both causal structures and latent variables of the hierarchical model can be identified asymptotically by explicitly constructing an estimation procedure. To the best of our knowledge, our work is the first to establish identifiability guarantees for both causal structures and latent variables in nonlinear latent hierarchical models.\nAuthors: Lingjing Kong, Biwei Huang, Feng Xie, E. Xing, Yuejie Chi, Kun Zhang\nVenue: Neural Information Processing Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work develops an identification criterion in the form of novel identifiability guarantees for an elementary latent variable model and shows that both causal structures and latent variables of the hierarchical model can be identified asymptotically by explicitly constructing an estimation procedure.'}\nUrl: http://arxiv.org/pdf/2306.07916",
  "Faculty Name: eric xing\nPaperid: 0ba649135b008efa0f7d7db83a7405d3fa580658\nTitle: Effective Multi-Agent Deep Reinforcement Learning Control with Relative Entropy Regularization\nYear: 2023\nAbstract: In this paper, a novel Multi-agent Reinforcement Learning (MARL) approach, Multi-Agent Continuous Dynamic Policy Gradient (MACDPP) was proposed to tackle the issues of limited capability and sample efficiency in various scenarios controlled by multiple agents. It alleviates the inconsistency of multiple agents' policy updates by introducing the relative entropy regularization to the Centralized Training with Decentralized Execution (CTDE) framework with the Actor-Critic (AC) structure. Evaluated by multi-agent cooperation and competition tasks and traditional control tasks including OpenAI benchmarks and robot arm manipulation, MACDPP demonstrates significant superiority in learning capability and sample efficiency compared with both related multi-agent and widely implemented signal-agent baselines and therefore expands the potential of MARL in effectively learning challenging control scenarios.",
  "Evaluated by multi-agent cooperation and competition tasks and traditional control tasks including OpenAI benchmarks and robot arm manipulation, MACDPP demonstrates significant superiority in learning capability and sample efficiency compared with both related multi-agent and widely implemented signal-agent baselines and therefore expands the potential of MARL in effectively learning challenging control scenarios.\nAuthors: Chenyang Miao, Yunduan Cui, Huiyun Li, Xin Wu\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Evaluated by multi-agent cooperation and competition tasks and traditional control tasks including OpenAI benchmarks and robot arm manipulation, MACDPP demonstrates significant superiority in learning capability and sample efficiency compared with both related multi- agent and widely implemented signal-agent baselines and therefore expands the potential of MARL in effectively learning challenging control scenarios.'}\nUrl: https://arxiv.org/pdf/2309.14727",
  "Faculty Name: eric xing\nPaperid: 1250676d646a9b48cf3bab66f13dc3c628ff68af\nTitle: 3D Open-vocabulary Segmentation with Foundation Models\nYear: 2023\nAbstract: Open-vocabulary segmentation of 3D scenes is a fundamental function of human perception and thus a crucial objective in computer vision research. However, this task is heavily impeded by the lack of large-scale and diverse 3D open-vocabulary segmentation datasets for training robust and generalizable models. Distilling knowledge from pre-trained 2D open-vocabulary segmentation models helps but it compromises the open-vocabulary feature significantly as the 2D models are mostly finetuned with close-vocabulary datasets. We tackle the challenges in 3D open-vocabulary segmentation by exploiting the open-vocabulary multimodal knowledge and object reasoning capability of pre-trained foundation models CLIP and DINO, without necessitating any fine-tuning. Specifically, we distill open-vocabulary visual and textual knowledge from CLIP into a neural radiance field (NeRF) which effectively lifts 2D features into view-consistent 3D segmentation.",
  "Specifically, we distill open-vocabulary visual and textual knowledge from CLIP into a neural radiance field (NeRF) which effectively lifts 2D features into view-consistent 3D segmentation. Furthermore, we introduce the Relevancy-Distribution Alignment loss and Feature-Distribution Alignment loss to respectively mitigate the ambiguities of CLIP features and distill precise object boundaries from DINO features, eliminating the need for segmentation annotations during training. Extensive experiments show that our method even outperforms fully supervised models trained with segmentation annotations, suggesting that 3D open-vocabulary segmentation can be effectively learned from 2D images and text-image pairs.",
  "Extensive experiments show that our method even outperforms fully supervised models trained with segmentation annotations, suggesting that 3D open-vocabulary segmentation can be effectively learned from 2D images and text-image pairs.\nAuthors: Kunhao Liu, Fangneng Zhan, Jiahui Zhang, Muyu Xu, Yingchen Yu, Abdulmotaleb El-Saddik, Christian Theobalt, Eric P. Xing, Shijian Lu\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work distill open-vocabulary visual and textual knowledge from CLIP into a neural radiance field (NeRF) which effectively lifts 2D features into view-consistent 3D segmentation, suggesting that 3D open- Vocabulary segmentation can be effectively learned from 2D images and text-image pairs.'}\nUrl: https://arxiv.org/pdf/2305.14093",
  "Faculty Name: eric xing\nPaperid: 1262758538525835d918007d15726794e19a07b7\nTitle: Squeeze, Recover and Relabel: Dataset Condensation at ImageNet Scale From A New Perspective\nYear: 2023\nAbstract: We present a new dataset condensation framework termed Squeeze, Recover and Relabel (SRe$^2$L) that decouples the bilevel optimization of model and synthetic data during training, to handle varying scales of datasets, model architectures and image resolutions for efficient dataset condensation. The proposed method demonstrates flexibility across diverse dataset scales and exhibits multiple advantages in terms of arbitrary resolutions of synthesized images, low training cost and memory consumption with high-resolution synthesis, and the ability to scale up to arbitrary evaluation network architectures. Extensive experiments are conducted on Tiny-ImageNet and full ImageNet-1K datasets. Under 50 IPC, our approach achieves the highest 42.5% and 60.8% validation accuracy on Tiny-ImageNet and ImageNet-1K, outperforming all previous state-of-the-art methods by margins of 14.5% and 32.9%, respectively.",
  "Under 50 IPC, our approach achieves the highest 42.5% and 60.8% validation accuracy on Tiny-ImageNet and ImageNet-1K, outperforming all previous state-of-the-art methods by margins of 14.5% and 32.9%, respectively. Our approach also surpasses MTT in terms of speed by approximately 52$\\times$ (ConvNet-4) and 16$\\times$ (ResNet-18) faster with less memory consumption of 11.6$\\times$ and 6.4$\\times$ during data synthesis. Our code and condensed datasets of 50, 200 IPC with 4K recovery budget are available at https://github.com/VILA-Lab/SRe2L.\nAuthors: Zeyuan Yin, Eric P. Xing, Zhiqiang Shen\nVenue: Neural Information Processing Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The proposed dataset condensation framework demonstrates flexibility across diverse dataset scales and exhibits multiple advantages in terms of arbitrary resolutions of synthesized images, low training cost and memory consumption with high-resolution synthesis, and the ability to scale up to arbitrary evaluation network architectures.'}",
  "Url: http://arxiv.org/pdf/2306.13092",
  "Faculty Name: eric xing\nPaperid: 165e6111afcb14cf92b10d70cd1dad1c4aad4ada\nTitle: Convolutional Neural Network Measurement of Non-Fiducial Electrons Cosmic-Rays Using the DAMPE Experiment.\nYear: 2023\nAbstract: None\nAuthors: E. Putti-Garcia, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Zi-Yuan Chen, P. Coppin, M. Cui, T. Cui, Y. Cui, I. De Mitri, F. de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, J. Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang,",
  "de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, J. Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, Lu Jiang, Weizhong Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, Tao Ma, Xiao Ma, G. Marsella, M. N. Mazziotta,",
  "Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, Tao Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, Rui Qiao, J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, H. Su, Meng Su, H. Sun, Zhigang Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu,",
  "Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hong-yun Zhao, Xu Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: None\nUrl: https://pos.sissa.it/444/130/pdf",
  "Faculty Name: eric xing\nPaperid: 16b42fc85f4c073aa00c410cbdce965d7c6f8d4d\nTitle: One-for-All: Generalized LoRA for Parameter-Efficient Fine-tuning\nYear: 2023\nAbstract: We present Generalized LoRA (GLoRA), an advanced approach for universal parameter-efficient fine-tuning tasks. Enhancing Low-Rank Adaptation (LoRA), GLoRA employs a generalized prompt module to optimize pre-trained model weights and adjust intermediate activations, providing more flexibility and capability across diverse tasks and datasets. Moreover, GLoRA facilitates efficient parameter adaptation by employing a scalable, modular, layer-wise structure search that learns individual adapter of each layer. Originating from a unified mathematical formulation, GLoRA exhibits strong transfer learning, few-shot learning and domain generalization abilities, as it adapts to new tasks through not only weights but also additional dimensions like activations. Comprehensive experiments demonstrate that GLoRA outperforms all previous methods in natural, specialized, and structured vision benchmarks, achieving superior accuracy with fewer parameters and computations.",
  "Comprehensive experiments demonstrate that GLoRA outperforms all previous methods in natural, specialized, and structured vision benchmarks, achieving superior accuracy with fewer parameters and computations. The proposed method on LLaMA-1 and LLaMA-2 also show considerable enhancements compared to the original LoRA in the language domain. Furthermore, our structural re-parameterization design ensures that GLoRA incurs no extra inference cost, rendering it a practical solution for resource-limited applications. Code and models are available at: https://github.com/Arnav0400/ViT-Slim/tree/master/GLoRA.\nAuthors: Arnav Chavan, Zhuang Liu, D. Gupta, Eric P. Xing, Zhiqiang Shen\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Generalized LoRA is presented, an advanced approach for universal parameter-efficient fine-tuning tasks, which outperforms all previous methods in natural, specialized, and structured vision benchmarks, achieving superior accuracy with fewer parameters and computations.'}\nUrl: http://arxiv.org/pdf/2306.07967",
  "Faculty Name: eric xing\nPaperid: 19ce6aa0fd8a7b7decd836326e2e3fe8222bae22\nTitle: Visible and Infrared Image Fusion of Forest Fire Scenes Based on Generative Adversarial Networks with Multi-Classification and Multi-Level Constraints\nYear: 2023\nAbstract: Aimed at addressing deficiencies in existing image fusion methods, this paper proposed a multi-level and multi-classification generative adversarial network (GAN)-based method (MMGAN) for fusing visible and infrared images of forest fire scenes (the surroundings of firefighters), which solves the problem that GANs tend to ignore visible contrast ratio information and detailed infrared texture information. The study was based on real-time visible and infrared image data acquired by visible and infrared binocular cameras on forest firefighters\u2019 helmets. We improved the GAN by, on the one hand, splitting the input channels of the generator into gradient and contrast ratio paths, increasing the depth of convolutional layers, and improving the extraction capability of shallow networks.",
  "We improved the GAN by, on the one hand, splitting the input channels of the generator into gradient and contrast ratio paths, increasing the depth of convolutional layers, and improving the extraction capability of shallow networks. On the other hand, we designed a discriminator using a multi-classification constraint structure and trained it against the generator in a continuous and adversarial manner to supervise the generator, generating better-quality fused images. Our results indicated that compared to mainstream infrared and visible image fusion methods, including anisotropic diffusion fusion (ADF), guided filtering fusion (GFF), convolutional neural networks (CNN), FusionGAN, and dual-discriminator conditional GAN (DDcGAN), the MMGAN model was overall optimal and had the best visual effect when applied to image fusions of forest fire surroundings. Five of the six objective metrics were optimal, and one ranked second-to-optimal. The image fusion speed was more than five times faster than that of the other methods. The MMGAN model significantly improved the quality of fused images of forest fire scenes, preserved the contrast ratio information of visible images and the detailed texture information of infrared images of forest fire scenes, and could accurately reflect information on forest fire scene surroundings.",
  "The MMGAN model significantly improved the quality of fused images of forest fire scenes, preserved the contrast ratio information of visible images and the detailed texture information of infrared images of forest fire scenes, and could accurately reflect information on forest fire scene surroundings.\nAuthors: Qi Jin, Sanqing Tan, Gui Zhang, Zhi Yang, Yijun Wen, Huashun Xiao, Xin Wu\nVenue: Forests\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A multi-level and multi-classification generative adversarial network (GAN)-based method for fusing visible and infrared images of forest fire scenes (the surroundings of firefighters), which solves the problem that GANs tend to ignore visible contrast ratio information and detailed infrared texture information.'}\nUrl: https://www.mdpi.com/1999-4907/14/10/1952/pdf?version=1695721390",
  "Faculty Name: eric xing\nPaperid: 1d54cbcb331af0f618c4f9537b1164061727007d\nTitle: The split delivery vehicle routing problem with time windows and three-dimensional loading constraints\nYear: 2023\nAbstract: None\nAuthors: Miao Yan, L. Chu, Xin Wu\nVenue: Journal of Industrial and Management Optimization\nTldr: None\nUrl: https://www.aimsciences.org/data/article/export-pdf?id=64ec64cec82b5f110a3cd149",
  "Faculty Name: eric xing\nPaperid: 1db4a8f3c35ae1d2e8f7029abf67f37b0030ea2a\nTitle: Defending Against Malicious Behaviors in Federated Learning with Blockchain\nYear: 2023\nAbstract: In the era of deep learning, federated learning (FL) presents a promising approach that allows multi-institutional data owners, or clients, to collaboratively train machine learning models without compromising data privacy. However, most existing FL approaches rely on a centralized server for global model aggregation, leading to a single point of failure. This makes the system vulnerable to malicious attacks when dealing with dishonest clients. In this work, we address this problem by proposing a secure and reliable FL system based on blockchain and distributed ledger technology. Our system incorporates a peer-to-peer voting mechanism and a reward-and-slash mechanism, which are powered by on-chain smart contracts, to detect and deter malicious behaviors. Both theoretical and empirical analyses are presented to demonstrate the effectiveness of the proposed approach, showing that our framework is robust against malicious client-side behaviors.",
  "Our system incorporates a peer-to-peer voting mechanism and a reward-and-slash mechanism, which are powered by on-chain smart contracts, to detect and deter malicious behaviors. Both theoretical and empirical analyses are presented to demonstrate the effectiveness of the proposed approach, showing that our framework is robust against malicious client-side behaviors.\nAuthors: Nanqing Dong, Zhipeng Wang, Jiahao Sun, Michael C. Kampffmeyer, Yizhe Wen, Shuoying Zhang, W. Knottenbelt, Eric P. Xing\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes a secure and reliable FL system based on blockchain and distributed ledger technology that incorporates a peer-to-peer voting mechanism and a reward-and-slash mechanism, which are powered by on-chain smart contracts, to detect and deter malicious behaviors.'}\nUrl: http://arxiv.org/pdf/2307.00543",
  "Faculty Name: eric xing\nPaperid: 21aecd6ba669c18397295fd63e312c010c2eeca3\nTitle: A Novel Definition of Fuzzy Difference on Non-increasing Fuzzy Real Numbers\nYear: 2023\nAbstract: In this paper, firstly, a novel definition of a fuzzy difference based on non-increasing fuzzy real numbers is introduced, which is different from the previous definitions by using fuzzy interval-numbers and Zadeh\u2019s extension principle. Then we give some important conclusions of fuzzy difference from the view of two cuts of fuzzy sets. Moreover, a definition of a opposite fuzzy real number is given so that we show the connection between the fuzzy difference and fuzzy addition on fuzzy real numbers. Finally, we provide several examples for the sake of illustrating the fuzzy difference on non-increasing fuzzy real numbers is reasonable generalization of classical difference. In addition, we give the prospect that we want to use this difference to research fuzzy derivatives.",
  "Finally, we provide several examples for the sake of illustrating the fuzzy difference on non-increasing fuzzy real numbers is reasonable generalization of classical difference. In addition, we give the prospect that we want to use this difference to research fuzzy derivatives.\nAuthors: Xin Wu, Yun Zhang, Shuang Lin, Yu Zhong\nVenue: Journal of Physics: Conference Series\nTldr: {'model': 'tldr@v2.0.0', 'text': None}\nUrl: https://iopscience.iop.org/article/10.1088/1742-6596/2449/1/012003/pdf",
  "Faculty Name: eric xing\nPaperid: 274b363f94a741f38cad95f1ab68edaadf6fc0d9\nTitle: Analysis of Individual Cosmic-Ray Proton and Helium Fluxes towards PeV Energies with DAMPE\nYear: 2023\nAbstract: The DArk Matter Particle Explorer (DAMPE) is a satellite-borne experiment, in operation since 2015, aimed at studying cosmic rays and high-energy gamma rays. Proton and helium are the first-and second-most abundant components in cosmic rays. Given their smaller interaction cross sections with the interstellar medium, compared to heavier nuclei, they can travel larger distances, thereby becoming important probes to cosmic-ray sources as well as acceleration and propagation mechanisms. Recently, in the DAMPE collaboration, machine learning (ML) techniques were developed and deployed to improve particle tracking and identification and correct for the calorimeter readout saturation at high energies. This work presents a direct measurement of the energy spectra of cosmic-ray protons and helium nuclei, using 84 and 81 months of data, respectively, recorded by DAMPE.",
  "This work presents a direct measurement of the energy spectra of cosmic-ray protons and helium nuclei, using 84 and 81 months of data, respectively, recorded by DAMPE. Application of the above-mentioned ML techniques helps in extending the spectra to higher kinetic energies than those previously reported by DAMPE\nAuthors: A. Ruina, P. Coppin, A. Kotenko, Pengxiong Ma, M. Stolpovskiy, A. Tykhonov, C. Yue, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, F. de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R.",
  "Yu-Xin Cui, I. De Mitri, F. de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, Luyang Jiang, Wei Jiang, Y. Jiang, J. Kong, D. Kyratzis, S. Lei, W. Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, T. Ma, Xiao Ma, G. Marsella, M.",
  "Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, Z. Shangguan, E. Xu, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, H. Su, Meng Su, H. Sun, Zhigang Sun, A. Surdo, X. Teng, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu, Zunlei Xu, G.",
  "Ying Wang, Y. Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hongying Zhao, Xu Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: None\nUrl: https://pos.sissa.it/444/170/pdf",
  "Faculty Name: eric xing\nPaperid: 279aeb0ffdaec08391f6a50695e2b01d6a148b7e\nTitle: The First LHAASO Catalog of Gamma-Ray Sources\nYear: 2023\nAbstract: \n We present the first catalog of very-high-energy and ultra-high-energy gamma-ray sources detected by the Large High Altitude Air Shower Observatory. The catalog was compiled using 508 days of data collected by the Water Cherenkov Detector Array from 2021 March to 2022 September and 933 days of data recorded by the Kilometer Squared Array from 2020 January to 2022 September. This catalog represents the main result from the most sensitive large coverage gamma-ray survey of the sky above 1 TeV, covering decl. from \u221220\u00b0 to 80\u00b0. In total, the catalog contains 90 sources with an extended size smaller than 2\u00b0 and a significance of detection at >5\u03c3. Based on our source association criteria, 32 new TeV sources are proposed in this study.",
  "from \u221220\u00b0 to 80\u00b0. In total, the catalog contains 90 sources with an extended size smaller than 2\u00b0 and a significance of detection at >5\u03c3. Based on our source association criteria, 32 new TeV sources are proposed in this study. Among the 90 sources, 43 sources are detected with ultra-high energy (E > 100 TeV) emission at >4\u03c3 significance level. We provide the position, extension, and spectral characteristics of all the sources in this catalog.\nAuthors: Z. Cao, F. Aharonian, Q. An, Axikegu, Y. Bai, Y. Bao, D. Bastieri, X. Bi, Y. Bi, J. Cai, Q. Cao, W. Cao, Z. Cao, J. Chang, J. Chang, A. Chen, E. Chen, Liang Chen, Lin Chen, Long Chen, M. Chen, M. Chen, Q. Chen, S. Chen, S. Z. Chen, T. Chen, Y. Chen, N. Cheng, Y. Cheng, M. Cui, S. Cui, X. Cui, Y. Cui,",
  "Lin Chen, Long Chen, M. Chen, M. Chen, Q. Chen, S. Chen, S. Z. Chen, T. Chen, Y. Chen, N. Cheng, Y. Cheng, M. Cui, S. Cui, X. Cui, Y. Cui, B. Dai, H. Dai, Z. Dai, Danzengluobu, D. Volpe, X. Dong, K. Duan, J. Fan, Y. Z. Fan, J. Fang, K. Fang, C. Feng, L. Feng, S. Feng, X. Feng, Y. Feng, S. Gabici, B. Gao, C. Gao, L. Gao, Q. Gao, W. Gao, W. Gao, M. Ge, L. Geng, G. Giacinti, G. Gong, Q. Gou, M. Gu, F. Guo, X. Guo, Y. Guo, Y. Guo, Y. Han, H. He, Haoyu He, J. Y. He, X. He, Y. He, M. Heller, Y. Hor, B.",
  "Gou, M. Gu, F. Guo, X. Guo, Y. Guo, Y. Guo, Y. Han, H. He, Haoyu He, J. Y. He, X. He, Y. He, M. Heller, Y. Hor, B. Hou, C. Hou, X. Hou, H. Hu, Q. Hu, S. Hu, D. Huang, T. Q. Huang, W. Huang, X. Huang, X. Y. Huang, Y. Huang, Z. Huang, X. Ji, H. Jia, K. Jia, K. Jiang, X. W. Jiang, Z. Jiang, M. Jin, M. Kang, T. Ke, D. Kuleshov, K. Kurinov, B. Li, Cheng Li, Cong Li, D. Li, F. Li, H. B. Li, H. C. Li, H. Li, J. Li, Jian Li, Jie Li, K. Li, W. Li, X. Li, Xin Li, Y. Li, Zhe Li, Zhuo Li, E. Liang, Y. Liang, S.",
  "B. Li, H. C. Li, H. Li, J. Li, Jian Li, Jie Li, K. Li, W. Li, X. Li, Xin Li, Y. Li, Zhe Li, Zhuo Li, E. Liang, Y. Liang, S. Lin, B. Liu, C. Liu, D. Liu, H. Liu, H. Liu, J. Liu, J. Liu, J. Liu, M. Y. Liu, R. Liu, S. M. Liu, W. Liu, Y. Liu, Y. N. Liu, R. Lu, Q. Luo, H. Lv, B. Ma, L. Ma, X. Ma, J. Mao, Z. Min, W. Mitthumsiri, H. Mu, Y. Nan, A. Neronov, Z. Ou, B. Pang, P. Pattarakijwanich, Z. Pei, M. Qi, Y. Qi, B. Qiao, J. Qin, D. Ruffolo, A. S'aiz, D. Semikoz, C. Shao, L. Shao, O. Shchegolev,",
  "Pattarakijwanich, Z. Pei, M. Qi, Y. Qi, B. Qiao, J. Qin, D. Ruffolo, A. S'aiz, D. Semikoz, C. Shao, L. Shao, O. Shchegolev, X. Sheng, F. Shu, H. Song, Y. Stenkin, V. Stepanov, Y. Su, Q. Sun, X. Sun, Z. Sun, P. Tam, Q. Tang, Z. Tang, W. Tian, C. Wang, C. Wang, G. W. Wang, H. Wang, H. H. Wang, J. C. Wang, K. Wang, L. Wang, L. Y. Wang, P. Wang, R. Wang, W. Wang, X. G. Wang, X. Y. Wang, Y. Wang, Y. Wang, Y. J. Wang, Z. H. Wang, Z. X. Wang, Zhen Wang, Z. Wang, D. Wei, J. Wei, Y. J. Wei, T. Wen, C. Y. Wu, H. Wu, S. Wu,",
  "Wang, Y. Wang, Y. J. Wang, Z. H. Wang, Z. X. Wang, Zhen Wang, Z. Wang, D. Wei, J. Wei, Y. J. Wei, T. Wen, C. Y. Wu, H. Wu, S. Wu, Xin Wu, Y. Wu, S. Xi, J. Xia, J. Xia, G. Xiang, D. Xiao, G. Xiao, G. Xin, Y. Xin, Yangang Xing, Z. Xiong, D. Xu, R. Xu, R. Xu, W. Xu, L. Xue, D. Yan, J. Yan, T. Yan, C. Yang, F. Yang, F. Yang, H. W. Yang, J. Y. Yang, L. L. Yang, M. Yang, R. Yang, S. Yang, Y. Yao, Z. Yao, Y. Ye, L. Yin, N. Yin, X. You, Z. You, Y. Yu, Q. Yuan, H. Yue, H. Zeng, T. Zeng, W. Zeng, M. Zha, B. Zhang, F.",
  "Yao, Z. Yao, Y. Ye, L. Yin, N. Yin, X. You, Z. You, Y. Yu, Q. Yuan, H. Yue, H. Zeng, T. Zeng, W. Zeng, M. Zha, B. Zhang, F. Zhang, H. Zhang, H. Zhang, J. Zhang, L. X. Zhang, Li Zhang, P. Zhang, P. Zhang, R. Zhang, S. B. Zhang, S. Zhang, S. Zhang, X. Zhang, X. Zhang, Y. Zhang, Yi. Zhang, Yong Zhang, B. Zhao, J. Zhao, Liang Zhao, L. Zhao, S. Zhao, F. Zheng, B. Zhou, H. Zhou, J. Zhou, M. Zhou, P. Zhou, R. Zhou, X. Zhou, C. Zhu, F. Zhu, H. Zhu, K. Zhu, X. Zuo\nVenue: Astrophysical Journal Supplement Series\nTldr: None\nUrl: https://iopscience.iop.org/article/10.3847/1538-4365/acfd29/pdf",
  "Faculty Name: eric xing\nPaperid: 28378edeeca3aafb81b7a07454fcf41146736a3e\nTitle: Machine Learning for Predicting Forest Fire Occurrence in Changsha: An Innovative Investigation into the Introduction of a Forest Fuel Factor\nYear: 2023\nAbstract: Affected by global warming and increased extreme weather, Hunan Province saw a phased and concentrated outbreak of forest fires in 2022, causing significant damage and impact. Predicting the occurrence of forest fires can enhance the ability to make early predictions and strengthen early warning and responses. Currently, fire prevention and extinguishing in China\u2019s forests and grasslands face severe challenges due to the overlapping of natural and social factors. Existing forest fire occurrence prediction models mostly take into account vegetation, topographic, meteorological and human activity factors; however, the occurrence of forest fires is closely related to the forest fuel moisture content.",
  "Existing forest fire occurrence prediction models mostly take into account vegetation, topographic, meteorological and human activity factors; however, the occurrence of forest fires is closely related to the forest fuel moisture content. In this study, the traditional driving factors of forest fire such as satellite hotspots, vegetation, meteorology, topography and human activities from 2004 to 2021 were introduced along with forest fuel factors (vegetation canopy water content and evapotranspiration from the top of the vegetation canopy), and a database of factors for predicting forest fire occurrence was constructed. And a forest fire occurrence prediction model was built using machine learning methods such as the Random Forest model (RF), the Gradient Boosting Decision Tree model (GBDT) and the Adaptive Augmentation Model (AdaBoost). The accuracy of the models was verified using Area Under Curve (AUC) and four other metrics. The RF model with an AUC value of 0.981 was more accurate than all other models in predicting the probability of forest fire occurrence, followed by the GBDT (AUC = 0.978) and AdaBoost (AUC = 0.891) models.",
  "The RF model with an AUC value of 0.981 was more accurate than all other models in predicting the probability of forest fire occurrence, followed by the GBDT (AUC = 0.978) and AdaBoost (AUC = 0.891) models. The RF model, which has the best accuracy, was selected to predict the monthly forest fire probability in Changsha in 2022 and combined with the Inverse Distance Weight Interpolation method to plot the monthly forest fire probability in Changsha. We found that the monthly spatial and temporal distribution of forest fire probability in Changsha varied significantly, with March, April, May, September, October, November and December being the months with higher forest fire probability. The highest probability of forest fires occurred in the central and northern regions. In this study, the core drivers affecting the occurrence of forest fires in Changsha City were found to be vegetation canopy evapotranspiration and vegetation canopy water content. The RF model was identified as a more suitable forest fire occurrence probability prediction model for Changsha City.",
  "In this study, the core drivers affecting the occurrence of forest fires in Changsha City were found to be vegetation canopy evapotranspiration and vegetation canopy water content. The RF model was identified as a more suitable forest fire occurrence probability prediction model for Changsha City. Meanwhile, this study found that vegetation characteristics and combustible factors have more influence on forest fire occurrence in Changsha City than meteorological factors, and surface temperature has less influence on forest fire occurrence in Changsha City.\nAuthors: Xin Wu, Gui Zhang, Zhi Yang, Sanqing Tan, Yongke Yang, Ziheng Pang\nVenue: Remote Sensing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It was found that vegetation characteristics and combustible factors have more influence on forest fire occurrence in Changsha City than meteorological factors, and surface temperature has less influence on tree canopy evapotranspiration and vegetation canopy water content.'}\nUrl: https://www.mdpi.com/2072-4292/15/17/4208/pdf?version=1693125211",
  "Faculty Name: eric xing\nPaperid: 3970960ccc1a73da4257cf5580665eaae1a15edb\nTitle: ViT-Based Terrain Recognition System for wearable soft exosuit\nYear: 2023\nAbstract: None\nAuthors: Fangliang Yang, Chunjie Chen, Zhuo Wang, Hui Chen, Yao Liu, Gang Li, Xin Wu\nVenue: Biomimetic Intelligence and Robotics\nTldr: None\nUrl: N/A",
  "Faculty Name: eric xing\nPaperid: 39bb5d44735c07b1e1f4341a2d4bc8d5e783f491\nTitle: SlimPajama-DC: Understanding Data Combinations for LLM Training\nYear: 2023\nAbstract: This paper aims to understand the impacts of various data combinations (e.g., web text, wikipedia, github, books) on the training of large language models using SlimPajama. SlimPajama is a rigorously deduplicated, multi-source dataset, which has been refined and further deduplicated to 627B tokens from the extensive 1.2T tokens RedPajama dataset contributed by Together. We've termed our research as SlimPajama-DC, an empirical analysis designed to uncover fundamental characteristics and best practices associated with employing SlimPajama in the training of large language models. During our research with SlimPajama, two pivotal observations emerged: (1) Global deduplication vs. local deduplication. We analyze and discuss how global (across different sources of datasets) and local (within the single source of dataset) deduplications affect the performance of trained models.",
  "local deduplication. We analyze and discuss how global (across different sources of datasets) and local (within the single source of dataset) deduplications affect the performance of trained models. (2) Proportions of high-quality/highly-deduplicated multi-source datasets in the combination. To study this, we construct six configurations of SlimPajama dataset and train individual ones using 1.3B Cerebras-GPT model with Alibi and SwiGLU. Our best configuration outperforms the 1.3B model trained on RedPajama using the same number of training tokens by a significant margin. All our 1.3B models are trained on Cerebras 16$\\times$ CS-2 cluster with a total of 80 PFLOP/s in bf16 mixed precision. We further extend our discoveries (such as increasing data diversity is crucial after global deduplication) on a 7B model with large batch-size training.",
  "We further extend our discoveries (such as increasing data diversity is crucial after global deduplication) on a 7B model with large batch-size training. Our models and the separate SlimPajama-DC datasets are available at: https://huggingface.co/MBZUAI-LLM and https://huggingface.co/datasets/cerebras/SlimPajama-627B.\nAuthors: Zhiqiang Shen, Tianhua Tao, Liqun Ma, W. Neiswanger, Zhengzhong Liu, Hongyi Wang, Bowen Tan, Joel Hestness, Natalia Vassilieva, Daria Soboleva, Eric P. Xing\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper aims to understand the impacts of various data combinations on the training of large language models using SlimPajama, a rigorously deduplicated, multi-source dataset, and analyzes and discusses how global and local dedUplications affect the performance of trained models.'}\nUrl: https://arxiv.org/pdf/2309.10818",
  "Faculty Name: eric xing\nPaperid: 3dc80cea6704a2bc1d714e3bbd502846f3498743\nTitle: Carbon Flux with DAMPE Using Machine Learning Methods\nYear: 2023\nAbstract: DAMPE space-borne cosmic ray experiment has been collecting data since December 2015. Many high-impact results on the ion, electron and photon fluxes were obtained. This submission presents the carbon flux analysis with DAMPE using machine learning techniques. The readout electronics would saturate at energy deposits above several TeV in a single BGO bar of the DAMPE calorimeter. The total energy loss per event due to saturation can sometimes reach over a hundred TeV. We present a convolutional neural network model which can accurately recover the energy lost due to saturation and thus significantly increase the dynamic range of DAMPE. Another machine learning model combines the resolution of the hodoscopic BGO calorimeter and the high-resolution tracker of DAMPE to provide the best possible prediction of the direction of the incoming particle. This allows measuring charges at energies up to several hundred TeV. In this work, we present the application of these methods to carbon flux analysis.",
  "This allows measuring charges at energies up to several hundred TeV. In this work, we present the application of these methods to carbon flux analysis.\nAuthors: M. Stolpovskiy, Francesco Alemanno, C. Altomare, Qi An, P. Azzarello, F. Barbato, P. Bernardini, Xiaomei Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Yunqiang Cui, I. De Mitri, Francesco de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, Piergiorgio Fusco, Min Gao, F. Gargano, Essna Ghose,",
  "Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, Piergiorgio Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guangshun Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, Luyang Jiang, Weizhong Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, Tao Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia,",
  "P. Ma, Tao Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, H. Su, Meng Su, H. Sun, Zhiyu Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Yuanzhu Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zizhong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan,",
  "Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zizhong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hong-yun Zhao, Xu Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A convolutional neural network model is presented which can accurately recover the energy lost due to saturation and thus significantly increase the dynamic range of DAMPE.'}\nUrl: https://pos.sissa.it/444/168/pdf",
  "Faculty Name: eric xing\nPaperid: 3ecea2ef252d44745caf04860f4ca2983d427f30\nTitle: Acupuncture Alleviates CUMS-Induced Depression-Like Behaviors by Restoring Prefrontal Cortex Neuroplasticity\nYear: 2023\nAbstract: Purpose To explore the therapeutic efficiency of acupuncture and the related molecular mechanism of neural plasticity in depression. Methods Chronic unpredictable mild stress- (CUMS-) induced rats were established for the depression animal model. There were a total of four rat groups, including the control group, the CUMS group, the CUMS+acupuncture group, and the CUMS+fluoxetine group. The acupuncture group and the fluoxetine group were given a 3-week treatment after the modeling intervention. The researcher performed the open-field, elevated plus maze, and sucrose preference tests to evaluate depressive behaviors. The number of nerve cells, dendrites' length, and the prefrontal cortex's spine density were detected using Golgi staining.",
  "The researcher performed the open-field, elevated plus maze, and sucrose preference tests to evaluate depressive behaviors. The number of nerve cells, dendrites' length, and the prefrontal cortex's spine density were detected using Golgi staining. The prefrontal cortex expression, such as BDNF, PSD95, SYN, and PKMZ protein, was detected using the western blot and RT-PCR. Results Acupuncture could alleviate depressive-like behaviors and promote the recovery of the neural plasticity functions in the prefrontal cortex, showing the increasing cell numbers, prolonging the length of the dendrites, and enhancing the spine density. The neural plasticity-related proteins in the prefrontal cortex, including BDNF, PSD95, SYN, and PKMZ, were all downregulated in the CUMS-induced group; however, these effects could be partly reversed after being treated by acupuncture and fluoxetine (P < 0.05). Conclusion Acupuncture can ameliorate depressive-like behaviors by promoting the recovery of neural plasticity functions and neural plasticity-related protein upregulation in the prefrontal cortex of CUMS-induced depressed rats.",
  "Conclusion Acupuncture can ameliorate depressive-like behaviors by promoting the recovery of neural plasticity functions and neural plasticity-related protein upregulation in the prefrontal cortex of CUMS-induced depressed rats. Our study provides new insights into the antidepressant approach, and further studies are warranted to elucidate the mechanisms of acupuncture involved in depression treatment.\nAuthors: Peng Li, Wenya Huang, Yi-ping Chen, M. Aslam, Wen-jing Cheng, Yang Huang, Wenjie Chen, Yanxun Huang, Xin Wu, Yining Yan, Junliang Shen, Tao Tong, Shuqiong Huang, Xianjun Meng\nVenue: Journal of Neural Transplantation and Plasticity\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This study provides new insights into the antidepressant approach, and further studies are warranted to elucidate the mechanisms of acupuncture involved in depression treatment.'}\nUrl: https://downloads.hindawi.com/journals/np/2023/1474841.pdf",
  "Faculty Name: eric xing\nPaperid: 3ed28c3ee6f1d7645fa46b7353f1475a3122a6c4\nTitle: Influence of sensor array on MS/AE source location accuracy in rock mass\nYear: 2023\nAbstract: None\nAuthors: Lin-qi Huang, Xin Wu, Xi-bing Li, Shao-feng Wang\nVenue: Transactions of Nonferrous Metals Society of China\nTldr: None\nUrl: N/A",
  "Faculty Name: eric xing\nPaperid: 44772fe1c3fa422a3da7e25092db2544893d6bfb\nTitle: Improved Logical Reasoning of Language Models via Differentiable Symbolic Programming\nYear: 2023\nAbstract: Pre-trained large language models (LMs) struggle to perform logical reasoning reliably despite advances in scale and compositionality. In this work, we tackle this challenge through the lens of symbolic programming. We propose DSR-LM, a Differentiable Symbolic Reasoning framework where pre-trained LMs govern the perception of factual knowledge, and a symbolic module performs deductive reasoning. In contrast to works that rely on hand-crafted logic rules, our differentiable symbolic reasoning framework efficiently learns weighted rules and applies semantic loss to further improve LMs. DSR-LM is scalable, interpretable, and allows easy integration of prior knowledge, thereby supporting extensive symbolic programming to robustly derive a logical conclusion. The results of our experiments suggest that DSR-LM improves the logical reasoning abilities of pre-trained language models, resulting in a significant increase in accuracy of over 20% on deductive reasoning benchmarks.",
  "The results of our experiments suggest that DSR-LM improves the logical reasoning abilities of pre-trained language models, resulting in a significant increase in accuracy of over 20% on deductive reasoning benchmarks. Furthermore, DSR-LM outperforms a variety of competitive baselines when faced with systematic changes in sequence length.\nAuthors: Hanlin Zhang, Jiani Huang, Ziyang Li, M. Naik, Eric P. Xing\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'DSR-LM is proposed, a Differentiable Symbolic Reasoning framework where pre-trained LMs govern the perception of factual knowledge, and a symbolic module performs deductive reasoning, and efficiently learns weighted rules and applies semantic loss to further improve LMs.'}\nUrl: http://arxiv.org/pdf/2305.03742",
  "Faculty Name: eric xing\nPaperid: 44a8056e5be87941c574b92b0c07193662c0c5c0\nTitle: Gpr35 shapes gut microbial ecology to modulate hepatic steatosis.\nYear: 2023\nAbstract: None\nAuthors: Xin Wu, Shuobing Chen, Qingyuan Yan, Feng Yu, Hua Shao, Xiao Zheng, Xueli Zhang\nVenue: Pharmacological Research\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work identifies G protein-coupled receptor 35 (Gpr35) as a regulator of gut microbial ecology and the susceptibility to obesity and hepatic steatosis in mice and provides mechanistic insights into a genetic-diet-microbe interplay that dictates susceptibility to metabolic disorder.'}\nUrl: N/A",
  "Faculty Name: eric xing\nPaperid: 484206a2d2fabaf267e3fcf99bd04b124e9bc64d\nTitle: An innovative divertor concept, the fish tail divertor, for reducing the surface temperature on the divertor target plate in EAST tokamak experiments\nYear: 2023\nAbstract: An innovative divertor concept, the fish tail divertor, is proposed in this paper, aimed at reducing the surface temperature on the tokamak divertor plate as well as that due to the edge localized modes. This new concept has been implemented in experiments to demonstrate its capability of strike point sweeping on the plate at a frequency range from 10 to 100 Hz by using an oscillating magnetic field. A strike point movement of 5\u20136 cm is achieved by applying a coil current of several percent of plasma current, leading to a significant reduction of divertor surface temperature. The result indicates a possible application in a fusion reactor.",
  "A strike point movement of 5\u20136 cm is achieved by applying a coil current of several percent of plasma current, leading to a significant reduction of divertor surface temperature. The result indicates a possible application in a fusion reactor.\nAuthors: Yang Zhang, Xiaodong Zhang, Q. Qiu, Jian Zhang, B. Li, Lei Chen, Zheng-ping Luo, J. Qian, Liang Wang, Haiqing Liu, L. Meng, Xianghang Liu, Bin Zhang, B. Shen, Q. Yuan, B. Xiao, X. Gong, G. Xu, Jiansheng Hu, K. Lu, Xin Wu, Yuntao Song\nVenue: Nuclear Fusion\nTldr: None\nUrl: https://iopscience.iop.org/article/10.1088/1741-4326/acd865/pdf",
  "Faculty Name: eric xing\nPaperid: 48d3d400d7aced1caf1dcace33f37b8df50735f7\nTitle: Special issue on wearable robots and intelligent device\nYear: 2023\nAbstract: None\nAuthors: Xin Wu, S. Bai, L. O\u2019Sullivan\nVenue: Biomimetic Intelligence and Robotics\nTldr: None\nUrl: N/A",
  "Faculty Name: eric xing\nPaperid: 53a8712c48ddcd2bf1af30f9235f42b372f66980\nTitle: The response linearity of energy measurement up to TeV in the DAMPE experiment\nYear: 2023\nAbstract: The DArk Matter Particle Explorer (DAMPE) space mission is designed to measure cosmic rays and gamma rays. The key sub-detector of DAMPE is the Bismuth Germanium Oxide (BGO) Electromagnetic CALorimeter (ECAL), which measures the energies of electrons/gamma-rays ranging from 5 GeV - 10 TeV. A laser test carried out to study the response of the BGO ECAL to up to \u223c TeV energy deposition revealed that the BGO \ufb02uorescence response retains linearity at laser energy deposition densities higher than that induced by a \u223c 10 TeV electromagnetic shower. The energy measurements obtained from on-orbit data were also compared with Monte Carlo simulation results. The present study con\ufb01rms that there is no \ufb02uorescence quenching e\ufb00ect in the DAMPE BGO ECAL.",
  "The energy measurements obtained from on-orbit data were also compared with Monte Carlo simulation results. The present study con\ufb01rms that there is no \ufb02uorescence quenching e\ufb00ect in the DAMPE BGO ECAL.\nAuthors: Cong-Ying Zhao, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, Francesco de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, J. Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco,",
  "G. Donvito, D. Droz, J. Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, L. Jiang, Weizhong Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X.",
  "F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, H. Su, Meng Su, H. Sun, Zhigang Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zizhong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang,",
  "Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zizhong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Hongying Zhao, Xu Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: None\nUrl: https://pos.sissa.it/444/163/pdf",
  "Faculty Name: eric xing\nPaperid: 5c577988ccebfea96de86678d04fd94fad367d2e\nTitle: Jais and Jais-chat: Arabic-Centric Foundation and Instruction-Tuned Open Generative Large Language Models\nYear: 2023\nAbstract: We introduce Jais and Jais-chat, new state-of-the-art Arabic-centric foundation and instruction-tuned open generative large language models (LLMs). The models are based on the GPT-3 decoder-only architecture and are pretrained on a mixture of Arabic and English texts, including source code in various programming languages. With 13 billion parameters, they demonstrate better knowledge and reasoning capabilities in Arabic than any existing open Arabic and multilingual models by a sizable margin, based on extensive evaluation. Moreover, the models are competitive in English compared to English-centric open models of similar size, despite being trained on much less English data. We provide a detailed description of the training, the tuning, the safety alignment, and the evaluation of the models. We release two open versions of the model -- the foundation Jais model, and an instruction-tuned Jais-chat variant -- with the aim of promoting research on Arabic LLMs.",
  "We provide a detailed description of the training, the tuning, the safety alignment, and the evaluation of the models. We release two open versions of the model -- the foundation Jais model, and an instruction-tuned Jais-chat variant -- with the aim of promoting research on Arabic LLMs. Available at https://huggingface.co/inception-mbzuai/jais-13b-chat\nAuthors: Neha Sengupta, Sunil Kumar Sahu, Bokang Jia, Satheesh Katipomu, Haonan Li, Fajri Koto, Osama Mohammed Afzal, Samta Kamboj, O. Pandit, Rahul Pal, Lalit Pradhan, Zainul Mujahid, Massa Baali, Xudong Han, Alham Fikri Aji, Zhengzhong Liu, Andy Hock, Andrew Feldman, Jonathan Lee, A. Jackson, Preslav Nakov, Timothy Baldwin, Eric P. Xing\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Jais and Jais-chat are introduced, new state-of-the-art Arabic-centric foundation and instruction-tuned open generative large language models (LLMs) based on the GPT-3 decoder-only architecture that demonstrate better knowledge and reasoning capabilities in Arabic than any existing open Arabic and multilingual models by a sizable margin.'}",
  "Url: https://arxiv.org/pdf/2308.16149",
  "Faculty Name: eric xing\nPaperid: 5d17963ceb279be116e7a1207542ea94f1b2a8c8\nTitle: Contextualized Policy Recovery: Modeling and Interpreting Medical Decisions with Adaptive Imitation Learning\nYear: 2023\nAbstract: Interpretable policy learning seeks to estimate intelligible decision policies from observed actions; however, existing models fall short by forcing a tradeoff between accuracy and interpretability. This tradeoff limits data-driven interpretations of human decision-making process. e.g. to audit medical decisions for biases and suboptimal practices, we require models of decision processes which provide concise descriptions of complex behaviors. Fundamentally, existing approaches are burdened by this tradeoff because they represent the underlying decision process as a universal policy, when in fact human decisions are dynamic and can change drastically with contextual information. Thus, we propose Contextualized Policy Recovery (CPR), which re-frames the problem of modeling complex decision processes as a multi-task learning problem in which complex decision policies are comprised of context-specific policies.",
  "Thus, we propose Contextualized Policy Recovery (CPR), which re-frames the problem of modeling complex decision processes as a multi-task learning problem in which complex decision policies are comprised of context-specific policies. CPR models each context-specific policy as a linear observation-to-action mapping, and generates new decision models $\\textit{on-demand}$ as contexts are updated with new observations. CPR is compatible with fully offline and partially observable decision environments, and can be tailored to incorporate any recurrent black-box model or interpretable decision model. We assess CPR through studies on simulated and real data, achieving state-of-the-art performance on the canonical tasks of predicting antibiotic prescription in intensive care units ($+22\\%$ AUROC vs. previous SOTA) and predicting MRI prescription for Alzheimer's patients ($+7.7\\%$ AUROC vs. previous SOTA). With this improvement in predictive performance, CPR closes the accuracy gap between interpretable and black-box methods for policy learning, allowing high-resolution exploration and analysis of context-specific decision models.",
  "previous SOTA). With this improvement in predictive performance, CPR closes the accuracy gap between interpretable and black-box methods for policy learning, allowing high-resolution exploration and analysis of context-specific decision models.\nAuthors: J. Deuschel, Caleb N. Ellington, Benjamin J. Lengerich, Yingtao Luo, Pascal Friederich, Eric P. Xing\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Contextualized Policy Recovery is proposed, which re-frames the problem of modeling complex decision processes as a multi-task learning problem in which complex decision policies are comprised of context-specific policies, and closes the accuracy gap between interpretable and black-box methods for policy learning.'}\nUrl: https://arxiv.org/pdf/2310.07918",
  "Faculty Name: eric xing\nPaperid: 5db910c3ccf8a8b2cbea22d65cc56268c57a64df\nTitle: Characterization of Asphaltene Deposition Behavior in Diluted Heavy Oil under High-Pressure Conditions\nYear: 2023\nAbstract: Some oil wells in the Tahe oilfield have been reported to produce extremely heavy oil due to asphaltene deposition. To enhance the flow of crude oil through the wellbore, engineers adopted the use of light oil from nearby wells to dissolve the heavy crude in the wells\u2019 sections to maximize recovery from the Tahe oilfield. However, this mixing has led to the problem of accelerated asphaltene deposition, which often blocks the wellbore in the process. In this research, the factors that influence the stability of diluted heavy oil, temperature, and mixing ratio on asphaltene deposition characteristics under high pressure are studied using a high-temperature and high-pressure crude oil flow property experimental device based on the differential pressure method. The results under high pressure show that the initial deposition pressure of asphaltene decreases as the experimental temperature increases.",
  "The results under high pressure show that the initial deposition pressure of asphaltene decreases as the experimental temperature increases. With an increase in the mixing light oil ratio, the initial deposition pressure of diluted heavy oil increases, and the deposition trend of asphaltene strengthens. The asphaltene accumulation and deposition will be aggravated by filling quartz sand and pipe diameter changes. The research here is helpful to understand the deposition characteristics of asphaltene during the production of diluted heavy oil. It offers significant guidance in the prevention and control of asphaltene precipitation in heavy oil wells.\nAuthors: Zuguo Yang, Xin Wu, Jixiang Guo, Jianjun Zhang, R. Xiong, Lei Liu, Wyclif Kiyingi\nVenue: Energies\nTldr: None\nUrl: https://www.mdpi.com/1996-1073/16/19/6780/pdf?version=1695454292",
  "Faculty Name: eric xing\nPaperid: 5e424004958853f4e366e7a86a1c3a56a76cb2a4\nTitle: LightSeq: Sequence Level Parallelism for Distributed Training of Long Context Transformers\nYear: 2023\nAbstract: Increasing the context length of large language models (LLMs) unlocks fundamentally new capabilities, but also significantly increases the memory footprints of training. Previous model-parallel systems such as Megatron-LM partition and compute different attention heads in parallel, resulting in large communication volumes, so they cannot scale beyond the number of attention heads, thereby hindering its adoption. In this paper, we introduce a new approach, LightSeq, for long-context LLMs training. LightSeq has many notable advantages. First, LightSeq partitions over the sequence dimension, hence is agnostic to model architectures and readily applicable for models with varying numbers of attention heads, such as Multi-Head, Multi-Query and Grouped-Query attention. Second, LightSeq not only requires up to 4.7x less communication than Megatron-LM on popular LLMs but also overlaps the communication with computation.",
  "Second, LightSeq not only requires up to 4.7x less communication than Megatron-LM on popular LLMs but also overlaps the communication with computation. To further reduce the training time, LightSeq features a novel gradient checkpointing scheme to bypass an forward computation for memory-efficient attention. We evaluate LightSeq on Llama-7B and its variants with sequence lengths from 32K to 512K. Through comprehensive experiments on single and cross-node training, we show that LightSeq achieves up to 1.24-2.01x end-to-end speedup, and a 2-8x longer sequence length on models with fewer heads, compared to Megatron-LM. Codes will be available at https://github.com/RulinShao/LightSeq.",
  "Codes will be available at https://github.com/RulinShao/LightSeq.\nAuthors: Dacheng Li, Rulin Shao, Anze Xie, Eric P. Xing, Joseph E. Gonzalez, Ion Stoica, Xuezhe Ma, Hao Zhang\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A new approach, LightSeq, is introduced for long-context LLMs training that partitions over the sequence dimension, hence is agnostic to model architectures and readily applicable for models with varying numbers of attention heads, such as Multi-Head, Multi-Query and Grouped-Query attention.'}\nUrl: https://arxiv.org/pdf/2310.03294",
  "Faculty Name: eric xing\nPaperid: 5eceb4d435f1eb86d9b211ffc1f76c87f79aa2c8\nTitle: Practical Probabilistic Model-based Deep Reinforcement Learning by Integrating Dropout Uncertainty and Trajectory Sampling\nYear: 2023\nAbstract: This paper addresses the prediction stability, prediction accuracy and control capability of the current probabilistic model-based reinforcement learning (MBRL) built on neural networks. A novel approach dropout-based probabilistic ensembles with trajectory sampling (DPETS) is proposed where the system uncertainty is stably predicted by combining the Monte-Carlo dropout and trajectory sampling in one framework. Its loss function is designed to correct the fitting error of neural networks for more accurate prediction of probabilistic models. The state propagation in its policy is extended to filter the aleatoric uncertainty for superior control capability. Evaluated by several Mujoco benchmark control tasks under additional disturbances and one practical robot arm manipulation task, DPETS outperforms related MBRL approaches in both average return and convergence velocity while achieving superior performance than well-known model-free baselines with significant sample efficiency.",
  "Evaluated by several Mujoco benchmark control tasks under additional disturbances and one practical robot arm manipulation task, DPETS outperforms related MBRL approaches in both average return and convergence velocity while achieving superior performance than well-known model-free baselines with significant sample efficiency. The open source code of DPETS is available at https://github.com/mrjun123/DPETS.\nAuthors: Wenjun Huang, Yunduan Cui, Huiyun Li, Xin Wu\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Evaluated by several Mujoco benchmark control tasks under additional disturbances and one practical robot arm manipulation task, DPETS outperforms related MBRL approaches in both average return and convergence velocity while achieving superior performance than well-known model-free baselines with significant sample efficiency.'}\nUrl: https://arxiv.org/pdf/2309.11089",
  "Faculty Name: eric xing\nPaperid: 5ee7569f3be298494afd613f0d81add43b262e1d\nTitle: Realization of thousand-second improved confinement plasma with Super I-mode in Tokamak EAST\nYear: 2023\nAbstract: Mastering nuclear fusion, which is an abundant, safe, and environmentally competitive energy, is a great challenge for humanity. Tokamak represents one of the most promising paths toward controlled fusion. Obtaining a high-performance, steady-state, and long-pulse plasma regime remains a critical issue. Recently, a big breakthrough in steady-state operation was made on the Experimental Advanced Superconducting Tokamak (EAST). A steady-state plasma with a world-record pulse length of 1056 s was obtained, where the density and the divertor peak heat flux were well controlled, with no core impurity accumulation, and a new high-confinement and self-organizing regime (Super I-mode = I-mode + e-ITB) was discovered and demonstrated. These achievements contribute to the integration of fusion plasma technology and physics, which is essential to operate next-step devices.\nAuthors: Yuntao Song, X. Zou,",
  "These achievements contribute to the integration of fusion plasma technology and physics, which is essential to operate next-step devices.\nAuthors: Yuntao Song, X. Zou, X. Gong, A. Becoulet, R. Buttery, P. Bonoli, T. Hoang, R. Maingi, J. Qian, X. Zhong, A. Liu, E. Li, R. Ding, Juan Huang, Q. Zang, Haiqing Liu, Liang Wang, Ling Zhang, Guoqiang Li, Youwen Sun, A. Garofalo, T. Osborne, T. Leonard, S. Baek, G. Wallace, Liqing Xu, Bin Zhang, Shouxin Wang, Y. Chu, Tao Zhang, Y. Duan, Hui Lian, Xuexi Zhang, Yifei Jin, L. Zeng, B. Lyu, Binjia Xiao, Yao Huang, Yong Wang, B. Shen, N. Xiang, Yu Wu, Jiefeng Wu, Xiaojie Wang, B. Ding, Miaohui Li, Xinjun Zhang, C. Qin, Weibin Xi, Jian Zhang, Liansheng Huang, D. Yao,",
  "Yao Huang, Yong Wang, B. Shen, N. Xiang, Yu Wu, Jiefeng Wu, Xiaojie Wang, B. Ding, Miaohui Li, Xinjun Zhang, C. Qin, Weibin Xi, Jian Zhang, Liansheng Huang, D. Yao, Yanlan Hu, G. Zuo, Q. Yuan, Zhiwei Zhou, Mao Wang, Handong Xu, Yahong Xie, Zhengchu Wang, Junling Chen, Guosheng Xu, Jiansheng Hu, K. Lu, Fukun Liu, Xin Wu, B. Wan, Jiangang Li\nVenue: Science Advances\nTldr: None\nUrl: https://www.science.org/doi/pdf/10.1126/sciadv.abq5273?download=true",
  "Faculty Name: eric xing\nPaperid: 600c75049c0c8b9767f388664bd38ad9b4fa1549\nTitle: A new anti-colon cancer tumor pathway of Phenyllactic acid by reducing adhesion of Fusobacterium nucleatum\nYear: 2023\nAbstract: None\nAuthors: Xin Wu, Jinzhao Xu, Danping Wang, Xiaoying Yang, Xiaoxi Xu\nVenue: Food Science and Technology\nTldr: None\nUrl: https://www.scielo.br/j/cta/a/3Pv8FnVcpdWf8mK6CYFHDcw/?lang=en&format=pdf",
  "Faculty Name: eric xing\nPaperid: 640e1bcc472a71d36c6b9261403b60c680d93917\nTitle: GET: a foundation model of transcription across human cell types\nYear: 2023\nAbstract: Transcriptional regulation, involving the complex interplay between regulatory sequences and proteins, directs all biological processes. Computational models of transcriptions lack generalizability to accurately extrapolate in unseen cell types and conditions. Here, we introduce GET, an interpretable foundation model, designed to uncover regulatory grammars across 213 human fetal and adult cell types. Relying exclusively on chromatin accessibility data and sequence information, GET achieves experimental-level accuracy in predicting gene expression even in previously unseen cell types. GET showcases remarkable adaptability across new sequencing platforms and assays, enabling regulatory inference across a broad range of cell types and conditions, and uncovering universal and cell type specific transcription factor interaction networks. We evaluated its performance on prediction of regulatory activity, inference of regulatory elements and regulators, and identification of physical interactions between transcription factors. Specifically, we show GET outperforms current models in predicting lentivirus-based massive parallel reporter assay readout with reduced input data.",
  "We evaluated its performance on prediction of regulatory activity, inference of regulatory elements and regulators, and identification of physical interactions between transcription factors. Specifically, we show GET outperforms current models in predicting lentivirus-based massive parallel reporter assay readout with reduced input data. In Fetal erythroblast, we identify distal (>1Mbp) regulatory regions that were missed by previous models. In B cell, we identified a lymphocyte-specific transcription factor-transcription factor interaction that explains the functional significance of a lymphoma-risk predisposing germline mutation. In sum, we provide a generalizable and accurate model for transcription together with catalogs of gene regulation and transcription factor interactions, all with cell type specificity.",
  "In B cell, we identified a lymphocyte-specific transcription factor-transcription factor interaction that explains the functional significance of a lymphoma-risk predisposing germline mutation. In sum, we provide a generalizable and accurate model for transcription together with catalogs of gene regulation and transcription factor interactions, all with cell type specificity.\nAuthors: Xi Fu, Shentong Mo, Anqi Shao, Anouchka P. Laurent, Alejandro Buendia, Adolfo A. Ferrando, Alberto Ciccia, Yanyan Lan, Teresa Palomero, David M. Owens, Eric P. Xing, Ra\u00fal Rabad\u00e1n\nVenue: bioRxiv\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work introduces GET, an interpretable foundation model, designed to uncover regulatory grammars across 213 human fetal and adult cell types, and provides a generalizable and accurate model for transcription together with catalogs of gene regulation and transcription factor interactions, all with cell type specificity.'}\nUrl: https://www.biorxiv.org/content/biorxiv/early/2023/09/24/2023.09.24.559168.full.pdf",
  "Faculty Name: eric xing\nPaperid: 64b802537c34bc000be7c04652753c1c38d60dbc\nTitle: Poverty Alleviation Resettlement and Household Natural Resources Dependence: A Case Study from Ankang Prefecture, China\nYear: 2023\nAbstract: In order to assess the degree to which China\u2019s poverty alleviation resettlement (PAR) has been able to address the development conundrum of natural resources reliance and human welfare, it was necessary to investigate the effects of PAR on rural households with regard to their dependence on natural resources. This article evaluated households\u2019 natural resources dependence in rural China by constructing a natural resources dependence index and empirically analyzing the effect of PAR on households by using household survey data from Ankang Prefecture, located in southern Shaanxi Province. The findings demonstrated that PAR could effectively decrease the dependence of households on local natural resources, thus safeguarding the natural environment. Moreover, there were noteworthy distinctions regarding households\u2019 natural resources dependence.",
  "The findings demonstrated that PAR could effectively decrease the dependence of households on local natural resources, thus safeguarding the natural environment. Moreover, there were noteworthy distinctions regarding households\u2019 natural resources dependence. This research endeavored to complete the fusion of natural resource dependence and PAR at the household level, and then contemplated the policy implications of PAR on rural households\u2019 dependence on resources, furnishing fresh information for future evaluations of nature conservation and development policies.\nAuthors: Wei Liu, Xin Wu\nVenue: Agriculture\nTldr: None\nUrl: https://www.mdpi.com/2077-0472/13/5/1034/pdf?version=1683710339",
  "Faculty Name: eric xing\nPaperid: 66ec74cffac0cc70bdb07a1677cb7915d79fe1f7\nTitle: A study of Forbush Decreases effects with DAMPE experiment\nYear: 2023\nAbstract: Forbush Decrease (FD) is a rapid decrease and slow recover in the observed galactic cosmic ray intensity, caused by active solar events sweeping low energy galactic cosmic rays (GCRs) away from Earth. Differnet properties of FDs have been observed by different scientific experiment but mostly from worldwide ground based Neutron Monitors (NMS), they focus on secondary neutron from the atmosphere. The Dark Matter Particle Explorer (DAMPE) is a satellite-based cosmic-ray experiment that has been stably operated for more than 7 years. Precise measurements of cosmic ray electrons and positrons from DAMPE make it possible to directly study FDs from a new perspective. We analyze the FD properties, such as decrease amplitude and recover time as a function of energy, observed by DAMPE from 2017 to 2021. Finally we simulate the FDs with a numerical model, and successfully reproduce the FDs.",
  "We analyze the FD properties, such as decrease amplitude and recover time as a function of energy, observed by DAMPE from 2017 to 2021. Finally we simulate the FDs with a numerical model, and successfully reproduce the FDs. The preliminary result shows that the head-on events causes energy related recover time, while edge-on events causes energy unrelated recover time of FDs.\nAuthors: WenHsiung Li, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, Xiaomei Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, Francesco de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang,",
  "Francesco de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, Piergiorgio Fusco, M. Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guangshun Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, Lulu Jiang, Wei Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N.",
  "X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, Hong-mei Su, Meng Su, H. Sun, Zhiyu Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Yuanzhu Wang, D. Wei, J. Wei, Yifeng Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu,",
  "J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Yuanzhu Wang, D. Wei, J. Wei, Yifeng Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zizhong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hongying Zhao, Xun Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: None\nUrl: https://pos.sissa.it/444/1311/pdf",
  "Faculty Name: eric xing\nPaperid: 6721244fad7f4790272be86e8b165fccd69578ab\nTitle: KD-DLGAN: Data Limited Image Generation via Knowledge Distillation\nYear: 2023\nAbstract: Generative Adversarial Networks (GANs) rely heavily on large-scale training data for training high-quality image generation models. With limited training data, the GAN discriminator often suffers from severe overfitting which directly leads to degraded generation especially in generation diversity. Inspired by the recent advances in knowledge distillation (KD), we propose KD-DLGAN, a knowledge-distillation based generation framework that introduces pre-trained vision-language models for training effective data-limited generation models. KD-DLGAN consists of two innovative designs. The first is aggregated generative KD that mitigates the discriminator overfitting by challenging the discriminator with harder learning tasks and distilling more generalizable knowledge from the pre-trained models. The second is correlated generative KD that improves the generation diversity by distilling and preserving the diverse image-text correlation within the pre-trained models. Extensive experiments over multiple benchmarks show that KD-DLGAN achieves superior image generation with limited training data.",
  "The second is correlated generative KD that improves the generation diversity by distilling and preserving the diverse image-text correlation within the pre-trained models. Extensive experiments over multiple benchmarks show that KD-DLGAN achieves superior image generation with limited training data. In addition, KD-DLGAN complements the state-of-the-art with consistent and substantial performance gains. Note that codes will be released.\nAuthors: Kaiwen Cui, Yingchen Yu, Fangneng Zhan, Shengcai Liao, Shijian Lu1, Eric P. Xing\nVenue: Computer Vision and Pattern Recognition\nTldr: {'model': 'tldr@v2.0.0', 'text': 'KD-DLGAN is proposed, a knowledge-distillation based generation framework that introduces pre-trained vision-language models for training effective data-limited generation models and achieves superior image generation with limited training data.'}\nUrl: https://arxiv.org/pdf/2303.17158",
  "Faculty Name: eric xing\nPaperid: 7124f495399759ce089e6637dc48e073e9d168aa\nTitle: 3D Semantic Segmentation in the Wild: Learning Generalized Models for Adverse-Condition Point Clouds\nYear: 2023\nAbstract: Robust point cloud parsing under all-weather conditions is crucial to level-5 autonomy in autonomous driving. However, how to learn a universal 3D semantic segmentation (3DSS) model is largely neglected as most existing benchmarks are dominated by point clouds captured under normal weather. We introduce SemanticSTF, an adverse-weather point cloud dataset that provides dense point-level annotations and allows to study 3DSS under various adverse weather conditions. We study all-weather 3DSS modeling under two setups: 1) domain adaptive 3DSS that adapts from normal-weather data to adverse-weather data; 2) domain generalizable 3DSS that learns all-weather 3DSS models from normal-weather data.",
  "We study all-weather 3DSS modeling under two setups: 1) domain adaptive 3DSS that adapts from normal-weather data to adverse-weather data; 2) domain generalizable 3DSS that learns all-weather 3DSS models from normal-weather data. Our studies reveal the challenge while existing 3DSS methods encounter adverse-weather data, showing the great value of SemanticSTF in steering the future endeavor along this very meaningful research direction. In addition, we design a domain randomization technique that alternatively randomizes the geometry styles of point clouds and aggregates their embeddings, ultimately leading to a generalizable model that can improve 3DSS under various adverse weather effectively. The SemanticSTF and related codes are available at https://github.com/xiaoaoran/SemanticSTF.",
  "The SemanticSTF and related codes are available at https://github.com/xiaoaoran/SemanticSTF.\nAuthors: Aoran Xiao, Jiaxing Huang, Weihao Xuan, Ruijie Ren, Kangcheng Liu, Dayan Guan, A. E. Saddik, Shijian Lu, Eric P. Xing\nVenue: Computer Vision and Pattern Recognition\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work introduces SemanticSTF, an adverse-weather point cloud dataset that provides dense point-level annotations and allows to study 3DSS under various adverse weather conditions, and designs a domain randomization technique that alternatively randomizes the geometry styles of point clouds and aggregates their embeddings, ultimately leading to a generalizable model that can improve 3D semantic segmentation underVarious adverse weather effectively.'}\nUrl: https://arxiv.org/pdf/2304.00690",
  "Faculty Name: eric xing\nPaperid: 719cff0d9a4cfcafb7507b7f301838655f3f3dbf\nTitle: Direct measurement of Ne-Mg-Si nuclei in cosmic rays with DAMPE\nYear: 2023\nAbstract: A precise measurement of the cosmic-ray spectra provides important information on their origin, acceleration and propagation processes in the Galaxy. The Dark Matter Particle Explorer (DAMPE) is a satellite-based cosmic-ray experiment that has been operational for more than 7 years. Since its launch in December 2015, it is continuously collecting data on high-energy cosmic particles with very good statistics and particle identification capabilities, thanks to a large geometric factor and a good charge resolution. In this contribution, the direct measurement of the intermediate mass cosmic rays is presented, in particular the observation of the cosmic-ray Ne, Mg and Si nuclei, which are thought to be mainly produced and accelerated in astrophysical sources.\nAuthors: E. Casilli, Francesco Alemanno, Q. An, P. Azzarello, F. Barbato, X. Bi, I. Cagnoli, M. Cai, E. Catanzani, Jin Chang,",
  "Authors: E. Casilli, Francesco Alemanno, Q. An, P. Azzarello, F. Barbato, X. Bi, I. Cagnoli, M. Cai, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, J. Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, C. Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco, M. Gao, F. Gargano, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, L. Jiang, Wei Jiang, Y. Jiang, J. Kong, A. Kotenko,",
  "Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, L. Jiang, Wei Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, Hong-mei Su, Meng Su, H. Sun, Zhigang Sun,",
  "J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, Hong-mei Su, Meng Su, H. Sun, Zhigang Sun, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hongying Zhao, Xu Zhao, C. Zhou,",
  "C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hongying Zhao, Xu Zhao, C. Zhou, Yanzi Zhu, C. Altomare, P. Bernardini, F. de Palma, Essna Ghose, A. Surdo\nVenue: International Conference on Rebooting Computing\nTldr: None\nUrl: https://pos.sissa.it/444/115/pdf",
  "Faculty Name: eric xing\nPaperid: 747c188af4df6c33421078ddfa450b648a9cbfc6\nTitle: Probing hadronic cross sections in the TeV - PeV regime with DAMPE through machine learning techniques\nYear: 2023\nAbstract: Thanks to its large calorimeter\nAuthors: P. Coppin, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, F. de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng,",
  "M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, Luyang Jiang, Wei Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, Tao Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu,",
  "Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, Tao Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, H. Su, Meng Su, H. Sun, Zhigang Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yinong Wei, Di Wu, Jian Wu, Li Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zijun Xu, Zunlei Xu,",
  "Ying Wang, Y. Wang, D. Wei, J. Wei, Yinong Wei, Di Wu, Jian Wu, Li Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zijun Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hong-yun Zhao, Xu Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: {'model': 'tldr@v2.0.0', 'text': None}\nUrl: https://pos.sissa.it/444/142/pdf",
  "Faculty Name: eric xing\nPaperid: 7ab88e8c5f6cbe53a653aa504574782b71fc2e5c\nTitle: Point-like Source Catalog Observed by DAMPE\nYear: 2023\nAbstract: The DArk Matter Particle Explorer (DAMPE) is a high-energy cosmic ray and gamma-ray detector located in space. Over a period of seven years since its launch on December 17, 2015, DAMPE has surveyed the entire sky and collected an extensive dataset of more than 300,000 photons with energies above 2 GeV. To analyze the gamma-ray data obtained by DAMPE, instrument response functions (IRFs) have been derived, and a specialized software called DmpST has been developed. In this context, we present the results of the DAMPE gamma-ray point-like source catalog. This catalog provides valuable information about the detected gamma-ray sources, which includes details such as the positions, energy spectra, and flux measurements of these point-like gamma-ray sources. By studying these sources, scientists can gain insights into various astrophysical phenomena, including the emission processes and distribution of gamma-ray sources in the universe.\nAuthors: K.",
  "By studying these sources, scientists can gain insights into various astrophysical phenomena, including the emission processes and distribution of gamma-ray sources in the universe.\nAuthors: K. Duan, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Y. Cui, I. De Mitri, Francesco de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D.",
  "Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guangshun Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, Lujie Jiang, Yao Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Z.",
  "M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, H. Su, Meng Su, Hao-Lun Sun, Zhigang Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Yuanzhu Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, Li Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J.",
  "Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Ya Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hong-yun Zhao, Xu Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: None\nUrl: https://pos.sissa.it/444/669/pdf",
  "Faculty Name: eric xing\nPaperid: 815ba42bacfe231664de6c4ab1f46b6c54bd1950\nTitle: DArk Matter Particle Explorer: 7 years in Space\nYear: 2023\nAbstract: The DArk Matter Particle Explorer (DAMPE) is a pioneering calorimetric experiment that has been successfully operating in space since December 2015, designed to detect cosmic rays up to unprecedentedly high energies thanks to the fine-grained thick BGO calorimeter and relatively large geometric factor. Among the scientific goals of DAMPE are the precise measurements of cosmic-ray electron plus positron spectrum, including the detection of possible indirect dark matter signatures, spectral measurements of primary and secondary cosmic-ray species, and gamma-ray physics. For electrons and gamma rays, it covers an energy range from GeV to about 10 TeV, with an outstanding energy resolution close to 1%. Proton and ion cosmic rays can be measured up to hundreds of TeV in kinetic energy. In this contribution, we first give an overview of the DAMPE mission and its on-orbit operation status.",
  "Proton and ion cosmic rays can be measured up to hundreds of TeV in kinetic energy. In this contribution, we first give an overview of the DAMPE mission and its on-orbit operation status. Then, we highlight the key scientific results, including the measurements of the BCNO group, boron-to-carbon ratio, proton plus helium spectrum beyond 100 TeV, gamma-ray physics and more. Finally, the ongoing efforts for lepton, light, and heavy hadron cosmic rays are briefly discussed along with the new data analysis techniques.\nAuthors: A. Tykhonov, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, Paolo Bernardini, Xiao-Jun Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Zi-Yuan Chen, P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, Francesco de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G.",
  "Zi-Yuan Chen, P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, Francesco de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, Piergiorgio Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, L. Jiang, Wei Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, Wei Liang Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F.",
  "Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, Wei Liang Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, Pengxiong Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, Xiaozhong Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Shangguan Zhi, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, Hong-mei Su, Meng Su, Hao-Lun Sun, Zhigang Sun, A. Surdo, X. Teng, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei,",
  "Hong-mei Su, Meng Su, Hao-Lun Sun, Zhigang Sun, A. Surdo, X. Teng, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zizhong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Ya Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hongying Zhao, Xu Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: None\nUrl: https://pos.sissa.it/444/003/pdf",
  "Faculty Name: eric xing\nPaperid: 82aefa38673ab37a5c8c2d4931ad623651941be7\nTitle: Observational signatures of Schwarzschild-MOG black holes in scalar\u2013tensor\u2013vector gravity: images of the accretion disk\nYear: 2023\nAbstract: None\nAuthors: Shiyang Hu, Chen Deng, Sen Guo, Xin Wu, Enwei Liang\nVenue: The European Physical Journal C\nTldr: None\nUrl: https://link.springer.com/content/pdf/10.1140/epjc/s10052-023-11411-3.pdf",
  "Faculty Name: eric xing\nPaperid: 83aa9762c0fa099e6f893bb895e287a18b482d7e\nTitle: Evaluating emotional labor from a career management perspective\nYear: 2023\nAbstract: Emotional labor claims its significance as the key indicator both of the psychological health of contemporary employees, and the productivity of service-based businesses depending upon genuine emotional input of employees. By far, research on emotional labor of employees in an organizational context is still lacking. This study aims to explore the relationships among emotional labor, organizational support, career competences and career commitment to investigate how emotional labor interacts with the organizational context and affects the career management of the employee. Data were collected from a sample of 387 frontline employees working at two luxury hotel brands in China. Structural equation modeling (SEM) was utilized to estimate the relationships among the constructs. It is demonstrated by the findings that organizational support mediates positively on emotional labor, which exerts positive influences on career competences and career commitment. Sound handling of emotional labor, boosted by a supportive organizational environment, has been ascertained to positively predict long-term career paths of the employees at the company.",
  "It is demonstrated by the findings that organizational support mediates positively on emotional labor, which exerts positive influences on career competences and career commitment. Sound handling of emotional labor, boosted by a supportive organizational environment, has been ascertained to positively predict long-term career paths of the employees at the company. This study provides insights into how the tourism and hospitality industry can optimize the functions of emotional labor for in enhancing service quality and customer satisfaction, as well as promoting the psychological well-being of the employees.\nAuthors: Yunhong Hu, Wei Tu, Li Zhou, Xin Wu, Qi Yan\nVenue: Frontiers in Psychology\nTldr: None\nUrl: https://www.frontiersin.org/articles/10.3389/fpsyg.2022.1093723/pdf",
  "Faculty Name: eric xing\nPaperid: 83cf0caccd1d55c7af171604eca38c85e379a1cf\nTitle: Penetrating particle ANalyzer (PAN)\nYear: 2023\nAbstract: The Penetrating particle Analyzer (PAN) is a compact magnetic spectrometer with relatively low power budget allowing it to be used in deep space and interplanetary missions for cosmic rays, solar physics and space weather studies. It can precisely measure and monitor the flux, composition, and direction of highly penetrating particles in the range between 100 MeV/n and 10 GeV/n. The device consists of permanent magnet sections, silicon strip detectors, scintillating detectors and silicon pixel detectors. At the current stage of the R&D, the first smaller prototype, called Mini.PAN, was built. Mini.PAN is designed to demonstrate the capabilities and performance of the instrument concept.",
  "The device consists of permanent magnet sections, silicon strip detectors, scintillating detectors and silicon pixel detectors. At the current stage of the R&D, the first smaller prototype, called Mini.PAN, was built. Mini.PAN is designed to demonstrate the capabilities and performance of the instrument concept. The key component of Mini.PAN is the fine-pitched and thin\nAuthors: D. Sukhonos, G. Ambrosi, P. Azzarello, M. Barbanera, Benedikt Bergmann, P. Burian, F. Cadoux, Y. Favre, J. Hulsman, D. Marra, T. Iizawa, M. Ionica, Eduardo Mancini, L. Nicola, M. Paniccia, G. Silvestre, P. Smolyanskiy, Jerry Stauffer, Adrien Stil, P. Thonet, P. Xie, Xin Wu\nVenue: International Conference on Rebooting Computing\nTldr: None\nUrl: https://pos.sissa.it/444/045/pdf",
  "Faculty Name: eric xing\nPaperid: 84a36e19f9394f22b34f79756fa9628a795e02ea\nTitle: LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset\nYear: 2023\nAbstract: Studying how people interact with large language models (LLMs) in real-world scenarios is increasingly important due to their widespread use in various applications. In this paper, we introduce LMSYS-Chat-1M, a large-scale dataset containing one million real-world conversations with 25 state-of-the-art LLMs. This dataset is collected from 210K unique IP addresses in the wild on our Vicuna demo and Chatbot Arena website. We offer an overview of the dataset's content, including its curation process, basic statistics, and topic distribution, highlighting its diversity, originality, and scale. We demonstrate its versatility through four use cases: developing content moderation models that perform similarly to GPT-4, building a safety benchmark, training instruction-following models that perform similarly to Vicuna, and creating challenging benchmark questions.",
  "We demonstrate its versatility through four use cases: developing content moderation models that perform similarly to GPT-4, building a safety benchmark, training instruction-following models that perform similarly to Vicuna, and creating challenging benchmark questions. We believe that this dataset will serve as a valuable resource for understanding and advancing LLM capabilities. The dataset is publicly available at https://huggingface.co/datasets/lmsys/lmsys-chat-1m.",
  "We believe that this dataset will serve as a valuable resource for understanding and advancing LLM capabilities. The dataset is publicly available at https://huggingface.co/datasets/lmsys/lmsys-chat-1m.\nAuthors: Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Tianle Li, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zhuohan Li, Zi Lin, Eric P. Xing, Joseph E. Gonzalez, Ion Stoica, Haotong Zhang\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper introduces LMSYS-Chat-1M, a large-scale dataset containing one million real-world conversations with 25 state-of-the-art LLMs, and demonstrates its versatility through four use cases: developing content moderation models that perform similarly to GPT-4, building a safety benchmark, training instruction-following models that performs similarly to Vicuna, and creating challenging benchmark questions.'}\nUrl: https://arxiv.org/pdf/2309.11998",
  "Faculty Name: eric xing\nPaperid: 8a6ac6d5f8967f2112672a9274b541f515a7380f\nTitle: POLAR-2, the next generation of GRB polarization detector\nYear: 2023\nAbstract: The POLAR-2 Gamma-Ray Burst (GRB) Polarimetry mission is a follow-up to the successful POLAR mission. POLAR collected six months of data in 2016-2017 on board the Tiangong-2 Chinese Space laboratory. From a polarization study on 14 GRBs, POLAR measured an overall low polarization and a hint for an unexpected complexity in the time evolution of polarization during GRBs. Energy-dependent measurements of the GRB polarization will be presented by N. de Angelis in GA21-09 (August 2nd). These results demonstrate the need for measurements with significantly improved accuracy. Moreover, the recent discovery of gravitational waves and their connection to GRBs justifies a high-precision GRB polarimeter that can provide both high-precision polarimetry and detection of very faint GRBs.",
  "These results demonstrate the need for measurements with significantly improved accuracy. Moreover, the recent discovery of gravitational waves and their connection to GRBs justifies a high-precision GRB polarimeter that can provide both high-precision polarimetry and detection of very faint GRBs. The POLAR-2 polarimeter is based on the same Compton scattering measurement principle as POLAR, but with an extended energy range and an order of magnitude increase in total effective area for polarized events. Proposed and developed by a joint effort of Switzerland, China, Poland and Germany, the device was selected for installation on the China Space Station and is scheduled to start operation for at least 2 years in 2025.\nAuthors: Nicolas Produit, M. Kole, Xin Wu, Nicolas De Angelis, Hancheng Li, D. Rybka, A. Pollo, S. Mianowski, J. Greiner, J. Burgess, Jianchao Sun, Shuang-Nan Zhang\nVenue: International Conference on Rebooting Computing\nTldr: None\nUrl: https://pos.sissa.it/444/550/pdf",
  "Faculty Name: eric xing\nPaperid: 8cc1cd002bfc36a8cba8bcbe63d32eacc656097f\nTitle: StyleRF: Zero-Shot 3D Style Transfer of Neural Radiance Fields\nYear: 2023\nAbstract: 3D style transfer aims to render stylized novel views of a 3D scene with multiview consistency. However, most existing work suffers from a three-way dilemma over accurate geometry reconstruction, high-quality stylization, and being generalizable to arbitrary new styles. We propose StyleRF (Style Radiance Fields), an innovative 3D style transfer technique that resolves the three-way dilemma by performing style transformation within the feature space of a radiance field. StyleRF employs an explicit grid of high-level features to represent 3D scenes, with which highfidelity geometry can be reliably restored via volume rendering. In addition, it transforms the grid features according to the reference style which directly leads to high-quality zero-shot style transfer. StyleRF consists of two innovative designs. The first is sampling-invariant content transformation that makes the transformation invariant to the holistic statistics of the sampled 3D points and accordingly ensures multi-view consistency.",
  "StyleRF consists of two innovative designs. The first is sampling-invariant content transformation that makes the transformation invariant to the holistic statistics of the sampled 3D points and accordingly ensures multi-view consistency. The second is deferred style transformation of 2D feature maps which is equivalent to the transformation of 3D points but greatly reduces memory footprint without degrading multi-view consistency. Extensive experiments show that StyleRF achieves superior 3D stylization quality with precise geometry reconstruction and it can generalize to various new styles in a zero-shot manner.",
  "Extensive experiments show that StyleRF achieves superior 3D stylization quality with precise geometry reconstruction and it can generalize to various new styles in a zero-shot manner. Project website: https://kunhao-liu.github.io/StyleRF/\nAuthors: Kunhao Liu, Fangneng Zhan, Yiwen Chen, Jiahui Zhang, Yingchen Yu, Abdulmotaleb El Saddik, Shijian Lu, E. Xing\nVenue: Computer Vision and Pattern Recognition\nTldr: {'model': 'tldr@v2.0.0', 'text': 'StyleRF (Style Radiance Fields), an innovative 3D style transfer technique that resolves the three-way dilemma by performing style transformation within the feature space of a radiance field, achieves superior 3D stylization quality with precise geometry reconstruction and it can generalize to various new styles in a zero-shot manner.'}\nUrl: https://arxiv.org/pdf/2303.10598",
  "Faculty Name: eric xing\nPaperid: 953e415f1fd006e968aa13b49cd7523856c0c0fe\nTitle: Fusing Models with Complementary Expertise\nYear: 2023\nAbstract: Training AI models that generalize across tasks and domains has long been among the open problems driving AI research. The emergence of Foundation Models made it easier to obtain expert models for a given task, but the heterogeneity of data that may be encountered at test time often means that any single expert is insufficient. We consider the Fusion of Experts (FoE) problem of fusing outputs of expert models with complementary knowledge of the data distribution and formulate it as an instance of supervised learning. Our method is applicable to both discriminative and generative tasks and leads to significant performance improvements in image and text classification, text summarization, multiple-choice QA, and automatic evaluation of generated text. We also extend our method to the\"frugal\"setting where it is desired to reduce the number of expert model evaluations at test time.",
  "We also extend our method to the\"frugal\"setting where it is desired to reduce the number of expert model evaluations at test time.\nAuthors: Hongyi Wang, Felipe Maia Polo, Yuekai Sun, Souvik Kundu, Eric P. Xing, M. Yurochkin\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work considers the Fusion of Experts (FoE) problem of fusing outputs of expert models with complementary knowledge of the data distribution and formulate it as an instance of supervised learning and leads to significant performance improvements in image and text classification, text summarization, multiple-choice QA, and automatic evaluation of generated text.'}\nUrl: https://arxiv.org/pdf/2310.01542",
  "Faculty Name: eric xing\nPaperid: 96d6fc4281e739c0e5bc1ea4b7b14ea1ab3bce52\nTitle: Measurement of Heavy Nulei beyond Iron in Cosmic Rays with the DAMPE Experiment\nYear: 2023\nAbstract: None\nAuthors: Haoran Sun, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, F. de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng,",
  "M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, Luyang Jiang, Wei Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu,",
  "Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, H. Su, Meng Su, H. Sun, Zhigang Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yifeng Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zizhong Xu,",
  "Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yifeng Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zizhong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hongying Zhao, Xu Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: None\nUrl: https://pos.sissa.it/444/174/pdf",
  "Faculty Name: eric xing\nPaperid: 9a99b8f8c1999de1ac723e99a708931b53a573ec\nTitle: Recent Advances in Decellularized Extracellular Matrix-Based Bioinks for 3D Bioprinting in Tissue Engineering\nYear: 2023\nAbstract: In recent years, three-dimensional (3D) bioprinting has been widely utilized as a novel manufacturing technique by more and more researchers to construct various tissue substitutes with complex architectures and geometries. Different biomaterials, including natural and synthetic materials, have been manufactured into bioinks for tissue regeneration using 3D bioprinting. Among the natural biomaterials derived from various natural tissues or organs, the decellularized extracellular matrix (dECM) has a complex internal structure and a variety of bioactive factors that provide mechanistic, biophysical, and biochemical signals for tissue regeneration and remodeling. In recent years, more and more researchers have been developing the dECM as a novel bioink for the construction of tissue substitutes.",
  "In recent years, more and more researchers have been developing the dECM as a novel bioink for the construction of tissue substitutes. Compared with other bioinks, the various ECM components in dECM-based bioink can regulate cellular functions, modulate the tissue regeneration process, and adjust tissue remodeling. Therefore, we conducted this review to discuss the current status of and perspectives on dECM-based bioinks for bioprinting in tissue engineering. In addition, the various bioprinting techniques and decellularization methods were also discussed in this study.\nAuthors: Man Zhe, Xin Wu, Peiyun Yu, Jiawei Xu, Ming Liu, Guang Yang, Zhou Xiang, F. Xing, U. Ritz\nVenue: Materials\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The current status of and perspectives on dECM-based bioinks for bioprinting in tissue engineering are discussed and the various biopprinting techniques and decellularization methods were discussed in this study.'}\nUrl: https://www.mdpi.com/1996-1944/16/8/3197/pdf?version=1681816529",
  "Faculty Name: eric xing\nPaperid: 9d4302e77ab4f6f39a4c040b9b53e075c62797ae\nTitle: Evaluation of thermal comfort in air-conditioned rooms based on structure/control-related parameters and data-mining method\nYear: 2023\nAbstract: None\nAuthors: S. Zhao, Lin He, Xin Wu, Guowen Xu, Junlong Xie, Shanshan Cai\nVenue: International Journal of Air-Conditioning and Refrigeration\nTldr: None\nUrl: https://link.springer.com/content/pdf/10.1007/s44189-023-00020-0.pdf",
  "Faculty Name: eric xing\nPaperid: a06a4a38668c4737ab2ce80badc177ea3f520456\nTitle: Cuttlefish: Low-Rank Model Training without All the Tuning\nYear: 2023\nAbstract: Recent research has shown that training low-rank neural networks can effectively reduce the total number of trainable parameters without sacrificing predictive accuracy, resulting in end-to-end speedups. However, low-rank model training necessitates adjusting several additional factorization hyperparameters, such as the rank of the factorization at each layer. In this paper, we tackle this challenge by introducing Cuttlefish, an automated low-rank training approach that eliminates the need for tuning factorization hyperparameters. Cuttlefish leverages the observation that after a few epochs of full-rank training, the stable rank (i.e., an approximation of the true rank) of each layer stabilizes at a constant value. Cuttlefish switches from full-rank to low-rank training once the stable ranks of all layers have converged, setting the dimension of each factorization to its corresponding stable rank.",
  "Cuttlefish switches from full-rank to low-rank training once the stable ranks of all layers have converged, setting the dimension of each factorization to its corresponding stable rank. Our results show that Cuttlefish generates models up to 5.6 times smaller than full-rank models, and attains up to a 1.2 times faster end-to-end training process while preserving comparable accuracy. Moreover, Cuttlefish outperforms state-of-the-art low-rank model training methods and other prominent baselines. The source code for our implementation can be found at: https://github.com/hwang595/Cuttlefish.",
  "Moreover, Cuttlefish outperforms state-of-the-art low-rank model training methods and other prominent baselines. The source code for our implementation can be found at: https://github.com/hwang595/Cuttlefish.\nAuthors: Hongyi Wang, Saurabh Agarwal, Pongsakorn U-chupala, Yoshiki Tanaka, Eric P. Xing, Dimitris Papailiopoulos\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper introduces Cuttlefish, an automated low-rank training approach that eliminates the need for tuning factorization hyperparameters, and generates models up to 5.6 times smaller than full-rank models, and attains up to a 1.2 times faster end-to-end training process while preserving comparable accuracy.'}\nUrl: http://arxiv.org/pdf/2305.02538",
  "Faculty Name: eric xing\nPaperid: a0a79dad89857a96f8f71b14238e5237cbfc4787\nTitle: Judging LLM-as-a-judge with MT-Bench and Chatbot Arena\nYear: 2023\nAbstract: Evaluating large language model (LLM) based chat assistants is challenging due to their broad capabilities and the inadequacy of existing benchmarks in measuring human preferences. To address this, we explore using strong LLMs as judges to evaluate these models on more open-ended questions. We examine the usage and limitations of LLM-as-a-judge, including position, verbosity, and self-enhancement biases, as well as limited reasoning ability, and propose solutions to mitigate some of them. We then verify the agreement between LLM judges and human preferences by introducing two benchmarks: MT-bench, a multi-turn question set; and Chatbot Arena, a crowdsourced battle platform. Our results reveal that strong LLM judges like GPT-4 can match both controlled and crowdsourced human preferences well, achieving over 80% agreement, the same level of agreement between humans.",
  "Our results reveal that strong LLM judges like GPT-4 can match both controlled and crowdsourced human preferences well, achieving over 80% agreement, the same level of agreement between humans. Hence, LLM-as-a-judge is a scalable and explainable way to approximate human preferences, which are otherwise very expensive to obtain. Additionally, we show our benchmark and traditional benchmarks complement each other by evaluating several variants of LLaMA and Vicuna. The MT-bench questions, 3K expert votes, and 30K conversations with human preferences are publicly available at https://github.com/lm-sys/FastChat/tree/main/fastchat/llm_judge.",
  "The MT-bench questions, 3K expert votes, and 30K conversations with human preferences are publicly available at https://github.com/lm-sys/FastChat/tree/main/fastchat/llm_judge.\nAuthors: Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, E. Xing, Haotong Zhang, Joseph Gonzalez, Ion Stoica\nVenue: Neural Information Processing Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The results reveal that strong LLM judges like GPT-4 can match both controlled and crowdsourced human preferences well, achieving over 80% agreement, the same level of agreement between humans, and LLM-as-a-judge is a scalable and explainable way to approximate human preferences, which are otherwise very expensive to obtain.'}\nUrl: https://arxiv.org/pdf/2306.05685",
  "Faculty Name: eric xing\nPaperid: a1a18645ee975e8b8fa0e9f922353c0ed6da361b\nTitle: Does compressing activations help model parallel training?\nYear: 2023\nAbstract: Large-scale Transformer models are known for their exceptional performance in a range of tasks, but training them can be difficult due to the requirement for communication-intensive model parallelism. One way to improve training speed is to compress the message size in communication. Previous approaches have primarily focused on compressing gradients in a data parallelism setting, but compression in a model-parallel setting is an understudied area. We have discovered that model parallelism has fundamentally different characteristics than data parallelism. In this work, we present the first empirical study on the effectiveness of compression methods for model parallelism. We implement and evaluate three common classes of compression algorithms - pruning-based, learning-based, and quantization-based - using a popular Transformer training framework. We evaluate these methods across more than 160 settings and 8 popular datasets, taking into account different hyperparameters, hardware, and both fine-tuning and pre-training stages. We also provide analysis when the model is scaled up.",
  "We evaluate these methods across more than 160 settings and 8 popular datasets, taking into account different hyperparameters, hardware, and both fine-tuning and pre-training stages. We also provide analysis when the model is scaled up. Finally, we provide insights for future development of model parallelism compression algorithms.\nAuthors: S. Bian, Dacheng Li, Hongyi Wang, Eric P. Xing, S. Venkataraman\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work presents the first empirical study on the effectiveness of compression methods for model parallelism, and implements and evaluates three common classes of compression algorithms - pruning-based, learning- based, and quantization-based - using a popular Transformer training framework.'}\nUrl: http://arxiv.org/pdf/2301.02654",
  "Faculty Name: eric xing\nPaperid: a3c4a5c18ef9bfffd9c8aac0dc2b75b8f18b9f7c\nTitle: Effects of Coupling Constants on Chaos of Charged Particles in the Einstein\u2013\u00c6ther Theory\nYear: 2023\nAbstract: There are two free coupling parameters\u00a0c13\u00a0and\u00a0c14\u00a0in the Einstein\u2013\u00c6ther metric describing a non-rotating black hole. This metric is the Reissner\u2013Nordstr\u00f6m black hole solution when\u00a00\u22642c13<c14<2, but it is not for\u00a00\u2264c14<2c13<2. When the black hole is immersed in an external asymptotically uniform magnetic field, the Hamiltonian system describing the motion of charged particles around the black hole is not integrable; however, the Hamiltonian allows for the construction of explicit symplectic integrators. The proposed fourth-order explicit symplectic scheme is used to investigate the dynamics of charged particles because it exhibits excellent long-term performance in conserving the Hamiltonian.",
  "The proposed fourth-order explicit symplectic scheme is used to investigate the dynamics of charged particles because it exhibits excellent long-term performance in conserving the Hamiltonian. No universal rule can be given to the dependence of regular and chaotic dynamics on varying one or two parameters\u00a0c13\u00a0and\u00a0c14\u00a0in the two cases of\u00a00\u22642c13<c14<2\u00a0and\u00a00\u2264c14<2c13<2. The distributions of order and chaos in the binary parameter space\u00a0(c13,c14)\u00a0rely on different combinations of the other parameters and the initial conditions.\nAuthors: Caiyu Liu, Xin Wu\nVenue: Universe\nTldr: None\nUrl: https://www.mdpi.com/2218-1997/9/8/365/pdf?version=1691388673",
  "Faculty Name: eric xing\nPaperid: a5bf216fc2dfc7f9e1d3fe6b8b06986758b60577\nTitle: A PCA-based Method for Electron-Proton Discrimination of the DAMPE Experiment\nYear: 2023\nAbstract: None\nAuthors: M. Cui, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, Francesco de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M.",
  "Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, L. Jiang, Weizhong Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu,",
  "Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, H. Su, Meng Su, H. Sun, Zhigang Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Yuanzhu Wang, D. Wei, J. Wei, Yifeng Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu,",
  "Wang, Ying Wang, Yuanzhu Wang, D. Wei, J. Wei, Yifeng Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hongying Zhao, Xun Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: None\nUrl: https://pos.sissa.it/444/131/pdf",
  "Faculty Name: eric xing\nPaperid: a71dca7b72a8fb8f1f337721a2a0042faf9bd70b\nTitle: Cosmic Ray Carbon and Oxygen Flux Measurements with the DAMPE Experiment\nYear: 2023\nAbstract: The DArk Matter Particle Explorer (DAMPE), a space-based high-energy particle detector\nAuthors: Yifeng Wei, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, Francesco de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, J. Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K.",
  "Francesco de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, J. Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, Luyang Jiang, Wei Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N.",
  "X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, H. Su, Meng Su, H. Sun, Zhigang Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu,",
  "L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zizhong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hongying Zhao, Xu Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: None\nUrl: https://pos.sissa.it/444/165/pdf",
  "Faculty Name: eric xing\nPaperid: a815c3209e7baff4466dbf6e129129511f842b7e\nTitle: Making Scalable Meta Learning Practical\nYear: 2023\nAbstract: Despite its flexibility to learn diverse inductive biases in machine learning programs, meta learning (i.e., learning to learn) has long been recognized to suffer from poor scalability due to its tremendous compute/memory costs, training instability, and a lack of efficient distributed training support. In this work, we focus on making scalable meta learning practical by introducing SAMA, which combines advances in both implicit differentiation algorithms and systems. Specifically, SAMA is designed to flexibly support a broad range of adaptive optimizers in the base level of meta learning programs, while reducing computational burden by avoiding explicit computation of second-order gradient information, and exploiting efficient distributed training techniques implemented for first-order gradients. Evaluated on multiple large-scale meta learning benchmarks, SAMA showcases up to 1.7/4.8x increase in throughput and 2.0/3.8x decrease in memory consumption respectively on single-/multi-GPU setups compared to other baseline meta learning algorithms.",
  "Evaluated on multiple large-scale meta learning benchmarks, SAMA showcases up to 1.7/4.8x increase in throughput and 2.0/3.8x decrease in memory consumption respectively on single-/multi-GPU setups compared to other baseline meta learning algorithms. Furthermore, we show that SAMA-based data optimization leads to consistent improvements in text classification accuracy with BERT and RoBERTa large language models, and achieves state-of-the-art results in both small- and large-scale data pruning on image classification tasks, demonstrating the practical applicability of scalable meta learning across language and vision domains.\nAuthors: Sang Keun Choe, Sanket Vaibhav Mehta, Hwijeen Ahn, W. Neiswanger, Pengtao Xie, Emma Strubell, Eric P. Xing\nVenue: Neural Information Processing Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'SAMA is designed to flexibly support a broad range of adaptive optimizers in the base level of meta learning programs, while reducing computational burden by avoiding explicit computation of second-order gradient information, and exploiting efficient distributed training techniques implemented for first-order gradients.'}",
  "Url: https://arxiv.org/pdf/2310.05674",
  "Faculty Name: eric xing\nPaperid: a91026808c2139b79e4daf8df8fbe5008f389f9f\nTitle: Erratum: New insight into the shape coexistence and shape evolution of \n<mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"><mml:mmultiscripts><mml:mi>Yb</mml:mi><mml:mprescripts /><mml:none /><mml:mn>157</mml:mn></mml:mmultiscripts></mml:math>\n [Phys. Rev.",
  "Rev. C \n<b>83</b>\n, 014318 (2011)]\nYear: 2023\nAbstract: None\nAuthors: C. Xu, H. Hua, Xiao Li, J. Meng, Z. Li, F. Xu, Y. Shi, H. Liu, Shengyao Zhang, Z. Li, L. Zhu, Xin Wu, G. Li, C. He, S. G. Zhou, S. Y. Wang, Y. Ye, D. Jiang, T. Zheng, J. Lou, L. Ma, E. Wang, Y. Y. Cheng, C. He\nVenue: Physical Review C\nTldr: None\nUrl: http://link.aps.org/pdf/10.1103/PhysRevC.107.039903",
  "Faculty Name: eric xing\nPaperid: aa8a3b4d472e707dc019a93498f52f6aaf5b9a7b\nTitle: Applicability of the 0\u20131 test for chaos in magnetized Kerr\u2013Newman spacetimes\nYear: 2023\nAbstract: None\nAuthors: Daqi Yang, Xin Wu\nVenue: The European Physical Journal C\nTldr: None\nUrl: https://link.springer.com/content/pdf/10.1140/epjc/s10052-023-11978-x.pdf",
  "Faculty Name: eric xing\nPaperid: ab70103b8cc85fd1cd52200aa134c58c7e9c0e03\nTitle: FedNAR: Federated Optimization with Normalized Annealing Regularization\nYear: 2023\nAbstract: Weight decay is a standard technique to improve generalization performance in modern deep neural network optimization, and is also widely adopted in federated learning (FL) to prevent overfitting in local clients. In this paper, we first explore the choices of weight decay and identify that weight decay value appreciably influences the convergence of existing FL algorithms. While preventing overfitting is crucial, weight decay can introduce a different optimization goal towards the global objective, which is further amplified in FL due to multiple local updates and heterogeneous data distribution. To address this challenge, we develop {\\it Federated optimization with Normalized Annealing Regularization} (FedNAR), a simple yet effective and versatile algorithmic plug-in that can be seamlessly integrated into any existing FL algorithms. Essentially, we regulate the magnitude of each update by performing co-clipping of the gradient and weight decay.",
  "Essentially, we regulate the magnitude of each update by performing co-clipping of the gradient and weight decay. We provide a comprehensive theoretical analysis of FedNAR's convergence rate and conduct extensive experiments on both vision and language datasets with different backbone federated optimization algorithms. Our experimental results consistently demonstrate that incorporating FedNAR into existing FL algorithms leads to accelerated convergence and heightened model accuracy. Moreover, FedNAR exhibits resilience in the face of various hyperparameter configurations. Specifically, FedNAR has the ability to self-adjust the weight decay when the initial specification is not optimal, while the accuracy of traditional FL algorithms would markedly decline. Our codes are released at \\href{https://github.com/ljb121002/fednar}{https://github.com/ljb121002/fednar}.",
  "Our codes are released at \\href{https://github.com/ljb121002/fednar}{https://github.com/ljb121002/fednar}.\nAuthors: Junbo Li, Ang Li, Chong Tian, Qirong Ho, Eric P. Xing, Hongyi Wang\nVenue: Neural Information Processing Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper develops FedNAR, a simple yet effective and versatile algorithmic plug-in that can be seamlessly integrated into any existing FL algorithms and has the ability to self-adjust the weight decay when the initial specification is not optimal, while the accuracy of traditional FL algorithms would markedly decline.'}\nUrl: https://arxiv.org/pdf/2310.03163",
  "Faculty Name: eric xing\nPaperid: abd11a40c2b51a3af211302141db7f4a94d71497\nTitle: Measurements of the boron-to-carbon and boron-to-oxygen flux ratios in cosmic rays with DAMPE\nYear: 2023\nAbstract: Boron nuclei in cosmic rays (CRs) are believed to be mainly produced by the fragmentation of heavier nuclei, such as carbon and oxygen, via collisions with the interstellar matter. Therefore, the boron-to-carbon \ufb02ux ratio (B/C) and the boron-to-oxygen \ufb02ux ratio (B/O) are very essential probes of the CR propagation. With a large geometric factor and a good charge resolution, the DArk Matter Particle Explorer (DAMPE)\nAuthors: C. Yue, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z.",
  "An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, Francesco de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, Piergiorgio Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, L. Jiang, Wei Jiang, Y. Jiang, J.",
  "Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, L. Jiang, Wei Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, Wei Liang Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, Pengxiong Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Shangguan Zhi, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, H. Su, Meng Su, H.",
  "Rui Qiao, J. Rao, A. Ruina, Shangguan Zhi, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, H. Su, Meng Su, H. Sun, Zhigang Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Yuanzhu Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zizhong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Ya Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hong-yun Zhao,",
  "G. Yuan, Qiang Yuan, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Ya Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hong-yun Zhao, Xu Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: None\nUrl: https://pos.sissa.it/444/159/pdf",
  "Faculty Name: eric xing\nPaperid: aca66f06cc3f988ebfc0420b3f969466a6984fef\nTitle: Federated Learning as Variational Inference: A Scalable Expectation Propagation Approach\nYear: 2023\nAbstract: The canonical formulation of federated learning treats it as a distributed optimization problem where the model parameters are optimized against a global loss function that decomposes across client loss functions. A recent alternative formulation instead treats federated learning as a distributed inference problem, where the goal is to infer a global posterior from partitioned client data (Al-Shedivat et al., 2021). This paper extends the inference view and describes a variational inference formulation of federated learning where the goal is to find a global variational posterior that well-approximates the true posterior. This naturally motivates an expectation propagation approach to federated learning (FedEP), where approximations to the global posterior are iteratively refined through probabilistic message-passing between the central server and the clients. We conduct an extensive empirical study across various algorithmic considerations and describe practical strategies for scaling up expectation propagation to the modern federated setting.",
  "We conduct an extensive empirical study across various algorithmic considerations and describe practical strategies for scaling up expectation propagation to the modern federated setting. We apply FedEP on standard federated learning benchmarks and find that it outperforms strong baselines in terms of both convergence speed and accuracy.\nAuthors: Han Guo, P. Greengard, Hongyi Wang, A. Gelman, Yoon Kim, Eric P. Xing\nVenue: International Conference on Learning Representations\nTldr: {'model': 'tldr@v2.0.0', 'text': 'An extensive empirical study across various algorithmic considerations and describes practical strategies for scaling up expectation propagation to the modern federated setting and applies FedEP on standard federated learning benchmarks and finds that it outperforms strong baselines in terms of both convergence speed and accuracy.'}\nUrl: http://arxiv.org/pdf/2302.04228",
  "Faculty Name: eric xing\nPaperid: ae98f67ff27c9a817a62e1b52a3f2cc1c20bf94f\nTitle: Integrating symbol similarities with knowledge\u00a0graph embedding for entity alignment: an unsupervised framework\nYear: 2023\nAbstract: None\nAuthors: Tingting Jiang, Chenyang Bu, Yi Zhu, Xin Wu\nVenue: Intelligent Computing\nTldr: None\nUrl: N/A",
  "Faculty Name: eric xing\nPaperid: ae9cc1f7ba5c905684f5c4211dbb7f0bb2cd4458\nTitle: Measurement of Ultra-High-Energy Diffuse Gamma-Ray Emission of the Galactic Plane from 10\u00a0TeV to 1\u00a0PeV with LHAASO-KM2A.\nYear: 2023\nAbstract: The diffuse Galactic \u03b3-ray emission, mainly produced via interactions between cosmic rays and the interstellar medium and/or radiation field, is a very important probe of the distribution, propagation, and interaction of cosmic rays in the Milky\u00a0Way. In this Letter, we report the measurements of diffuse \u03b3 rays from the Galactic plane between 10\u00a0TeV and 1\u00a0PeV energies, with the square kilometer array of the Large High Altitude Air Shower Observatory (LHAASO). Diffuse emissions from the inner (15\u00b0<l<125\u00b0, |b|<5\u00b0) and outer (125\u00b0<l<235\u00b0, |b|<5\u00b0) Galactic plane are detected with 29.1\u03c3 and 12.7\u03c3 significance, respectively.",
  "Diffuse emissions from the inner (15\u00b0<l<125\u00b0, |b|<5\u00b0) and outer (125\u00b0<l<235\u00b0, |b|<5\u00b0) Galactic plane are detected with 29.1\u03c3 and 12.7\u03c3 significance, respectively. The outer Galactic plane diffuse emission is detected for the first time in the very- to ultra-high-energy domain (E>10\u2009\u2009TeV). The energy spectrum in the inner Galaxy regions can be described by a power-law function with an index of -2.99\u00b10.04, which is different from the curved spectrum as expected from hadronic interactions between locally measured cosmic rays and the line-of-sight integrated gas content. Furthermore, the measured flux is higher by a factor of \u223c3 than the prediction. A similar spectrum with an index of -2.99\u00b10.07 is found in the outer Galaxy region, and the absolute flux for 10\u2272E\u227260\u2009\u2009TeV is again higher than the prediction for hadronic cosmic ray interactions. The latitude distributions of the diffuse emission are consistent with the gas distribution, while the longitude distributions show clear deviation from the gas distribution.",
  "The latitude distributions of the diffuse emission are consistent with the gas distribution, while the longitude distributions show clear deviation from the gas distribution. The LHAASO measurements imply that either additional emission sources exist or cosmic ray intensities have spatial variations.\nAuthors: Z. Cao, F. Aharonian, Q. An, Axikegu, Y. Bai, Y. Bao, D. Bastieri, X. Bi, Y. Bi, J. Cai, Q. Cao, W. Cao, Z. Cao, J. Chang, J. Chang, A. Chen, E. Chen, Liang Chen, Lin Chen, Long Chen, M. Chen, M. Chen, Q. Chen, S. Chen, S. Z. Chen, T. Chen, Y. Chen, N. Cheng, Y. Cheng, M. Cui, S. Cui, X. Cui, Y. Cui, B. Dai, H. Dai, Z. Dai, Danzengluobu, D. Volpe, X. Dong, K. Duan, J. Fan, Y. Fan, J. Fang, K. Fang, C. Feng, L. Feng, S.",
  "Y. Cui, B. Dai, H. Dai, Z. Dai, Danzengluobu, D. Volpe, X. Dong, K. Duan, J. Fan, Y. Fan, J. Fang, K. Fang, C. Feng, L. Feng, S. Feng, X. Feng, Y. Feng, S. Gabici, B. Gao, C. Gao, L. Gao, Q. Gao, W. Gao, W. Gao, M. Ge, L. Geng, G. Giacinti, G. Gong, Q. Gou, M. Gu, F. Guo, X. Guo, Y. Guo, Y. Guo, Y. Han, H. He, Haoyu He, J. Y. He, X. He, Y. He, M. Heller, Y. Hor, B. Hou, C. Hou, X. Hou, H. Hu, Q. Hu, S. Hu, D. Huang, T. Q. Huang, W. Huang, X. Huang, X. Y. Huang, Y. Huang, Z. Huang, X. Ji, H.",
  "Hor, B. Hou, C. Hou, X. Hou, H. Hu, Q. Hu, S. Hu, D. Huang, T. Q. Huang, W. Huang, X. Huang, X. Y. Huang, Y. Huang, Z. Huang, X. Ji, H. Jia, K. Jia, K. Jiang, X. W. Jiang, Z. Jiang, M. Jin, M. Kang, T. Ke, D. Kuleshov, K. Kurinov, B. Li, Cheng Li, Cong Li, D. Li, F. Li, H. B. Li, H. C. Li, H. Li, J. Li, Jian Li, Jie Li, K. Li, W. Li, X. Li, Xin Li, Y. Li, Zhe Li, Zhuo Li, E. Liang, Y. Liang, S. Lin, B. Liu, C. Liu, D. Liu, H. Liu, H. Liu, J. Liu, J. Liu, J. Liu, M. Liu, R. Liu, S. M. Liu, W. Liu, Y. Liu, Y. N.",
  "S. Lin, B. Liu, C. Liu, D. Liu, H. Liu, H. Liu, J. Liu, J. Liu, J. Liu, M. Liu, R. Liu, S. M. Liu, W. Liu, Y. Liu, Y. N. Liu, R. Lu, Q. Luo, H. Lv, B. Ma, L. Ma, X. Ma, J. Mao, Z. Min, W. Mitthumsiri, H. Mu, Y. Nan, A. Neronov, Z. Ou, B. Pang, P. Pattarakijwanich, Z. Pei, M. Qi, Y. Qi, B. Qiao, J. Qin, D. Ruffolo, A. S\u00e1iz, D. Semikoz, C. Shao, L. Shao, O. Shchegolev, X. Sheng, F. Shu, H. Song, Y. Stenkin, V. Stepanov, Y. Su, Q. Sun, X. Sun, Z. Sun, P. Tam, Q. Tang, Z. Tang, W. Tian, C. Wang, C.",
  "X. Sheng, F. Shu, H. Song, Y. Stenkin, V. Stepanov, Y. Su, Q. Sun, X. Sun, Z. Sun, P. Tam, Q. Tang, Z. Tang, W. Tian, C. Wang, C. Wang, G. W. Wang, H. Wang, H. H. Wang, J. C. Wang, K. Wang, L. Wang, L. Y. Wang, P. Wang, R. Wang, W. Wang, X. G. Wang, X. Y. Wang, Y. Wang, Y. Wang, Y. J. Wang, Z. H. Wang, Z. X. Wang, Zhen Wang, Z. Wang, D. Wei, J. Wei, Y. J. Wei, T. Wen, C. Y. Wu, H. Wu, S. Wu, Xin Wu, Y. Wu, S. Xi, J. Xia, J. Xia, G. Xiang, D. Xiao, G. Xiao, G. Xin, Y. Xin, Yangang Xing, Z. Xiong, D. Xu, R. Xu, R. Xu,",
  "Xin Wu, Y. Wu, S. Xi, J. Xia, J. Xia, G. Xiang, D. Xiao, G. Xiao, G. Xin, Y. Xin, Yangang Xing, Z. Xiong, D. Xu, R. Xu, R. Xu, W. Xu, L. Xue, Dong Yan, J. Yan, T. Yan, C. Yang, F. Yang, F. Yang, H. W. Yang, J. Y. Yang, L. L. Yang, M. Yang, R. Yang, S. Yang, Y. Yao, Z. Yao, Y. Ye, L. Yin, N. Yin, X. You, Z. You, Y. Yu, Q. Yuan, H. Yue, H. Zeng, T. Zeng, W. Zeng, M. Zha, B. Zhang, F. Zhang, H. Zhang, H. Zhang, J. Zhang, L. X. Zhang, Li Zhang, P. Zhang, P. Zhang, R. Zhang, S. B. Zhang, S. Zhang, S. Zhang, X. Zhang, X. Zhang, Y. Zhang, Yi.",
  "Zhang, H. Zhang, H. Zhang, J. Zhang, L. X. Zhang, Li Zhang, P. Zhang, P. Zhang, R. Zhang, S. B. Zhang, S. Zhang, S. Zhang, X. Zhang, X. Zhang, Y. Zhang, Yi. Zhang, Yong Zhang, B. Zhao, J. Zhao, Liang Zhao, L. Zhao, S. Zhao, F. Zheng, B. Zhou, H. Zhou, J. Zhou, M. Zhou, P. Zhou, R. Zhou, X. Zhou, C. Zhu, F. Zhu, H. Zhu, K. Zhu, X. Zuo\nVenue: Physical Review Letters\nTldr: None\nUrl: https://arxiv.org/pdf/2305.05372",
  "Faculty Name: eric xing\nPaperid: b1e645b0028ab543e2f8b823a0aad7ee72091f32\nTitle: Metasurface Deflector Enhanced Grating Coupler for Perfectly Vertical Coupling\nYear: 2023\nAbstract: We propose a perfectly vertical coupling scheme based on metasurface deflectors (meta-deflectors) and grating couplers (GCs). An approach for optimizing the GCs based on the Gaussian-fitting using the genetic algorithm is proposed. An meta-deflector based on amorphous silicon (a-Si) pillars is designed to the optimal coupling angle of the GC to ensure good coupling efficiency (CE). Simulations predict peak vertical CE to be 78% at the wavelength of 2 \u03bcm, with 1 dB bandwidth \u226535 nm. The design process of GC and meta-deflector is provided in detail, and the influence of fabrication error on the CE is analyzed.",
  "Simulations predict peak vertical CE to be 78% at the wavelength of 2 \u03bcm, with 1 dB bandwidth \u226535 nm. The design process of GC and meta-deflector is provided in detail, and the influence of fabrication error on the CE is analyzed.\nAuthors: Xin Wu, Yang Qiu, Shaonan Zheng, Xingyan Zhao, Yuan Dong, Qize Zhong, L. Jia, Ting Hu\nVenue: Photonics\nTldr: None\nUrl: https://www.mdpi.com/2304-6732/10/4/436/pdf?version=1681294625",
  "Faculty Name: eric xing\nPaperid: b9ab633b1e9eec9c810627d881da6d172bd2cebe\nTitle: Forest Fire Smoke Detection Research Based on the Random Forest Algorithm and Sub-Pixel Mapping Method\nYear: 2023\nAbstract: In order to locate forest fire smoke more precisely and expand existing forest fire monitoring methods, this research employed Himawari-8 data with a sub-pixel positioning concept in smoke detection. In this study, Himawari-8 data of forest fire smoke in Xichang and Linzhi were selected. An improved sub-pixel mapping method based on random forest results was proposed to realize the identification and sub-pixel positioning of smoke. More spatial details of forest fire smoke were restored in the final results. The continuous monitoring of smoke indicated the dynamic changes therein. The accuracy evaluation of smoke detection was realized using a confusion matrix. Based on the improved sub-pixel mapping method, the overall accuracies were 87.95% and 86.32%. Compared with the raw images, the smoke contours of the improved sub-pixel mapping results were clearer and smoother.",
  "Based on the improved sub-pixel mapping method, the overall accuracies were 87.95% and 86.32%. Compared with the raw images, the smoke contours of the improved sub-pixel mapping results were clearer and smoother. The improved sub-pixel mapping method outperforms traditional classification methods in locating smoke range. Moreover, it especially made a breakthrough in the limitations of the pixel scale and in realizing sub-pixel positioning. Compared with the results of the classic PSA method, there were fewer \u201cspots\u201d and \u201choles\u201d after correction. The final results of this study show higher accuracies of smoke discrimination, with it becoming the basis for another method of forest fire monitoring.\nAuthors: Xihao Li, Gui Zhang, Sanqing Tan, Zhi Yang, Xin Wu\nVenue: Forests\nTldr: None\nUrl: https://www.mdpi.com/1999-4907/14/3/485/pdf?version=1677565582",
  "Faculty Name: eric xing\nPaperid: cb5bfd9718f2703ad77281980d2050f52d4f6883\nTitle: A Magnetically Controlled Guidewire Robot System with Steering and Propulsion Capabilities for Vascular Interventional Surgery\nYear: 2023\nAbstract: Magnetically manipulated interventional robotic systems offer outstanding advantages for improving vascular interventions, including minimizing radiation exposure to physicians and increasing the controllability of magnetic interventional devices in hard\u2010to\u2010reach vessels. However, automatic control of magnetic guidewires (MGs) is still challenging in terms of modeling of guidewires and trajectory planning. Herein, a magnetically controlled guidewire robotic system (MCGRS) with steering and propulsion capabilities is proposed based on adequate modeling and trajectory planning methods. The steering kinematics of MG is first modeled by constant curvature theory. Then, a continuum mechanics model is built to predict the deformation of the magnetic tip by combining the dipole model and the Cosserat\u2010rod model. Moreover, a trajectory planning algorithm is developed to navigate the MG through vessels.",
  "The steering kinematics of MG is first modeled by constant curvature theory. Then, a continuum mechanics model is built to predict the deformation of the magnetic tip by combining the dipole model and the Cosserat\u2010rod model. Moreover, a trajectory planning algorithm is developed to navigate the MG through vessels. Furthermore, trajectory following experiments within three vascular phantoms confirm that the proposed model and algorithm are reliable and capable of navigating the MG through the desired trajectory. Finally, two extra navigation experiments are implemented in 3D vascular phantom, which show that the MCGRS can be remotely controlled to manipulate the MG to actively steer and reach the target site. The system and methods will build the foundation for automatic control of MG and help to improve the autonomy.",
  "Finally, two extra navigation experiments are implemented in 3D vascular phantom, which show that the MCGRS can be remotely controlled to manipulate the MG to actively steer and reach the target site. The system and methods will build the foundation for automatic control of MG and help to improve the autonomy.\nAuthors: Shixiong Fu, Binghan Chen, Dong Li, Jianguo Han, Sheng Xu, Shu Wang, Chenyang Huang, Ming Qiu, Si Cheng, Xin Wu, Li Zhang, Shiwei Du, Tiantian Xu\nVenue: Advanced Intelligent Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A magnetically controlled guidewire robotic system (MCGRS) with steering and propulsion capabilities is proposed based on adequate modeling and trajectory planning methods that will build the foundation for automatic control of MG and help to improve the autonomy.'}\nUrl: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/aisy.202300267",
  "Faculty Name: eric xing\nPaperid: cc48851430aca07e19f7f48c1733b009ea654bdf\nTitle: Measurement of the p+He energy spectrum with the DAMPE space mission\nYear: 2023\nAbstract: None\nAuthors: Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, F. de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P.",
  "Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco, M. Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, Luyao Jiang, Wei Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng,",
  "Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, H. Su, Meng Su, H. Sun, Zhigang Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu, Zunlei Xu, G. Xue,",
  "D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hongying Zhao, Xu Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: None\nUrl: https://pos.sissa.it/444/138/pdf",
  "Faculty Name: eric xing\nPaperid: cd76c60e754330964796ec980528b00ad38346a5\nTitle: Study of hadronic cross-sections with cosmic ray Carbon from GeV to TeV by the DAMPE experiment\nYear: 2023\nAbstract: None\nAuthors: E. Xu, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Y. Cui, I. De Mitri, F. de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, J. Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso,",
  "Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, J. Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, Luyang Jiang, Wei Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A.",
  "Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, Hong-mei Su, Meng Su, H. Sun, Zhigang Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yifeng Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu,",
  "Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yifeng Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hongying Zhao, Xu Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: None\nUrl: https://pos.sissa.it/444/161/pdf",
  "Faculty Name: eric xing\nPaperid: d1c1061841cf16e8739a582308ea17ae0e8465cf\nTitle: Latest results on searching for fractionally charged particles with the DAMPE experiment\nYear: 2023\nAbstract: The existence of fractionally charged particles (FCP) is foreseen in extensions of or beyond the Standard Model of particle physics. Most of the previously conducted searches for FCPs in cosmic rays were based on experiments underground or at high altitudes. However, there have been few searches for FCPs in cosmic rays carried out in orbit other than AMS-01 flown by a space shuttle and BESS by a balloon at the top of the atmosphere. In this study, we conduct an FCP search in space based on on-orbit data obtained using the Dark Matter Particle Explorer (DAMPE) satellite over a period of five years. Unlike underground experiments, which require an FCP energy of the order of hundreds of GeV, our FCP search starts at only a few GeV. An upper limit of 6 .",
  "Unlike underground experiments, which require an FCP energy of the order of hundreds of GeV, our FCP search starts at only a few GeV. An upper limit of 6 . 2 \u00d7 10 \u2212 10 cm \u2212 2 sr \u2212 1 s \u2212 1 is obtained for the flux. Our results demonstrate that DAMPE exhibits higher sensitivity than experiments of similar types by three orders of magnitude that more stringently restricts the conditions for the existence of FCP in primary cosmic rays.\nAuthors: Chengming Liu, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, Francesco de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz,",
  "P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, Francesco de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, Luyang Jiang, Wei Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo,",
  "Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, Pengxiong Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, H. Su, Meng Su, H. Sun, Zhigang Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yining Wei, Di Wu,",
  "Zhigang Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hong-yun Zhao, Xu Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: None\nUrl: https://pos.sissa.it/444/149/pdf",
  "Faculty Name: eric xing\nPaperid: d2c03c788ad3fbd6d783cbbc4393c31b1a260691\nTitle: Enhancing the Generalization for Text Classification through Fusion of Backward Features\nYear: 2023\nAbstract: Generalization has always been a keyword in deep learning. Pretrained models and domain adaptation technology have received widespread attention in solving the problem of generalization. They are all focused on finding features in data to improve the generalization ability and to prevent overfitting. Although they have achieved good results in various tasks, those models are unstable when classifying a sentence whose label is positive but still contains negative phrases. In this article, we analyzed the attention heat map of the benchmarks and found that previous models pay more attention to the phrase rather than to the semantic information of the whole sentence. Moreover, we proposed a method to scatter the attention away from opposite sentiment words to avoid a one-sided judgment. We designed a two-stream network and stacked the gradient reversal layer and feature projection layer within the auxiliary network.",
  "Moreover, we proposed a method to scatter the attention away from opposite sentiment words to avoid a one-sided judgment. We designed a two-stream network and stacked the gradient reversal layer and feature projection layer within the auxiliary network. The gradient reversal layer can reverse the gradient of features in the training stage so that the parameters are optimized following the reversed gradient in the backpropagation stage. We utilized an auxiliary network to extract the backward features and then fed them into the main network to merge them with normal features extracted by the main network. We applied this method to the three baselines of TextCNN, BERT, and RoBERTa using sentiment analysis and sarcasm detection datasets. The results show that our method can improve the sentiment analysis datasets by 0.5% and the sarcasm detection datasets by 2.1%.\nAuthors: D. Seng, Xin Wu\nVenue: Italian National Conference on Sensors\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A method to scatter the attention away from opposite sentiment words to avoid a one-sided judgment is proposed and can improve the sentiment analysis datasets by 0.5% and the sarcasm detection datasets by 2.1%.'}",
  "Url: https://www.mdpi.com/1424-8220/23/3/1287/pdf?version=1675655236",
  "Faculty Name: eric xing\nPaperid: d9bbc9aca54ea5c62a7a91c1a763789ba259975f\nTitle: Evaluation of hydraulic fracturing of horizontal wells in tight reservoirs based on the deep neural network with physical constraints\nYear: 2023\nAbstract: None\nAuthors: H. Qu, Jian-long Zhang, Fu-Jian Zhou, Yan Peng, Zhengfu Pan, Xin Wu\nVenue: Petroleum Science\nTldr: None\nUrl: N/A",
  "Faculty Name: eric xing\nPaperid: da07ca45e25c0a632f5b66ad63358e98a8d70af6\nTitle: Exploring Fundamental Particle Acceleration and Loss Processes in Heliophysics through an Orbiting X-ray Instrument in the Jovian System\nYear: 2023\nAbstract: Jupiter's magnetosphere is considered to be the most powerful particle accelerator in the Solar System, accelerating electrons from eV to 70 MeV and ions to GeV energies. How electromagnetic processes drive energy and particle flows, producing and removing energetic particles, is at the heart of Heliophysics. Particularly, the 2013 Decadal Strategy for Solar and Space Physics was to\"Discover and characterize fundamental processes that occur both within the heliosphere and throughout the universe\". The Jovian system offers an ideal natural laboratory to investigate all of the universal processes highlighted in the previous Decadal. The X-ray waveband has been widely used to remotely study plasma across astrophysical systems. The majority of astrophysical emissions can be grouped into 5 X-ray processes: fluorescence, thermal/coronal, scattering, charge exchange and particle acceleration.",
  "The X-ray waveband has been widely used to remotely study plasma across astrophysical systems. The majority of astrophysical emissions can be grouped into 5 X-ray processes: fluorescence, thermal/coronal, scattering, charge exchange and particle acceleration. The Jovian system offers perhaps the only system that presents a rich catalog of all of these X-ray emission processes and can also be visited in-situ, affording the special possibility to directly link fundamental plasma processes with their resulting X-ray signatures. This offers invaluable ground-truths for astrophysical objects beyond the reach of in-situ exploration (e.g. brown dwarfs, magnetars or galaxy clusters that map the cosmos). Here, we show how coupling in-situ measurements with in-orbit X-ray observations of Jupiter's radiation belts, Galilean satellites, Io Torus, and atmosphere addresses fundamental heliophysics questions with wide-reaching impact across helio- and astrophysics. New developments like miniaturized X-ray optics and radiation-tolerant detectors, provide compact, lightweight, wide-field X-ray instruments perfectly suited to the Jupiter system, enabling this exciting new possibility.",
  "New developments like miniaturized X-ray optics and radiation-tolerant detectors, provide compact, lightweight, wide-field X-ray instruments perfectly suited to the Jupiter system, enabling this exciting new possibility.\nAuthors: William Dunn, G. Berland, E. Roussos, George Clark, P. Kollmann, D. Turner, Charly Feldman, Tom Stallard, G. Branduardi\u2010Raymont, E. Woodfield, I. J. Rae, L. Ray, J. Carter, Simon Lindsay, Zhonghua Yao, Robert Marshall, A. Jaynes, Y. Ezoe, M. Numazawa, G. Hospodarsky, Xin Wu, D. Weigt, C. Jackman, K. Mori, Q. N\u00e9non, R. Desai, L. Blum, T. Nordheim, Jan-Uwe Ness, Dennis Bodewits, T. Kimura, Wen Li, H. Smith, Dimitrios Millas, A. Wibisono, N. Achilleos, D. Koutroumpa, S. McEntee, H. Collier, Anil Bhardwaj, A. Martindale, S. Wolk, S. Badman, Ralph P. Kraft\nVenue: Vol.",
  "55, Issue 3 (Heliophysics 2024 Decadal Whitepapers)\nTldr: None\nUrl: https://baas.aas.org/pub/2023n3i101/download/pdf",
  "Faculty Name: eric xing\nPaperid: dcb4f2b9b0e6da0d629878d1ad0469aee3df2020\nTitle: Understanding Masked Autoencoders via Hierarchical Latent Variable Models\nYear: 2023\nAbstract: Masked autoencoder (MAE), a simple and effective self-supervised learning framework based on the reconstruction of masked image regions, has recently achieved prominent success in a variety of vision tasks. Despite the emergence of intriguing empirical observations on MAE, a theoretically principled understanding is still lacking. In this work, we formally characterize and justify existing empirical in-sights and provide theoretical guarantees of MAE. We formulate the underlying data-generating process as a hierarchical latent variable model, and show that under reasonable assumptions, MAE provably identifies a set of latent variables in the hierarchical model, explaining why MAE can extract high-level information from pixels. Further, we show how key hyperparameters in MAE (the masking ratio and the patch size) determine which true latent variables to be recovered, therefore influencing the level of semantic information in the representation. Specifically, extremely large or small masking ratios inevitably lead to low-level representations.",
  "Further, we show how key hyperparameters in MAE (the masking ratio and the patch size) determine which true latent variables to be recovered, therefore influencing the level of semantic information in the representation. Specifically, extremely large or small masking ratios inevitably lead to low-level representations. Our theory offers coherent explanations of existing empirical observations and provides insights for potential empirical improvements and fundamental limitations of the masked-reconstruction paradigm. We conduct extensive experiments to validate our theoretical insights.\nAuthors: Lingjing Kong, Martin Q. Ma, Guan-Hong Chen, E. Xing, Yuejie Chi, Louis-Philippe Morency, Kun Zhang\nVenue: Computer Vision and Pattern Recognition\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work formally characterize and justify existing empirical in-sights and provide theoretical guarantees of MAE, and formulate the underlying data-generating process as a hierarchical latent variable model, and shows that under reasonable assumptions, MAE provably identifies a set of latent variables in the hierarchical model.'}\nUrl: https://arxiv.org/pdf/2306.04898",
  "Faculty Name: eric xing\nPaperid: e6dbe34d154591618ef78d56d5e8a50583b5f9d1\nTitle: Contextualized Networks Reveal Heterogeneous Transcriptomic Regulation in Tumors at Sample-Specific Resolution\nYear: 2023\nAbstract: Cancers are shaped by somatic mutations, microenvironment, and patient background, each altering gene expression and regulation in complex ways, resulting in heterogeneous cellular states and dynamics. Inferring gene regulatory network (GRN) models from expression data can help characterize this regulation-driven heterogeneity, but network inference requires many statistical samples, traditionally limiting GRNs to cluster-level analyses that ignore intra-cluster heterogeneity. We propose to move beyond cluster-based analyses by using contextualized learning, a multi-task learning paradigm which allows us to infer sample-specific models using phenotypic, molecular, and environmental information pertinent to the model, encoded as the model\u2019s \u201ccontext\u201d to be conditioned on.",
  "We propose to move beyond cluster-based analyses by using contextualized learning, a multi-task learning paradigm which allows us to infer sample-specific models using phenotypic, molecular, and environmental information pertinent to the model, encoded as the model\u2019s \u201ccontext\u201d to be conditioned on. We unify three network model classes (Correlation, Markov, Neighborhood) and estimate context-specific GRNs for 7997 tumors across 25 tumor types, with each network contextualized by copy number and driver mutation profiles, tumor microenvironment, and patient demographics. Contextualized GRNs provide a structured view of expression dynamics at sample-specific resolution, which reveal co-expression modules in correlation networks (CNs), as well as cliques and independent regulatory elements in Markov Networks (MNs) and Neighborhood Regression Networks (NNs). Our generative modeling approach allows us to predict GRNs for unseen tumor types based on a pan-cancer model of how somatic mutations affect gene regulation. Finally, contextualized networks enable GRN-based precision oncology, explaining known biomarkers in terms of network-mediated effects, and leading to novel subtypings for thyroid, brain, and gastrointestinal tumors that improve survival prognosis.",
  "Finally, contextualized networks enable GRN-based precision oncology, explaining known biomarkers in terms of network-mediated effects, and leading to novel subtypings for thyroid, brain, and gastrointestinal tumors that improve survival prognosis.\nAuthors: Caleb N. Ellington, B. Lengerich, Thomas B.K. Watkins, Jie-Ying Yang, Hanxi Xiao, M. Kellis, Eric P. Xing\nVenue: bioRxiv\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Contextualized networks enable GRN-based precision oncology, explaining known biomarkers in terms of network-mediated effects, and leading to novel subtypings for thyroid, brain, and gastrointestinal tumors that improve survival prognosis.'}\nUrl: https://www.biorxiv.org/content/biorxiv/early/2023/12/04/2023.12.01.569658.full.pdf",
  "Faculty Name: eric xing\nPaperid: e7e497e0a5dc0d1d8be63cbba1b361ff6964dd25\nTitle: Forest Cover Change Monitoring Using Sub-Pixel Mapping with Edge-Matching Correction\nYear: 2023\nAbstract: Sentinel-2 serves as a crucial data source for monitoring forest cover change. In this study, a sub-pixel mapping of forest cover is performed on Sentinel-2 images, downscaling the spatial resolution of the positioned results to 2.5 m, enabling sub-pixel-level forest cover monitoring. A novel sub-pixel mapping with edge-matching correction is proposed on the basis of the Sentinel-2 images, combining edge-matching technology to extract the forest boundary of Jilin-1 images at sub-meter level as spatial constraint information for sub-pixel mapping. This approach enables accurate mapping of forest cover, surpassing traditional pixel-level monitoring in terms of accuracy and robustness. The corrected mapping method allows more spatial detail to be restored at forest boundaries, monitoring forest changes at a smaller scale, which is highly similar to actual forest boundaries on the surface.",
  "This approach enables accurate mapping of forest cover, surpassing traditional pixel-level monitoring in terms of accuracy and robustness. The corrected mapping method allows more spatial detail to be restored at forest boundaries, monitoring forest changes at a smaller scale, which is highly similar to actual forest boundaries on the surface. The overall accuracy of the modified sub-pixel mapping method reaches 93.15%, an improvement of 1.96% over the conventional Sub-pixel-pixel Spatial Attraction Model (SPSAM). Additionally, the kappa coefficient improved by 0.15 to reach 0.892 during the correction. In summary, this study introduces a new method of forest cover monitoring, enhancing the accuracy and efficiency of acquiring forest resource information. This approach provides a fresh perspective in the field of forest cover monitoring, especially for monitoring small deforestation and forest degradation activities.",
  "In summary, this study introduces a new method of forest cover monitoring, enhancing the accuracy and efficiency of acquiring forest resource information. This approach provides a fresh perspective in the field of forest cover monitoring, especially for monitoring small deforestation and forest degradation activities.\nAuthors: Siran Xia, Zhi Yang, Gui Zhang, Xin Wu\nVenue: Forests\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A new method of forest cover monitoring is introduced, enhancing the accuracy and efficiency of acquiring forest resource information and combining edge-matching technology to extract the forest boundary of Jilin-1 images at sub-meter level as spatial constraint information for sub-pixel mapping.'}\nUrl: https://www.mdpi.com/1999-4907/14/9/1776/pdf?version=1693547821",
  "Faculty Name: eric xing\nPaperid: ec772c1f1a994d0377030e3110adc00263b31cfc\nTitle: Analysis of cosmic lithium, beryllium and boron with the DAMPE mission\nYear: 2023\nAbstract: None\nAuthors: A. Parenti, Zhan-Fang Chen, I. De Mitri, M. Stolpovskiy, Li Wu, E. Xu, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, Francesco de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K.",
  "Francesco de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, Luyang Jiang, Wei Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N.",
  "X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, H. Su, Meng Su, H. Sun, Zhigang Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, Sha Wu, Xin Wu, Z. Xia, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu, Zunlei Xu, G. Xue,",
  "Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, Sha Wu, Xin Wu, Z. Xia, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hongying Zhao, Xu Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: None\nUrl: https://pos.sissa.it/444/137/pdf",
  "Faculty Name: eric xing\nPaperid: ec9b461093bbcdccfec86052f7b815547b0650dd\nTitle: Energy-dependent polarization of Gamma-Ray Bursts' prompt emission with the POLAR and POLAR-2 instruments\nYear: 2023\nAbstract: Gamma-Ray Bursts are among the most powerful events in the Universe. Despite half a century of observations of these transient sources, many open questions remain about their nature. Polarization measurements of the GRB prompt emission have long been theorized to be able to answer most of these questions. With the aim of characterizing the polarization of these prompt emissions, a compact Compton polarimeter, called POLAR, has been launched to space in September 2016. Time integrated polarization analysis of the POLAR GRB catalog have shown that the prompt emission is lowly polarized or fully unpolarized. However, time resolved analysis depicted strong hints of an evolving polarization angle within single pulses, washing out the polarization degree in time integrated analyses. Here we will for the first time present energy resolved polarization measurements with the POLAR data.",
  "However, time resolved analysis depicted strong hints of an evolving polarization angle within single pulses, washing out the polarization degree in time integrated analyses. Here we will for the first time present energy resolved polarization measurements with the POLAR data. The novel analysis, performed on several GRBs, will provide new insights and alter our understanding of GRB polarization. The analysis was performed using the 3ML framework to fit polarization parameters versus energy in parallel to the spectral parameters. Although limited by statistics, the results could provide a very relevant input to disentangle between existing theoretical models. In order to gather more statistics per GRB and perform joint time and energy resolved analysis, a successor instrument, called POLAR-2, is under development with a launch window early 2025 to the CSS. After presenting the first energy resolved polarization results of the POLAR mission, we will present the prospects for such measurements with the upcoming POLAR-2 mission.",
  "After presenting the first energy resolved polarization results of the POLAR mission, we will present the prospects for such measurements with the upcoming POLAR-2 mission.\nAuthors: Nicolas De Angelis, J. Burgess, F. Cadoux, J. Greiner, M. Kole, Hancheng Li, S. Mianowski, A. Pollo, Nicolas Produit, D. Rybka, Jianchao Sun, Xin Wu, S. Zhang\nVenue: International Conference on Rebooting Computing\nTldr: None\nUrl: https://pos.sissa.it/444/619/pdf",
  "Faculty Name: eric xing\nPaperid: fdf9f4c09451e847e0bd1b251621ca56e0eb491b\nTitle: Memory-adaptive Depth-wise Heterogenous Federated Learning\nYear: 2023\nAbstract: Federated learning is a promising paradigm that allows multiple clients to collaboratively train a model without sharing the local data. However, the presence of heterogeneous devices in federated learning, such as mobile phones and IoT devices with varying memory capabilities, would limit the scale and hence the performance of the model could be trained. The mainstream approaches to address memory limitations focus on width-slimming techniques, where different clients train subnetworks with reduced widths locally and then the server aggregates the subnetworks. The global model produced from these methods suffers from performance degradation due to the negative impact of the actions taken to handle the varying subnetwork widths in the aggregation phase. In this paper, we introduce a memory-adaptive depth-wise learning solution in FL called FeDepth, which adaptively decomposes the full model into blocks according to the memory budgets of each client and trains blocks sequentially to obtain a full inference model.",
  "In this paper, we introduce a memory-adaptive depth-wise learning solution in FL called FeDepth, which adaptively decomposes the full model into blocks according to the memory budgets of each client and trains blocks sequentially to obtain a full inference model. Our method outperforms state-of-the-art approaches, achieving 5% and more than 10% improvements in top-1 accuracy on CIFAR-10 and CIFAR-100, respectively. We also demonstrate the effectiveness of depth-wise fine-tuning on ViT. Our findings highlight the importance of memory-aware techniques for federated learning with heterogeneous devices and the success of depth-wise training strategy in improving the global model's performance.\nAuthors: Kai Zhang, Yutong Dai, Hongyi Wang, Eric P. Xing, Xun Chen, Lichao Sun\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A memory-adaptive depth-wise learning solution in FL called FeDepth, which adaptively decomposes the full model into blocks according to the memory budgets of each client and trains blocks sequentially to obtain a full inference model, which outperforms state-of-the-art approaches.'}",
  "Url: http://arxiv.org/pdf/2303.04887",
  "List of 2023 Open Access papers by eric xing are:\nSlimPajama-DC: Understanding Data Combinations for LLM Training\nFusing Models with Complementary Expertise\nMaking Scalable Meta Learning Practical\n3D Open-vocabulary Segmentation with Foundation Models\nSqueeze, Recover and Relabel: Dataset Condensation at ImageNet Scale From A New Perspective\nOne-for-All: Generalized LoRA for Parameter-Efficient Fine-tuning\nDefending Against Malicious Behaviors in Federated Learning with Blockchain\nImproved Logical Reasoning of Language Models via Differentiable Symbolic Programming\nJais and Jais-chat: Arabic-Centric Foundation and Instruction-Tuned Open Generative Large Language Models\nKD-DLGAN: Data Limited Image Generation via Knowledge Distillation\n3D Semantic Segmentation in the Wild: Learning Generalized Models for Adverse-Condition Point Clouds\nCuttlefish: Low-Rank Model Training without All the Tuning\nDoes compressing activations help model parallel training?",
  "Federated Learning as Variational Inference: A Scalable Expectation Propagation Approach\nMemory-adaptive Depth-wise Heterogenous Federated Learning\nIdentification of Nonlinear Latent Hierarchical Models\nStyleRF: Zero-Shot 3D Style Transfer of Neural Radiance Fields\nJudging LLM-as-a-judge with MT-Bench and Chatbot Arena\nUnderstanding Masked Autoencoders via Hierarchical Latent Variable Models\nLightSeq: Sequence Level Parallelism for Distributed Training of Long Context Transformers\nLMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset\nFedNAR: Federated Optimization with Normalized Annealing Regularization\nUS residents' preferences for sharing of electronic health record and genetic information: a discrete choice experiment.",
  "Contextualized Policy Recovery: Modeling and Interpreting Medical Decisions with Adaptive Imitation Learning\nGET: a foundation model of transcription across human cell types\nContextualized Networks Reveal Heterogeneous Transcriptomic Regulation in Tumors at Sample-Specific Resolution\nResearch on the Training Path of Live E-commerce Talents Oriented by Industry Development\nRecent progresses on the gamma-ray observations of DAMPE\nEffective Multi-Agent Deep Reinforcement Learning Control with Relative Entropy Regularization\nConvolutional Neural Network Measurement of Non-Fiducial Electrons Cosmic-Rays Using the DAMPE Experiment.",
  "Visible and Infrared Image Fusion of Forest Fire Scenes Based on Generative Adversarial Networks with Multi-Classification and Multi-Level Constraints\nThe split delivery vehicle routing problem with time windows and three-dimensional loading constraints\nA Novel Definition of Fuzzy Difference on Non-increasing Fuzzy Real Numbers\nAnalysis of Individual Cosmic-Ray Proton and Helium Fluxes towards PeV Energies with DAMPE\nThe First LHAASO Catalog of Gamma-Ray Sources\nMachine Learning for Predicting Forest Fire Occurrence in Changsha: An Innovative Investigation into the Introduction of a Forest Fuel Factor\nViT-Based Terrain Recognition System for wearable soft exosuit\nCarbon Flux with DAMPE Using Machine Learning Methods\nAcupuncture Alleviates CUMS-Induced Depression-Like Behaviors by Restoring Prefrontal Cortex Neuroplasticity\nInfluence of sensor array on MS/AE source location accuracy in rock mass\nGpr35 shapes gut microbial ecology to modulate hepatic steatosis.\nAn innovative divertor concept, the fish tail divertor,",
  "An innovative divertor concept, the fish tail divertor, for reducing the surface temperature on the divertor target plate in EAST tokamak experiments\nSpecial issue on wearable robots and intelligent device\nThe response linearity of energy measurement up to TeV in the DAMPE experiment\nCharacterization of Asphaltene Deposition Behavior in Diluted Heavy Oil under High-Pressure Conditions\nPractical Probabilistic Model-based Deep Reinforcement Learning by Integrating Dropout Uncertainty and Trajectory Sampling\nRealization of thousand-second improved confinement plasma with Super I-mode in Tokamak EAST\nA new anti-colon cancer tumor pathway of Phenyllactic acid by reducing adhesion of Fusobacterium nucleatum\nPoverty Alleviation Resettlement and Household Natural Resources Dependence: A Case Study from Ankang Prefecture,",
  "China\nA study of Forbush Decreases effects with DAMPE experiment\nDirect measurement of Ne-Mg-Si nuclei in cosmic rays with DAMPE\nProbing hadronic cross sections in the TeV - PeV regime with DAMPE through machine learning techniques\nPoint-like Source Catalog Observed by DAMPE\nDArk Matter Particle Explorer: 7 years in Space\nObservational signatures of Schwarzschild-MOG black holes in scalar\u2013tensor\u2013vector gravity: images of the accretion disk\nEvaluating emotional labor from a career management perspective\nPenetrating particle ANalyzer (PAN)\nPOLAR-2,",
  "the next generation of GRB polarization detector\nMeasurement of Heavy Nulei beyond Iron in Cosmic Rays with the DAMPE Experiment\nRecent Advances in Decellularized Extracellular Matrix-Based Bioinks for 3D Bioprinting in Tissue Engineering\nEvaluation of thermal comfort in air-conditioned rooms based on structure/control-related parameters and data-mining method\nEffects of Coupling Constants on Chaos of Charged Particles in the Einstein\u2013\u00c6ther Theory\nA PCA-based Method for Electron-Proton Discrimination of the DAMPE Experiment\nCosmic Ray Carbon and Oxygen Flux Measurements with the DAMPE Experiment\nErratum: New insight into the shape coexistence and shape evolution of \n<mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"><mml:mmultiscripts><mml:mi>Yb</mml:mi><mml:mprescripts /><mml:none /><mml:mn>157</mml:mn></mml:mmultiscripts></mml:math>\n [Phys. Rev.",
  "Rev. C \n<b>83</b>\n, 014318 (2011)]\nApplicability of the 0\u20131 test for chaos in magnetized Kerr\u2013Newman spacetimes\nMeasurements of the boron-to-carbon and boron-to-oxygen flux ratios in cosmic rays with DAMPE\nIntegrating symbol similarities with knowledge\u00a0graph embedding for entity alignment: an unsupervised framework\nMeasurement of Ultra-High-Energy Diffuse Gamma-Ray Emission of the Galactic Plane from 10\u00a0TeV to 1\u00a0PeV with LHAASO-KM2A.",
  "Metasurface Deflector Enhanced Grating Coupler for Perfectly Vertical Coupling\nForest Fire Smoke Detection Research Based on the Random Forest Algorithm and Sub-Pixel Mapping Method\nA Magnetically Controlled Guidewire Robot System with Steering and Propulsion Capabilities for Vascular Interventional Surgery\nMeasurement of the p+He energy spectrum with the DAMPE space mission\nStudy of hadronic cross-sections with cosmic ray Carbon from GeV to TeV by the DAMPE experiment\nLatest results on searching for fractionally charged particles with the DAMPE experiment\nEnhancing the Generalization for Text Classification through Fusion of Backward Features\nEvaluation of hydraulic fracturing of horizontal wells in tight reservoirs based on the deep neural network with physical constraints\nExploring Fundamental Particle Acceleration and Loss Processes in Heliophysics through an Orbiting X-ray Instrument in the Jovian System\nForest Cover Change Monitoring Using Sub-Pixel Mapping with Edge-Matching Correction\nAnalysis of cosmic lithium, beryllium and boron with the DAMPE mission\nEnergy-dependent polarization of Gamma-Ray Bursts' prompt emission with the POLAR and POLAR-2 instruments",
  "Eric Nyberg\nProfessor, Language Technologies Institute\nResearch Area\nInformation Extraction, Summarization and Question Answering, Information Retrieval, Text Mining and Analytics, Language Technologies for Education\n\nhttps://www.cs.cmu.edu/~ehn/\n6715 \u2014Gates & Hillman Centers\nEmail ehn@cs.cmu.edu\n412-268-7281",
  "Eric P. Xing\nProfessor (On Leave), Language Technologies Institute\nContact\n8101 \u2014Gates & Hillman Centers\nEmail epxing@andrew.cmu.edu\n412-268-2559\nResearch\nThe major theme of Professor Xing's research lies in the development of machine learning and statistical methodology; especially for building quantitative models and predictive understandings of the evolutionary mechanism, regulatory circuitry, and developmental processes of biological systems; and for building intelligent systems for a wide range of applications in vision, IR and NLP that involves computational learning and reasoning under uncertainty.\n\nFoundations of Statistical Learning, including theory and algorithms for: 1) Time/space varying-coefficient models with evolving structures; 2) Sparse structured input/output models in high-dimensional problems; 3) Nonparametric Bayesian techniques for infinite-dimensional models; 4) RKHS embedding, nonparametric inference, and spectral methods for graphical models; 5) Distributed and online algorithms for optimization, approximate inference, and sampling on massive data.",
  "Large-scale Information & Intelligent System: 1) Development of scalable parallel architecture, protocol, programming interface, generic algorithms and models, for Big Learning; 2) Multi-view latent space models, topics models, and sparse coding for image/text/relational data mining; 3) Evolving structure, stable metrics, and prediction for dynamic social networks, goal-driven network design and optimization; 4) Web-scale image understanding, search, prediction, and storyline synthesis; 5) Information visualization, indexing and storage, web/mobile app development.\n\nComputational Biology: 1) Understanding genome-microenvironment interactions in cancer and embryogenesis via joint analysis of genomic, proteomic, and pathway signaling data; 2) Genetic analysis of population variation, demography and evolution; 3) Statistical inference of genome-transcriptome-phenome association in complex diseases; 4) Personalized diagnosis and treatment of spectrum diseases via next generation sequencing and computational \"omic\" analysis; 5) Biological image and text mining.\n\nhttp://www.cs.cmu.edu/~epxing/",
  "yonatan bisk is an assistant professor, language technologies institute at CMU.\nralf brown is the senior systems scientist/chair of admissions, language technologies institute at CMU.\njamie callan is a professor, language technologies institute at CMU.\njustine cassel is a professor (on leave), language technologies institute at CMU.\nmona diab is the lti director and tenured professor, language technologies institute at CMU.\nfernando diaz is an associate professor, language technologies institute at CMU.\nscott fahlman is the professor emeritus, language technologies institute at CMU.\nrobert frederking is the associate dean for PhD programs and chair for MLT program, language technologies institute at CMU.\ndaniel fried is an assistant professor, language technologies institute at CMU.\nalexander hauptmann is a research professor, language technologies institute at CMU.\ndaphne ippolito is an assistant professor, language technologies institute at CMU.\nlori levin is a research professor, language technologies institute at CMU.\nlei li is an assistant professor, language technologies institute at CMU.\nteruko mitamura is a research professor, language technologies institute at CMU.",
  "lori levin is a research professor, language technologies institute at CMU.\nlei li is an assistant professor, language technologies institute at CMU.\nteruko mitamura is a research professor, language technologies institute at CMU.\nlouis-philippe morency is the leonardo associate professor of computer science (on leave), language technologies institute at CMU.\ndavid mortensen is an assistant research professor, language technologies institute at CMU.\ngraham neubig is an associate professor, language technologies institute at CMU.\neric nyberg is a professor, language technologies institute at CMU.\nkemal oflazer is a teaching professor, language technologies institute at CMU.\nbhiksha raj is a professor, language technologies institute at CMU.\ncarolyn rose is a professor, language technologies institute at CMU.\nalexander rudnicky is the \"research professor emeritus\", language technologies institute at CMU.\nmaarten sap is an assistant professor, language technologies institute at CMU.\nmichael shamos is the \"distinguished career professor\", language technologies institute at CMU.\nrita singh is an associate research professor, language technologies institute at CMU.",
  "maarten sap is an assistant professor, language technologies institute at CMU.\nmichael shamos is the \"distinguished career professor\", language technologies institute at CMU.\nrita singh is an associate research professor, language technologies institute at CMU.\nemma strubell is an assistant professor, language technologies institute at CMU.\nalexander waibel is a professor (on leave), language technologies institute at CMU.\nshinji watanabe is an associate professor, language technologies institute at CMU.\nsean welleck is an assistant professor, language technologies institute at CMU.\neric xing is the professor (on leave), language technologies institute at CMU.\nchenyan xiong is an associate professor, language technologies institute at CMU.\nyiming yang is a professor, language technologies institute at CMU.",
  "Faculty Name: fernando diaz\nPaperid: 023ea96250244e082b961657a95545638d9f8329\nTitle: Cost analysis of three-dimensional radiation therapy versus intensity-modulated chemoradiotherapy for locally advanced cervical cancer in Peruvian citizens\nYear: 2023\nAbstract: Background and objectives The standard treatment for locally advanced cervical cancer (CC) is chemoradiotherapy (CTRT) followed by high-dose-rate brachytherapy (HDRBT). The ideal scenario would be under novel intensity-modulated radiation therapy (IMRT) volumetric-modulated arc therapy (VMAT) radiation techniques over three-dimensional (3D) radiation therapy. However, radiotherapy (RT) centres in low- and middle-income countries have limited equipment for teletherapy services like HDRBT. This is why the 3D modality is still in use. The objective of this study was to analyse costs in a comparison of 3D versus IMRT versus VMAT based on clinical staging.",
  "This is why the 3D modality is still in use. The objective of this study was to analyse costs in a comparison of 3D versus IMRT versus VMAT based on clinical staging. Materials and methods From 02/01/2022 to 05/01/2023 a prospective registry of the costs for oncological management was carried out for patients with locally advanced CC who received CTRT \u00b1 HDRBT. This included the administration of radiation with chemotherapy. The cost associated with patient and family transfers and hours in the hospital was also identified. These expenses were used to project the direct and indirect costs of 3D versus IMRT versus VMAT. Results The treatment regimens for stage IIIC2, including 3D and novel techniques, are those with the highest costs. The administration of 3D RT for IIIC2 and novel IMRT or VMAT techniques, is $3,881.69, $3,374.76, and $2,862.80, respectively.",
  "The administration of 3D RT for IIIC2 and novel IMRT or VMAT techniques, is $3,881.69, $3,374.76, and $2,862.80, respectively. The indirect cost from stage IIB to IIIC1 in descending order is IMRT, 3D and VMAT, but in IIIC2 the novel technique regimens reduce by up to 33.99% compared to 3D. Conclusion In RT centres with an available supply of RT equipment, VMAT should be preferred over IMRT/3D since it reduces costs and toxicity. However, in RT centres where demand exceeds supply in the VMAT technique planning systems, the use of 3D teletherapy over IMRT/VMAT could continue to be used in patients with stage IIB to IIIC1.",
  "However, in RT centres where demand exceeds supply in the VMAT technique planning systems, the use of 3D teletherapy over IMRT/VMAT could continue to be used in patients with stage IIB to IIIC1.\nAuthors: Jos\u00e9 Fernando Robles D\u00edaz\nVenue: ecancermedicalscience\nTldr: {'model': 'tldr@v2.0.0', 'text': 'In RT centres with an available supply of RT equipment, VMAT should be preferred over IMRT/3D since it reduces costs and toxicity and in RT centres where demand exceeds supply in the VMAT technique planning systems, the use of 3D teletherapy over IM RT/VMAT could continue to be used in patients with stage IIB to IIIC1.'}\nUrl: https://ecancer.org/en/journal/article/1531-cost-analysis-of-three-dimensional-radiation-therapy-versus-intensitymodulated-chemoradiotherapy-for-locally-advanced-cervical-cancer-in-peruvian-citizens/pdf",
  "Faculty Name: fernando diaz\nPaperid: 11c44e8f63b8fb6e726cbf9c1fcd56b21053df44\nTitle: PLATFORM BASED ON DATA ANALYTICS AND STATISTICS TO PREDICT AND MONITOR THE INTEGRATED AND INTELLIGENT ENERGY MANAGEMENT OF ENERGY-INTENSIVE BUILDINGS\nYear: 2023\nAbstract: ABSTRACT: \nCurrently, large buildings are often equipped with building management systems (BMS), but either because of the type of control or the difficulty of interacting with them, they do not allow optimization policies to be implemented. As far as energy efficiency is concerned, optimization strategies often result from the analysis of monitored data by a specialist, which slows down both decision making and implementation. \nAware of this problem, this project arises, in which a complementary platform to the BMS systems is developed to provide them with greater intelligence.",
  "As far as energy efficiency is concerned, optimization strategies often result from the analysis of monitored data by a specialist, which slows down both decision making and implementation. \nAware of this problem, this project arises, in which a complementary platform to the BMS systems is developed to provide them with greater intelligence. For its design, the Puerta del Hierro Hospital in Madrid has been taken as a pilot case, from the data captured by its own BMS and using the 6 SIGMA methodology, algorithms have been developed capable of optimizing the production systems themselves, thus helping to make up for the weaknesses in the operation of the systems and reducing energy consumption, minimizing the environmental impact and allowing to obtain the maximum performance of its assets. \nThe platform uses the information gathered by the BMS and weather forecasts to predict a building's energy demand and, based on this, optimize energy production at any given moment.\nKeywords: Commissioning, Energy efficiency, Smart building, Degree-days, BMS, 6 SIGMA.",
  "The platform uses the information gathered by the BMS and weather forecasts to predict a building's energy demand and, based on this, optimize energy production at any given moment.\nKeywords: Commissioning, Energy efficiency, Smart building, Degree-days, BMS, 6 SIGMA.\nAuthors: Juan Manuel GALLARDO SALAZAR, Alicia Desiree MANCERAS RODRIGUEZ, Fernando DIAZ RODRIGUEZ, Fernando MORENO ABRAS, Rogelio ZUBIZARRETA JIMENEZ\nVenue: DYNA ENERGIA Y SOSTENIBILIDAD\nTldr: None\nUrl: http://www.dyna-energia.com/Reports/ArticulosMasDescargados.aspx",
  "Faculty Name: fernando diaz\nPaperid: 217fce1552139ca00ac113b2124a36365fa579ca\nTitle: Impact of outpatient radiotherapy on direct non-medical cost in patients in the Central Macro Region of Peru 2021\nYear: 2023\nAbstract: Background Financial toxicity arises in cancer patients due to the objective financial burden of the disease or treatment, being associated with worse clinical outcomes. Direct non-medical spending on cancer patients undergoing radiotherapy in Peru under its publicly funded health system has not been described. Objective To know the expenses related to the transfer of the radiotherapy outpatient. Methodology For patients who started radiation therapy in 2021, treatment demographics and expenses related to transporting the patient from home to the radiation therapy center were prospectively collected. Association and connection tests were used, such as the Mann\u2013Whitney/Kruskal\u2013Wallis U-test and Spearman\u2019s Rho. A value of p < 0.05 is considered statistically significant. Results 398 patients were collected, with average weekly expenses for transportation, lodging and food of $17.04, $6.69 and $45.91, respectively.",
  "A value of p < 0.05 is considered statistically significant. Results 398 patients were collected, with average weekly expenses for transportation, lodging and food of $17.04, $6.69 and $45.91, respectively. Confirmation was positive between weekly spending and remoteness, likewise it was negative between effective teletherapy and remoteness, both analyses being statistically significant. Conclusion The expense associated with transfer for radiotherapy is high, exceeding the average monthly income of the patient, as a consequence they have a worse therapeutic result, and may cause financial toxicity in cancer patients.\nAuthors: Jos\u00e9 Fernando Robles D\u00edaz\nVenue: ecancermedicalscience\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The expense associated with transfer for radiotherapy is high, exceeding the average monthly income of the patient, as a consequence they have a worse therapeutic result, and may cause financial toxicity in cancer patients.'}\nUrl: https://ecancer.org/en/journal/article/1580-impact-of-outpatient-radiotherapy-on-direct-non-medical-cost-in-patients-in-the-central-macro-region-of-peru-2021/pdf",
  "Faculty Name: fernando diaz\nPaperid: 414fc2423dbd9bcfd7870ea856485f51a4fc3e62\nTitle: Comparative Efficacy of First and Second Generation long-acting injectable antipsychotic upon schizophrenic patients: a systematic review and network meta-analysis\nYear: 2023\nAbstract: Introduction: Long-acting injectable antipsychotics (LAIA) can lead the course of treatment with the potential to increase adherence in schizophrenia treatment. The objective of this systematic review and network meta-analysis is to find the efficacy of SG-LAIAs, FG-LAIAs compared to each other for schizophrenia. \nMethods: This systematic review and network meta-analysis was designed following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA), with registration in Prospero (ID CRD42019128700). A database in MEDLINE, EMBASE, Web of Science, and Scopus, until June 17, 2020, with an actualization from June 2020 to September 14, 2021.",
  "A database in MEDLINE, EMBASE, Web of Science, and Scopus, until June 17, 2020, with an actualization from June 2020 to September 14, 2021.\u00a0 \nResults: The SMDs for the four (80%) antipsychotics that significantly reduced PANSS score compared with placebo ranged between \u20130\u00b772 (95% CrI \u20130\u00b799 to \u20130\u00b746) for haloperidol to \u20130\u00b745 (\u20130\u00b754 to \u20130\u00b737) for paliperidone. 8 studies reported usable results for negative symptoms and positive symptoms (Four antipsychotics compared). The SMDs for the three (75%) antipsychotics that significantly reduced negative symptoms compared with placebo ranged between \u20130\u00b740 (95% CrI \u20130\u00b753 to \u20130\u00b726) for aripiprazole to \u20130\u00b732 (\u20130\u00b744 to \u20130\u00b719) for risperidone.",
  "The SMDs for the three (100%) drugs that significantly reduced positive symptoms compared with placebo ranged between \u20130\u00b750 (95% CrI \u20130\u00b763 to \u20130\u00b737) for aripiprazole to \u20130\u00b719 (\u20130\u00b757 to 0\u00b720) for zuclopenthixol. \nDiscussion: We found evidence suggesting that all long-acting injectable antipsychotics, except for zuclopenthixol, are equally efficient in reducing symptoms in schizophrenia, \nConclusions: Most LAIAs are equally efficient at reducing overall symptoms, and differences between individual LAIAs are non-significant.",
  "Discussion: We found evidence suggesting that all long-acting injectable antipsychotics, except for zuclopenthixol, are equally efficient in reducing symptoms in schizophrenia, \nConclusions: Most LAIAs are equally efficient at reducing overall symptoms, and differences between individual LAIAs are non-significant.\nAuthors: Erasmo Sauceo-Uribe, P. J. Gonz\u00e1lez-Mallozzi, Ra\u00fal Ricardo Medrano-Garza, Fernando D\u00edaz Gonz\u00e1lez-Colmenero, Farid Carranza-Navarro, P. L. Castillo-Morales, Paloma C. Leyva-Camacho, Yessica Herrera-Montemayor, Mauricio Vidal-Tijerina, M. K. Enr\u00edquez-Navarro, Samantha B. Medrano, Stefan Fern\u00e1ndez-Zambrano, Claudia Magdalena Mancias-Guerra, Claudia Lizeth Saucedo-Mancias, Manuel Ramiro Sanchez-Ramirez\nVenue: Archivos de Neurociencias\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Evidence is found suggesting that all long-acting injectable antipsychotics, except for zuclopenthixol, are equally efficient in reducing symptoms in schizophrenia, and differences between individual LAIAs are non-significant.'}",
  "Url: https://archivosdeneurociencias.org/index.php/ADN/article/download/432/787",
  "Faculty Name: fernando diaz\nPaperid: 442b8568036949fc51734ef47f41313d9afef6db\nTitle: Discordance Between Social Vulnerability and Cancer-Related Mortality in Border Counties - A Letter to the Editor Regarding \u201cLocal Social Vulnerability as a Predictor for Cancer-Related Mortality Among US Counties\u201d\nYear: 2023\nAbstract: This letter to the editor remarks on results of a recently published study and highlights the need for multinational and interinstitutional registries so health departments in the US and Latin American countries can accurately capture cancer incidence and mortality data.\nAuthors: M. LaPelusa, F. Diaz, Patricia Mae G Santos, H. Verduzco-Aguirre, E. Soto-P\u00e9rez-de-Celis\nVenue: The Oncologist\nTldr: {'model': 'tldr@v2.0.0', 'text': None}\nUrl: https://academic.oup.com/oncolo/advance-article-pdf/doi/10.1093/oncolo/oyad271/51791454/oyad271.pdf",
  "Faculty Name: fernando diaz\nPaperid: 53e57edca377b168c010cfed423f1b90f56007a4\nTitle: Understanding of the Effect of the Adsorption of Atom and Cluster Silver on Chitosan: An In Silico Analysis\nYear: 2023\nAbstract: In this work, the structural, electronic, and optical stability properties of the chitosan monomer (M-Ch) and atomic silver complex are reported, as well as a unitary cell of a silver cluster in the gas phase and acetic acid. The generalized gradient approximation HSEh1PBE/def2-TZVPP50 results established the structures\u2019 anionic charge (Q = \u22121|e|) and the doublet state (M = 2). The high cohesive energy indicates structural stability, and the quantum-mechanical descriptors show a high polarity and low chemical reactivity. Also, the quantum-mechanical descriptors present a low work function that shows the structures are suitable for applications in light-emitting diodes. Finally, the electronic behavior observed by the |HOMO-LUMO| gap energy changes depending on the atomic silver incorporated into the complex.",
  "Also, the quantum-mechanical descriptors present a low work function that shows the structures are suitable for applications in light-emitting diodes. Finally, the electronic behavior observed by the |HOMO-LUMO| gap energy changes depending on the atomic silver incorporated into the complex.\nAuthors: A. Rodr\u00edguez-Ju\u00e1rez, Veronica Carmona-\u00c1lvarez, F. D\u00edaz-Monge, E. Chigo-Anota, O. Zaca-Moran\nVenue: Molecules\nTldr: None\nUrl: https://www.mdpi.com/1420-3049/28/15/5809/pdf?version=1690899554",
  "Faculty Name: fernando diaz\nPaperid: 55704caaf3d31e1795a1ca0c3bed9e77ae3a3c95\nTitle: Best-Case Retrieval Evaluation: Improving the Sensitivity of Reciprocal Rank with Lexicographic Precision\nYear: 2023\nAbstract: Across a variety of ranking tasks, researchers use reciprocal rank to measure the effectiveness for users interested in exactly one relevant item. Despite its widespread use, evidence suggests that reciprocal rank is brittle when discriminating between systems. This brittleness, in turn, is compounded in modern evaluation settings where current, high-precision systems may be difficult to distinguish. We address the lack of sensitivity of reciprocal rank by introducing and connecting it to the concept of best-case retrieval, an evaluation method focusing on assessing the quality of a ranking for the most satisfied possible user across possible recall requirements. This perspective allows us to generalize reciprocal rank and define a new preference-based evaluation we call lexicographic precision or lexiprecision. By mathematical construction, we ensure that lexiprecision preserves differences detected by reciprocal rank, while empirically improving sensitivity and robustness across a broad set of retrieval and recommendation tasks.",
  "This perspective allows us to generalize reciprocal rank and define a new preference-based evaluation we call lexicographic precision or lexiprecision. By mathematical construction, we ensure that lexiprecision preserves differences detected by reciprocal rank, while empirically improving sensitivity and robustness across a broad set of retrieval and recommendation tasks.\nAuthors: Fernando Diaz\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work addresses the lack of sensitivity of reciprocal rank by introducing and connecting it to the concept of best-case retrieval, an evaluation method focusing on assessing the quality of a ranking for the most satisfied possible user across possible recall requirements.'}\nUrl: http://arxiv.org/pdf/2306.07908",
  "Faculty Name: fernando diaz\nPaperid: 567f6bc975deb3d728feec9bfcf7d4036ceabb12\nTitle: Fairness Through Domain Awareness: Mitigating Popularity Bias For Music Discovery\nYear: 2023\nAbstract: As online music platforms grow, music recommender systems play a vital role in helping users navigate and discover content within their vast musical databases. At odds with this larger goal, is the presence of popularity bias, which causes algorithmic systems to favor mainstream content over, potentially more relevant, but niche items. In this work we explore the intrinsic relationship between music discovery and popularity bias. To mitigate this issue we propose a domain-aware, individual fairness-based approach which addresses popularity bias in graph neural network (GNNs) based recommender systems. Our approach uses individual fairness to reflect a ground truth listening experience, i.e., if two songs sound similar, this similarity should be reflected in their representations. In doing so, we facilitate meaningful music discovery that is robust to popularity bias and grounded in the music domain. We apply our BOOST methodology to two discovery based tasks, performing recommendations at both the playlist level and user level.",
  "In doing so, we facilitate meaningful music discovery that is robust to popularity bias and grounded in the music domain. We apply our BOOST methodology to two discovery based tasks, performing recommendations at both the playlist level and user level. Then, we ground our evaluation in the cold start setting, showing that our approach outperforms existing fairness benchmarks in both performance and recommendation of lesser-known content. Finally, our analysis explains why our proposed methodology is a novel and promising approach to mitigating popularity bias and improving the discovery of new and niche content in music recommender systems.\nAuthors: Rebecca Salganik, Fernando Diaz, G. Farnadi\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes a domain-aware, individual fairness-based approach which addresses popularity bias in graph neural network (GNNs) based recommender systems and applies the BOOST methodology to two discovery based tasks, performing recommendations at both the playlist level and user level.'}\nUrl: https://arxiv.org/pdf/2308.14601",
  "Faculty Name: fernando diaz\nPaperid: 574fe6378d43b1f1f2e8467bda1574292d6c586d\nTitle: Females translate male mRNA transferred during mating\nYear: 2023\nAbstract: Although RNA is found in the seminal fluid of diverse organisms, it is unknown whether this RNA is functional within females. Here, we develop an experimental proteomic method called VESPA (Variant Enabled SILAC Proteomic Analysis) to test the hypothesis that Drosophila male seminal fluid RNA is translated by females. We find strong evidence for 67 male-derived, female-translated proteins (mdFTPs) in female lower reproductive tracts at six hours postmating, many with predicted functions relevant to reproduction. Gene knockout experiments indicate that genes coding for mdFTPs play diverse roles in postmating interactions, with effects on fertilization efficiency, and the formation and persistence of the insemination reaction mass, a trait hypothesized to be involved in sexual conflict. These findings advance our understanding of reproduction by revealing a novel mechanism of postmating molecular interactions between the sexes that strengthens and extends male influences on reproductive outcomes in previously unrecognized ways.",
  "These findings advance our understanding of reproduction by revealing a novel mechanism of postmating molecular interactions between the sexes that strengthens and extends male influences on reproductive outcomes in previously unrecognized ways. Given the diverse species known to carry RNA in seminal fluid, this discovery has broad significance for understanding molecular mechanisms of cooperation and conflict during reproduction.\nAuthors: Luciano M. Matzkin, J. Bono, Helen K. Pigage, Carson W. Allan, Fernando D\u00edaz, J. McCoy, Clinton C. Green, Jeffrey B. Callan, Stephen P. Delahunt\nVenue: bioRxiv\nTldr: {'model': 'tldr@v2.0.0', 'text': 'An experimental proteomic method is developed to test the hypothesis that Drosophila male seminal fluid RNA is translated by females, finding strong evidence for 67 male-derived, female-translated proteins in female lower reproductive tracts at six hours postmating, many with predicted functions relevant to reproduction.'}\nUrl: N/A",
  "Faculty Name: fernando diaz\nPaperid: 5e1ba2d4416333dd6f6a31a4ff4221b40dfb74b1\nTitle: Overview of the TREC 2021 Fair Ranking Track\nYear: 2023\nAbstract: The TREC Fair Ranking Track aims to provide a platform for participants to develop and evaluate novel retrieval algorithms that can provide a fair exposure to a mixture of demographics or attributes, such as ethnicity, that are represented by relevant documents in response to a search query. For example, particular demographics or attributes can be represented by the documents' topical content or authors. The 2021 Fair Ranking Track adopted a resource allocation task. The task focused on supporting Wikipedia editors who are looking to improve the encyclopedia's coverage of topics under the purview of a WikiProject. WikiProject coordinators and/or Wikipedia editors search for Wikipedia documents that are in need of editing to improve the quality of the article.",
  "The task focused on supporting Wikipedia editors who are looking to improve the encyclopedia's coverage of topics under the purview of a WikiProject. WikiProject coordinators and/or Wikipedia editors search for Wikipedia documents that are in need of editing to improve the quality of the article. The 2021 Fair Ranking track aimed to ensure that documents that are about, or somehow represent, certain protected characteristics receive a fair exposure to the Wikipedia editors, so that the documents have an fair opportunity of being improved and, therefore, be well-represented in Wikipedia. The under-representation of particular protected characteristics in Wikipedia can result in systematic biases that can have a negative human, social, and economic impact, particularly for disadvantaged or protected societal groups.\nAuthors: Asia J. Biega, Fernando Diaz, Michael D. Ekstrand, Sebastian Kohlmeier\nVenue: Text Retrieval Conference\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The 2021 Fair Ranking track aimed to ensure that documents that are about, or somehow represent, certain protected characteristics receive a fair exposure to the Wikipedia editors, so that the documents have an fair opportunity of being improved and, therefore, be well-represented in Wikipedia.'}",
  "Url: http://arxiv.org/pdf/2302.10856",
  "Faculty Name: fernando diaz\nPaperid: 70753c30b5eef5fd9bf8673cee4b586105f47c20\nTitle: Cross-border utilization of cancer care by patients in the US and Mexico \u2013 a survey of Mexican oncologists\nYear: 2023\nAbstract: None\nAuthors: M. LaPelusa, H. Verduzco-Aguirre, F. Diaz, F. Aldaco, E. Soto-P\u00e9rez-de-Celis\nVenue: Globalization and Health\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The type of care sought, as well as the reasons for seeking it, differ between US and Mexico-based patients, highlighting unmet needs for patients with cancer in both countries and calling for policy changes to improve outcomes in border regions.'}\nUrl: https://globalizationandhealth.biomedcentral.com/counter/pdf/10.1186/s12992-023-00983-0",
  "Faculty Name: fernando diaz\nPaperid: a76e7e394112a26116446a2920467a2702de5f56\nTitle: Pre-vaccination CD56 dimCD16 +NK cell abundance and T h1/T h17 ratio predict responsiveness to conjugated pneumococcal vaccine in older adults\nYear: 2023\nAbstract: \n Older adults are at high risk of morbidity and mortality from Streptococcus pneumoniae (pneumococcus) infections. There are two available vaccines for pneumococcus: T-cell-independent capsular polysaccharide Pneumovax and T-cell-dependent conjugated Prevnar. However, how older adults respond to these vaccines at the cellular level and whether there are baseline predictors for responsiveness, is not known. To address this, we recruited older adults (60+ yrs), who are vaccinated with Prevnar (n=19) or Pneumovax (n=20). Vaccine responsiveness was quantified using opsonophagocytic assays, which revealed that both vaccines induce strong responses. Interestingly, sex was associated with Prevnar responses, where women mounted stronger responses than men.",
  "Vaccine responsiveness was quantified using opsonophagocytic assays, which revealed that both vaccines induce strong responses. Interestingly, sex was associated with Prevnar responses, where women mounted stronger responses than men. Pre-vaccination flow cytometry data showed that Th1 cells positively, Th17 cells negatively correlated with Prevnar responses. Furthermore, bulk RNA-seq data from PBMCs showed that baseline expression levels of cytotoxic genes (NCAM1, GNLY, PRF1) are negatively associated with Prevnar responses. scRNA-seq data from top and bottom responders showed that this cytotoxicity signature stems from CD56 dimCD16 +NK cells, where having more of these cells are detrimental to responses. Interestingly, women had significantly higher Th1, lower Th17 and lower CD16+ NK cells compared to men, which explains their stronger Prevnar responses. This is the first study to uncover older adults\u2019 responses to two pneumococcal vaccines; we uncovered an activated immune phenotype of Th and NK cell subsets that impedes responses to Prevnar. Interestingly, this phenotype only affected adjuvanted vaccine responses, providing an opportunity for precision vaccinology for pneumococcus disease.",
  "Interestingly, this phenotype only affected adjuvanted vaccine responses, providing an opportunity for precision vaccinology for pneumococcus disease.\n Supported by grants from National Institute of Health (R35 GM124922, R01 AG052608) and JAX cancer center (JAX-CC).\nAuthors: S. Ravichandran, F. E. D\u00edaz, Onur E Karakaslar, R. Marches, Robert J. Rossi, M. Nahm, D. Chaussabel, G. Kuchel, J. Banchereau, D. Ucar\nVenue: Journal of Immunology\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This is the first study to uncover older adults\u2019 responses to two pneumococcal vaccines; an activated immune phenotype of Th and NK cell subsets that impedes responses to Prevnar is uncovered.'}\nUrl: https://journals.aai.org/jimmunol/article-pdf/210/1_Supplement/252.03/1632514/252_03.pdf",
  "Faculty Name: fernando diaz\nPaperid: b79041565cbd9da52daf97f73c4097eed0afd723\nTitle: Concomitant inhibition of PPAR\u03b3 and mTORC1 induces the differentiation of human monocytes into highly immunogenic dendritic cells.\nYear: 2023\nAbstract: None\nAuthors: F. Erra D\u00edaz, I. Mazzitelli, Luc\u00eda Bleichmar, C. Melucci, Asa Thibodeau, Tom\u00e1s Dalotto Moreno, R. Marches, G. Rabinovich, D. Ucar, J. Geffner\nVenue: Cell Reports\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is found that simultaneous inhibition of PPAR\u03b3 and the nutrient sensor mammalian target of rapamycin complex 1 (mTORC1) induces the differentiation of Mo-DCs with stronger phenotypic stability, superior immunogenicity, and a transcriptional profile characterized by a strong type I interferon signature.'}\nUrl: N/A",
  "Faculty Name: fernando diaz\nPaperid: cbe6b6d58254ee2434d091ed7b8466e444ef892a\nTitle: Clusterin protects mature dendritic cells from reactive oxygen species mediated cell death\nYear: 2023\nAbstract: ABSTRACT Dendritic cells (DCs) play a key role in the induction of the adaptive immune response. They capture antigens in peripheral tissues and prime na\u00efve T lymphocytes, triggering the adaptive immune response. In the course of inflammatory processes DCs face stressful conditions including hypoxia, low pH and high concentrations of reactive oxygen species (ROS), among others. How DCs survive under these adverse conditions remain poorly understood. Clusterin is a protein highly expressed by tumors and usually associated with bad prognosis. It promotes cancer cell survival by different mechanisms such as apoptosis inhibition and promotion of autophagy. Here, we show that, upon maturation, human monocyte-derived DCs (MoDCs) up-regulate clusterin expression. Clusterin protects MoDCs from ROS-mediated toxicity, enhancing DC survival and promoting their ability to induce T cell activation.",
  "Here, we show that, upon maturation, human monocyte-derived DCs (MoDCs) up-regulate clusterin expression. Clusterin protects MoDCs from ROS-mediated toxicity, enhancing DC survival and promoting their ability to induce T cell activation. In line with these results, we found that clusterin is expressed by a population of mature LAMP3+ DCs, called mregDCs, but not by immature DCs in human cancer. The expression of clusterin by intratumoral DCs was shown to be associated with a transcriptomic profile indicative of cellular response to stress. These results uncover an important role for clusterin in DC physiology.",
  "The expression of clusterin by intratumoral DCs was shown to be associated with a transcriptomic profile indicative of cellular response to stress. These results uncover an important role for clusterin in DC physiology.\nAuthors: \u00c1lvaro L\u00f3pez Malizia, A. Merlotti, P. Bont\u00e9, Melina Sager, Yago Arribas De Sandoval, C. Goudot, F. Erra D\u00edaz, Pehu\u00e9n Pereyra-Gerber, A. Ceballos, S. Amigorena, J. Geffner, J. Sabatte\u0301\nVenue: Oncoimmunology\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is found that clusterin is expressed by a population of mature LAMP3+ DCs, called mregDCs, but not by immature DCs in human cancer, and this results uncover an important role for clusterin in DC physiology.'}\nUrl: https://www.tandfonline.com/doi/pdf/10.1080/2162402X.2023.2294564?needAccess=true",
  "Faculty Name: fernando diaz\nPaperid: cda03f3d8b1eff888174c0dc4262e1dc73be2d49\nTitle: Population well-being and the COVID-19 vaccination program in Chile: evidence from Google Trends\nYear: 2023\nAbstract: None\nAuthors: F. D\u00edaz, Pablo A. Henr\u00edquez, Nicol\u00e1s Hardy, D. Ponce\nVenue: Public Health\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is found that mental well-being responds positively to the percentage of inoculated people, and this phenomenon appears to be permanent and affected by socioeconomic status, with the wealthier population experiencing greater improvements than the less wealthy.'}\nUrl: N/A",
  "Faculty Name: fernando diaz\nPaperid: cda71255a5e02e0d3a5fe99e711caea09417bf3f\nTitle: Transcriptional Misexpression in Hybrids between Species Linked by Gene Flow Is Associated With Patterns of Sequence Divergence\nYear: 2023\nAbstract: Abstract The extent to which hybridization disrupts a gene's pattern of expression likely governs its propensity for introgression, whereas its extent of molecular divergence can itself underlie such disruption. Together, these phenomena shape the landscape of sequence and transcriptional divergence across the genome as species diverge. To understand this process, we characterize gene expression inheritance, regulatory divergence, and molecular divergence in the reproductive transcriptomes of species linked by gene flow: the fruit flies Anastrepha fraterculus and A. obliqua, which show evidence of gene flow despite clear evolutionary divergence. We find that their transcriptional patterns are a mosaic between those typically observed within and between allopatric species. Transcripts showing transgressive expression in hybrids or cis-regulatory divergence between species are associated with greater sequence divergence.",
  "We find that their transcriptional patterns are a mosaic between those typically observed within and between allopatric species. Transcripts showing transgressive expression in hybrids or cis-regulatory divergence between species are associated with greater sequence divergence. This may reflect pleiotropic constraints that make them resistant to gene flow or they may be more likely to experience divergent selection. Although these more divergent gene classes are likely to be important contributors to species differences, they are relatively rare. Instead, most differentially regulated transcripts, including those linked to reproduction, show high degrees of dominance in hybrids and trans-regulated divergence between species, suggesting widespread genetic compatibility that potentially allowed for introgression. These findings provide insights into how postzygotic isolating mechanisms might evolve in the presence of gene flow: regions showing cis-regulatory divergence or transgressive expression contribute to reproductive isolation, whereas regions with dominant expression and trans-regulatory divergence allow for introgression. These patterns create a genomic mosaic of transcriptional regulation that is tied to sequence divergence.",
  "These patterns create a genomic mosaic of transcriptional regulation that is tied to sequence divergence.\nAuthors: Fernando D\u00edaz, J. Wolf, R. D. de Brito\nVenue: Genome Biology and Evolution\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Analysis of reproductive transcriptomes of fruit flies linked by gene flow provides insights into how postzygotic isolating mechanisms might evolve in the presence of gene flow: regions showing cis-regulatory divergence or transgressive expression contribute to reproductive isolation, whereas regions with dominant expression and trans-regulations allow for introgression.'}\nUrl: https://academic.oup.com/gbe/article-pdf/15/5/evad071/50385144/evad071.pdf",
  "Faculty Name: fernando diaz\nPaperid: e59a99c198ee4012e34fd79d7cb33be75d0a120d\nTitle: Amplification-free, highly sensitive electrochemical DNA-based sensor for simultaneous detection of stx1 and stx2 genes of Shiga toxin-producing E. coli (STEC)\nYear: 2023\nAbstract: None\nAuthors: L. Wasiewska, F. Diaz, S. Teixeira, C. Burgess, G. Duffy, A. O\u2019Riordan\nVenue: Electrochimica Acta\nTldr: None\nUrl: N/A",
  "Faculty Name: fernando diaz\nPaperid: edde6245557416c5911a5e29c5ea93bf2deabf1f\nTitle: A Bibliometric Analysis on Cooperatives in Circular Economy and Eco-Innovation Studies\nYear: 2023\nAbstract: Cooperatives address societal challenges embracing values beyond mere profit-oriented production. Considering the ongoing shift to achieve efficient use of resources and increased circularity, cooperatives should be better equipped to incorporate circular economy (CE) and eco-innovation (EI) into their strategies (compared to regular enterprises). This paper reviews the scholarly literature focusing on the application of CE and EI within cooperative studies with the aim to understand the relationships between these topics, identify the existing scholarly communities, and to observe salient research themes. This study refined the method of van den Hoven and Rubalcaba (2016) to conduct a two-step bibliographic review of documents: a thematic analysis of citation data from Scopus (including a manual review of 16 papers) was followed by a bibliometric analysis of 101 documents from Web of Science (using R-Studio\u2019s Biblioshiny).",
  "Our results identified three intellectual clusters of cooperative studies focusing on the downstream of CE: (1) industrial ecology; (2) recycling; and (3) waste management. Our study also revealed an emerging scholarly field focused on cooperatives and CE, and with little attention to EI. These findings aim at catalyzing the integration of cooperatives more effectively into scholarly discussions, suggesting that environmental sustainability should be recognized as an additional principle of the cooperative identity\u2014providing a wider perspective that enhances interest in the research of these topics and their interconnections.\nAuthors: Asia Guerreschi, Fernando J. D\u00edaz L\u00f3pez\nVenue: Sustainability\nTldr: None\nUrl: https://www.mdpi.com/2071-1050/15/21/15595/pdf?version=1699005682",
  "List of 2023 Open Access papers by fernando diaz are:\nAmplification-free, highly sensitive electrochemical DNA-based sensor for simultaneous detection of stx1 and stx2 genes of Shiga toxin-producing E. coli (STEC)\nDiscordance Between Social Vulnerability and Cancer-Related Mortality in Border Counties - A Letter to the Editor Regarding \u201cLocal Social Vulnerability as a Predictor for Cancer-Related Mortality Among US Counties\u201d\nCross-border utilization of cancer care by patients in the US and Mexico \u2013 a survey of Mexican oncologists\nFemales translate male mRNA transferred during mating\nTranscriptional Misexpression in Hybrids between Species Linked by Gene Flow Is Associated With Patterns of Sequence Divergence\nPopulation well-being and the COVID-19 vaccination program in Chile: evidence from Google Trends\nPre-vaccination CD56 dimCD16 +NK cell abundance and T h1/T h17 ratio predict responsiveness to conjugated pneumococcal vaccine in older adults\nBest-Case Retrieval Evaluation: Improving the Sensitivity of Reciprocal Rank with Lexicographic Precision\nFairness Through Domain Awareness: Mitigating Popularity Bias For Music Discovery\nOverview of the TREC 2021 Fair Ranking Track\nCost analysis of three-dimensional radiation",
  "vaccine in older adults\nBest-Case Retrieval Evaluation: Improving the Sensitivity of Reciprocal Rank with Lexicographic Precision\nFairness Through Domain Awareness: Mitigating Popularity Bias For Music Discovery\nOverview of the TREC 2021 Fair Ranking Track\nCost analysis of three-dimensional radiation therapy versus intensity-modulated chemoradiotherapy for locally advanced cervical cancer in Peruvian citizens\nImpact of outpatient radiotherapy on direct non-medical cost in patients in the Central Macro Region of Peru 2021\nPLATFORM BASED ON DATA ANALYTICS AND STATISTICS TO PREDICT AND MONITOR THE INTEGRATED AND INTELLIGENT ENERGY MANAGEMENT OF ENERGY-INTENSIVE BUILDINGS\nComparative Efficacy of First and Second Generation long-acting injectable antipsychotic upon schizophrenic patients: a systematic review and network meta-analysis\nA Bibliometric Analysis on Cooperatives in Circular Economy and Eco-Innovation Studies\nConcomitant inhibition of PPAR\u03b3 and mTORC1 induces the differentiation of human monocytes into highly immunogenic dendritic cells.",
  "injectable antipsychotic upon schizophrenic patients: a systematic review and network meta-analysis\nA Bibliometric Analysis on Cooperatives in Circular Economy and Eco-Innovation Studies\nConcomitant inhibition of PPAR\u03b3 and mTORC1 induces the differentiation of human monocytes into highly immunogenic dendritic cells.\nClusterin protects mature dendritic cells from reactive oxygen species mediated cell death\nUnderstanding of the Effect of the Adsorption of Atom and Cluster Silver on Chitosan: An In Silico Analysis",
  "Fernando Diaz\nAssociate Professor, Language Technologies Institute\nResearch Area: Information Retrieval, Text Mining and Analytics, Natural Language Processing and Computational Linguistics\nResearch: \nInformation Retrieval: Recommender Systems, Retrieval and Ranking Models\nNatural Language Processing: Fairness and Ethics in Language Technology, Creativity, Evaluation\nPersonal Website: https://841.io/\nContact:\nEmail : diazf@cmu.edu",
  "Faculty Name: graham neubig\nPaperid: 03c7f61b0c6bc4c480ed6da4e9d7dda104ddfec3\nTitle: Cross-Modal Fine-Tuning: Align then Refine\nYear: 2023\nAbstract: Fine-tuning large-scale pretrained models has led to tremendous progress in well-studied modalities such as vision and NLP. However, similar gains have not been observed in many other modalities due to a lack of relevant pretrained models. In this work, we propose ORCA, a general cross-modal fine-tuning framework that extends the applicability of a single large-scale pretrained model to diverse modalities. ORCA adapts to a target task via an align-then-refine workflow: given the target input, ORCA first learns an embedding network that aligns the embedded feature distribution with the pretraining modality. The pretrained model is then fine-tuned on the embedded data to exploit the knowledge shared across modalities.",
  "The pretrained model is then fine-tuned on the embedded data to exploit the knowledge shared across modalities. Through extensive experiments, we show that ORCA obtains state-of-the-art results on 3 benchmarks containing over 60 datasets from 12 modalities, outperforming a wide range of hand-designed, AutoML, general-purpose, and task-specific methods. We highlight the importance of data alignment via a series of ablation studies and demonstrate ORCA's utility in data-limited regimes.\nAuthors: Junhong Shen, Liam Li, L. Dery, Corey Staten, M. Khodak, Graham Neubig, Ameet Talwalkar\nVenue: International Conference on Machine Learning\nTldr: {'model': 'tldr@v2.0.0', 'text': \"This work proposes ORCA, a general cross-modal fine-tuning framework that extends the applicability of a single large-scale pretrained model to diverse modalities and highlights the importance of data alignment via a series of ablation studies and demonstrates ORCA's utility in data-limited regimes.\"}\nUrl: http://arxiv.org/pdf/2302.05738",
  "Faculty Name: graham neubig\nPaperid: 11a571eaab42a6ffb1d938635a093315e392756d\nTitle: ChatGPT MT: Competitive for High- (but Not Low-) Resource Languages\nYear: 2023\nAbstract: Large language models (LLMs) implicitly learn to perform a range of language tasks, including machine translation (MT). Previous studies explore aspects of LLMs\u2019 MT capabilities. However, there exist a wide variety of languages for which recent LLM MT performance has never before been evaluated. Without published experimental evidence on the matter, it is difficult for speakers of the world\u2019s diverse languages to know how and whether they can use LLMs for their languages. We present the first experimental evidence for an expansive set of 204 languages, along with MT cost analysis, using the FLORES-200 benchmark. Trends reveal that GPT models approach or exceed traditional MT model performance for some high-resource languages (HRLs) but consistently lag for low-resource languages (LRLs), under-performing traditional MT for 84.1% of languages we covered.",
  "Trends reveal that GPT models approach or exceed traditional MT model performance for some high-resource languages (HRLs) but consistently lag for low-resource languages (LRLs), under-performing traditional MT for 84.1% of languages we covered. Our analysis reveals that a language\u2019s resource level is the most important feature in determining ChatGPT\u2019s relative ability to translate it, and suggests that ChatGPT is especially disadvantaged for LRLs and African languages.\nAuthors: Nathaniel R. Robinson, Perez Ogayo, David R. Mortensen, Graham Neubig\nVenue: Conference on Machine Translation\nTldr: {'model': 'tldr@v2.0.0', 'text': \"This work presents the first experimental evidence for an expansive set of 204 languages, along with MT cost analysis, using the FLORES-200 benchmark, and reveals that a language\u2019s resource level is the most important feature in determining ChatGPT's relative ability to translate it, and suggests thatChatGPT is especially disadvantaged for LRLs and African languages.\"}\nUrl: https://arxiv.org/pdf/2309.07423",
  "Faculty Name: graham neubig\nPaperid: 17605c43ca3eb982c99642052ddc21a93d116594\nTitle: GlobalBench: A Benchmark for Global Progress in Natural Language Processing\nYear: 2023\nAbstract: Despite the major advances in NLP, significant disparities in NLP system performance across languages still exist. Arguably, these are due to uneven resource allocation and sub-optimal incentives to work on less resourced languages. To track and further incentivize the global development of equitable language technology, we introduce GlobalBench. Prior multilingual benchmarks are static and have focused on a limited number of tasks and languages. In contrast, GlobalBench is an ever-expanding collection that aims to dynamically track progress on all NLP datasets in all languages. Rather than solely measuring accuracy, GlobalBench also tracks the estimated per-speaker utility and equity of technology across all languages, providing a multi-faceted view of how language technology is serving people of the world. Furthermore, GlobalBench is designed to identify the most under-served languages, and rewards research efforts directed towards those languages.",
  "Furthermore, GlobalBench is designed to identify the most under-served languages, and rewards research efforts directed towards those languages. At present, the most under-served languages are the ones with a relatively high population, but nonetheless overlooked by composite multilingual benchmarks (like Punjabi, Portuguese, and Wu Chinese). Currently, GlobalBench covers 966 datasets in 190 languages, and has 1,128 system submissions spanning 62 languages.",
  "Currently, GlobalBench covers 966 datasets in 190 languages, and has 1,128 system submissions spanning 62 languages.\nAuthors: Yueqi Song, Catherine Cui, Simran Khanuja, Pengfei Liu, FAHIM FAISAL, Alissa Ostapenko, Genta Indra Winata, Alham Fikri Aji, Samuel Cahyawijaya, Yulia Tsvetkov, Antonios Anastasopoulos, Graham Neubig\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work introduces GlobalBench, an ever-expanding collection that aims to dynamically track progress on all NLP datasets in all languages and tracks the estimated per-speaker utility and equity of technology across all languages, providing a multi-faceted view of how language technology is serving people of the world.'}\nUrl: http://arxiv.org/pdf/2305.14716",
  "Faculty Name: graham neubig\nPaperid: 1786a2f9140ed7211b21302977de64e948b92308\nTitle: Learning Performance-Improving Code Edits\nYear: 2023\nAbstract: The waning of Moore's Law has shifted the focus of the tech industry towards alternative methods for continued performance gains. While optimizing compilers are a standard tool to help increase program efficiency, programmers continue to shoulder much responsibility in crafting and refactoring code with better performance characteristics. In this paper, we investigate the ability of large language models (LLMs) to suggest functionally correct, performance improving code edits. We hypothesize that language models can suggest such edits in ways that would be impractical for static analysis alone. We investigate these questions by curating a large-scale dataset of Performance-Improving Edits, PIE. PIE contains trajectories of programs, where a programmer begins with an initial, slower version and iteratively makes changes to improve the program's performance. We use PIE to evaluate and improve the capacity of large language models. Specifically, use examples from PIE to fine-tune multiple variants of CODEGEN, a billion-scale Transformer-decoder model.",
  "We use PIE to evaluate and improve the capacity of large language models. Specifically, use examples from PIE to fine-tune multiple variants of CODEGEN, a billion-scale Transformer-decoder model. Additionally, we use examples from PIE to prompt OpenAI's CODEX using a few-shot prompting. By leveraging PIE, we find that both CODEX and CODEGEN can generate performance-improving edits, with speedups of more than 2.5x for over 25% of the programs, for C++ and Python, even after the C++ programs were compiled using the O3 optimization level. Crucially, we show that PIE allows CODEGEN, an open-sourced and 10x smaller model than CODEX, to match the performance of CODEX on this challenging task. Overall, this work opens new doors for creating systems and methods that can help programmers write efficient code.",
  "Crucially, we show that PIE allows CODEGEN, an open-sourced and 10x smaller model than CODEX, to match the performance of CODEX on this challenging task. Overall, this work opens new doors for creating systems and methods that can help programmers write efficient code.\nAuthors: Aman Madaan, Alex Shypula, Uri Alon, Milad Hashemi, Parthasarathy Ranganathan, Yiming Yang, Graham Neubig, A. Yazdanbakhsh\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper investigates the ability of large language models (LLMs) to suggest functionally correct, performance improving code edits, and hypothesizes that language models can suggest such edits in ways that would be impractical for static analysis alone.'}\nUrl: http://arxiv.org/pdf/2302.07867",
  "Faculty Name: graham neubig\nPaperid: 31366ff634fc905affd78dbd8ddc9a872c006a87\nTitle: CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code\nYear: 2023\nAbstract: Since the rise of neural natural-language-to-code models (NL->Code) that can generate long expressions and statements rather than a single next-token, one of the major problems has been reliably evaluating their generated output. In this paper, we propose CodeBERTScore: an evaluation metric for code generation, which builds on BERTScore (Zhang et al., 2020). Instead of encoding only the generated tokens as in BERTScore, CodeBERTScore also encodes the natural language input preceding the generated code, thus modeling the consistency between the generated code and its given natural language context as well. We perform an extensive evaluation of CodeBERTScore across four programming languages. We find that CodeBERTScore achieves a higher correlation with human preference and with functional correctness than all existing metrics. That is, generated code that receives a higher score by CodeBERTScore is more likely to be preferred by humans, as well as to function correctly when executed.",
  "We find that CodeBERTScore achieves a higher correlation with human preference and with functional correctness than all existing metrics. That is, generated code that receives a higher score by CodeBERTScore is more likely to be preferred by humans, as well as to function correctly when executed. We release five language-specific pretrained models to use with our publicly available code. Our language-specific models have been downloaded more than 1,000,000 times from the Huggingface Hub. Our code and data are available at https://github.com/neulab/code-bert-score\nAuthors: Shuyan Zhou, Uri Alon, Sumit Agarwal, Graham Neubig\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is found that generated code that receives a higher score by CodeBERTScore is more likely to be preferred by humans, as well as to function correctly when executed, than all existing metrics.'}\nUrl: http://arxiv.org/pdf/2302.05527",
  "Faculty Name: graham neubig\nPaperid: 405f1a5602867c66e015491c26d2be5504eed458\nTitle: Neural Machine Translation for the Indigenous Languages of the Americas: An Introduction\nYear: 2023\nAbstract: Neural models have drastically advanced state of the art for machine translation (MT) between high-resource languages. Traditionally, these models rely on large amounts of training data, but many language pairs lack these resources. However, an important part of the languages in the world do not have this amount of data. Most languages from the Americas are among them, having a limited amount of parallel and monolingual data, if any. Here, we present an introduction to the interested reader to the basic challenges, concepts, and techniques that involve the creation of MT systems for these languages. Finally, we discuss the recent advances and findings and open questions, product of an increased interest of the NLP community in these languages.",
  "Here, we present an introduction to the interested reader to the basic challenges, concepts, and techniques that involve the creation of MT systems for these languages. Finally, we discuss the recent advances and findings and open questions, product of an increased interest of the NLP community in these languages.\nAuthors: Manuel Mager, R. Bhatnagar, Graham Neubig, Ngoc Thang Vu, Katharina Kann\nVenue: AMERICASNLP\nTldr: {'model': 'tldr@v2.0.0', 'text': 'An introduction to the interested reader to the basic challenges, concepts, and techniques that involve the creation of MT systems for high- resource languages between high-resource languages.'}\nUrl: http://arxiv.org/pdf/2306.06804",
  "Faculty Name: graham neubig\nPaperid: 43c0f77f116f986b53eb04f5c9b33f10132ded55\nTitle: User-Centric Evaluation of OCR Systems for Kwak\u2019wala\nYear: 2023\nAbstract: There has been recent interest in improving optical character recognition (OCR) for endangered languages, particularly because a large number of documents and books in these languages are not in machine-readable formats. The performance of OCR systems is typically evaluated using automatic metrics such as character and word error rates. While error rates are useful for the comparison of different models and systems, they do not measure whether and how the transcriptions produced from OCR tools are useful to downstream users. In this paper, we present a human-centric evaluation of OCR systems, focusing on the Kwak'wala language as a case study. With a user study, we show that utilizing OCR reduces the time spent in the manual transcription of culturally valuable documents -- a task that is often undertaken by endangered language community members and researchers -- by over 50%. Our results demonstrate the potential benefits that OCR tools can have on downstream language documentation and revitalization efforts.",
  "With a user study, we show that utilizing OCR reduces the time spent in the manual transcription of culturally valuable documents -- a task that is often undertaken by endangered language community members and researchers -- by over 50%. Our results demonstrate the potential benefits that OCR tools can have on downstream language documentation and revitalization efforts.\nAuthors: Shruti Rijhwani, Daisy Rosenblum, Michayla King, Antonios Anastasopoulos, Graham Neubig\nVenue: COMPUTEL\nTldr: {'model': 'tldr@v2.0.0', 'text': \"This paper presents a human-centric evaluation of OCR systems, focusing on the Kwak'wala language as a case study, and shows that utilizing OCR reduces the time spent in the manual transcription of culturally valuable documents by over 50%.\"}\nUrl: http://arxiv.org/pdf/2302.13410",
  "Faculty Name: graham neubig\nPaperid: 4d74a5048b884e8bb3842240abf98915c619c8f8\nTitle: Multi-Dimensional Evaluation of Text Summarization with In-Context Learning\nYear: 2023\nAbstract: Evaluation of natural language generation (NLG) is complex and multi-dimensional. Generated text can be evaluated for fluency, coherence, factuality, or any other dimensions of interest. Most frameworks that perform such multi-dimensional evaluation require training on large manually or synthetically generated datasets. In this paper, we study the efficacy of large language models as multi-dimensional evaluators using in-context learning, obviating the need for large training datasets. Our experiments show that in-context learning-based evaluators are competitive with learned evaluation frameworks for the task of text summarization, establishing state-of-the-art on dimensions such as relevance and factual consistency. We then analyze the effects of factors such as the selection and number of in-context examples on performance. Finally, we study the efficacy of in-context learning based evaluators in evaluating zero-shot summaries written by large language models such as GPT-3.",
  "We then analyze the effects of factors such as the selection and number of in-context examples on performance. Finally, we study the efficacy of in-context learning based evaluators in evaluating zero-shot summaries written by large language models such as GPT-3.\nAuthors: Sameer Jain, Vaishakh Keshava, Swarnashree Mysore Sathyendra, Patrick Fernandes, Pengfei Liu, Graham Neubig, Chunting Zhou\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The experiments show that in-context learning-based evaluators are competitive with learned evaluation frameworks for the task of text summarization, establishing state-of-the-art on dimensions such as relevance and factual consistency.'}\nUrl: https://aclanthology.org/2023.findings-acl.537.pdf",
  "Faculty Name: graham neubig\nPaperid: 5ea8eedcb31859c5730dd1da3804e1be529ffabb\nTitle: A Gold Standard Dataset for the Reviewer Assignment Problem\nYear: 2023\nAbstract: Many peer-review venues are either using or looking to use algorithms to assign submissions to reviewers. The crux of such automated approaches is the notion of the\"similarity score\"--a numerical estimate of the expertise of a reviewer in reviewing a paper--and many algorithms have been proposed to compute these scores. However, these algorithms have not been subjected to a principled comparison, making it difficult for stakeholders to choose the algorithm in an evidence-based manner. The key challenge in comparing existing algorithms and developing better algorithms is the lack of the publicly available gold-standard data that would be needed to perform reproducible research. We address this challenge by collecting a novel dataset of similarity scores that we release to the research community. Our dataset consists of 477 self-reported expertise scores provided by 58 researchers who evaluated their expertise in reviewing papers they have read previously. We use this data to compare several popular algorithms employed in computer science conferences and come up with recommendations for stakeholders.",
  "Our dataset consists of 477 self-reported expertise scores provided by 58 researchers who evaluated their expertise in reviewing papers they have read previously. We use this data to compare several popular algorithms employed in computer science conferences and come up with recommendations for stakeholders. Our main findings are as follows. First, all algorithms make a non-trivial amount of error. For the task of ordering two papers in terms of their relevance for a reviewer, the error rates range from 12%-30% in easy cases to 36%-43% in hard cases, highlighting the vital need for more research on the similarity-computation problem. Second, most existing algorithms are designed to work with titles and abstracts of papers, and in this regime the Specter+MFR algorithm performs best. Third, to improve performance, it may be important to develop modern deep-learning based algorithms that can make use of the full texts of papers: the classical TD-IDF algorithm enhanced with full texts of papers is on par with the deep-learning based Specter+MFR that cannot make use of this information.",
  "Third, to improve performance, it may be important to develop modern deep-learning based algorithms that can make use of the full texts of papers: the classical TD-IDF algorithm enhanced with full texts of papers is on par with the deep-learning based Specter+MFR that cannot make use of this information.\nAuthors: Ivan Stelmakh, J. Wieting, Graham Neubig, Nihar B. Shah\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A novel dataset of similarity scores provided by 58 researchers who evaluated their expertise in reviewing papers they have read previously is collected and used to compare several popular algorithms employed in computer science conferences and come up with recommendations for stakeholders.'}\nUrl: http://arxiv.org/pdf/2303.16750",
  "Faculty Name: graham neubig\nPaperid: 659be1ff350634f50cc066d258ee6a45e697e552\nTitle: SigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing\nYear: 2023\nAbstract: In our submission to the SIGMORPHON 2023 Shared Task on interlinear glossing (IGT), we explore approaches to data augmentation and modeling across seven low-resource languages. For data augmentation, we explore two approaches: creating artificial data from the provided training data and utilizing existing IGT resources in other languages. On the modeling side, we test an enhanced version of the provided token classification baseline as well as a pretrained multilingual seq2seq model. Additionally, we apply post-correction using a dictionary for Gitksan, the language with the smallest amount of data. We find that our token classification models are the best performing, with the highest word-level accuracy for Arapaho and highest morpheme-level accuracy for Gitksan out of all submissions. We also show that data augmentation is an effective strategy, though applying artificial data pretraining has very different effects across both models tested.",
  "We find that our token classification models are the best performing, with the highest word-level accuracy for Arapaho and highest morpheme-level accuracy for Gitksan out of all submissions. We also show that data augmentation is an effective strategy, though applying artificial data pretraining has very different effects across both models tested.\nAuthors: Taiqi He, Lindia Tjuatja, Nathaniel R. Robinson, Shinji Watanabe, David R. Mortensen, Graham Neubig, L. Levin\nVenue: Special Interest Group on Computational Morphology and Phonology Workshop\nTldr: {'model': 'tldr@v2.0.0', 'text': 'In this submission to the SIGMORPHON 2023 Shared Task on interlinear glossing (IGT), approaches to data augmentation and modeling across seven low-resource languages are explored and token classification models are found to be the best performing.'}\nUrl: https://aclanthology.org/2023.sigmorphon-1.22.pdf",
  "Faculty Name: graham neubig\nPaperid: 74b05bba46db21e589a2cc0f916f81069b0368ef\nTitle: Bridging the Gap: A Survey on Integrating (Human) Feedback for Natural Language Generation\nYear: 2023\nAbstract: Many recent advances in natural language generation have been fueled by training large language models on internet-scale data. However, this paradigm can lead to models that generate toxic, inaccurate, and unhelpful content, and automatic evaluation metrics often fail to identify these behaviors. As models become more capable, human feedback is an invaluable signal for evaluating and improving models. This survey aims to provide an overview of the recent research that has leveraged human feedback to improve natural language generation. First, we introduce an encompassing formalization of feedback, and identify and organize existing research into a taxonomy following this formalization. Next, we discuss how feedback can be described by its format and objective, and cover the two approaches proposed to use feedback (either for training or decoding): directly using the feedback or training feedback models. We also discuss existing datasets for human-feedback data collection, and concerns surrounding feedback collection.",
  "Next, we discuss how feedback can be described by its format and objective, and cover the two approaches proposed to use feedback (either for training or decoding): directly using the feedback or training feedback models. We also discuss existing datasets for human-feedback data collection, and concerns surrounding feedback collection. Finally, we provide an overview of the nascent field of AI feedback, which exploits large language models to make judgments based on a set of principles and minimize the need for human intervention.\nAuthors: Patrick Fernandes, Aman Madaan, Emmy Liu, Ant\u00f3nio Farinhas, Pedro Henrique Martins, Amanda Bertsch, Jos\u00e9 G. C. de Souza, Shuyan Zhou, Tongshuang Sherry Wu, Graham Neubig, Andr\u00e9 F. T. Martins\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'An overview of the recent research that has leveraged human feedback to improve natural language generation and the nascent field of AI feedback, which exploits large language models to make judgments based on a set of principles and minimize the need for human intervention is provided.'}\nUrl: http://arxiv.org/pdf/2305.00955",
  "Faculty Name: graham neubig\nPaperid: 7a5b44ea10a51708e18786595c8d70b18950da11\nTitle: FacTool: Factuality Detection in Generative AI - A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios\nYear: 2023\nAbstract: The emergence of generative pre-trained models has facilitated the synthesis of high-quality text, but it has also posed challenges in identifying factual errors in the generated text. In particular: (1) A wider range of tasks now face an increasing risk of containing factual errors when handled by generative models. (2) Generated texts tend to be lengthy and lack a clearly defined granularity for individual facts. (3) There is a scarcity of explicit evidence available during the process of fact checking. With the above challenges in mind, in this paper, we propose FacTool, a task and domain agnostic framework for detecting factual errors of texts generated by large language models (e.g., ChatGPT). Experiments on four different tasks (knowledge-based QA, code generation, mathematical reasoning, and scientific literature review) show the efficacy of the proposed method.",
  "Experiments on four different tasks (knowledge-based QA, code generation, mathematical reasoning, and scientific literature review) show the efficacy of the proposed method. We release the code of FacTool associated with ChatGPT plugin interface at https://github.com/GAIR-NLP/factool .\nAuthors: Ethan Chern, Steffi Chern, Shiqi Chen, Weizhe Yuan, Kehua Feng, Chunting Zhou, Junxian He, Graham Neubig, Pengfei Liu\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper proposes FacTool, a task and domain agnostic framework for detecting factual errors of texts generated by large language models (e.g., ChatGPT), and demonstrates the efficacy of the proposed method.'}\nUrl: https://arxiv.org/pdf/2307.13528",
  "Faculty Name: graham neubig\nPaperid: 88884b8806262a4095036041e3567d450dba39f7\nTitle: Active Retrieval Augmented Generation\nYear: 2023\nAbstract: Despite the remarkable ability of large language models (LMs) to comprehend and generate language, they have a tendency to hallucinate and create factually inaccurate output. Augmenting LMs by retrieving information from external knowledge resources is one promising solution. Most existing retrieval augmented LMs employ a retrieve-and-generate setup that only retrieves information once based on the input. This is limiting, however, in more general scenarios involving generation of long texts, where continually gathering information throughout generation is essential. In this work, we provide a generalized view of active retrieval augmented generation, methods that actively decide when and what to retrieve across the course of the generation. We propose Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens.",
  "We propose Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens. We test FLARE along with baselines comprehensively over 4 long-form knowledge-intensive generation tasks/datasets. FLARE achieves superior or competitive performance on all tasks, demonstrating the effectiveness of our method. Code and datasets are available at https://github.com/jzbjyb/FLARE.\nAuthors: Zhengbao Jiang, Frank F. Xu, Luyu Gao, Zhiqing Sun, Qian Liu, Jane Dwivedi-Yu, Yiming Yang, Jamie Callan, Graham Neubig\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens.'}",
  "Url: http://arxiv.org/pdf/2305.06983",
  "Faculty Name: graham neubig\nPaperid: 8e8a1489bf4d782d2435cdeb93f7d1f165747c63\nTitle: Large Language Models Enable Few-Shot Clustering\nYear: 2023\nAbstract: Unlike traditional unsupervised clustering, semi-supervised clustering allows users to provide meaningful structure to the data, which helps the clustering algorithm to match the user's intent. Existing approaches to semi-supervised clustering require a significant amount of feedback from an expert to improve the clusters. In this paper, we ask whether a large language model can amplify an expert's guidance to enable query-efficient, few-shot semi-supervised text clustering. We show that LLMs are surprisingly effective at improving clustering. We explore three stages where LLMs can be incorporated into clustering: before clustering (improving input features), during clustering (by providing constraints to the clusterer), and after clustering (using LLMs post-correction). We find incorporating LLMs in the first two stages can routinely provide significant improvements in cluster quality, and that LLMs enable a user to make trade-offs between cost and accuracy to produce desired clusters.",
  "We find incorporating LLMs in the first two stages can routinely provide significant improvements in cluster quality, and that LLMs enable a user to make trade-offs between cost and accuracy to produce desired clusters. We release our code and LLM prompts for the public to use.\nAuthors: Vijay Viswanathan, Kiril Gashteovski, Carolin (Haas) Lawrence, Tongshuang Sherry Wu, Graham Neubig\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is found that incorporating LLMs in the first two stages can routinely provide significant improvements in cluster quality, and that LLMs enable a user to make trade-offs between cost and accuracy to produce desired clusters.'}\nUrl: http://arxiv.org/pdf/2307.00524",
  "Faculty Name: graham neubig\nPaperid: 9bce3661f01825ad56dc9d2b3d254fd9e3792360\nTitle: Solving NLP Problems through Human-System Collaboration: A Discussion-based Approach\nYear: 2023\nAbstract: Humans work together to solve common problems by having discussions, explaining, and agreeing or disagreeing with each other. Similarly, if a system can have discussions with humans when solving tasks, it can improve the system's performance and reliability. In previous research on explainability, it has only been possible for the system to make predictions and for humans to ask questions about them rather than having a mutual exchange of opinions. This research aims to create a dataset and computational framework for systems that discuss and refine their predictions through dialogue. Through experiments, we show that the proposed system can have beneficial discussions with humans improving the accuracy by up to 25 points in the natural language inference task.",
  "This research aims to create a dataset and computational framework for systems that discuss and refine their predictions through dialogue. Through experiments, we show that the proposed system can have beneficial discussions with humans improving the accuracy by up to 25 points in the natural language inference task.\nAuthors: Masahiro Kaneko, Graham Neubig, Naoaki Okazaki\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This research aims to create a dataset and computational framework for systems that discuss and refine their predictions through dialogue and shows that the proposed system can have beneficial discussions with humans improving the accuracy by up to 25 points in the natural language inference task.'}\nUrl: http://arxiv.org/pdf/2305.11789",
  "Faculty Name: graham neubig\nPaperid: b4987da792dd45a84232cfb06d71b1c2ec488f38\nTitle: Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting\nYear: 2023\nAbstract: Idioms are common in everyday language, but often pose a challenge to translators because their meanings do not follow from the meanings of their parts. Despite significant advances, machine translation systems still struggle to translate idiomatic expressions. We provide a simple characterization of idiomatic translation and related issues. This allows us to conduct a synthetic experiment revealing a tipping point at which transformer-based machine translation models correctly default to idiomatic translations. To expand multilingual resources, we compile a dataset of ~4k natural sentences containing idiomatic expressions in French, Finnish, and Japanese. To improve translation of natural idioms, we introduce two straightforward yet effective techniques: the strategic upweighting of training loss on potentially idiomatic sentences, and using retrieval-augmented models.",
  "To improve translation of natural idioms, we introduce two straightforward yet effective techniques: the strategic upweighting of training loss on potentially idiomatic sentences, and using retrieval-augmented models. This not only improves the accuracy of a strong pretrained MT model on idiomatic sentences by up to 13% in absolute accuracy, but also holds potential benefits for non-idiomatic sentences.\nAuthors: Emmy Liu, Aditi Chaudhary, Graham Neubig\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'To improve translation of natural idioms, this work introduces two straightforward yet effective techniques: the strategic upweighting of training loss on potentially idiomatic sentences, and using retrieval-augmented models.'}\nUrl: https://arxiv.org/pdf/2310.07081",
  "Faculty Name: graham neubig\nPaperid: c432aff446d55e72a28394a1508e760cc9a25c08\nTitle: Why do Nearest Neighbor Language Models Work?\nYear: 2023\nAbstract: Language models (LMs) compute the probability of a text by sequentially computing a representation of an already-seen context and using this representation to predict the next word. Currently, most LMs calculate these representations through a neural network consuming the immediate previous context. However recently, retrieval-augmented LMs have shown to improve over standard neural LMs, by accessing information retrieved from a large datastore, in addition to their standard, parametric, next-word prediction. In this paper, we set out to understand why retrieval-augmented language models, and specifically why k-nearest neighbor language models (kNN-LMs) perform better than standard parametric LMs, even when the k-nearest neighbor component retrieves examples from the same training set that the LM was originally trained on. To this end, we perform a careful analysis of the various dimensions over which kNN-LM diverges from standard LMs, and investigate these dimensions one by one.",
  "To this end, we perform a careful analysis of the various dimensions over which kNN-LM diverges from standard LMs, and investigate these dimensions one by one. Empirically, we identify three main reasons why kNN-LM performs better than standard LMs: using a different input representation for predicting the next tokens, approximate kNN search, and the importance of softmax temperature for the kNN distribution. Further, we incorporate these insights into the model architecture or the training procedure of the standard parametric LM, improving its results without the need for an explicit retrieval component. The code is available at https://github.com/frankxu2004/knnlm-why.\nAuthors: Frank F. Xu, Uri Alon, Graham Neubig\nVenue: International Conference on Machine Learning\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper identifies three main reasons why k-nearest neighbor language models (kNN-LM) perform better than standard LMs: using a different input representation for predicting the next tokens, approximate kNN search, and the importance of softmax temperature for the kNN distribution.'}\nUrl: http://arxiv.org/pdf/2301.02828",
  "Faculty Name: graham neubig\nPaperid: c5207241406586f4263b235667e004b71ea68953\nTitle: Syntax and Semantics Meet in the \u201cMiddle\u201d: Probing the Syntax-Semantics Interface of LMs Through Agentivity\nYear: 2023\nAbstract: Recent advances in large language models have prompted researchers to examine their abilities across a variety of linguistic tasks, but little has been done to investigate how models handle the interactions in meaning across words and larger syntactic forms\u2014i.e. phenomena at the intersection of syntax and semantics. We present the semantic notion of agentivity as a case study for probing such interactions. We created a novel evaluation dataset by utilitizing the unique linguistic properties of a subset of optionally transitive English verbs. This dataset was used to prompt varying sizes of three model classes to see if they are sensitive to agentivity at the lexical level, and if they can appropriately employ these word-level priors given a specific syntactic context. Overall, GPT-3 text-davinci-003 performs extremely well across all experiments, outperforming all other models tested by far.",
  "Overall, GPT-3 text-davinci-003 performs extremely well across all experiments, outperforming all other models tested by far. In fact, the results are even better correlated with human judgements than both syntactic and semantic corpus statistics. This suggests that LMs may potentially serve as more useful tools for linguistic annotation, theory testing, and discovery than select corpora for certain tasks.\nAuthors: Lindia Tjuatja, Emmy Liu, L. Levin, Graham Neubig\nVenue: STARSEM\nTldr: {'model': 'tldr@v2.0.0', 'text': 'GPT-3 text-davinci-003 performs extremely well across all experiments, outperforming all other models tested by far and suggests that LMs may potentially serve as more useful tools for linguistic annotation, theory testing, and discovery than select corpora for certain tasks.'}\nUrl: https://arxiv.org/pdf/2305.18185",
  "Faculty Name: graham neubig\nPaperid: cc1705fe421c70d85254b557634bd4669fdd49b0\nTitle: DataFinder: Scientific Dataset Recommendation from Natural Language Descriptions\nYear: 2023\nAbstract: Modern machine learning relies on datasets to develop and validate research ideas. Given the growth of publicly available data, finding the right dataset to use is increasingly difficult. Any research question imposes explicit and implicit constraints on how well a given dataset will enable researchers to answer this question, such as dataset size, modality, and domain. We operationalize the task of recommending datasets given a short natural language description of a research idea, to help people find relevant datasets for their needs. Dataset recommendation poses unique challenges as an information retrieval problem; datasets are hard to directly index for search and there are no corpora readily available for this task. To facilitate this task, we build the DataFinder Dataset which consists of a larger automatically-constructed training set (17.5K queries) and a smaller expert-annotated evaluation set (392 queries).",
  "To facilitate this task, we build the DataFinder Dataset which consists of a larger automatically-constructed training set (17.5K queries) and a smaller expert-annotated evaluation set (392 queries). Using this data, we compare various information retrieval algorithms on our test set and present a superior bi-encoder retriever for text-based dataset recommendation. This system, trained on the DataFinder Dataset, finds more relevant search results than existing third-party dataset search engines. To encourage progress on dataset recommendation, we release our dataset and models to the public.\nAuthors: Vijay Viswanathan, Luyu Gao, Tongshuang Sherry Wu, Pengfei Liu, Graham Neubig\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work operationalizes the task of recommending datasets given a short natural language description of a research idea, to help people find relevant datasets for their needs, and builds the DataFinder Dataset, a larger automatically-constructed training set and a smaller expert-annotated evaluation set.'}\nUrl: http://arxiv.org/pdf/2305.16636",
  "Faculty Name: graham neubig\nPaperid: d5dd7230cccace7e77095d3b5fd8394850f59170\nTitle: Multi-lingual and Multi-cultural Figurative Language Understanding\nYear: 2023\nAbstract: Figurative language permeates human communication, but at the same time is relatively understudied in NLP. Datasets have been created in English to accelerate progress towards measuring and improving figurative language processing in language models (LMs). However, the use of figurative language is an expression of our cultural and societal experiences, making it difficult for these phrases to be universally applicable. In this work, we create a figurative language inference dataset, \\datasetname, for seven diverse languages associated with a variety of cultures: Hindi, Indonesian, Javanese, Kannada, Sundanese, Swahili and Yoruba. Our dataset reveals that each language relies on cultural and regional concepts for figurative expressions, with the highest overlap between languages originating from the same region. We assess multilingual LMs' abilities to interpret figurative language in zero-shot and few-shot settings.",
  "Our dataset reveals that each language relies on cultural and regional concepts for figurative expressions, with the highest overlap between languages originating from the same region. We assess multilingual LMs' abilities to interpret figurative language in zero-shot and few-shot settings. All languages exhibit a significant deficiency compared to English, with variations in performance reflecting the availability of pre-training and fine-tuning data, emphasizing the need for LMs to be exposed to a broader range of linguistic and cultural variation during training.\nAuthors: Anubha Kabra, Emmy Liu, Simran Khanuja, Alham Fikri Aji, Genta Indra Winata, Samuel Cahyawijaya, Anuoluwapo Aremu, Perez Ogayo, Graham Neubig\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': \"This work assesses multilingual LMs' abilities to interpret figurative language in zero-shot and few-shot settings, and reveals that each language relies on cultural and regional concepts for figurative expressions, with the highest overlap between languages originating from the same region.\"}\nUrl: http://arxiv.org/pdf/2305.16171",
  "Faculty Name: graham neubig\nPaperid: d6ae4c0679bdceb029f652efd2a854ac5ade772f\nTitle: It\u2019s MBR All the Way Down: Modern Generation Techniques Through the Lens of Minimum Bayes Risk\nYear: 2023\nAbstract: Minimum Bayes Risk (MBR) decoding is a method for choosing the outputs of a machine learning system based not on the output with the highest probability, but the output with the lowest risk (expected error) among multiple candidates. It is a simple but powerful method: for an additional cost at inference time, MBR provides reliable several-point improvements across metrics for a wide variety of tasks without any additional data or training. Despite this, MBR is not frequently applied in NLP works, and knowledge of the method itself is limited. We first provide an introduction to the method and the recent literature. We show that several recent methods that do not reference MBR can be written as special cases of MBR; this reformulation provides additional theoretical justification for the performance of these methods, explaining some results that were previously only empirical.",
  "We first provide an introduction to the method and the recent literature. We show that several recent methods that do not reference MBR can be written as special cases of MBR; this reformulation provides additional theoretical justification for the performance of these methods, explaining some results that were previously only empirical. We provide theoretical and empirical results about the effectiveness of various MBR variants and make concrete recommendations for the application of MBR in NLP models, including future directions in this area.\nAuthors: Amanda Bertsch, Alex Xie, Graham Neubig, Matthew R. Gormley\nVenue: BIGPICTURE\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is shown that several recent methods that do not reference MBR can be written as special cases of MBR; this reformulation provides additional theoretical justification for the performance of these methods, explaining some results that were previously only empirical.'}\nUrl: https://arxiv.org/pdf/2310.01387",
  "Faculty Name: graham neubig\nPaperid: dbc368bc8b49347dd27679894524fa62f88492c9\nTitle: Unlimiformer: Long-Range Transformers with Unlimited Length Input\nYear: 2023\nAbstract: Since the proposal of transformers, these models have been limited to bounded input lengths, because of their need to attend to every token in the input. In this work, we propose Unlimiformer: a general approach that wraps any existing pretrained encoder-decoder transformer, and offloads the cross-attention computation to a single k-nearest-neighbor (kNN) index, while the returned kNN distances are the attention dot-product scores. This kNN index can be kept on either the GPU or CPU memory and queried in sub-linear time; this way, we can index practically unlimited input sequences, while every attention head in every decoder layer retrieves its top-k keys, instead of attending to every key. We evaluate Unlimiformer on several long-document and book-summarization benchmarks, showing that it can process even 500k token-long inputs from the BookSum dataset, without any input truncation at test time.",
  "We evaluate Unlimiformer on several long-document and book-summarization benchmarks, showing that it can process even 500k token-long inputs from the BookSum dataset, without any input truncation at test time. We demonstrate that Unlimiformer improves pretrained models such as BART and Longformer by extending them to unlimited inputs without additional learned weights and without modifying their code. We make our code and models publicly available at https://github.com/abertsch72/unlimiformer .\nAuthors: Amanda Bertsch, Uri Alon, Graham Neubig, Matthew R. Gormley\nVenue: Neural Information Processing Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes Unlimiformer: a general approach that wraps any existing pretrained encoder-decoder transformer, and offloads the cross-attention computation to a single k-nearest-neighbor (kNN) index, while the returned kNN distances are the attention dot-product scores.'}\nUrl: http://arxiv.org/pdf/2305.01625",
  "Faculty Name: graham neubig\nPaperid: e41482f4ee984f17382f6cdd900df094d928be06\nTitle: WebArena: A Realistic Web Environment for Building Autonomous Agents\nYear: 2023\nAbstract: With advances in generative AI, there is now potential for autonomous agents to manage daily tasks via natural language commands. However, current agents are primarily created and tested in simplified synthetic environments, leading to a disconnect with real-world scenarios. In this paper, we build an environment for language-guided agents that is highly realistic and reproducible. Specifically, we focus on agents that perform tasks on the web, and create an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management. Our environment is enriched with tools (e.g., a map) and external knowledge bases (e.g., user manuals) to encourage human-like task-solving. Building upon our environment, we release a set of benchmark tasks focusing on evaluating the functional correctness of task completions. The tasks in our benchmark are diverse, long-horizon, and designed to emulate tasks that humans routinely perform on the internet.",
  "Building upon our environment, we release a set of benchmark tasks focusing on evaluating the functional correctness of task completions. The tasks in our benchmark are diverse, long-horizon, and designed to emulate tasks that humans routinely perform on the internet. We experiment with several baseline agents, integrating recent techniques such as reasoning before acting. The results demonstrate that solving complex tasks is challenging: our best GPT-4-based agent only achieves an end-to-end task success rate of 14.41%, significantly lower than the human performance of 78.24%. These results highlight the need for further development of robust agents, that current state-of-the-art large language models are far from perfect performance in these real-life tasks, and that WebArena can be used to measure such progress.",
  "These results highlight the need for further development of robust agents, that current state-of-the-art large language models are far from perfect performance in these real-life tasks, and that WebArena can be used to measure such progress.\nAuthors: Shuyan Zhou, Frank F. Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, Yonatan Bisk, Daniel Fried, Uri Alon, Graham Neubig\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper builds an environment for language-guided agents that is highly realistic and reproducible, and creates an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management.'}\nUrl: https://arxiv.org/pdf/2307.13854",
  "Faculty Name: graham neubig\nPaperid: e69684fb06a7b1fe621d7ef0c97fc2ca0e122c43\nTitle: Prompt2Model: Generating Deployable Models from Natural Language Instructions\nYear: 2023\nAbstract: Large language models (LLMs) enable system builders today to create competent NLP systems through prompting, where they only need to describe the task in natural language and provide a few examples. However, in other ways, LLMs are a step backward from traditional special-purpose NLP models; they require extensive computational resources for deployment and can be gated behind APIs. In this paper, we propose Prompt2Model, a general-purpose method that takes a natural language task description like the prompts provided to LLMs, and uses it to train a special-purpose model that is conducive to deployment. This is done through a multi-step process of retrieval of existing datasets and pretrained models, dataset generation using LLMs, and supervised fine-tuning on these retrieved and generated datasets.",
  "This is done through a multi-step process of retrieval of existing datasets and pretrained models, dataset generation using LLMs, and supervised fine-tuning on these retrieved and generated datasets. Over three tasks, we demonstrate that given the same few-shot prompt as input, Prompt2Model trains models that outperform the results of a strong LLM, gpt-3.5-turbo, by an average of 20% while being up to 700 times smaller. We also show that this data can be used to obtain reliable performance estimates of model performance, enabling model developers to assess model reliability before deployment. Prompt2Model is available open-source at https://github.com/neulab/prompt2model.\nAuthors: Vijay Viswanathan, Chenyang Zhao, Amanda Bertsch, Tongshuang Sherry Wu, Graham Neubig\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper proposes Prompt2Model, a general-purpose method that takes a natural language task description like the prompts provided to LLMs, and uses it to train a special-purpose model that is conducive to deployment.'}",
  "Url: https://arxiv.org/pdf/2308.12261",
  "Faculty Name: graham neubig\nPaperid: e7b3b692b0816821aafc0d354749bc3802cbf6ac\nTitle: Computational Language Acquisition with Theory of Mind\nYear: 2023\nAbstract: Unlike current state-of-the-art language models, young children actively acquire language through interactions with their surrounding environment and caretakers. One mechanism that has been argued to be critical to language learning is the ability to infer the mental states of other agents in social environments, coined Theory of Mind (ToM) by Premack&Woodruff (1978). Drawing inspiration from the modern operationalized versions of ToM implemented in Rabinowitz et al. (2018) and Zhu et al. (2021), we build language-learning agents equipped with ToM, and measure its effects on the learning process. We model ToM by giving the speaker agent an internal listener model that is trained alongside the speaker and used to rerank potential utterances. We experiment with varying task difficulty, hypothesizing that models will acquire more complex language to adapt to stronger environmental pressures.",
  "We model ToM by giving the speaker agent an internal listener model that is trained alongside the speaker and used to rerank potential utterances. We experiment with varying task difficulty, hypothesizing that models will acquire more complex language to adapt to stronger environmental pressures. We find that training speakers with a highly weighted ToM listener component leads to performance gains in our image referential game setting. We also find some evidence that increasing task difficulty in the training process results in more fluent and precise utterances in evaluation. This suggests the potential utility of further incorporating ToM, as well as other insights from child language acquisition, into computational models of language acquisition.\nAuthors: Andy T. Liu, Hao Zhu, Emmy Liu, Yonatan Bisk, Graham Neubig\nVenue: International Conference on Learning Representations\nTldr: {'model': 'tldr@v2.0.0', 'text': \"It is found that training speakers with a highly weighted ToM listener component leads to performance gains in the authors' image referential game setting, and suggests the potential utility of further incorporating ToM, as well as other insights from child language acquisition, into computational models of language acquisition.\"}",
  "Url: http://arxiv.org/pdf/2303.01502",
  "Faculty Name: graham neubig\nPaperid: f640e89fcede075b4bde3b2fa0dc78f591589ba3\nTitle: Improving Factuality of Abstractive Summarization via Contrastive Reward Learning\nYear: 2023\nAbstract: Modern abstractive summarization models often generate summaries that contain hallucinated or contradictory information. In this paper, we propose a simple but effective contrastive learning framework that incorporates recent developments in reward learning and factuality metrics. Empirical studies demonstrate that the proposed framework enables summarization models to learn from feedback of factuality metrics using contrastive reward learning, leading to more factual summaries by human evaluations. This suggests that further advances in learning and evaluation algorithms can feed directly into providing more factual summaries. Code and human evaluation results will be publicly available at \\url{https://github.com/EthanC111/factuality_summarization}.",
  "This suggests that further advances in learning and evaluation algorithms can feed directly into providing more factual summaries. Code and human evaluation results will be publicly available at \\url{https://github.com/EthanC111/factuality_summarization}.\nAuthors: Ethan Chern, Zhiruo Wang, Sanjan Das, Bhavuk Sharma, Pengfei Liu, Graham Neubig\nVenue: TRUSTNLP\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Empirical studies demonstrate that the proposed framework enables summarization models to learn from feedback of factuality metrics using contrastive reward learning, leading to more factual summaries by human evaluations, suggesting that further advances in learning and evaluation algorithms can feed directly into providing morefactuality summaries.'}\nUrl: https://arxiv.org/pdf/2307.04507",
  "Faculty Name: graham neubig\nPaperid: fd80f7f3673fc6ca02f192d5d73426f11a4be659\nTitle: The Devil Is in the Errors: Leveraging Large Language Models for Fine-grained Machine Translation Evaluation\nYear: 2023\nAbstract: Automatic evaluation of machine translation (MT) is a critical tool driving the rapid iterative development of MT systems. While considerable progress has been made on estimating a single scalar quality score, current metrics lack the informativeness of more detailed schemes that annotate individual errors, such as Multidimensional Quality Metrics (MQM). In this paper, we help fill this gap by proposing AutoMQM, a prompting technique which leverages the reasoning and in-context learning capabilities of large language models (LLMs) and asks them to identify and categorize errors in translations. We start by evaluating recent LLMs, such as PaLM and PaLM-2, through simple score prediction prompting, and we study the impact of labeled data through in-context learning and finetuning.",
  "We start by evaluating recent LLMs, such as PaLM and PaLM-2, through simple score prediction prompting, and we study the impact of labeled data through in-context learning and finetuning. We then evaluate AutoMQM with PaLM-2 models, and we find that it improves performance compared to just prompting for scores (with particularly large gains for larger models) while providing interpretability through error spans that align with human annotations.\nAuthors: Patrick Fernandes, Daniel Deutsch, M. Finkelstein, Parker Riley, Andr\u00e9 F. T. Martins, Graham Neubig, Ankush Garg, J. Clark, Markus Freitag, Orhan Firat\nVenue: Conference on Machine Translation\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper proposes AutoMQM, a prompting technique which leverages the reasoning and in-context learning capabilities of large language models (LLMs) and asks them to identify and categorize errors in translations, and finds that it improves performance compared to just prompting for scores.'}\nUrl: https://arxiv.org/pdf/2308.07286",
  "List of 2023 Open Access papers by graham neubig are:\nCross-Modal Fine-Tuning: Align then Refine\nChatGPT MT: Competitive for High- (but Not Low-) Resource Languages\nGlobalBench: A Benchmark for Global Progress in Natural Language Processing\nLearning Performance-Improving Code Edits\nCodeBERTScore: Evaluating Code Generation with Pretrained Models of Code\nNeural Machine Translation for the Indigenous Languages of the Americas: An Introduction\nUser-Centric Evaluation of OCR Systems for Kwak\u2019wala\nMulti-Dimensional Evaluation of Text Summarization with In-Context Learning\nA Gold Standard Dataset for the Reviewer Assignment Problem\nSigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing\nBridging the Gap: A Survey on Integrating (Human) Feedback for Natural Language Generation\nFacTool: Factuality Detection in Generative AI - A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios\nActive Retrieval Augmented Generation\nLarge Language Models Enable Few-Shot Clustering\nSolving NLP Problems through Human-System Collaboration: A Discussion-based Approach\nCrossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss",
  "Augmented Framework for Multi-Task and Multi-Domain Scenarios\nActive Retrieval Augmented Generation\nLarge Language Models Enable Few-Shot Clustering\nSolving NLP Problems through Human-System Collaboration: A Discussion-based Approach\nCrossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting\nWhy do Nearest Neighbor Language Models Work?\nSyntax and Semantics Meet in the \u201cMiddle\u201d: Probing the Syntax-Semantics Interface of LMs Through Agentivity\nDataFinder: Scientific Dataset Recommendation from Natural Language Descriptions\nMulti-lingual and Multi-cultural Figurative Language Understanding\nIt\u2019s MBR All the Way Down: Modern Generation Techniques Through the Lens of Minimum Bayes Risk\nUnlimiformer: Long-Range Transformers with Unlimited Length Input\nWebArena: A Realistic Web Environment for Building Autonomous Agents\nPrompt2Model: Generating Deployable Models from Natural Language Instructions\nComputational Language Acquisition with Theory of Mind\nImproving Factuality of Abstractive Summarization via Contrastive Reward Learning\nThe Devil Is in the Errors: Leveraging Large Language Models for Fine-grained Machine Translation Evaluation",
  "Graham Neubig\nAssociate Professor, Language Technologies Institute\nResearch Area\nMachine Learning, Machine Translation, Natural Language Processing and Computational Linguistics, Spoken Interfaces and Dialogue Processing\n\nEducation\nMaster of Science in Intelligent Information Systems\nResearch\nMy research is concerned with language and its role in human communication. In particular, my long-term research goal is to break down barriers in human-human or human-machine communication through the development of natural language processing (NLP) technologies. This includes the development of technology for machine translation, which helps break down barriers in communication for people who speak different languages, and natural language understanding, which helps computers understand and respond to human language. Within this overall goal of breaking down barriers to human communication, I have focused on several aspects of language that both make it interesting as a scientific subject, and hold potential for the construction of practical systems.\n\nAdvances in core NLP technology: Human language is complex and nuanced, and handling this complexity in a computational way requires sophisticated algorithms or learning techniques, the development of which is far from a solved problem. The first major area of my work focuses on advances in core NLP technology, which improve the accuracy with which we can analyze, translate, generate, or reply to textual inputs.",
  "The first major area of my work focuses on advances in core NLP technology, which improve the accuracy with which we can analyze, translate, generate, or reply to textual inputs. \n\nModels of language associated with other modalities: Human language does not exist in a vacuum, and is often associated with context from the world around it. The second thread of my research focuses on models of natural language associated with other modalities, tackling the problems, and exploiting the fascinating possibilities presented by having text associated with other types of information. Specifically, I have worked extensively with speech, and am also interested in associations between natural and formal languages such as source code.\n\nLearning from naturally occurring data: Language data exists in abundance, particularly due to the advent of the internet, and it is possible to acquire extremely large amounts of this data for scientific or engineering purposes. A third thread of my research focuses on learning NLP models from naturally occurring data through the use of unsupervised, semi-supervised, or active learning, which allows us to exploit this data to improve models while reducing the necessity for costly manual annotation.\n\nhttp://www.phontron.com/\n5409 \u2014Gates & Hillman Centers\ngneubig@cs.cmu.edu",
  "Faculty Name: jamie callan\nPaperid: 197d5fbc3764ff18186275545d0764d5b1c7659b\nTitle: Conversational Search with Random Walks over Entity Graphs\nYear: 2023\nAbstract: The entities that emerge during a conversation can be used to model topics, but not all entities are equally useful for this task. Modeling the conversation with entity graphs and predicting each entity's centrality in the conversation provides additional information that improves the retrieval of answer passages for the current question. Experiments show that using random walks to estimate entity centrality on conversation entity graphs improves top precision answer passage ranking over competitive transformer-based baselines.\nAuthors: Gustavo Gon\u00e7alves, Jo\u00e3o Magalh\u00e3es, Jamie Callan\nVenue: International Conference on the Theory of Information Retrieval\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Experiments show that using random walks to estimate entity centrality on conversation entity graphs improves top precision answer passage ranking over competitive transformer-based baselines.'}\nUrl: https://dl.acm.org/doi/pdf/10.1145/3578337.3605125",
  "Faculty Name: jamie callan\nPaperid: 1e0a4ff0c5d2d850ff5907e310ffcedc9cad9718\nTitle: KALE: Using a K-Sparse Projector for Lexical Expansion\nYear: 2023\nAbstract: Recent research has proposed retrieval approaches based on sparse representations and inverted indexes, with terms produced by neural language models and leveraging the advantages from both neural retrieval and lexical matching. This paper proposes KALE, a new lightweight method of this family that uses a small model with a k-sparse projector to convert dense representations into a sparse set of entries from a latent vocabulary. The KALE vocabulary captures semantic concepts than perform well when used in isolation, and perform better when extending the original lexical vocabulary, this way improving first-stage retrieval accuracy. Experiments with the MSMARCOv1 passage retrieval dataset, the TREC Deep Learning dataset, and BEIR datasets, examined the effectiveness of KALE under varying conditions. Results show that the KALE terms can replace the original lexical vocabulary, with gains in accuracy and efficiency.",
  "Experiments with the MSMARCOv1 passage retrieval dataset, the TREC Deep Learning dataset, and BEIR datasets, examined the effectiveness of KALE under varying conditions. Results show that the KALE terms can replace the original lexical vocabulary, with gains in accuracy and efficiency. Combining KALE with the original lexical vocabulary, or with other learned terms, can further improve retrieval accuracy with only a modest increase in computational cost.\nAuthors: Lu\u00eds Borges, Bruno Martins, Jamie Callan\nVenue: International Conference on the Theory of Information Retrieval\nTldr: {'model': 'tldr@v2.0.0', 'text': 'KALE is a new lightweight method that uses a small model with a k-sparse projector to convert dense representations into a sparse set of entries from a latent vocabulary, which can replace the original lexical vocabulary with gains in accuracy and efficiency.'}\nUrl: https://dl.acm.org/doi/pdf/10.1145/3578337.3605131",
  "Faculty Name: jamie callan\nPaperid: 6b7eefa15c0a461afeab4fa13cf862c5340fdc2a\nTitle: CSurF: Sparse Lexical Retrieval through Contextualized Surface Forms\nYear: 2023\nAbstract: Lexical exact-match systems perform text retrieval efficiently with sparse matching signals and fast retrieval through inverted lists, but naturally suffer from the mismatch between lexical surface form and implicit term semantics. This paper proposes to directly bridge the surface form space and the term semantics space in lexical exact-match retrieval via contextualized surface forms (CSF). Each CSF pairs a lexical surface form with a context source, and is represented by a lexical form weight and a contextualized semantic vector representation. This framework is able to perform sparse lexicon-based retrieval by learning to represent each query and document as a \"bag-of-CSFs\", simultaneously addressing two key factors in sparse retrieval: vocabulary expansion of surface form and semantic representation of term meaning. At retrieval time, it efficiently matches CSFs through exact-match of learned surface forms, and effectively scores each CSF pair via contextual semantic representations, leading to joint improvement in both term match and term scoring.",
  "At retrieval time, it efficiently matches CSFs through exact-match of learned surface forms, and effectively scores each CSF pair via contextual semantic representations, leading to joint improvement in both term match and term scoring. Multiple experiments show that this approach successfully resolves the main mismatch issues in lexical exact-match retrieval and outperforms state-of-the-art lexical exact-match systems, reaching comparable accuracy as lexical all-to-all soft match systems as an efficient exact-match-based system.\nAuthors: Zhen Fan, Luyu Gao, Jamie Callan\nVenue: International Conference on the Theory of Information Retrieval\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper proposes to directly bridge the surface form space and the term semantics space in lexical exact-match retrieval via contextualized surface forms (CSF), reaching comparable accuracy as lexical all-to-all soft match systems as an efficient exact- match-based system.'}\nUrl: https://dl.acm.org/doi/pdf/10.1145/3578337.3605126",
  "Faculty Name: jamie callan\nPaperid: 88884b8806262a4095036041e3567d450dba39f7\nTitle: Active Retrieval Augmented Generation\nYear: 2023\nAbstract: Despite the remarkable ability of large language models (LMs) to comprehend and generate language, they have a tendency to hallucinate and create factually inaccurate output. Augmenting LMs by retrieving information from external knowledge resources is one promising solution. Most existing retrieval augmented LMs employ a retrieve-and-generate setup that only retrieves information once based on the input. This is limiting, however, in more general scenarios involving generation of long texts, where continually gathering information throughout generation is essential. In this work, we provide a generalized view of active retrieval augmented generation, methods that actively decide when and what to retrieve across the course of the generation. We propose Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens.",
  "We propose Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens. We test FLARE along with baselines comprehensively over 4 long-form knowledge-intensive generation tasks/datasets. FLARE achieves superior or competitive performance on all tasks, demonstrating the effectiveness of our method. Code and datasets are available at https://github.com/jzbjyb/FLARE.\nAuthors: Zhengbao Jiang, Frank F. Xu, Luyu Gao, Zhiqing Sun, Qian Liu, Jane Dwivedi-Yu, Yiming Yang, Jamie Callan, Graham Neubig\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens.'}",
  "Url: http://arxiv.org/pdf/2305.06983",
  "Faculty Name: jamie callan\nPaperid: ac9ee72a5cd611e9143e385f668af662583721ee\nTitle: Multi-Objective Improvement of Android Applications\nYear: 2023\nAbstract: Non-functional properties, such as runtime or memory use, are important to mobile app users and developers, as they affect user experience. Previous work on automated improvement of non-functional properties in mobile apps failed to address the inherent trade-offs between such properties. We propose a practical approach and the first open-source tool, GIDroid (2023), for multi-objective automated improvement of Android apps. In particular, we use Genetic improvement, a search-based technique that navigates the space of software variants to find improved software. We use a simulation-based testing framework to greatly improve the speed of search. GIDroid contains three state-of-the-art multi-objective algorithms, and two new mutation operators, which cache the results of method calls. Genetic improvement relies on testing to validate patches. Previous work showed that tests in open-source Android applications are scarce. We thus wrote tests for 21 versions of 7 Android apps, creating a new benchmark for performance improvements.",
  "Genetic improvement relies on testing to validate patches. Previous work showed that tests in open-source Android applications are scarce. We thus wrote tests for 21 versions of 7 Android apps, creating a new benchmark for performance improvements. We used GIDroid to improve versions of mobile apps where developers had previously found improvements to runtime, memory, and bandwidth use. Our technique automatically re-discovers 64% of existing improvements. We then applied our approach to current versions of software in which there were no known improvements. We were able to improve execution time by up to 35%, and memory use by up to 33% in these apps.\nAuthors: Jamie Callan, J. Petke\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes a practical approach and the first open-source tool, GIDroid, for multi-objective automated improvement of Android apps, and uses Genetic improvement, a search-based technique that navigates the space of software variants to find improved software.'}\nUrl: https://arxiv.org/pdf/2308.11387",
  "List of 2023 Open Access papers by jamie callan are:\nConversational Search with Random Walks over Entity Graphs\nKALE: Using a K-Sparse Projector for Lexical Expansion\nCSurF: Sparse Lexical Retrieval through Contextualized Surface Forms\nActive Retrieval Augmented Generation\nMulti-Objective Improvement of Android Applications",
  "Jamie Callan\nProfessor, Language Technologies Institute\nResearch Area : Information Retrieval, Text Mining and Analytics\nResearch : My research and teaching focus on information retrieval and analysis. I have worked on a wide range of topics over the years, but am particularly interested in search engine architectures, information filtering and text mining. A sample of current projects is shown below. See my personal webpage for more information.\nProjects: \nLemur: The Lemur Project develops open-source search engines, toolbars, text analysis tools, search services and datasets that support international research and development. The project is best known for its Indri and Galago search engines, and large-scale ClueWeb datasets. Our software and datasets are widely used in scientific and research applications, and some commercial applications. Lemur's software development philosophy emphasizes state-of-the-art accuracy, flexibility and efficiency.\n\nSearch Engines With Knowledge Resources: This project develops new methods for using knowledge graphs and ontologies to improve search engine accuracy, especially for vague, ambiguous or poorly specified queries. Knowledge graphs and ontologies are less structured than typical relational databases and semantic web resources, but more structured than text stored in full-text search engines.",
  "Knowledge graphs and ontologies are less structured than typical relational databases and semantic web resources, but more structured than text stored in full-text search engines. The weak semantics in these semi-structured information resources can support interesting applications, but can also accommodate contradictions, inconsistencies and mistakes \u2014 making them easier to scale for large amounts of information. A search engine can use these resources to identify the probable meanings of query terms, and use this knowledge to identify documents that match those meanings.\n\nRetrieval of Scientific Data: Numerical data continues to expand as the results of scholarly research in data-rich sciences (e.g., non-textual data) continue to grow. This project extends search engine architectures to support large, centralized, universal repositories of affordable and easily used scientific data. Our goal is to access tabular, numeric and other non-textual information as easily and readily as documents without laborious additional work.\n\nSelective and Federated Search: I have a long-term interest in environments that contain numerous search engines. Much of my prior research focused on integrating many independent search engines \u2014 perhaps operated by different organizations with different interests\u2014 into a single integrated federated search system.",
  "Selective and Federated Search: I have a long-term interest in environments that contain numerous search engines. Much of my prior research focused on integrating many independent search engines \u2014 perhaps operated by different organizations with different interests\u2014 into a single integrated federated search system. My recent work investigates a related problem: decomposing a massive text collection into hundreds or thousands of small search engines designed to have skewed utility distributions that enable most index partitions to be ignored for most queries. This selective search architecture is as effective as conventional search engine architectures, but has far lower computational costs and reveals new challenges and opportunities in large-scale search. The decomposition process creates text collections, thus inviting research on the characteristics desired or to be avoided in a text collection to enable accurate search. We've developed new resource selection algorithms to address efficiency problems in existing algorithms and dynamically adjust search costs based on query difficulty. Our goal is an easily customizable and extensible off-the-shelf method that provides an order of magnitude reduction in search costs over the current state-of-the-art, especially on corpora of more than a billion documents.",
  "Our goal is an easily customizable and extensible off-the-shelf method that provides an order of magnitude reduction in search costs over the current state-of-the-art, especially on corpora of more than a billion documents.\n\nPersonal Website: https://www.cs.cmu.edu/~callan/\nContact: 5419 \u2014Gates & Hillman Centers\nEmail : callan@cs.cmu.edu\nPhone : 412-268-4525",
  "Faculty Name: justine cassell\nPaperid: 24bff26f19051b1413d1e343322c1ae4bba05428\nTitle: When to generate hedges in peer-tutoring interactions\nYear: 2023\nAbstract: This paper explores the application of machine learning techniques to predict where hedging occurs in peer-tutoring interactions. The study uses a naturalistic face-to-face dataset annotated for natural language turns, conversational strategies, tutoring strategies, and nonverbal behaviors. These elements are processed into a vector representation of the previous turns, which serves as input to several machine learning models, including MLP and LSTM. The results show that embedding layers, capturing the semantic information of the previous turns, significantly improves the model\u2019s performance. Additionally, the study provides insights into the importance of various features, such as interpersonal rapport and nonverbal behaviors, in predicting hedges by using Shapley values for feature explanation. We discover that the eye gaze of both the tutor and the tutee has a significant impact on hedge prediction. We further validate this observation through a follow-up ablation study.",
  "We discover that the eye gaze of both the tutor and the tutee has a significant impact on hedge prediction. We further validate this observation through a follow-up ablation study.\nAuthors: Alafate Abulimiti, C. Clavel, Justine Cassell\nVenue: SIGDIAL Conferences\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The results show that embedding layers, capturing the semantic information of the previous turns, significantly improves the model\u2019s performance and provides insights into the importance of various features, such as interpersonal rapport and nonverbal behaviors, in predicting hedges by using Shapley values for feature explanation.'}\nUrl: https://arxiv.org/pdf/2307.15582",
  "Faculty Name: justine cassell\nPaperid: 74fedee9d809ec766a2089a89435fa7dd1346693\nTitle: How About Kind of Generating Hedges using End-to-End Neural Models?\nYear: 2023\nAbstract: Hedging is a strategy for softening the impact of a statement in conversation. In reducing the strength of an expression, it may help to avoid embarrassment (more technically, \u201cface threat\u201d) to one\u2019s listener. For this reason, it is often found in contexts of instruction, such as tutoring. In this work, we develop a model of hedge generation based on i) fine-tuning state-of-the-art language models trained on human-human tutoring data, followed by ii) reranking to select the candidate that best matches the expected hedging strategy within a candidate pool using a hedge classifier. We apply this method to a natural peer-tutoring corpus containing a significant number of disfluencies, repetitions, and repairs. The results show that generation in this noisy environment is feasible with reranking. By conducting an error analysis for both approaches, we reveal the challenges faced by systems attempting to accomplish both social and task-oriented goals in conversation.",
  "The results show that generation in this noisy environment is feasible with reranking. By conducting an error analysis for both approaches, we reveal the challenges faced by systems attempting to accomplish both social and task-oriented goals in conversation.\nAuthors: Alafate Abulimiti, C. Clavel, Justine Cassell\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work develops a model of hedge generation based on fine-tuning state-of-the-art language models trained on human-human tutoring data, followed by reranking to select the candidate that best matches the expected hedging strategy within a candidate pool using a hedge classifier.'}\nUrl: http://arxiv.org/pdf/2306.14696",
  "Faculty Name: justine cassell\nPaperid: a82f56482b9e63714ea0d1948ac3aa6edb092001\nTitle: Beyond Single-Mindedness: A Figure-Ground Reversal for the Cognitive Sciences\nYear: 2023\nAbstract: A fundamental fact about human minds is that they are never truly alone: all minds are steeped in situated interaction. That social interaction matters is recognized by any experimentalist who seeks to exclude its influence by studying individuals in isolation. On this view, interaction complicates cognition. Here, we explore the more radical stance that interaction co-constitutes cognition: that we benefit from looking beyond single minds toward cognition as a process involving interacting minds. All around the cognitive sciences, there are approaches that put interaction center stage. Their diverse and pluralistic origins may obscure the fact that collectively, they harbor insights and methods that can respecify foundational assumptions and fuel novel interdisciplinary work. What might the cognitive sciences gain from stronger interactional foundations? This represents, we believe, one of the key questions for the future.",
  "Their diverse and pluralistic origins may obscure the fact that collectively, they harbor insights and methods that can respecify foundational assumptions and fuel novel interdisciplinary work. What might the cognitive sciences gain from stronger interactional foundations? This represents, we believe, one of the key questions for the future. Writing as a transdisciplinary collective assembled from across the classic cognitive science hexagon and beyond, we highlight the opportunity for a figure-ground reversal that puts interaction at the heart of cognition. The interactive stance is a way of seeing that deserves to be a key part of the conceptual toolkit of cognitive scientists.",
  "Writing as a transdisciplinary collective assembled from across the classic cognitive science hexagon and beyond, we highlight the opportunity for a figure-ground reversal that puts interaction at the heart of cognition. The interactive stance is a way of seeing that deserves to be a key part of the conceptual toolkit of cognitive scientists.\nAuthors: Mark Dingemanse, Andreas Liesenfeld, Marlou Rasenberg, Saul Albert, F. Ameka, Abeba Birhane, Dimitris Bolis, Justine Cassell, Rebecca Clift, E. Cuffari, H. Jaegher, C. Novaes, N. Enfield, Riccardo Fusaroli, E. Gregoromichelaki, E. Hutchins, Ivana Konvalinka, D. Milton, J. R\u0105czaszek-Leonardi, V. Reddy, F. Rossano, David Schlangen, J. Seibt, E. Stokoe, L. Suchman, C. Vesper, T. Wheatley, Martina Wiltschko\nVenue: Cognitive Sciences\nTldr: None\nUrl: https://repository.ubn.ru.nl/bitstream/handle/2066/291926/1/291926.pdf",
  "Faculty Name: justine cassell\nPaperid: b3efaa75beada858414a5ba2346dec317203633c\nTitle: \"You might think about slightly revising the title\u201d: Identifying Hedges in Peer-tutoring Interactions\nYear: 2023\nAbstract: Hedges have an important role in the management of rapport. In peer-tutoring, they are notably used by tutors in dyads experiencing low rapport to tone down the impact of instructions and negative feedback.Pursuing the objective of building a tutoring agent that manages rapport with teenagers in order to improve learning, we used a multimodal peer-tutoring dataset to construct a computational framework for identifying hedges. We compared approaches relying on pre-trained resources with others that integrate insights from the social science literature. Our best performance involved a hybrid approach that outperforms the existing baseline while being easier to interpret. We employ a model explainability tool to explore the features that characterize hedges in peer-tutoring conversations, and we identify some novel features, and the benefits of a such a hybrid model approach.",
  "Our best performance involved a hybrid approach that outperforms the existing baseline while being easier to interpret. We employ a model explainability tool to explore the features that characterize hedges in peer-tutoring conversations, and we identify some novel features, and the benefits of a such a hybrid model approach.\nAuthors: Yann Raphalen, C. Clavel, Justine Cassell\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A model explainability tool is employed to explore the features that characterize hedges in peer-tutoring conversations, and some novel features, and the benefits of a such a hybrid model approach are identified.'}\nUrl: https://aclanthology.org/2022.acl-long.153.pdf",
  "List of 2023 Open Access papers by justine cassell are:\nWhen to generate hedges in peer-tutoring interactions\nHow About Kind of Generating Hedges using End-to-End Neural Models?\nBeyond Single-Mindedness: A Figure-Ground Reversal for the Cognitive Sciences\n\"You might think about slightly revising the title\u201d: Identifying Hedges in Peer-tutoring Interactions",
  "Justine Cassell\nProfessor (On Leave), Language Technologies Institute\nHuman-Computer Interaction Institute : https://hcii.cmu.edu/\nPersonal Website: http://www.justinecassell.com/\nContact: 5107 \u2014Gates & Hillman Centers\nEmail: jcassell@andrew.cmu.edu\nPhone: 412-204-6268",
  "Faculty Name: kemal oflazer\nPaperid: 3b623333145c69cb29c63975213f7b3bac025954\nTitle: Abstractive summarization with deep reinforcement learning using semantic similarity rewards\nYear: 2023\nAbstract: \n Abstractive summarization is an approach to document summarization that is not limited to selecting sentences from the document but can generate new sentences as well. We address the two main challenges in abstractive summarization: how to evaluate the performance of a summarization model and what is a good training objective. We first introduce new evaluation measures based on the semantic similarity of the input and corresponding summary. The similarity scores are obtained by the fine-tuned BERTurk model using either the cross-encoder or a bi-encoder architecture. The fine-tuning is done on the Turkish Natural Language Inference and Semantic Textual Similarity benchmark datasets. We show that these measures have better correlations with human evaluations compared to Recall-Oriented Understudy for Gisting Evaluation (ROUGE) scores and BERTScore.",
  "The fine-tuning is done on the Turkish Natural Language Inference and Semantic Textual Similarity benchmark datasets. We show that these measures have better correlations with human evaluations compared to Recall-Oriented Understudy for Gisting Evaluation (ROUGE) scores and BERTScore. We then introduce a deep reinforcement learning algorithm that uses the proposed semantic similarity measures as rewards, together with a mixed training objective, in order to generate more natural summaries in terms of human readability. We show that training with a mixed training objective function compared to only the maximum-likelihood objective improves similarity scores.\nAuthors: Figen Beken Fikri, Kemal Oflazer, B. Yanikoglu\nVenue: Natural Language Engineering\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A deep reinforcement learning algorithm is introduced that uses the proposed semantic similarity measures as rewards, together with a mixed training objective, in order to generate more natural summaries in terms of human readability.'}",
  "Url: https://www.cambridge.org/core/services/aop-cambridge-core/content/view/740B4B5903AE80FE14709F5DAEE7AD41/S1351324923000505a.pdf/div-class-title-abstractive-summarization-with-deep-reinforcement-learning-using-semantic-similarity-rewards-div.pdf",
  "List of 2023 Open Access papers by kemal oflazer are:\nAbstractive summarization with deep reinforcement learning using semantic similarity rewards",
  "Kemal Oflazer\nTeaching Professor, Language Technologies Institute\nComputer Science Department\nContact\n1009 \u2014Carnegie Mellon - Qatar Campus\nEmail\nComputer Science - Qatar https://www.qatar.cmu.edu/academics-research/academics/computer-science/#/?feed=news&category=49&limit=3&featuredCategory=49&page=1\nPersonal Website https://www.andrew.cmu.edu/user/ko/",
  "Faculty Name: lei li\nPaperid: 01d95a39a3a3f333768a1c123eabaa066bf0d20f\nTitle: P53 protein and the diseases in central nervous system\nYear: 2023\nAbstract: P53 protein is the product of P53 gene, which is a well acknowledged tumor suppressor gene. The function of P53 and the relevant mechanisms of anti-neoplasm have raised the interest of researchers since many years ago. It is demonstrated that P53 is a basic cell cycle regulator and a strong inhibitor for versatile cancers in humans. However, most research focuses on other organs and systems instead of the central nervous system (CNS). In fact, in recent years, more and more studies have been suggesting that P53 plays a significant role in multiple CNS tumors and other diseases and disorders such as cerebral stroke and neurodegenerative diseases. In this work, we mainly reviewed the P53\u2019s relationship with CNS tumors, cerebral stroke and neurodegenerative diseases, together with the relevant mechanisms, aiming to summarize the research achievements and providing new insight to the future study on diseases in CNS.",
  "In this work, we mainly reviewed the P53\u2019s relationship with CNS tumors, cerebral stroke and neurodegenerative diseases, together with the relevant mechanisms, aiming to summarize the research achievements and providing new insight to the future study on diseases in CNS.\nAuthors: Li Lei, Qixiong Lu, Guifang Ma, Tao Li, Jiahong Deng, Weijia Li\nVenue: Frontiers in Genetics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The P53\u2019s relationship with CNS tumors, cerebral stroke and neurodegenerative diseases, together with the relevant mechanisms are reviewed, aiming to summarize the research achievements and provide new insight to the future study on diseases in CNS.'}\nUrl: https://www.frontiersin.org/articles/10.3389/fgene.2022.1051395/pdf",
  "Faculty Name: lei li\nPaperid: 0c840a5a5e483ff48cec60e81aa0b0bfa1a99498\nTitle: A Study of Yuediao Folk Music Knowledge Development in Zhoukou, Henan Province, China\nYear: 2023\nAbstract: None\nAuthors: Lei Li, Awirut Thotham\nVenue: Education Quarterly Reviews\nTldr: None\nUrl: https://osf.io/tgyjh/download",
  "Faculty Name: lei li\nPaperid: 1386e5712607e293f0b0288a133540e60aaeae67\nTitle: Influence of banded \u03b5-martensite and deformation twin on cryogenic toughness of Fe-Mn-xAl-C steel\nYear: 2023\nAbstract: None\nAuthors: Leilei Li, G. Niu, N. Gong, Hongfei Liu, Xuelin Wang, Chengjia Shang, Yong Wang, Huibin Wu\nVenue: Journal of Materials Research and Technology\nTldr: None\nUrl: N/A",
  "Faculty Name: lei li\nPaperid: 3c92fd24ea2a49aeba4b368abe3ef13cbce40987\nTitle: Long-tailed Extreme Multi-label Text Classification by the Retrieval of Generated Pseudo Label Descriptions\nYear: 2023\nAbstract: Extreme Multi-label Text Classification (XMTC) has been a tough challenge in machine learning research and applications due to the sheer sizes of the label spaces and the severe data scarcity problem associated with the long tail of rare labels in highly skewed distributions. This paper addresses the challenge of tail label prediction by leveraging the power of dense neural retrieval model in mapping input documents (as queries) to relevant label descriptions. To further enhance the quality of label descriptions, we propose to generate pseudo label descriptions from a trained bag-of-words (BoW) classifier, which demonstrates better classification performance under severe scarce data conditions.The proposed approach achieves the state-of-the-art (SOTA) performance of overall label prediction on XMTC benchmark datasets and especially outperforms the SOTA models in the tail label prediction. We also provide a theoretical analysis for relating the BoW and neural models w.r.t. performance lower bound.",
  "We also provide a theoretical analysis for relating the BoW and neural models w.r.t. performance lower bound.\nAuthors: Ruohong Zhang, Yau-Shian Wang, Yiming Yang, Donghan Yu, Tom Vu, Li Lei\nVenue: Findings\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper addresses the challenge of tail label prediction by leveraging the power of dense neural retrieval model in mapping input documents to relevant label descriptions and generates pseudo label descriptions from a trained bag-of-words (BoW) classifier, which demonstrates better classification performance under severe scarce data conditions.'}\nUrl: https://aclanthology.org/2023.findings-eacl.81.pdf",
  "Faculty Name: lei li\nPaperid: 45e961e87f86888cbe0a117b7a21335690e13c17\nTitle: Oral phage therapy with microencapsulated phage A221 against Escherichia coli infections in weaned piglets\nYear: 2023\nAbstract: None\nAuthors: Xinyu Mao, Yuxin Wu, Runwen Ma, Lei Li, Leping Wang, Yizhou Tan, Ziyong Li, Hui Liu, Kaiou Han, Yajie Cao, Yinan Li, Hao Peng, Xun Li, Chuan-Huo Hu, Xiaoye Wang\nVenue: BMC Veterinary Research\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Oral microencapsulated phage A221 has a good therapeutic effect on bacterial diarrhea of weaned piglets, which provides guidance for the clinical application of phage therapy in the future.'}\nUrl: https://bmcvetres.biomedcentral.com/counter/pdf/10.1186/s12917-023-03724-y",
  "Faculty Name: lei li\nPaperid: 4fac3037fb156bcc42be6d7dbfb90cb933f80f91\nTitle: Correction: Polydopamine-functionalized selenium nanoparticles as an efficient photoresponsive antibacterial platform\nYear: 2023\nAbstract: Correction for \u2018Polydopamine-functionalized selenium nanoparticles as an efficient photoresponsive antibacterial platform\u2019 by Meng Sun et al., RSC Adv., 2023, 13, 9998\u201310004, https://doi.org/10.1039/D2RA07737J.\nAuthors: Meng Sun, Ping Gao, Bao Wang, Xiangyang Li, Donghan Shao, Yan-Jun Xu, Leijiao Li, Yunhui Li, Jianwei Zhu, Wenliang Li, Yingxue Xue\nVenue: RSC Advances\nTldr: {'model': 'tldr@v2.0.0', 'text': None}\nUrl: https://pubs.rsc.org/en/content/articlepdf/2023/ra/d3ra90039h",
  "Faculty Name: lei li\nPaperid: 56de9c4c63ee74757be1b203d2ea852690087ded\nTitle: Hence, Socrates is mortal: A Benchmark for Natural Language Syllogistic Reasoning\nYear: 2023\nAbstract: Syllogistic reasoning, a typical form of deductive reasoning, is a critical capability widely required in natural language understanding tasks, such as text entailment and question answering. To better facilitate research on syllogis-tic reasoning, we develop a benchmark called S YLLO B ASE that differs from existing syllo-gistic datasets in three aspects: (1) Covering a complete taxonomy of syllogism reasoning patterns; (2) Containing both automatically and manually constructed samples; and (3) Involving both the generation and understanding tasks. We automatically construct 50k template-based syllogism samples by mining syllogism patterns from Wikidata and ConceptNet. To improve our dataset\u2019s naturalness and challenge, we apply GPT-3 to paraphrase the template-based data and further manually rewrite 1,000 samples as the test set.",
  "To improve our dataset\u2019s naturalness and challenge, we apply GPT-3 to paraphrase the template-based data and further manually rewrite 1,000 samples as the test set. State-of-the-art pre-trained language models can achieve the best generation ROUGE-L of 38.72 by T5 and the best multi-choice accuracy of 72.77% by RoBERTa on S YLLO B ASE , which indicates the great challenge of learning diverse syllo-gistic reasoning types on S YLLO B ASE .",
  "Our datasets are released at https://github.com/ casually-PYlearner\nAuthors: Yongkang Wu, Meng Han, Yutao Zhu, Lei Li, Xinyu Zhang, Ruofei Lai, Xiaoguang Li, Yuanhang Ren, Zhicheng Dou, Zhao Cao\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A benchmark called S YLLO B ASE that differs from existing syllo-gistic datasets in three aspects, covering a complete taxonomy of syllogism reasoning patterns; containing both automatically and manually constructed samples; and involving both the generation and understanding tasks.'}\nUrl: https://aclanthology.org/2023.findings-acl.148.pdf",
  "Faculty Name: lei li\nPaperid: 6d91a5ce236d4f97a69eb326296133e7f0a352ba\nTitle: Research on torsional stiffness of flexspline-flexible bearing contact pair in harmonic drive based on macro-micro scale modeling\nYear: 2023\nAbstract: The flexspline and flexible bearing constitute a critical contact pair in a harmonic drive system, and their torsional stiffness has a significant impact on the performance characteristics manifested by the harmonic drive. In this study, a micro scale three-dimensional fractal model was combined with a macro scale finite element simulation method to establish an equivalent torsional stiffness model for the flexspline-flexible bearing contact pair (FS-FB contact pair), which enables the theoretical prediction of the torsional stiffness of this contact pair. A torsional stiffness testing platform was constructed for a harmonic drive, and the consistency between the experimental results of the torsional stiffness curve and the theoretical predictions validates the effectiveness of the proposed model. The influences of torque, installation eccentricity, and deformation coefficient on the torsional stiffness of the FS-FB contact pair were also discussed.",
  "The influences of torque, installation eccentricity, and deformation coefficient on the torsional stiffness of the FS-FB contact pair were also discussed. The results indicate that the torsional stiffness of the FS-FB contact pair increases nonlinearly with an increase in torque. On the other hand, the torsional stiffness of the FS-FB contact pair decreases with an increase in installation eccentricity, and increases before subsequently decreasing with an increase in deformation coefficient. Moreover, as torque increases, the impact of installation eccentricity and deformation coefficient on the torsional stiffness diminishes. This article provides a theoretical reference for the optimization design and performance enhancement of harmonic drives.\nAuthors: Qiushi Hu, Hengtao Li, Guang Wang, Leitao Li\nVenue: Frontiers in Materials\nTldr: None\nUrl: https://www.frontiersin.org/articles/10.3389/fmats.2023.1211019/pdf",
  "Faculty Name: lei li\nPaperid: 7005e58d3b5593c4be1d9e2933825d0a99ca93cc\nTitle: Low-Voltage Solution-Processed Zinc-Doped CuI Thin Film Transistors with NOR Logic and Artificial Synaptic Function\nYear: 2023\nAbstract: Low-voltage Zn-doped CuI thin film transistors (TFTs) gated by chitosan dielectric were fabricated at a low temperature. The Zn-doped CuI TFT exhibited a more superior on/off current ratio than CuI TFT due to the substitution or supplementation of copper vacancies by Zn ions. The Zn-doped CuI films were characterized by scanning electron microscope, X-ray diffraction, and X-ray photoelectron spectroscopy. The Zn-doped CuI TFTs exhibited an on/off current ratio of 1.58 \u00d7 104, a subthreshold swing of 70 mV/decade, and a field effect mobility of 0.40 cm2V\u22121s\u22121, demonstrating good operational stability.",
  "The Zn-doped CuI TFTs exhibited an on/off current ratio of 1.58 \u00d7 104, a subthreshold swing of 70 mV/decade, and a field effect mobility of 0.40 cm2V\u22121s\u22121, demonstrating good operational stability. Due to the electric-double-layer (EDL) effect and high specific capacitance (17.3 \u03bcF/cm2) of chitosan gate dielectric, Zn-doped CuI TFT operates at a voltage below \u22122 V. The threshold voltage is \u22120.2 V. In particular, we have prepared Zn-doped CuI TFTs with two in-plane gates and NOR logic operation is implemented on such TFTs. In addition, using the ion relaxation effect and EDL effect of chitosan film, a simple pain neuron simulation is realized on such a p-type TFTs for the first time through the bottom gate to regulate the carrier transport of the channel. This p-type device has promising applications in low-cost electronic devices, complementary electronic circuit, and biosensors.",
  "This p-type device has promising applications in low-cost electronic devices, complementary electronic circuit, and biosensors.\nAuthors: Xiaomin Gan, Wei Dou, Wei-Tzu Hou, Xingchen A. Yuan, Liu Lei, Yulan Zhou, Jia Yang, Diandian Chen, Weichang Zhou, Dongsheng Tang\nVenue: Nanomaterials\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A simple pain neuron simulation is realized on such a p-type TFTs for the first time through the bottom gate to regulate the carrier transport of the channel, which has promising applications in low-cost electronic devices, complementary electronic circuit, and biosensors.'}\nUrl: https://www.mdpi.com/2079-4991/13/16/2345/pdf?version=1692146819",
  "Faculty Name: lei li\nPaperid: 73c9f93d448a359c744447af6daa0b599fb9be4b\nTitle: Optimizing Heat Treatment to Improve the Microstructures and Mechanical Properties of 5CrNiMoV Steel\nYear: 2023\nAbstract: A strategy combining intercritical quenching, pre-tempering, and tempering processes was implemented to optimize the microstructures and mechanical properties of 5CrNiMoV steel. By intercritically quenching at 1050 \u00b0C, pr-tempering at 600 \u00b0C, and tempering at 550 \u00b0C, the steel exhibited a comprehensive performance with a yield strength of 1120 MPa, an ultimate tensile strength of 1230 MPa, and an elongation of 8.2%. The high strength of the steel is attributed to the presence of tempered martensite and abundant secondary carbides. The favorable ductility is mainly provided by the pearlite inherited from intercritical quenching and tempering.",
  "The high strength of the steel is attributed to the presence of tempered martensite and abundant secondary carbides. The favorable ductility is mainly provided by the pearlite inherited from intercritical quenching and tempering. Additionally, the precipitation of secondary carbides not only enhances precipitation strengthening, but also reduces the dislocation density and lattice strain of the matrix, thereby enhancing strength and ductility. This study offers a scheme for producing strong and ductile 5CrNiMoV steel.\nAuthors: Wanhui Huang, Li-sheng Lei, G. Fang\nVenue: Metals\nTldr: None\nUrl: https://www.mdpi.com/2075-4701/13/7/1263/pdf?version=1689243786",
  "Faculty Name: lei li\nPaperid: 75b68d0903af9d9f6e47ce3cf7e1a7d27ec811dc\nTitle: Provable Robust Watermarking for AI-Generated Text\nYear: 2023\nAbstract: We study the problem of watermarking large language models (LLMs) generated text -- one of the most promising approaches for addressing the safety challenges of LLM usage. In this paper, we propose a rigorous theoretical framework to quantify the effectiveness and robustness of LLM watermarks. We propose a robust and high-quality watermark method, Unigram-Watermark, by extending an existing approach with a simplified fixed grouping strategy. We prove that our watermark method enjoys guaranteed generation quality, correctness in watermark detection, and is robust against text editing and paraphrasing. Experiments on three varying LLMs and two datasets verify that our Unigram-Watermark achieves superior detection accuracy and comparable generation quality in perplexity, thus promoting the responsible use of LLMs. Code is available at https://github.com/XuandongZhao/Unigram-Watermark.",
  "Experiments on three varying LLMs and two datasets verify that our Unigram-Watermark achieves superior detection accuracy and comparable generation quality in perplexity, thus promoting the responsible use of LLMs. Code is available at https://github.com/XuandongZhao/Unigram-Watermark.\nAuthors: Xuandong Zhao, P. Ananth, Lei Li, Yu-Xiang Wang\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A robust and high-quality watermark method, Unigram-Watermark, is proposed by extending an existing approach with a simplified fixed grouping strategy that enjoys guaranteed generation quality, correctness in watermark detection, and is robust against text editing and paraphrasing.'}\nUrl: https://arxiv.org/pdf/2306.17439",
  "Faculty Name: lei li\nPaperid: 75d672cf3e648bdbeb9bbe31e91d8d721b550304\nTitle: Combining non-negative matrix factorization with graph Laplacian regularization for predicting drug-miRNA associations based on multi-source information fusion\nYear: 2023\nAbstract: Increasing evidences suggest that miRNAs play a key role in the occurrence and progression of many complex human diseases. Therefore, targeting dysregulated miRNAs with small molecule drugs in the clinical has become a new treatment. Nevertheless, it is high cost and time-consuming for identifying miRNAs-targeted with drugs by biological experiments. Thus, more reliable computational method for identification associations of drugs with miRNAs urgently need to be developed. In this study, we proposed an efficient method, called GNMFDMA, to predict potential associations of drug with miRNA by combining graph Laplacian regularization with non-negative matrix factorization. We first calculated the overall similarity matrices of drugs and miRNAs according to the collected different biological information. Subsequently, the new drug-miRNA association adjacency matrix was reformulated based on the K nearest neighbor profiles so as to put right the false negative associations.",
  "We first calculated the overall similarity matrices of drugs and miRNAs according to the collected different biological information. Subsequently, the new drug-miRNA association adjacency matrix was reformulated based on the K nearest neighbor profiles so as to put right the false negative associations. Finally, graph Laplacian regularization collaborative non-negative matrix factorization was used to calculate the association scores of drugs with miRNAs. In the cross validation, GNMFDMA obtains AUC of 0.9193, which outperformed the existing methods. In addition, case studies on three common drugs (i.e., 5-Aza-CdR, 5-FU and Gemcitabine), 30, 31 and 34 of the top-50 associations inferred by GNMFDMA were verified. These results reveal that GNMFDMA is a reliable and efficient computational approach for identifying the potential drug-miRNA associations.",
  "These results reveal that GNMFDMA is a reliable and efficient computational approach for identifying the potential drug-miRNA associations.\nAuthors: Mei-Neng Wang, Yu Li, Li-lan Lei, D. Ding, Xue-Jun Xie\nVenue: Frontiers in Pharmacology\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The proposed GNMFDMA is a reliable and efficient computational approach for identifying the potential drug-miRNA associations and outperformed the existing methods.'}\nUrl: https://www.frontiersin.org/articles/10.3389/fphar.2023.1132012/pdf",
  "Faculty Name: lei li\nPaperid: 7a47828ca29d646967e100bfcd8c9457c682bb38\nTitle: Integrated Valve Product Fluid Simulation and Test Verification\nYear: 2023\nAbstract: The integrated valve product\u2019s main function is to electrolytic oxygen generation subsystem to produce hydrogen and oxygen to realize automatic discharge, to maintain the space station astronauts in orbit around in comfort and safety, high reliability, easy maintenance, and the device should be easy replacement of human-computer ergonomics requirements to ensure long-term on-orbit operation station. Based on the above requirements, an integrated valve product based on environmental control and a health protection system is designed. The integrated product includes hydrogen normal and backup emission branches, oxygen normal and backup emission branches. Through fluid simulation and experimental verification, it is verified that the flow rate and other key indicators of the integrated valve product meet the requirements, which has certain reference and guiding significance for the design of similar integrated products in the future.",
  "The integrated product includes hydrogen normal and backup emission branches, oxygen normal and backup emission branches. Through fluid simulation and experimental verification, it is verified that the flow rate and other key indicators of the integrated valve product meet the requirements, which has certain reference and guiding significance for the design of similar integrated products in the future.\nAuthors: Lei-Lei Li, Baorong Liu, Shengbo Gong, Jian Zhao, Q. Tao, Xu Zhou, Yingli Xu, Menglei Guo\nVenue: Journal of Physics: Conference Series\nTldr: None\nUrl: N/A",
  "Faculty Name: lei li\nPaperid: 7fcd5d8f8b492533444a8179a07888df267da5a4\nTitle: Editorial: Strategies for functional polymeric nanocomposites and its multifunctional applications\nYear: 2023\nAbstract: The development of nanomaterial\u2019s has greatly contributed to the development of modern medicine and optics, and polymers are an important support and branch of nanomaterial\u2019s. They are non-toxic and harmless, can be degraded into small fragments in the body, and are finally excreted without causing inflammation. Due to their many advantages, biodegradable polymers have attracted more and more attention. In this Research Topic, we focus on reviewing and introducing some polymers for wound repair, drug loading or with special optical properties. These articles are categorized into three themes: 1) polydopamine for wound repair; 2) dendrimers as drug carriers; 3) optical polymers.",
  "In this Research Topic, we focus on reviewing and introducing some polymers for wound repair, drug loading or with special optical properties. These articles are categorized into three themes: 1) polydopamine for wound repair; 2) dendrimers as drug carriers; 3) optical polymers.\nAuthors: Qinqing Wang, A. Prasannan, Nimita Jebaranjitham J., Leijiao Li, Wenliang Li\nVenue: Frontiers in Chemistry\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This Research Topic focuses on reviewing and introducing some polymers for wound repair, drug loading or with special optical properties, and categorized into three themes: 1) polydopamine for wounds repair; 2) dendrimers as drug carriers; 3) optical polymers.'}\nUrl: https://www.frontiersin.org/articles/10.3389/fchem.2023.1274460/pdf",
  "Faculty Name: lei li\nPaperid: 81a0ff93d7a3678330c0fb362fab427217bf2483\nTitle: Population pharmacokinetic analysis and dosing regimen optimization of teicoplanin in critically ill patients with sepsis\nYear: 2023\nAbstract: Objectives: Teicoplanin has been extensively used in the treatment for infections caused by gram-positive bacteria including methicillin-resistant Staphylococcus aureus (MRSA). However, current teicoplanin treatment is challenging due to relatively low and variable concentrations under standard dosage regimens. This study aimed to investigate the population pharmacokinetics (PPK) characteristics of teicoplanin in adult sepsis patients and provide recommendations for optimal teicoplanin dosing regimens. Methods: A total of 249 serum concentration samples from 59 septic patients were prospectively collected in the intensive care unit (ICU). Teicoplanin concentrations were detected, and patients\u2019 clinical data were recorded. PPK analysis was performed using a non-linear, mixed-effect modeling approach. Monte Carlo simulations were performed to evaluate currently recommended dosing and other dosage regimens.",
  "Teicoplanin concentrations were detected, and patients\u2019 clinical data were recorded. PPK analysis was performed using a non-linear, mixed-effect modeling approach. Monte Carlo simulations were performed to evaluate currently recommended dosing and other dosage regimens. The optimal dosing regimens were defined and compared by different pharmacokinetic/pharmacodynamic parameters, including trough concentration (Cmin), the ratio of 24-h area under the concentration-time curve to the minimum inhibitory concentration (AUC0-24/MIC), as well as the probability of target attainment (PTA) and the cumulative fraction of response (CFR) against MRSA. Results: A two-compartment model adequately described the data. The final model parameter estimates for clearance, central compartment volume of distribution, intercompartmental clearance and peripheral compartment volume were 1.03 L/h, 20.1 L, 3.12 L/h and 101 L, respectively. Glomerular filtration rate (GFR) was the only covariate that significantly affected teicoplanin clearance.",
  "Glomerular filtration rate (GFR) was the only covariate that significantly affected teicoplanin clearance. Model-based simulations revealed that 3 or 5 loading doses of 12/15 mg/kg every 12 h followed by a maintenance dose of 12/15 mg/kg every 24 h\u201372 h for patients with different renal functions were required to achieve a target Cmin of 15 mg/L and a target AUC0-24/MIC of 610. For MRSA infections, PTAs and CFRs were not satisfactory for simulated regimens. Prolonging the dosing interval may be easier to achieve the target AUC0-24/MIC than reducing the unit dose for renal insufficient patients. Conclusion: A PPK model for teicoplanin in adult septic patients was successfully developed. Model-based simulations revealed that current standard doses may result in undertherapeutic Cmin and AUC, and a single dose of at least 12 mg/kg may be needed.",
  "Conclusion: A PPK model for teicoplanin in adult septic patients was successfully developed. Model-based simulations revealed that current standard doses may result in undertherapeutic Cmin and AUC, and a single dose of at least 12 mg/kg may be needed. AUC0-24/MIC should be preferred as the PK/PD indicator of teicoplanin, if AUC estimation is unavailable, in addition to routine detection of teicoplanin Cmin on Day 4, follow-up therapeutic drug monitoring at steady-state is recommended.\nAuthors: Chao-Yang Chen, M. Xie, J. Gong, Ning Yu, Ran Wei, Lili Lei, Siru Zhao, Ruoming Li, Xiu Dong, Xiang-lin Zhang, Ying Zhou, Shuangling Li, Yi-min Cui\nVenue: Frontiers in Pharmacology\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A PPK model for teicoplanin in adult septic patients was successfully developed and revealed that current standard doses may result in undertherapeutic Cmin and AUC, and a single dose of at least 12 mg/kg may be needed.'}",
  "Url: https://www.frontiersin.org/articles/10.3389/fphar.2023.1132367/pdf",
  "Faculty Name: lei li\nPaperid: 8a9ff288d3800863ec80c5abe3998f0d35f2d6da\nTitle: MCM6 is a Poor Prognostic Biomarker and Promotes Progression in Breast Cancer.\nYear: 2023\nAbstract: BACKGROUND\nBreast cancer is the commonest global malignancy and the primary cause of carcinoma death. MCM6 is vital to carcinogenesis, but the pathogenesis of MCM6 remains unclear.",
  "METHODS\nMCM6 expression in patients with breast cancer was examined through The Cancer Genome Atlas (TCGA) database, immunohistochemistry, Quantitative Real-Time PCR (qRT\u2012PCR) and Western blotting. The prognostic factors were assessed by the Kaplan\u2012Meier method and Cox regression. On the basis of the key factors selected by multivariable Cox regression analysis, a nomogram risk prediction model was adopted for clinical risk assessment. The TCGA database was utilized to determine how MCM6 is correlated with chemotherapy sensitivity, immune checkpoint-related genes (ICGs), tumor-infiltrating immune cells, along with tumor mutation burden (TMB) and methylation. The impact of MCM6 on carcinoma cells was investigated in terms of proliferation, cell cycle as well as migrating and invasive behavior through CCK assays, flow cytometry, wound healing assays, Transwell assays and xenotransplantation experiments.",
  "RESULTS\nMCM6 expression was upregulated, which is closely associated with the size of the tumor (p = 0.001) and lymph node metastasis (p = 0.012) in patients with breast cancer. Multivariate analysis revealed MCM6 to be an independent risk factor for prognosis in patients with breast carcinoma. The nomograph prediction model included MCM6, age, ER, M and N stage, which displayed good discrimination with a C index of 0.817 and good calibration. Overexpression of MCM6 correlated with chemotherapy sensitivity, immune checkpoint-related genes (ICGs), tumor-infiltrating immune cells, tumor mutation burden (TMB), and methylation. Silencing MCM6 significantly inhibited proliferation, prolonged the G1 phase of the cell cycle, and restrained the proliferation, migration and invasive behavior of cancerous cells and inhibited tumor growth in vivo.",
  "CONCLUSIONS\nOur research shows that MCM6 is highly expressed in breast cancer and can be used as an independent prognostic factor, which is expected to become a new target for the treatment of breast cancer in the future.\nAuthors: Zi Lei, Peng Wang, Da-Qi Jia, Lei Li, Yi-peng Wu, Yuan Yang, Guo-Qing Pan\nVenue: Frontiers in Bioscience\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Research shows that MCM6 is highly expressed in breast cancer and can be used as an independent prognostic factor, which is expected to become a new target for the treatment of breast cancer in the future.'}\nUrl: https://www.imrpress.com/journal/FBL/28/8/10.31083/j.fbl2808188/pdf",
  "Faculty Name: lei li\nPaperid: 8c2fae4c9622fefe0e7594e7637175d2bb4e2125\nTitle: Variation of virtual temperature and wind in the atmospheric boundary layer over the pearl river estuary during 2011\u20132020\nYear: 2023\nAbstract: Most studies of the effects of urbanisation on local climate have been based on ground observation data. In contrast, we used observation data from a boundary layer radar wind profiler, radio-acoustic sounding system, and automatic meteorological station located at Shenzhen Bao\u2019an International Airport to analyse changes in wind and virtual temperature in the upper level atmosphere, with a top height of 1,200 m, over the Pearl River Estuary between 2011 and 2020. Our results show that during the decade evaluated, the wind speed and virtual temperature of the upper level atmosphere over the Pearl River Estuary changed very significantly and faster than the changes observed at ground level. During the study period, the linear warming rate of the virtual temperature of the upper level atmosphere reached 0.24\u00b0C/a, whereas that on the land surface was 0.17\u00b0C/a.",
  "During the study period, the linear warming rate of the virtual temperature of the upper level atmosphere reached 0.24\u00b0C/a, whereas that on the land surface was 0.17\u00b0C/a. The mean decreases in the upper level atmosphere and land surface wind speeds were \u22120.12 and \u22120.05 m/s\u00b7a, respectively. Additionally, the rate of change in the upper level climate was faster in winter than in summer for both wind speed and virtual temperature. These changes in the climate of the upper level atmosphere over the Pearl River Estuary may be related to the rapid increase in the number of high-rise buildings in the region during that decade, which generally negatively affected the atmospheric environment.\nAuthors: Lei Li, Qian-Jin Zhou, P. Chan, Hong-Long Yang\nVenue: Frontiers in Environmental Science\nTldr: None\nUrl: https://www.frontiersin.org/articles/10.3389/fenvs.2022.1104553/pdf",
  "Faculty Name: lei li\nPaperid: 8e54fd15fb5f8c035a772ecdfdebd8c9449d4656\nTitle: Numerical simulation research on the overturning of gantry crane by downbursts\nYear: 2023\nAbstract: None\nAuthors: Jia-Chen Su, Lei Li, P. Chan, Qian-Jin Zhou, Hong-Long Yang\nVenue: Heliyon\nTldr: None\nUrl: http://www.cell.com/article/S2405844023058498/pdf",
  "Faculty Name: lei li\nPaperid: 937bb21fe0836419762ea8410ce989e4840052ec\nTitle: Wavefront shaping improves the transparency of the scattering media: a review\nYear: 2023\nAbstract: Abstract. Significance Wavefront shaping (WFS) can compensate for distortions by optimizing the wavefront of the input light or reversing the transmission matrix of the media. It is a promising field of research. A thorough understanding of principles and developments of WFS is important for optical research. Aim To provide insight into WFS for researchers who deal with scattering in biomedicine, imaging, and optical communication, our study summarizes the basic principles and methods of WFS and reviews recent progress. Approach The basic principles, methods of WFS, and the latest applications of WFS in focusing, imaging, and multimode fiber (MMF) endoscopy are described. The practical challenges and prospects of future development are also discussed. Results Data-driven learning-based methods are opening up new possibilities for WFS. High-resolution imaging through MMFs can support small-diameter endoscopy in the future.",
  "The practical challenges and prospects of future development are also discussed. Results Data-driven learning-based methods are opening up new possibilities for WFS. High-resolution imaging through MMFs can support small-diameter endoscopy in the future. Conclusion The rapid development of WFS over the past decade has shown that the best solution is not to avoid scattering but to find ways to correct it or even use it. WFS with faster speed, more optical modes, and more modulation degrees of freedom will continue to drive exciting developments in various fields.\nAuthors: Chunxu Ding, Rongjun Shao, Qiaozhi He, Lei S Li, Jiamiao Yang\nVenue: Journal of Biomedical Optics\nTldr: None\nUrl: https://www.spiedigitallibrary.org/journals/journal-of-biomedical-optics/volume-29/issue-S1/S11507/Wavefront-shaping-improves-the-transparency-of-the-scattering-media/10.1117/1.JBO.29.S1.S11507.pdf",
  "Faculty Name: lei li\nPaperid: a499e33f815180fa77c5067b0dfc0dc540940da0\nTitle: p53 deacetylation alleviates calcium oxalate deposition-induced renal fibrosis by inhibiting ferroptosis.\nYear: 2023\nAbstract: None\nAuthors: Zehua Ye, Yu-qi Xia, Lei Li, Bojun Li, Lijia Chen, Wei-min Yu, Y. Ruan, T. Rao, Xiangjun Zhou, F. Cheng\nVenue: Biomedicine & pharmacotherapy = Biomedecine & pharmacotherapie\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is concluded that ferroptosis is one of the critical mechanisms contributing to CaOx crystal-induced renal fibrosis, and the pharmacological induction of ferroPTosis via sirtuin 1-mediated p53 deacetylation may be a potential target for preventing renal Fibrosis in patients with nephrolithiasis.'}\nUrl: N/A",
  "Faculty Name: lei li\nPaperid: a61f910a00c60bbf8b9ba1eae7c1757bb0b36426\nTitle: PTTG1 reprograms asparagine metabolism to promote hepatocellular carcinoma progression.\nYear: 2023\nAbstract: Hepatocellular carcinoma (HCC) is the most common type of primary liver cancer and has a poor prognosis. Pituitary tumor transforming gene 1 (PTTG1) is highly expressed in HCC, suggesting it could play an important role in hepatocellular carcinogenesis. Here, we evaluated the impact of PTTG1 deficiency on HCC development using a diethylnitrosamine (DEN)-induced HCC mouse model and a hepatitis B virus regulatory X protein (HBx)-induced spontaneous HCC mouse model. PTTG1 deficiency significantly suppressed DEN- and HBx-induced hepatocellular carcinogenesis. Mechanistically, PTTG1 promoted asparagine synthetase (ASNS) transcription by binding to its promoter, and asparagine levels were correspondingly increased. The elevated levels of asparagine subsequently activated the mTOR pathway to facilitate HCC progression.",
  "Mechanistically, PTTG1 promoted asparagine synthetase (ASNS) transcription by binding to its promoter, and asparagine levels were correspondingly increased. The elevated levels of asparagine subsequently activated the mTOR pathway to facilitate HCC progression. In addition, asparaginase treatment reversed the proliferation induced by PTTG1 overexpression. Furthermore, HBx promoted ASNS and asparagine metabolism by upregulating PTTG1 expression. Overall, PTTG1 is involved in the reprogramming of asparagine metabolism to promote HCC progression and may serve as a therapeutic and diagnostic target for HCC.\nAuthors: Qi Zhou, Leijia Li, Feifei Sha, Yiming Lei, Xuanen Tian, Lingjun Chen, Yan Chen, Huiling Liu, Yunwei Guo\nVenue: Cancer Research\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Overall, PTTG1 is involved in the reprogramming of asparagine metabolism to promote HCC progression and may serve as a therapeutic and diagnostic target for HCC.'}\nUrl: N/A",
  "Faculty Name: lei li\nPaperid: a64ab230ee2d32f91a05fa2881fb159d90187ee0\nTitle: Study on thermal stability and biocompatibility of bimodal microstructure in Cr\u2013Mn\u2013N austenitic stainless steel\nYear: 2023\nAbstract: None\nAuthors: G. Niu, Leilei Li, Haoxiu Chen, C. Gu, Jinxu Liu, N. Gong, Hui-bin Wu\nVenue: Journal of Materials Research and Technology\nTldr: None\nUrl: N/A",
  "Faculty Name: lei li\nPaperid: acd17a514d5aa3fbdb150205641aa05400e7e96b\nTitle: Phosphorus Availability Affects the Photosynthesis and Antioxidant System of Contrasting Low-P-Tolerant Cotton Genotypes\nYear: 2023\nAbstract: Phosphorus (P) is an essential macronutrient, and an important component of plant metabolism. However, little is known about the effects of low P availability on P absorption, the photosynthetic electron transport chain, and the antioxidant system in cotton. This study used cotton genotypes (sensitive FJA and DLNTDH and tolerant BX014 and LuYuan343) with contrasting low-P tolerance in a hydroponic experiment under 15 \u00b5M, 50 \u00b5M, and 500 \u03bcM P concentrations. The results showed that low P availability reduced plant development and leaf area, shoot length, and dry weight in FJA and DLNADH, compared to BX014 and LuYuan343.",
  "The results showed that low P availability reduced plant development and leaf area, shoot length, and dry weight in FJA and DLNADH, compared to BX014 and LuYuan343. The low P availability decreased the gas-exchange parameters such as the net photosynthetic rate, transpiration rate, and stomatal conductance, and increased the intercellular CO2 concentration. Chlorophyll a fluorescence demonstrated that the leaves\u2019 absorption and trapped-energy flux were largely steady. In contrast, considerable gains in absorption and trapped-energy flux per reaction center resulted from decreases in the electron transport per reaction center under low-P conditions. In addition, low P availability reduced the activities of antioxidant enzymes and increased the content of malondialdehyde in the cotton genotypes, especially in FJA and DLNTDH. Moreover, low P availability reduced the activity of PEPC and generated a decline in the content of ATP and NADPH. Our research can provide a theoretical physiological basis for the growth and tolerance of cotton under low-P conditions.",
  "Moreover, low P availability reduced the activity of PEPC and generated a decline in the content of ATP and NADPH. Our research can provide a theoretical physiological basis for the growth and tolerance of cotton under low-P conditions.\nAuthors: Mirezhatijiang Kayoumu, A. Iqbal, N. Muhammad, Xiaotong Li, Leilei Li, Xiangru Wang, Huiping Gui, Qian Qi, Sijia Ruan, Ruishi Guo, Xiling Zhang, M. Song, Qiang Dong\nVenue: Antioxidants\nTldr: None\nUrl: https://www.mdpi.com/2076-3921/12/2/466/pdf?version=1677123742",
  "Faculty Name: lei li\nPaperid: aea4876c3a5b596ef95a828baea8b3d9022cda62\nTitle: Failure Analysis and Improvement of Check Valve Reverse Cut-off Seal\nYear: 2023\nAbstract: Given the failure of reverse cut-off seal performance in the test process of the check valve, the fault location and mechanism analysis were carried out, and the improvement measures were proposed and verified by the test. It is analyzed that the main reason for the failure is the unreasonable design of the moving pair and the welding position of the check valve, which makes the sealing pair cannot fit effectively after the welding of the check valve, leading to the failure of the reverse cut-off seal. By controlling the ratio of the length of the guide surface to the diameter of the guide surface to 1.25, and controlling the distance between the welding position and the sealing pair to 10mm, the failure problem of the reverse cut-off seal of the check valve caused by the unreasonable design of the moving pair and the weld position is successfully solved. The effectiveness of the improved scheme of the check valve is verified by the test.",
  "The effectiveness of the improved scheme of the check valve is verified by the test.\nAuthors: Lei-Lei Li, Jian Zhao, Sheng-bo Gong, Baoguo Liu, H. Zhang, Xiao-lei Zhou, Lilei Miao, Peng Li\nVenue: Journal of Physics: Conference Series\nTldr: None\nUrl: https://iopscience.iop.org/article/10.1088/1742-6596/2450/1/012063/pdf",
  "Faculty Name: lei li\nPaperid: af7115085a46a2b884c38164050c0a4f23fb92af\nTitle: Integrated Transcriptome and Small RNA Sequencing Analyses Reveals Insights into the Molecular Mechanism of Seed Germination in Mung Bean\nYear: 2023\nAbstract: None\nAuthors: Yan-yan Pu, Liwen Wang, Leilei Li, Yujun Si, Shubin Xie, Yunzhe Cong, Dong Wang, Yongchao Gong, Rumei Tian, Xue Chen, Xiao-yue Zhang, Min Liu, H. Ding, Nana Li\nVenue: Phyton\nTldr: None\nUrl: N/A",
  "Faculty Name: lei li\nPaperid: affdee29f2c6d34e839e9e9a15afd6aa1c9b5af8\nTitle: Polydopamine-functionalized selenium nanoparticles as an efficient photoresponsive antibacterial platform\nYear: 2023\nAbstract: A photoresponsive therapeutic antibacterial platform was designed and constructed using polydopamine-functionalized selenium nanoparticles as a carrier loaded with indocyanine green (Se@PDA-ICG). The therapeutic platform was confirmed by characterization and the antibacterial activity of Se@PDA-ICG against Staphylococcus aureus (S. aureus) and Escherichia coli (E. coli) was investigated. Under 808 nm laser irradiation, the antibacterial rate of Se@PDA-ICG against E. coli and S. aureus was 100% at 125 \u03bcg mL\u22121.",
  "Under 808 nm laser irradiation, the antibacterial rate of Se@PDA-ICG against E. coli and S. aureus was 100% at 125 \u03bcg mL\u22121. Furthermore, in a mouse wound infection model, the wound closure rate of the Se@PDA-ICG photoresponse group was 88.74% compared with 45.8% for the control group after 8 days of treatment, indicating that it could effectively kill bacteria and dramatically accelerate the wound healing process. These results suggested that Se@PDA-ICG could be a promising photo-activated antibacterial candidate material for biomedical applications.\nAuthors: Meng Sun, P. Gao, Bao Wang, Xiangyang Li, Donghan Shao, Yan Xu, Leijiao Li, Yunhui Li, Jianwei Zhu, Wenliang Li, Yingxue Xue\nVenue: RSC Advances\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Results suggested that Se@PDA-ICG could be a promising photo-activated antibacterial candidate material for biomedical applications.'}",
  "Url: https://pubs.rsc.org/en/content/articlepdf/2023/ra/d2ra07737j",
  "Faculty Name: lei li\nPaperid: b2274c9fcd2d2c56e64441b4f93013d83faa24cb\nTitle: An ultrahigh-fidelity 3D holographic display using scattering to homogenize the angular spectrum\nYear: 2023\nAbstract: A three-dimensional (3D) holographic display (3DHD) can preserve all the volumetric information about an object. However, the poor fidelity of 3DHD constrains its applications. Here, we present an ultrahigh-fidelity 3D holographic display that uses scattering for homogenization of angular spectrum. A scattering medium randomizes the incident photons and homogenizes the angular spectrum distribution. The redistributed field is recorded by a photopolymer film with numerous modulation modes and a half-wavelength scale pixel size. We have experimentally improved the contrast of a focal spot to 6 \u00d7 106 and tightened its spatial resolution to 0.5 micrometers, respectively ~300 and 4.4 times better than digital approaches.",
  "We have experimentally improved the contrast of a focal spot to 6 \u00d7 106 and tightened its spatial resolution to 0.5 micrometers, respectively ~300 and 4.4 times better than digital approaches. By exploiting the spatial multiplexing ability of the photopolymer and the transmission channel selection capability of the scattering medium, we have realized a dynamic holographic display of 3D spirals consisting of 20 foci across 1 millimeter \u00d7 1 millimeter \u00d7 26 millimeters with uniform intensity.\nAuthors: Jiamiao Yang, Lei S Li, Qiaozhi He, Chengmingyue Li, Yuan Qu, Lihong V Wang\nVenue: Science Advances\nTldr: None\nUrl: https://www.science.org/doi/pdf/10.1126/sciadv.adi9987?download=true",
  "Faculty Name: lei li\nPaperid: b3a587d4cbe94d5e86f80ef7cce0b80fd9bf5bcd\nTitle: Gut microbiota in patients with kidney stones: a systematic review and meta-analysis\nYear: 2023\nAbstract: None\nAuthors: Tianhui Yuan, Yu-qi Xia, Bojun Li, Wei-min Yu, T. Rao, Zehua Ye, Xinzhou Yan, Baofeng Song, Lei Li, Fangyou Lin, F. Cheng\nVenue: BMC Microbiology\nTldr: {'model': 'tldr@v2.0.0', 'text': 'There is a characteristic gut microbiota dysbiosis in kidney stone patients and individualized therapies like microbial supplementation, probiotic or synbiotic preparations and adjusted diet patterns based on individual gut microbial characteristics of patients may be more effective in preventing stone formation and recurrence.'}\nUrl: https://bmcmicrobiol.biomedcentral.com/counter/pdf/10.1186/s12866-023-02891-0",
  "Faculty Name: lei li\nPaperid: be141055e9c7d70d37a1ec9499d7455c6816d146\nTitle: A Multilabel Learning-Based Automatic Annotation Method for Semantic Roles in English Text\nYear: 2023\nAbstract: With the increasing amount of textual information in the Internet, smart semantic comprehension is a practical demand. Among, automatic annotation for semantic roles remains the fundamental part for effective semantic comprehension. Although machine learning-based methods had received much attention in recent years, they mostly divided each sentences into separable parts for calculation. To deal with such challenge, this paper introduces multilabel learning to propose a novel automatic annotation method for semantic roles in English text. In the semantic representation of words, the method uses convolutional neural networks to extract local feature information of words from the character level. Such design can alleviate the problem of inconspicuous semantic features caused by random initialization of unregistered words. Secondly, in the process of implication recognition, by combining the interactive attention mechanism to construct a capsule for each implication relation separately, the recognition of the final implication relation is completed in the way of categorical learning.",
  "Secondly, in the process of implication recognition, by combining the interactive attention mechanism to construct a capsule for each implication relation separately, the recognition of the final implication relation is completed in the way of categorical learning. At last, some experiments are conducted on real-world data to verify the proposed method with being compared with several typical relevant methods. The obtained results show that the proposal achieves better Macro-F1 results on eight datasets compared to seven algorithms. Besides, the proposal also performs better than others in the sensitivity testing, as its performance can remain stable with the increase of noise input. In summary, the proposal can achieve good results and show strong capability in semantic role labeling tasks.\nAuthors: Li-Wen Lei, Hao Wang\nVenue: IEEE Access\nTldr: {'model': 'tldr@v2.0.0', 'text': None}\nUrl: https://ieeexplore.ieee.org/ielx7/6287639/6514899/10264071.pdf",
  "Faculty Name: lei li\nPaperid: c0bdff1f8bd63083641061a1996f844380f91b58\nTitle: Antimicrobial properties of heterojunction BiSnSbO_6-ZnO composites in wastewater treatment\nYear: 2023\nAbstract: None\nAuthors: J. Chen, M. Shan, Haojia Zhu, Shichuan Zhang, Jingmei Li, Leijiao Li\nVenue: Environmental science and pollution research international\nTldr: None\nUrl: https://www.researchsquare.com/article/rs-1747259/latest.pdf",
  "Faculty Name: lei li\nPaperid: c10808e5183ece07057050d1896ba81031d6640b\nTitle: Effect of instant surgery compared with traditional management on paediatric complicated acute appendicitis post\u2010surgery wound: A meta\u2010analysis\nYear: 2023\nAbstract: A meta\u2010analysis study to assess the influence of instant surgery (IS) compared with conservative therapy (CT) on paediatric complicated acute appendicitis (CAA) post\u2010surgery wounds. A comprehensive literature examination until January 2023 was implemented, and 2098 linked studies were appraised. The picked studies contained 66\u2009674 subjects with paediatric CAA post\u2010surgery wounds in the picked studies' baseline; 64\u2009643 of them were using IS, and 2031 were using CT. The odds ratio (OR) in addition to 95% confidence intervals (CIs) were used to calculate the consequence of the IS compared with the CT on paediatric CAA post\u2010surgery wounds using the dichotomous and continuous styles and a fixed or random model.",
  "The odds ratio (OR) in addition to 95% confidence intervals (CIs) were used to calculate the consequence of the IS compared with the CT on paediatric CAA post\u2010surgery wounds using the dichotomous and continuous styles and a fixed or random model. The IS had a significantly higher wound infection (OR, 4.97; 95% CI, 2.35\u201310.54, P <\u2009.001) with moderate heterogeneity (I2 =\u200957%) compared with the CT in a paediatric CAA post\u2010surgery wound. However, no significant difference was found between IS and CT in total antibiotic duration (MD, \u22125.34; 95% CI,\u221212.67 to \u22121.98, P =\u2009.15) with high heterogeneity (I2 =\u200995%) in paediatric CAA post\u2010surgery wounds. The IS had a significantly higher wound infection; however, no significant difference was found in total antibiotic duration compared with the CT in paediatric CAA post\u2010surgery wounds. Although precautions should be taken when commerce with the consequences because most of the studies picked for this meta\u2010analysis had low sample sizes.",
  "The IS had a significantly higher wound infection; however, no significant difference was found in total antibiotic duration compared with the CT in paediatric CAA post\u2010surgery wounds. Although precautions should be taken when commerce with the consequences because most of the studies picked for this meta\u2010analysis had low sample sizes.\nAuthors: Xiansheng Cao, Xuejing Geng, Chunlei Zhang, Jun-Hao Chen, Chao Zhang, Qi Liu, Tianyu Wu, Lei Li\nVenue: International Wound Journal\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A meta\u2010analysis study to assess the influence of instant surgery (IS) compared with conservative therapy (CT) on paediatric complicated acute appendicitis (CAA) post\u2010surgery wounds found no significant difference in total antibiotic duration and wound infection.'}\nUrl: https://onlinelibrary.wiley.com/doi/pdfdirect/10.1111/iwj.14163",
  "Faculty Name: lei li\nPaperid: c25d2a27f1abe169d7b68078071b6698f0980469\nTitle: Protecting Language Generation Models via Invisible Watermarking\nYear: 2023\nAbstract: Language generation models have been an increasingly powerful enabler for many applications. Many such models offer free or affordable API access, which makes them potentially vulnerable to model extraction attacks through distillation. To protect intellectual property (IP) and ensure fair use of these models, various techniques such as lexical watermarking and synonym replacement have been proposed. However, these methods can be nullified by obvious countermeasures such as\"synonym randomization\". To address this issue, we propose GINSEW, a novel method to protect text generation models from being stolen through distillation. The key idea of our method is to inject secret signals into the probability vector of the decoding steps for each target token. We can then detect the secret message by probing a suspect model to tell if it is distilled from the protected one. Experimental results show that GINSEW can effectively identify instances of IP infringement with minimal impact on the generation quality of protected APIs.",
  "We can then detect the secret message by probing a suspect model to tell if it is distilled from the protected one. Experimental results show that GINSEW can effectively identify instances of IP infringement with minimal impact on the generation quality of protected APIs. Our method demonstrates an absolute improvement of 19 to 29 points on mean average precision (mAP) in detecting suspects compared to previous methods against watermark removal attacks.\nAuthors: Xuandong Zhao, Yu-Xiang Wang, Lei Li\nVenue: International Conference on Machine Learning\nTldr: {'model': 'tldr@v2.0.0', 'text': 'GINSEW, a novel method to protect text generation models from being stolen through distillation by injecting secret signals into the probability vector of the decoding steps for each target token, is proposed.'}\nUrl: https://arxiv.org/pdf/2302.03162",
  "Faculty Name: lei li\nPaperid: c5bb69bbe1d41153d40a9eb31c4af077390c2d99\nTitle: The effects of pharmaceutical interventions on potentially inappropriate medications in older patients: a systematic review and meta-analysis\nYear: 2023\nAbstract: Introduction Potentially inappropriate medications (PIMs) is a particular concern in older patients and is associated with negative health outcomes. As various interventions have been developed to manage it, we performed a systematic review and meta-analysis to evaluate the effect of pharmaceutical interventions on outcomes of PIMs in older patients. Methods Meta-analysis of eligible randomized controlled trials (RCTs) was conducted to report the outcomes of pharmaceutical interventions in older patients searching from the databases of Cochrane Library, PubMed, Embase, Web of Science, Clinicaltrials.gov, SinoMed and Chinese Clinical Trial Registry (ChiCTR). The PRISMA guidelines were followed and the protocol was registered in PROSPERO (CRD42019134754). Cochrane bias risk assessment tool and the modified Jadad scale were used to assess the risk bias. RevMan software was used for data processing, analysis and graphical plotting.",
  "The PRISMA guidelines were followed and the protocol was registered in PROSPERO (CRD42019134754). Cochrane bias risk assessment tool and the modified Jadad scale were used to assess the risk bias. RevMan software was used for data processing, analysis and graphical plotting. Results Sixty-five thousand, nine hundred seventy-one patients in 14 RCTs were included. Of the primary outcomes, pharmaceutical interventions could significantly reduce the incidence of PIMs in older patients (OR\u2009=\u20090.51, 95% CI: 0.42, 0.62; p\u2009<\u20090.001), and the number of PIMs per person (MD\u2009=\u2009-0.41, 95%CI: \u22120.51, \u22120.31; p\u2009<\u20090.001), accompanying by a low heterogeneity. Subgroup analysis showed that the application of computer-based clinical decision support for pharmacological interventions could remarkably decrease the incidence of PIMs and two assessment tools were more effective.",
  "Subgroup analysis showed that the application of computer-based clinical decision support for pharmacological interventions could remarkably decrease the incidence of PIMs and two assessment tools were more effective. Of the secondary outcomes, the meta-analysis showed that pharmacological interventions could reduce the number of drugs used per person (MD\u2009=\u2009-0.94, 95%CI: \u22121.51, \u22120.36; p\u2009=\u20090.001) and 30-day readmission rate (OR\u2009=\u20090.58, 95%CI: 0.36, 0.92; p\u2009=\u20090.02), accompanying by a low heterogeneity. However, the pharmaceutical interventions demonstrated no significant improvement on all-cause mortality and the number of falls. Conclusion Our findings supported the efficacy of pharmaceutical interventions to optimize the use and management of drugs in older patients. Systematic review registration https://clinicaltrials.gov/, CRD42019134754.",
  "However, the pharmaceutical interventions demonstrated no significant improvement on all-cause mortality and the number of falls. Conclusion Our findings supported the efficacy of pharmaceutical interventions to optimize the use and management of drugs in older patients. Systematic review registration https://clinicaltrials.gov/, CRD42019134754.\nAuthors: Shuang Zhou, Rui Li, Xiaolin Zhang, Yutong Zong, Lili Lei, Zhenhui Tao, Minxue Sun, Hua Liu, Ying Zhou, Yi-min Cui\nVenue: Frontiers in Public Health\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The efficacy of pharmaceutical interventions to optimize the use and management of drugs in older patients is supported by a systematic review and meta-analysis of randomized controlled trials.'}\nUrl: https://www.frontiersin.org/articles/10.3389/fpubh.2023.1154048/pdf",
  "Faculty Name: lei li\nPaperid: dd3c82415e5704c60703e86a051ab3a003b0122b\nTitle: Intraoperative molecular imaging: 3rd biennial clinical trials update\nYear: 2023\nAbstract: Abstract. Significance This third biennial intraoperative molecular imaging (IMI) conference shows how optical contrast agents have been applied to develop clinically significant endpoints that improve precision cancer surgery. Aim National and international experts on IMI presented ongoing clinical trials in cancer surgery and preclinical work. Previously known dyes (with broader applications), new dyes, novel nonfluorescence-based imaging techniques, pediatric dyes, and normal tissue dyes were discussed. Approach Principal investigators presenting at the Perelman School of Medicine Abramson Cancer Center\u2019s third clinical trials update on IMI were selected to discuss their clinical trials and endpoints. Results Dyes that are FDA-approved or currently under clinical investigation in phase 1, 2, and 3 trials were discussed. Sections on how to move benchwork research to the bedside were also included.",
  "Results Dyes that are FDA-approved or currently under clinical investigation in phase 1, 2, and 3 trials were discussed. Sections on how to move benchwork research to the bedside were also included. There was also a dedicated section for pediatric dyes and nonfluorescence-based dyes that have been newly developed. Conclusions IMI is a valuable adjunct in precision cancer surgery and has broad applications in multiple subspecialties. It has been reliably used to alter the surgical course of patients and in clinical decision making. There remain gaps in the utilization of IMI in certain subspecialties and potential for developing newer and improved dyes and imaging techniques.",
  "It has been reliably used to alter the surgical course of patients and in clinical decision making. There remain gaps in the utilization of IMI in certain subspecialties and potential for developing newer and improved dyes and imaging techniques.\nAuthors: P. Bou-Samra, N. Muhammad, Austin Chang, Ritesh Karsalia, F. Azari, G. Kennedy, W. Stummer, J. Tanyi, Linda Martin, A. Vahrmeijer, Barbara Smith, E. Rosenthal, Patrick Wagner, David Rice, Amy Lee, Abdelhafeez H. Abdelhafeez, M. Malek, G. Kohanbash, Wilson Barry Edwards, E. Henderson, J. Skj\u00f8th-Rasmussen, Ryan Orosco, Summer L. Gibbs, R. Farnam, L. Shankar, B. Sumer, Anand T. N. Kumar, L. Marcu, Lei S Li, Victor Greuv, E. Delikatny, John Y. K. Lee, S. Singhal\nVenue: Journal of Biomedical Optics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'IMI has been reliably used to alter the surgical course of patients and in clinical decision making and remains a valuable adjunct in precision cancer surgery and has broad applications in multiple subspecialties.'}",
  "Url: https://www.spiedigitallibrary.org/journals/journal-of-biomedical-optics/volume-28/issue-5/050901/Intraoperative-molecular-imaging-3rd-biennial-clinical-trials-update/10.1117/1.JBO.28.5.050901.pdf",
  "Faculty Name: lei li\nPaperid: de54ffba68e0a65b7d9070538e2e84a7d58ced36\nTitle: Establishment of a N1-methyladenosine-related risk signature for breast carcinoma by bioinformatics analysis and experimental validation\nYear: 2023\nAbstract: None\nAuthors: Leilei Li, Wenhui Yang, Daqi Jia, Shiqi Zheng, Yu Gao, G. Wang\nVenue: Breast Cancer\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A m^1A RNA methylation regulator-related prognostic model was constructed, and a nomogram based on the prognostic model was constructed to provide a theoretical reference for individual counseling and clinical preventive intervention in BRCA.'}\nUrl: https://link.springer.com/content/pdf/10.1007/s12282-023-01458-1.pdf",
  "Faculty Name: lei li\nPaperid: f3ccbd6795a89dc98558679482da836b3c12fac8\nTitle: Effect of intragranular \u03ba carbides and intergranular precipitates on the hot deformation mechanism and dynamic recrystallization mechanism of Fe-28Mn-11Al-1.5C-5Cr lightweight steel\nYear: 2023\nAbstract: None\nAuthors: Jinxu Liu, Leilei Li, Shanwu Yang, Chao Ding, Enmao Wang, Xinpan Yu, Huibin Wu, G. Niu\nVenue: Journal of Materials Research and Technology\nTldr: None\nUrl: N/A",
  "Faculty Name: lei li\nPaperid: f7912c9af20f95cddaa3c959246ff63d34ab3a57\nTitle: Comprehensive Analysis of Cuproptosis Genes and Identification of Cuproptosis Subtypes in Breast Cancer\nYear: 2023\nAbstract: Background Copper-induced death (cuproptosis) is copper-dependent regulated cell death, which is different from known death mechanisms and is dependent on mitochondrial respiration. However, its effect on breast cancer (BRCA) is unclear. Objective The objective of this study is to explore the important clinical significance of cuproptosis genes and to provide a new idea for guiding the personalized immunotherapy strategy of BRCA patients. Materials and Methods We collected cuproptosis genes from published work. The gene alteration, differential expression, and prognostic value of cuproptosis genes were explored in BRCA based on TCGA database. We identified two subtypes (clusters A and B) by performing unsupervised clustering. The difference between two clusters was deeply explored, including clinical features, differential expressed genes (DEGs), pathways, and immune cell infiltration.",
  "We identified two subtypes (clusters A and B) by performing unsupervised clustering. The difference between two clusters was deeply explored, including clinical features, differential expressed genes (DEGs), pathways, and immune cell infiltration. Based on the DEGs between two clusters, a cuproptosis score was constructed and its predictive capability for overall survival of BRCA patients was validated. Results and Discussion Patients with high cuproptosis score have worse survival status, with an increased infiltration level of most immune cells. Further analysis suggested that BRCA patients with high cuproptosis score may be sensitive to immune checkpoint inhibitor (ICI) treatment. Conclusion Our findings may improve our understanding of cuproptosis in BRCA and may distinguish patients suitable for ICI treatment.\nAuthors: Jialin Li, Lei Li, Yi Dong, B. Zhong, W. Yin\nVenue: Combinatorial chemistry & high throughput screening\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The findings may improve the understanding of cuproptosis in BRCA and may distinguish patients suitable for ICI treatment.'}\nUrl: N/A",
  "List of 2023 Open Access papers by lei li are:\nEstablishment of a N1-methyladenosine-related risk signature for breast carcinoma by bioinformatics analysis and experimental validation\nPopulation pharmacokinetic analysis and dosing regimen optimization of teicoplanin in critically ill patients with sepsis\nThe effects of pharmaceutical interventions on potentially inappropriate medications in older patients: a systematic review and meta-analysis\nP53 protein and the diseases in central nervous system\nCorrection: Polydopamine-functionalized selenium nanoparticles as an efficient photoresponsive antibacterial platform\nEditorial: Strategies for functional polymeric nanocomposites and its multifunctional applications\nPolydopamine-functionalized selenium nanoparticles as an efficient photoresponsive antibacterial platform\nAntimicrobial properties of heterojunction BiSnSbO_6-ZnO composites in wastewater treatment\nA Study of Yuediao Folk Music Knowledge Development in Zhoukou, Henan Province,",
  "Henan Province, China\nInfluence of banded \u03b5-martensite and deformation twin on cryogenic toughness of Fe-Mn-xAl-C steel\nStudy on thermal stability and biocompatibility of bimodal microstructure in Cr\u2013Mn\u2013N austenitic stainless steel\nEffect of intragranular \u03ba carbides and intergranular precipitates on the hot deformation mechanism and dynamic recrystallization mechanism of Fe-28Mn-11Al-1.5C-5Cr lightweight steel\nWavefront shaping improves the transparency of the scattering media: a review\nAn ultrahigh-fidelity 3D holographic display using scattering to homogenize the angular spectrum\nIntraoperative molecular imaging: 3rd biennial clinical trials update\nResearch on torsional stiffness of flexspline-flexible bearing contact pair in harmonic drive based on macro-micro scale modeling\nIntegrated Valve Product Fluid Simulation and Test Verification\nFailure Analysis and Improvement of Check Valve Reverse Cut-off Seal\nPTTG1 reprograms asparagine metabolism to promote hepatocellular carcinoma progression.",
  "A Multilabel Learning-Based Automatic Annotation Method for Semantic Roles in English Text\nVariation of virtual temperature and wind in the atmospheric boundary layer over the pearl river estuary during 2011\u20132020\nNumerical simulation research on the overturning of gantry crane by downbursts\nCombining non-negative matrix factorization with graph Laplacian regularization for predicting drug-miRNA associations based on multi-source information fusion\nLow-Voltage Solution-Processed Zinc-Doped CuI Thin Film Transistors with NOR Logic and Artificial Synaptic Function\nLong-tailed Extreme Multi-label Text Classification by the Retrieval of Generated Pseudo Label Descriptions\nOptimizing Heat Treatment to Improve the Microstructures and Mechanical Properties of 5CrNiMoV Steel\nOral phage therapy with microencapsulated phage A221 against Escherichia coli infections in weaned piglets\nHence, Socrates is mortal: A Benchmark for Natural Language Syllogistic Reasoning\nProvable Robust Watermarking for AI-Generated Text\nMCM6 is a Poor Prognostic Biomarker and Promotes Progression in Breast Cancer.",
  "p53 deacetylation alleviates calcium oxalate deposition-induced renal fibrosis by inhibiting ferroptosis.\nGut microbiota in patients with kidney stones: a systematic review and meta-analysis\nEffect of instant surgery compared with traditional management on paediatric complicated acute appendicitis post\u2010surgery wound: A meta\u2010analysis\nProtecting Language Generation Models via Invisible Watermarking\nComprehensive Analysis of Cuproptosis Genes and Identification of Cuproptosis Subtypes in Breast Cancer\nPhosphorus Availability Affects the Photosynthesis and Antioxidant System of Contrasting Low-P-Tolerant Cotton Genotypes\nIntegrated Transcriptome and Small RNA Sequencing Analyses Reveals Insights into the Molecular Mechanism of Seed Germination in Mung Bean",
  "Lei Li\nAssistant Professor, Language Technologies Institute\nPersonal Website https://www.cs.cmu.edu/~leili/\n6403 Gates & Hillman Centers\nleili@andrew.cmu.edu\ntel:412-268-6355\nAddress\n5000 Forbes Avenue\nPittsburgh, PA 15213",
  "Faculty Name: lori levin\nPaperid: 2cdc646a6b70418e7cbd7fbdb8bb113176c4659f\nTitle: Somatosensory and motor representations following bilateral transplants of the hands: A 6-year longitudinal case report on the first pediatric bilateral hand transplant patient\nYear: 2023\nAbstract: None\nAuthors: W. Gaetz, C. Dockstader, P. Furlong, S. Amaral, A. Vossough, E. Schwartz, T. Roberts, Lori S. Levin\nVenue: Brain Research\nTldr: {'model': 'tldr@v2.0.0', 'text': None}\nUrl: N/A",
  "Faculty Name: lori levin\nPaperid: 2f540bab03c2672715539ecf17ff4872ea521605\nTitle: Identifying Health-Related Quality of Life Domains after Upper Extremity Transplantation.\nYear: 2023\nAbstract: None\nAuthors: D. Tulsky, Pamela A. Kisala, Callie E Tyner, J. Slotkin, C. Kaufman, C. Dearth, A. Horan, S. Talbot, J. Shores, K. Azari, C. Cetrulo, G. Brandacher, C. Cooney, David E Victorson, M. Dooley, Lori S. Levin, Cdr Scott M Tintle\nVenue: Archives of Physical Medicine and Rehabilitation\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This study identified key constructs for use in evaluation of the potentially substantial physical, medical, social, and emotional effects of UET, including physical functioning and medical complications, positive and negative emotional functioning, and social participation, relationships, and independence.'}\nUrl: N/A",
  "Faculty Name: lori levin\nPaperid: 52a97ad16605c18e23c9750a388a26a9cdf12200\nTitle: Assessment of quality of life after upper extremity transplantation: Framework for patient-reported outcome scale domains\nYear: 2023\nAbstract: Upper extremity transplantation offers the promise of restored function and regained quality of life (QOL) for individuals who have sustained hand or arm amputation. However, a major challenge for this procedure becoming an accessible treatment option for patients is the lack of standard measures to document benefits to QOL. Patient-reported outcomes (PRO) measures are well-suited for this kind of intervention, where the perspective of the patient is central to defining treatment success. To date, qualitative work with experts, clinicians, and patients has been used to identify the most important domains of QOL for PRO item development. Specifically, our group\u2019s qualitative work has identified several domains of QOL that are unique to individuals who have received upper extremity transplants, which are distinct from topics covered by existing PRO measures.",
  "Specifically, our group\u2019s qualitative work has identified several domains of QOL that are unique to individuals who have received upper extremity transplants, which are distinct from topics covered by existing PRO measures. These include emotional and social aspects of upper extremity transplant, such as Expectations and Perceived Outcomes, Integration and Assimilation of Transplant, Fitting in, and Post-Surgical Challenges and Complications. The broad topic of Satisfaction with Transplant was subdivided into three subtopics: Function, Sensation, and Aesthetics. Satisfaction with Sensation was also identified as a unique domain not evaluated by existing PRO measures. This report operationalizes these eight QOL domains by presenting scoping definitions. This manuscript describes the work that has been completed for domain characterization as an early step toward developing standardized PRO measures to evaluate these important outcomes specific to upper extremity transplantation.",
  "This report operationalizes these eight QOL domains by presenting scoping definitions. This manuscript describes the work that has been completed for domain characterization as an early step toward developing standardized PRO measures to evaluate these important outcomes specific to upper extremity transplantation.\nAuthors: Callie E Tyner, J. Slotkin, Pamela A. Kisala, Lori S. Levin, Scott M. Tintle, D. Tulsky\nVenue: Frontiers in Psychology\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Qualitative work with experts, clinicians, and patients has identified several domains of QOL that are unique to individuals who have received upper extremity transplants, which are distinct from topics covered by existing PRO measures.'}\nUrl: https://www.frontiersin.org/articles/10.3389/fpsyg.2022.989593/pdf",
  "Faculty Name: lori levin\nPaperid: 659be1ff350634f50cc066d258ee6a45e697e552\nTitle: SigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing\nYear: 2023\nAbstract: In our submission to the SIGMORPHON 2023 Shared Task on interlinear glossing (IGT), we explore approaches to data augmentation and modeling across seven low-resource languages. For data augmentation, we explore two approaches: creating artificial data from the provided training data and utilizing existing IGT resources in other languages. On the modeling side, we test an enhanced version of the provided token classification baseline as well as a pretrained multilingual seq2seq model. Additionally, we apply post-correction using a dictionary for Gitksan, the language with the smallest amount of data. We find that our token classification models are the best performing, with the highest word-level accuracy for Arapaho and highest morpheme-level accuracy for Gitksan out of all submissions. We also show that data augmentation is an effective strategy, though applying artificial data pretraining has very different effects across both models tested.",
  "We find that our token classification models are the best performing, with the highest word-level accuracy for Arapaho and highest morpheme-level accuracy for Gitksan out of all submissions. We also show that data augmentation is an effective strategy, though applying artificial data pretraining has very different effects across both models tested.\nAuthors: Taiqi He, Lindia Tjuatja, Nathaniel R. Robinson, Shinji Watanabe, David R. Mortensen, Graham Neubig, L. Levin\nVenue: Special Interest Group on Computational Morphology and Phonology Workshop\nTldr: {'model': 'tldr@v2.0.0', 'text': 'In this submission to the SIGMORPHON 2023 Shared Task on interlinear glossing (IGT), approaches to data augmentation and modeling across seven low-resource languages are explored and token classification models are found to be the best performing.'}\nUrl: https://aclanthology.org/2023.sigmorphon-1.22.pdf",
  "Faculty Name: lori levin\nPaperid: 7a08051aac75a809737096e39820bf836908d4e1\nTitle: Construction Grammar Provides Unique Insight into Neural Language Models\nYear: 2023\nAbstract: Construction Grammar (CxG) has recently been used as the basis for probing studies that have investigated the performance of large pretrained language models (PLMs) with respect to the structure and meaning of constructions. In this position paper, we make suggestions for the continuation and augmentation of this line of research. We look at probing methodology that was not designed with CxG in mind, as well as probing methodology that was designed for specific constructions. We analyse selected previous work in detail, and provide our view of the most important challenges and research questions that this promising new field faces.",
  "We look at probing methodology that was not designed with CxG in mind, as well as probing methodology that was designed for specific constructions. We analyse selected previous work in detail, and provide our view of the most important challenges and research questions that this promising new field faces.\nAuthors: Leonie Weissweiler, Taiqi He, Naoki Otani, David R. Mortensen, L. Levin, Hinrich Sch\u00fctze\nVenue: CXGSNLP\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The view of the most important challenges and research questions that this promising new field of research faces is provided, and an analysis of selected previous work in detail is provided.'}\nUrl: http://arxiv.org/pdf/2302.02178",
  "Faculty Name: lori levin\nPaperid: bf42c0462d1415cdde877c90d58da11545407b8a\nTitle: Generalized Glossing Guidelines: An Explicit, Human- and Machine-Readable, Item-and-Process Convention for Morphological Annotation\nYear: 2023\nAbstract: Interlinear glossing provides a vital type of morphosyntactic annotation, both for linguists and language revitalists, and numerous conventions exist for representing it formally and computationally. Some of these formats are human readable; others are machine readable. Some are easy to edit with general-purpose tools. Few represent non-concatentative processes like infixation, reduplication, mutation, truncation, and tonal overwriting in a consistent and formally rigorous way (on par with affixation). We propose an annotation convention\u00e2\u20ac\u201dGeneralized Glossing Guidelines (GGG) that combines all of these positive properties using an Item-and-Process (IP) framework. We describe the format, demonstrate its linguistic adequacy, and compare it with two other interlinear glossed text annotation schemes.",
  "We propose an annotation convention\u00e2\u20ac\u201dGeneralized Glossing Guidelines (GGG) that combines all of these positive properties using an Item-and-Process (IP) framework. We describe the format, demonstrate its linguistic adequacy, and compare it with two other interlinear glossed text annotation schemes.\nAuthors: David R. Mortensen, Ela Gulsen, Taiqi He, Nathaniel R. Robinson, Jonathan D. Amith, Lindia Tjuatja, L. Levin\nVenue: Special Interest Group on Computational Morphology and Phonology Workshop\nTldr: {'model': 'tldr@v2.0.0', 'text': 'An annotation convention is proposed that combines all of these positive properties using an Item-and-Process (IP) framework, and its linguistic adequacy is demonstrated, and it is compared with two other interlinear glossed text annotation schemes.'}\nUrl: https://aclanthology.org/2023.sigmorphon-1.7.pdf",
  "Faculty Name: lori levin\nPaperid: c5207241406586f4263b235667e004b71ea68953\nTitle: Syntax and Semantics Meet in the \u201cMiddle\u201d: Probing the Syntax-Semantics Interface of LMs Through Agentivity\nYear: 2023\nAbstract: Recent advances in large language models have prompted researchers to examine their abilities across a variety of linguistic tasks, but little has been done to investigate how models handle the interactions in meaning across words and larger syntactic forms\u2014i.e. phenomena at the intersection of syntax and semantics. We present the semantic notion of agentivity as a case study for probing such interactions. We created a novel evaluation dataset by utilitizing the unique linguistic properties of a subset of optionally transitive English verbs. This dataset was used to prompt varying sizes of three model classes to see if they are sensitive to agentivity at the lexical level, and if they can appropriately employ these word-level priors given a specific syntactic context. Overall, GPT-3 text-davinci-003 performs extremely well across all experiments, outperforming all other models tested by far.",
  "Overall, GPT-3 text-davinci-003 performs extremely well across all experiments, outperforming all other models tested by far. In fact, the results are even better correlated with human judgements than both syntactic and semantic corpus statistics. This suggests that LMs may potentially serve as more useful tools for linguistic annotation, theory testing, and discovery than select corpora for certain tasks.\nAuthors: Lindia Tjuatja, Emmy Liu, L. Levin, Graham Neubig\nVenue: STARSEM\nTldr: {'model': 'tldr@v2.0.0', 'text': 'GPT-3 text-davinci-003 performs extremely well across all experiments, outperforming all other models tested by far and suggests that LMs may potentially serve as more useful tools for linguistic annotation, theory testing, and discovery than select corpora for certain tasks.'}\nUrl: https://arxiv.org/pdf/2305.18185",
  "List of 2023 Open Access papers by lori levin are:\nSigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing\nConstruction Grammar Provides Unique Insight into Neural Language Models\nGeneralized Glossing Guidelines: An Explicit, Human- and Machine-Readable, Item-and-Process Convention for Morphological Annotation\nSyntax and Semantics Meet in the \u201cMiddle\u201d: Probing the Syntax-Semantics Interface of LMs Through Agentivity\nSomatosensory and motor representations following bilateral transplants of the hands: A 6-year longitudinal case report on the first pediatric bilateral hand transplant patient\nIdentifying Health-Related Quality of Life Domains after Upper Extremity Transplantation.\nAssessment of quality of life after upper extremity transplantation: Framework for patient-reported outcome scale domains",
  "Lori Levin\nResearch Professor, Language Technologies Institute\nResearch Area\nCorpus Annotation and Resources, Machine Translation, Natural Language Processing and Computational Linguistics\nResearch\nThere are more than 6,000 human languages, but less than a hundred of them have robust language technologies such as search engines, spell checkers or speech recognition. Nevertheless, speakers of the technologically poor languages may have uses for language technologies to access information related to education, politics, business, weather and health conditions \u2014 not to mention preservation of culture and community relationships. My work focuses on the linguistic aspects of language technologies, specifically the following: \n\nLanguage Technologies With Low Resources\nMany languages lack sufficient data for supervised or unsupervised machine learning. There may also be low-resource scenarios for technology-rich languages like English in specialized styles or subject areas.  Such cases may call for hybrids of human-engineered knowledge and machine learning. The human engineered knowledge can be in the form of handwritten rules, priors or feature engineering.  \n\nLanguage Universals and Typology\nWhen there is insufficient time or data to build an NLP system, it is useful to fall back on what is known about human languages in general or what is known about related languages.",
  "Language Universals and Typology\nWhen there is insufficient time or data to build an NLP system, it is useful to fall back on what is known about human languages in general or what is known about related languages. The field of linguistic typology and universals provides expectations for what languages might be like. We are exploring how to use typology and universals to develop language technologies for new languages on short timelines or in low-resource scenarios. \n\nCorpus Annotation and Linguistic Resources\nWhen time and data are available, language technologies can be based on supervised learning from annotated data. The annotations may be for any level of linguistic knowledge from sounds to social hierarchies. My approach to annotation is based on the linguistic theory of construction grammar.\n\nPersonal Website http://www.cs.cmu.edu/~lsl/\nContact 5717 \u2014Gates & Hillman Centers\nEmail lsl@cs.cmu.edu\n412-268-6193",
  "Faculty Name: louis philippe morency\nPaperid: 0a425c0d87c674b142104a07e17c5084b3ad28ca\nTitle: Quantifying & Modeling Feature Interactions: An Information Decomposition Framework\nYear: 2023\nAbstract: The recent explosion of interest in multimodal applications has resulted in a wide selection of datasets and methods for representing and integrating information from different signals. Despite these empirical advances, there remain fundamental research questions: how can we quantify the nature of interactions that exist among input features? Subsequently, how can we capture these interactions using suitable data-driven methods? To answer this question, we propose an information-theoretic approach to quantify the degree of redundancy , uniqueness , and synergy across input features, which we term the PID statistics of a multimodal distribution. Using 2 newly proposed estimators that scale to high-dimensional distributions, we demonstrate their usefulness in quantifying the interactions within multimodal datasets, the nature of interactions captured by multimodal models, and principled approaches for model selection. We conduct extensive experiments on both synthetic datasets where the PID statistics are known and on large-scale multimodal benchmarks where PID estimation was previously impossible.",
  "We conduct extensive experiments on both synthetic datasets where the PID statistics are known and on large-scale multimodal benchmarks where PID estimation was previously impossible. Finally, to demonstrate the real-world applicability of our approach, we present three case studies in pathology, mood prediction, and robotic perception where our framework accurately recommends strong multimodal models for each application.\nAuthors: P. Liang, Yun Cheng, Xiang Fan, Chun Kai Ling, Suzanne Nie, Richard J. Chen, Zihao Deng, Faisal Mahmood, R. Salakhutdinov, Louis-Philippe Morency\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes an information-theoretic approach to quantify the degree of redundancy, uniqueness, and synergy across input features, which is term the PID statistics of a multimodal distribution.'}\nUrl: https://arxiv.org/pdf/2302.12247",
  "Faculty Name: louis philippe morency\nPaperid: 114eafdb14145f002d503f259d768d67dae87479\nTitle: Reconstructing the neurodynamics of face perception during real world vision in humans using intracranial EEG recordings\nYear: 2023\nAbstract: None\nAuthors: Arish Alreja, Michael J. Ward, J. A. Colan, Qianli Ma, R. M. Richardson, Louis-Philippe Morency, A. Ghuman\nVenue: Journal of Vision\nTldr: None\nUrl: N/A",
  "Faculty Name: louis philippe morency\nPaperid: 40fb36ee67fdde99b196b4d1772de114aa821698\nTitle: MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning\nYear: 2023\nAbstract: Learning multimodal representations involves integrating information from multiple heterogeneous sources of data. In order to accelerate progress towards understudied modalities and tasks while ensuring real-world robustness, we release MultiZoo, a public toolkit consisting of standardized implementations of>20 core multimodal algorithms and MultiBench, a large-scale benchmark spanning 15 datasets, 10 modalities, 20 prediction tasks, and 6 research areas. Together, these provide an automated end-to-end machine learning pipeline that simplifies and standardizes data loading, experimental setup, and model evaluation. To enable holistic evaluation, we offer a comprehensive methodology to assess (1) generalization, (2) time and space complexity, and (3) modality robustness. MultiBench paves the way towards a better understanding of the capabilities and limitations of multimodal models, while ensuring ease of use, accessibility, and reproducibility.",
  "MultiBench paves the way towards a better understanding of the capabilities and limitations of multimodal models, while ensuring ease of use, accessibility, and reproducibility. Our toolkits are publicly available, will be regularly updated, and welcome inputs from the community.\nAuthors: P. Liang, Yiwei Lyu, Xiang Fan, Arav Agarwal, Yun Cheng, Louis-Philippe Morency, R. Salakhutdinov\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'MultiZoo is released, a public toolkit consisting of standardized implementations of>20 core multimodal algorithms and MultiBench, a large-scale benchmark spanning 15 datasets, 10 modalities, 20 prediction tasks, and 6 research areas that provide an automated end-to-end machine learning pipeline that simplifies and standardizes data loading, experimental setup, and model evaluation.'}\nUrl: http://arxiv.org/pdf/2306.16413",
  "Faculty Name: louis philippe morency\nPaperid: 47a4ac301820c3ea7da4efb8e2466cc6468ad631\nTitle: SenteCon: Leveraging Lexicons to Learn Human-Interpretable Language Representations\nYear: 2023\nAbstract: Although deep language representations have become the dominant form of language featurization in recent years, in many settings it is important to understand a model's decision-making process. This necessitates not only an interpretable model but also interpretable features. In particular, language must be featurized in a way that is interpretable while still characterizing the original text well. We present SenteCon, a method for introducing human interpretability in deep language representations. Given a passage of text, SenteCon encodes the text as a layer of interpretable categories in which each dimension corresponds to the relevance of a specific category. Our empirical evaluations indicate that encoding language with SenteCon provides high-level interpretability at little to no cost to predictive performance on downstream tasks.",
  "Given a passage of text, SenteCon encodes the text as a layer of interpretable categories in which each dimension corresponds to the relevance of a specific category. Our empirical evaluations indicate that encoding language with SenteCon provides high-level interpretability at little to no cost to predictive performance on downstream tasks. Moreover, we find that SenteCon outperforms existing interpretable language representations with respect to both its downstream performance and its agreement with human characterizations of the text.\nAuthors: Victoria Lin, Louis-Philippe Morency\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work presents SenteCon, a method for introducing human interpretability in deep language representations that outperforms existing interpretable language representations with respect to both its downstream performance and its agreement with human characterizations of the text.'}\nUrl: http://arxiv.org/pdf/2305.14728",
  "Faculty Name: louis philippe morency\nPaperid: 64703e760f662b1c0f647931bb63fe57e5ba91e4\nTitle: Neural Mixed Effects for Nonlinear Personalized Predictions\nYear: 2023\nAbstract: Personalized prediction is a machine learning approach that predicts a person\u2019s future observations based on their past labeled observations and is typically used for sequential tasks, e.g., to predict daily mood ratings. When making personalized predictions, a model can combine two types of trends: (a) trends shared across people, i.e., person-generic trends, such as being happier on weekends, and (b) unique trends for each person, i.e., person-specific trends, such as a stressful weekly meeting. Mixed effect models are popular statistical models to study both trends by combining person-generic and person-specific parameters. Though linear mixed effect models are gaining popularity in machine learning by integrating them with neural networks, these integrations are currently limited to linear person-specific parameters: ruling out nonlinear person-specific trends. In this paper, we propose Neural Mixed Effect (NME) models to optimize nonlinear person-specific parameters anywhere in a neural network in a scalable manner1.",
  "In this paper, we propose Neural Mixed Effect (NME) models to optimize nonlinear person-specific parameters anywhere in a neural network in a scalable manner1. NME combines the efficiency of neural network optimization with nonlinear mixed effects modeling. Empirically, we observe that NME improves performance across six unimodal and multimodal datasets, including a smartphone dataset to predict daily mood and a mother-adolescent dataset to predict affective state sequences where half the mothers experience symptoms of depression. Furthermore, we evaluate NME for two model architectures, including for neural conditional random fields (CRF) to predict affective state sequences where the CRF learns nonlinear person-specific temporal transitions between affective states. Analysis of these person-specific transitions on the mother-adolescent dataset shows interpretable trends related to the mother\u2019s depression symptoms.",
  "Analysis of these person-specific transitions on the mother-adolescent dataset shows interpretable trends related to the mother\u2019s depression symptoms.\nAuthors: T. W\u00f6rtwein, Nicholas Allen, Lisa B. Sheeber, R. Auerbach, J. Cohn, Louis-Philippe Morency\nVenue: International Conference on Multimodal Interaction\nTldr: {'model': 'tldr@v2.0.0', 'text': 'NME combines the efficiency of neural network optimization with nonlinear mixed effects modeling and improves performance across six unimodal and multimodal datasets, including a smartphone dataset to predict daily mood and a mother-adolescent datasets to predict affective state sequences where half the mothers experience symptoms of depression.'}\nUrl: https://dl.acm.org/doi/pdf/10.1145/3577190.3614115",
  "Faculty Name: louis philippe morency\nPaperid: 6838c43e702a3f995967ba2e3edd5f65ff5f5511\nTitle: SHAP-based Prediction of Mother's History of Depression to Understand the Influence on Child Behavior\nYear: 2023\nAbstract: Depression strongly impacts parents\u2019 behavior. Does parents\u2019 depression strongly affect the behavior of their children as well? To investigate this question, we compared dyadic interactions between 73 depressed and 75 non-depressed mothers and their adolescent child. Families were of low income and 84% were white. Child behavior was measured from audio-video recordings using manual annotation of verbal and nonverbal behavior by expert coders and by multimodal computational measures of facial expression, face and head dynamics, prosody, speech behavior, and linguistics. For both sets of measures, we used Support Vector Machines. For computational measures, we investigated the relative contribution of single versus multiple modalities using a novel approach to SHapley Additive exPlanations (SHAP). Computational measures outperformed manual ratings by human experts. Among individual computational measures, prosody was the most informative.",
  "For computational measures, we investigated the relative contribution of single versus multiple modalities using a novel approach to SHapley Additive exPlanations (SHAP). Computational measures outperformed manual ratings by human experts. Among individual computational measures, prosody was the most informative. SHAP reduction resulted in a four-fold decrease in the number of features and highest performance (77% accuracy; positive and negative agreements at 75% and 76%, respectively). These findings suggest that maternal depression strongly impacts the behavior of adolescent children; differences are most revealed in prosody; multimodal features together with SHAP reduction are most powerful.\nAuthors: Maneesh Bilalpur, Saurabh Hinduja, Laura Cariola, Lisa B. Sheeber, Nicholas B Allen, Louis-Philippe Morency, Jeffrey F. Cohn\nVenue: International Conference on Multimodal Interaction\nTldr: None\nUrl: https://dl.acm.org/doi/pdf/10.1145/3577190.3614136",
  "Faculty Name: louis philippe morency\nPaperid: 7dab13685363176edc5cc7882d0890811d2cb584\nTitle: Counterfactual Augmentation for Multimodal Learning Under Presentation Bias\nYear: 2023\nAbstract: In real-world machine learning systems, labels are often derived from user behaviors that the system wishes to encourage. Over time, new models must be trained as new training examples and features become available. However, feedback loops between users and models can bias future user behavior, inducing a presentation bias in the labels that compromises the ability to train new models. In this paper, we propose counterfactual augmentation, a novel causal method for correcting presentation bias using generated counterfactual labels. Our empirical evaluations demonstrate that counterfactual augmentation yields better downstream performance compared to both uncorrected models and existing bias-correction methods. Model analyses further indicate that the generated counterfactuals align closely with true counterfactuals in an oracle setting.",
  "Our empirical evaluations demonstrate that counterfactual augmentation yields better downstream performance compared to both uncorrected models and existing bias-correction methods. Model analyses further indicate that the generated counterfactuals align closely with true counterfactuals in an oracle setting.\nAuthors: Victoria Lin, Louis-Philippe Morency, D. Dimitriadis, Srinagesh Sharma\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Empirical evaluations demonstrate that counterfactual augmentation yields better downstream performance compared to both uncorrected models and existing bias-correction methods, and model analyses indicate that the generatedcounterfactuals align closely with true counterfactUALs in an oracle setting.'}\nUrl: http://arxiv.org/pdf/2305.14083",
  "Faculty Name: louis philippe morency\nPaperid: 8d0c37eee7162f33178979b4183f0211e2dcae0d\nTitle: Difference-Masking: Choosing What to Mask in Continued Pretraining\nYear: 2023\nAbstract: The self-supervised objective of masking-and-predicting has led to promising performance gains on a variety of downstream tasks. However, while most approaches randomly mask tokens, there is strong intuition that deciding what to mask can substantially improve learning outcomes. We investigate this in continued pretraining setting in which pretrained models continue to pretrain on domain-specific data before performing some downstream task. We introduce Difference-Masking, a masking strategy that automatically chooses what to mask during continued pretraining by considering what makes a task domain different from the pretraining domain. Empirically, we find that Difference-Masking outperforms baselines on continued pretraining settings across four diverse language-only and multimodal video tasks.",
  "Empirically, we find that Difference-Masking outperforms baselines on continued pretraining settings across four diverse language-only and multimodal video tasks.\nAuthors: Alex Wilf, Syeda Nahida Akter, Leena Mathur, P. Liang, Sheryl Mathew, Mengrou Shou, Eric Nyberg, Louis-Philippe Morency\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Difference-Masking is introduced, a masking strategy that automatically chooses what to mask during continued pretraining by considering what makes a task domain different from the pretraining domain.'}\nUrl: http://arxiv.org/pdf/2305.14577",
  "Faculty Name: louis philippe morency\nPaperid: 8d53c510928ad1164aebea4d9477812ed1893be2\nTitle: Expanding the Role of Affective Phenomena in Multimodal Interaction Research\nYear: 2023\nAbstract: In recent decades, the field of affective computing has made substantial progress in advancing the ability of AI systems to recognize and express affective phenomena, such as affect and emotions, during human-human and human-machine interactions. This paper describes our examination of research at the intersection of multimodal interaction and affective computing, with the objective of observing trends and identifying understudied areas. We examined over 16,000 papers from selected conferences in multimodal interaction, affective computing, and natural language processing: ACM International Conference on Multimodal Interaction, AAAC International Conference on Affective Computing and Intelligent Interaction, Annual Meeting of the Association for Computational Linguistics, and Conference on Empirical Methods in Natural Language Processing. We identified 910 affect-related papers and present our analysis of the role of affective phenomena in these papers.",
  "We identified 910 affect-related papers and present our analysis of the role of affective phenomena in these papers. We find that this body of research has primarily focused on enabling machines to recognize or express affect and emotion; there has been limited research on how affect and emotion predictions might, in turn, be used by AI systems to enhance machine understanding of human social behaviors and cognitive states. Based on our analysis, we discuss directions to expand the role of affective phenomena in multimodal interaction research.\nAuthors: Leena Mathur, Maja J Matari'c, Louis-Philippe Morency\nVenue: International Conference on Multimodal Interaction\nTldr: {'model': 'tldr@v2.0.0', 'text': 'An examination of research at the intersection of multimodal interaction and affective computing, with the objective of observing trends and identifying understudied areas, finds that this body of research has primarily focused on enabling machines to recognize or express affect and emotion.'}\nUrl: https://dl.acm.org/doi/pdf/10.1145/3577190.3614171",
  "Faculty Name: louis philippe morency\nPaperid: 90b09bdb1bd78875ee8d8d324a568a36955e4765\nTitle: Multimodal Fusion Interactions: A Study of Human and Automatic Quantification\nYear: 2023\nAbstract: In order to perform multimodal fusion of heterogeneous signals, we need to understand their interactions: how each modality individually provides information useful for a task and how this information changes in the presence of other modalities. In this paper, we perform a comparative study of how humans annotate two categorizations of multimodal interactions: (1) partial labels, where different annotators annotate the label given the first, second, and both modalities, and (2) counterfactual labels, where the same annotator annotates the label given the first modality before asking them to explicitly reason about how their answer changes when given the second.",
  "We further propose an alternative taxonomy based on (3) information decomposition, where annotators annotate the degrees of redundancy: the extent to which modalities individually and together give the same predictions, uniqueness: the extent to which one modality enables a prediction that the other does not, and synergy: the extent to which both modalities enable one to make a prediction that one would not otherwise make using individual modalities. Through experiments and annotations, we highlight several opportunities and limitations of each approach and propose a method to automatically convert annotations of partial and counterfactual labels to information decomposition, yielding an accurate and efficient method for quantifying multimodal interactions.\nAuthors: P. Liang, Yun Cheng, R. Salakhutdinov, Louis-Philippe Morency\nVenue: International Conference on Multimodal Interaction\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A comparative study of how humans annotate two categorizations of multimodal interactions is performed and a method to automatically convert annotations of partial and counterfactual labels to information decomposition is proposed, yielding an accurate and efficient method for quantifying multimodals interactions.'}",
  "Url: https://dl.acm.org/doi/pdf/10.1145/3577190.3614151",
  "Faculty Name: louis philippe morency\nPaperid: a988c09b7e76e86a93edcbf3f284dd028b0fb406\nTitle: Multimodal Learning Without Labeled Multimodal Data: Guarantees and Applications\nYear: 2023\nAbstract: In many machine learning systems that jointly learn from multiple modalities, a core research question is to understand the nature of multimodal interactions: the emergence of new task-relevant information during learning from both modalities that was not present in either alone. We study this challenge of interaction quantification in a semi-supervised setting with only labeled unimodal data and naturally co-occurring multimodal data (e.g., unlabeled images and captions, video and corresponding audio) but when labeling them is time-consuming. Using a precise information-theoretic definition of interactions, our key contributions are the derivations of lower and upper bounds to quantify the amount of multimodal interactions in this semi-supervised setting. We propose two lower bounds based on the amount of shared information between modalities and the disagreement between separately trained unimodal classifiers, and derive an upper bound through connections to approximate algorithms for min-entropy couplings.",
  "We propose two lower bounds based on the amount of shared information between modalities and the disagreement between separately trained unimodal classifiers, and derive an upper bound through connections to approximate algorithms for min-entropy couplings. We validate these estimated bounds and show how they accurately track true interactions. Finally, two semi-supervised multimodal applications are explored based on these theoretical results: (1) analyzing the relationship between multimodal performance and estimated interactions, and (2) self-supervised learning that embraces disagreement between modalities beyond agreement as is typically done.\nAuthors: P. Liang, Chun Kai Ling, Yun Cheng, A. Obolenskiy, Yudong Liu, Rohan Pandey, Alex Wilf, Louis-Philippe Morency, R. Salakhutdinov\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes two lower bounds based on the amount of shared information between modalities and the disagreement between separately trained unimodal classifiers, and derive an upper bound through connections to approximate algorithms for min-entropy couplings and validate these estimated bounds and show how they accurately track true interactions.'}",
  "Url: http://arxiv.org/pdf/2306.04539",
  "Faculty Name: louis philippe morency\nPaperid: bd94ea913fcf8698f2257f87a17755b46a420458\nTitle: Representation Learning for Interpersonal and Multimodal Behavior Dynamics: A Multiview Extension of Latent Change Score Models\nYear: 2023\nAbstract: Characterizing the dynamics of behavior across multiple modalities and individuals is a vital component of computational behavior analysis. This is especially important in certain applications, such as psychotherapy, where individualized tracking of behavior patterns can provide valuable information about the patient\u2019s mental state. Conventional methods that rely on aggregate statistics and correlational metrics may not always suffice, as they are often unable to capture causal relationships or evaluate the true probability of identified patterns. To address these challenges, we present a novel approach to learning multimodal and interpersonal representations of behavior dynamics during one-on-one interaction. Our approach is enabled by the introduction of a multiview extension of latent change score models, which facilitates the concurrent capture of both inter-modal and interpersonal behavior dynamics and the identification of directional relationships between them. A core advantage of our approach is its high level of interpretability while simultaneously achieving strong predictive performance.",
  "Our approach is enabled by the introduction of a multiview extension of latent change score models, which facilitates the concurrent capture of both inter-modal and interpersonal behavior dynamics and the identification of directional relationships between them. A core advantage of our approach is its high level of interpretability while simultaneously achieving strong predictive performance. We evaluate our approach within the domain of therapist-client interactions, with the objective of gaining a deeper understanding about the collaborative relationship between the two, a crucial element of the therapeutic process. Our results demonstrate improved performance over conventional approaches that rely upon summary statistics or correlational metrics. Furthermore, since our multiview approach includes the explicit modeling of uncertainty, it naturally lends itself to integration with probabilistic classifiers, such as Gaussian process models. We demonstrate that this integration leads to even further improved performance, all the while maintaining highly interpretable qualities. Our analysis provides compelling motivation for further exploration of stochastic systems within computational models of behavior.",
  "We demonstrate that this integration leads to even further improved performance, all the while maintaining highly interpretable qualities. Our analysis provides compelling motivation for further exploration of stochastic systems within computational models of behavior.\nAuthors: A. Vail, J. Girard, Lauren M. Bylsma, Jay Fournier, Holly A. Swartz, Jeffrey F. Cohn, Louis-Philippe Morency\nVenue: International Conference on Multimodal Interaction\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work presents a novel approach to learning multimodal and interpersonal representations of behavior dynamics during one-on-one interaction enabled by the introduction of a multiview extension of latent change score models that demonstrates improved performance over conventional approaches that rely upon summary statistics or correlational metrics.'}\nUrl: https://dl.acm.org/doi/pdf/10.1145/3577190.3614118",
  "Faculty Name: louis philippe morency\nPaperid: d01cc51c0d06583b809833a5f7ce71101d278528\nTitle: MultiViz: Towards User-Centric Visualizations and Interpretations of Multimodal Models\nYear: 2023\nAbstract: The nature of human and computer interactions are inherently multimodal, which has led to substantial interest in building interpretable, interactive, and reliable multimodal interfaces. However, modern multimodal models and interfaces are typically black-box neural networks, which makes it challenging to understand their internal mechanics. How can we visualize their internal workings in order to empower stakeholders to visualize model behavior, perform model debugging, and promote trust in these models? Our paper proposes MultiViz, a method for analyzing the behavior of multimodal models via 4 stages: (1) unimodal importance, (2) cross-modal interactions, (3) multimodal representations and (4) multimodal prediction. MultiViz includes modular visualization tools for each stage before combining outputs from all stages through an interactive and human-in-the-loop API.",
  "MultiViz includes modular visualization tools for each stage before combining outputs from all stages through an interactive and human-in-the-loop API. Through user studies with 21 participants on 8 trained models across 6 real-world tasks, we show that the complementary stages in MultiViz together enable users to (1) simulate model predictions, (2) assign interpretable concepts to features, (3) perform error analysis on model misclassifications, and (4) use insights from error analysis to debug models. MultiViz is publicly available at https://github.com/pliang279/MultiViz, will be regularly updated with new visualization tools and metrics, and welcomes input from the community1.",
  "MultiViz is publicly available at https://github.com/pliang279/MultiViz, will be regularly updated with new visualization tools and metrics, and welcomes input from the community1.\nAuthors: P. Liang, Yiwei Lyu, Gunjan Chhablani, Nihal Jain, Zihao Deng, Xingbo Wang, Louis-Philippe Morency, R. Salakhutdinov\nVenue: CHI Extended Abstracts\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is shown that the complementary stages in MultiViz together enable users to simulate model predictions, assign interpretable concepts to features, perform error analysis on model misclassifications, and use insights from error analysis to debug models.'}\nUrl: N/A",
  "Faculty Name: louis philippe morency\nPaperid: dcb4f2b9b0e6da0d629878d1ad0469aee3df2020\nTitle: Understanding Masked Autoencoders via Hierarchical Latent Variable Models\nYear: 2023\nAbstract: Masked autoencoder (MAE), a simple and effective self-supervised learning framework based on the reconstruction of masked image regions, has recently achieved prominent success in a variety of vision tasks. Despite the emergence of intriguing empirical observations on MAE, a theoretically principled understanding is still lacking. In this work, we formally characterize and justify existing empirical in-sights and provide theoretical guarantees of MAE. We formulate the underlying data-generating process as a hierarchical latent variable model, and show that under reasonable assumptions, MAE provably identifies a set of latent variables in the hierarchical model, explaining why MAE can extract high-level information from pixels. Further, we show how key hyperparameters in MAE (the masking ratio and the patch size) determine which true latent variables to be recovered, therefore influencing the level of semantic information in the representation. Specifically, extremely large or small masking ratios inevitably lead to low-level representations.",
  "Further, we show how key hyperparameters in MAE (the masking ratio and the patch size) determine which true latent variables to be recovered, therefore influencing the level of semantic information in the representation. Specifically, extremely large or small masking ratios inevitably lead to low-level representations. Our theory offers coherent explanations of existing empirical observations and provides insights for potential empirical improvements and fundamental limitations of the masked-reconstruction paradigm. We conduct extensive experiments to validate our theoretical insights.\nAuthors: Lingjing Kong, Martin Q. Ma, Guan-Hong Chen, E. Xing, Yuejie Chi, Louis-Philippe Morency, Kun Zhang\nVenue: Computer Vision and Pattern Recognition\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work formally characterize and justify existing empirical in-sights and provide theoretical guarantees of MAE, and formulate the underlying data-generating process as a hierarchical latent variable model, and shows that under reasonable assumptions, MAE provably identifies a set of latent variables in the hierarchical model.'}\nUrl: https://arxiv.org/pdf/2306.04898",
  "Faculty Name: louis philippe morency\nPaperid: e1b2a35a000ca296c32284b323c7e36a28fe0693\nTitle: Factorized Contrastive Learning: Going Beyond Multi-view Redundancy\nYear: 2023\nAbstract: In a wide range of multimodal tasks, contrastive learning has become a particularly appealing approach since it can successfully learn representations from abundant unlabeled data with only pairing information (e.g., image-caption or video-audio pairs). Underpinning these approaches is the assumption of multi-view redundancy - that shared information between modalities is necessary and sufficient for downstream tasks. However, in many real-world settings, task-relevant information is also contained in modality-unique regions: information that is only present in one modality but still relevant to the task. How can we learn self-supervised multimodal representations to capture both shared and unique information relevant to downstream tasks? This paper proposes FactorCL, a new multimodal representation learning method to go beyond multi-view redundancy.",
  "How can we learn self-supervised multimodal representations to capture both shared and unique information relevant to downstream tasks? This paper proposes FactorCL, a new multimodal representation learning method to go beyond multi-view redundancy. FactorCL is built from three new contributions: (1) factorizing task-relevant information into shared and unique representations, (2) capturing task-relevant information via maximizing MI lower bounds and removing task-irrelevant information via minimizing MI upper bounds, and (3) multimodal data augmentations to approximate task relevance without labels. On large-scale real-world datasets, FactorCL captures both shared and unique information and achieves state-of-the-art results on six benchmarks\nAuthors: P. Liang, Zihao Deng, Martin Q. Ma, James Y. Zou, Louis-Philippe Morency, R. Salakhutdinov\nVenue: Neural Information Processing Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'FactorCL is a new multimodal representation learning method to go beyond multi-view redundancy and captures both shared and unique information and achieves state-of-the-art results on six benchmarks.'}\nUrl: http://arxiv.org/pdf/2306.05268",
  "Faculty Name: louis philippe morency\nPaperid: f891e9eeedbf20cdc54429ffcc0402a10f48494e\nTitle: Language Models Get a Gender Makeover: Mitigating Gender Bias with Few-Shot Data Interventions\nYear: 2023\nAbstract: Societal biases present in pre-trained large language models are a critical issue as these models have been shown to propagate biases in countless downstream applications, rendering them unfair towards specific groups of people. Since large-scale retraining of these models from scratch is both time and compute-expensive, a variety of approaches have been previously proposed that de-bias a pre-trained model. While the majority of current state-of-the-art debiasing methods focus on changes to the training regime, in this paper, we propose data intervention strategies as a powerful yet simple technique to reduce gender bias in pre-trained models. Specifically, we empirically show that by fine-tuning a pre-trained model on only 10 debiased (intervened) training examples, the tendency to favor any gender is significantly reduced.",
  "Specifically, we empirically show that by fine-tuning a pre-trained model on only 10 debiased (intervened) training examples, the tendency to favor any gender is significantly reduced. Since our proposed method only needs a few training examples, we argue that our few-shot de-biasing approach is highly feasible and practical. Through extensive experimentation, we show that our de-biasing technique performs better than competitive state-of-the-art baselines with minimal loss in language modeling ability.\nAuthors: Himanshu Thakur, Atishay Jain, Praneetha Vaddamanu, P. Liang, Louis-Philippe Morency\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper empirically shows that by fine-tuning a pre-trained model on only 10 debiased (intervened) training examples, the tendency to favor any gender is significantly reduced, and argues that the few-shot de-biasing approach is highly feasible and practical.'}\nUrl: http://arxiv.org/pdf/2306.04597",
  "List of 2023 Open Access papers by louis philippe morency are:\nQuantifying & Modeling Feature Interactions: An Information Decomposition Framework\nReconstructing the neurodynamics of face perception during real world vision in humans using intracranial EEG recordings\nMultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning\nSenteCon: Leveraging Lexicons to Learn Human-Interpretable Language Representations\nNeural Mixed Effects for Nonlinear Personalized Predictions\nSHAP-based Prediction of Mother's History of Depression to Understand the Influence on Child Behavior\nCounterfactual Augmentation for Multimodal Learning Under Presentation Bias\nDifference-Masking: Choosing What to Mask in Continued Pretraining\nExpanding the Role of Affective Phenomena in Multimodal Interaction Research\nMultimodal Fusion Interactions: A Study of Human and Automatic Quantification\nMultimodal Learning Without Labeled Multimodal Data: Guarantees and Applications\nRepresentation Learning for Interpersonal and Multimodal Behavior Dynamics: A Multiview Extension of Latent Change Score Models\nMultiViz: Towards User-Centric Visualizations and Interpretations of Multimodal Models\nUnderstanding Masked Autoencoders via Hierarchical Latent Variable",
  "Data: Guarantees and Applications\nRepresentation Learning for Interpersonal and Multimodal Behavior Dynamics: A Multiview Extension of Latent Change Score Models\nMultiViz: Towards User-Centric Visualizations and Interpretations of Multimodal Models\nUnderstanding Masked Autoencoders via Hierarchical Latent Variable Models\nFactorized Contrastive Learning: Going Beyond Multi-view Redundancy\nLanguage Models Get a Gender Makeover: Mitigating Gender Bias with Few-Shot Data Interventions",
  "Louis-Philippe Morency\nLeonardo Associate Professor of Computer Science (On Leave), Language Technologies Institute\nResearch Area\nMachine Learning, Multimodal Computing and Interaction, Spoken Interfaces and Dialogue Processing\n\nResearch\nMy research interest lies at the intersection of machine learning, computer vision, computational linguistics and signal processing \u2014 building the computational foundations to enable computers with the abilities to analyze, recognize and predict subtle human communicative behaviors during social interactions. Human face-to-face communication is a little like a dance: participants continuously adjust their behaviors based on their interlocutor\u2019s speech, gestures and facial expressions during social interaction. The actual sophistication of human communication comes to the fore when we try to create computers that can understand and participate, however crudely, in this type of social interaction.",
  "The actual sophistication of human communication comes to the fore when we try to create computers that can understand and participate, however crudely, in this type of social interaction.\n\nHuman Communication Dynamics\nI formalize this new research endeavor with a human communication dynamics framework, addressing four key computational challenges: behavioral dynamics to model the appearance and temporal variations of individual communicative behaviors and their effects on perceived meanings; multimodal dynamics to model the interdependence between different communicative channels including visual gestures and expressions, language, and acoustic signals; interpersonal dynamics to model the social and conversational influence between participants during dyadic or small-group interactions (i.e., micro-level); and societal dynamics to model the cultural and behavioral changes in a larger groups (i.e., meso-level) or in different societies (i.e, macro-level).\n\nMultimodal Machine Learning\nCentral to this research effort is the introduction of new probabilistic models that can learn temporal and fine-grained dependencies across behaviors, modalities and interlocutors. These energy-based probabilistic models must address core computational issues with human communication dynamics, including hierarchical and nonlinear feature representation, multiview learning and potential over fitting on smaller training sets.",
  "These energy-based probabilistic models must address core computational issues with human communication dynamics, including hierarchical and nonlinear feature representation, multiview learning and potential over fitting on smaller training sets. For example, I created a family of latent probabilistic models (HCRF, LDCRF, CCNF, etc.) designed to automatically learn the hidden dynamics present in human verbal and nonverbal communication.\n\nHealth Behavior Informatics\nThis research has many applications in education (learning analytics), business (negotiation, interpersonal skills training) and social multimedia (opinion mining, social influence). One area I am particularly excited about is the development of new decision support tools for healthcare applications. For example, how can we quantify, analyze and summarize patient verbal and nonverbal behaviors during psychotherapy? This information could not only help clinicians between therapy sessions but also facilitate collaboration with other medical team members by providing objective behavior measures for the patient\u2019s medical record.\n\nPersonal Website http://www.cs.cmu.edu/~morency/\nContact 5411 \u2014Gates & Hillman Centers\nmorency@cs.cmu.edu\ntel:412-268-5508",
  "Faculty Name: maarten sap\nPaperid: 14ddefae2be4b5bb50b9fcb4a085e45fbecb5c5c\nTitle: Modeling Empathic Similarity in Personal Narratives\nYear: 2023\nAbstract: The most meaningful connections between people are often fostered through expression of shared vulnerability and emotional experiences in personal narratives. We introduce a new task of identifying similarity in personal stories based on empathic resonance, i.e., the extent to which two people empathize with each others' experiences, as opposed to raw semantic or lexical similarity, as has predominantly been studied in NLP. Using insights from social psychology, we craft a framework that operationalizes empathic similarity in terms of three key features of stories: main events, emotional trajectories, and overall morals or takeaways. We create EmpathicStories, a dataset of 1,500 personal stories annotated with our empathic similarity features, and 2,000 pairs of stories annotated with empathic similarity scores. Using our dataset, we fine-tune a model to compute empathic similarity of story pairs, and show that this outperforms semantic similarity models on automated correlation and retrieval metrics.",
  "Using our dataset, we fine-tune a model to compute empathic similarity of story pairs, and show that this outperforms semantic similarity models on automated correlation and retrieval metrics. Through a user study with 150 participants, we also assess the effect our model has on retrieving stories that users empathize with, compared to naive semantic similarity-based retrieval, and find that participants empathized significantly more with stories retrieved by our model. Our work has strong implications for the use of empathy-aware models to foster human connection and empathy between people.\nAuthors: Jocelyn Shen, Maarten Sap, Pedro Colon-Hernandez, Hae Won Park, C. Breazeal\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': \"A new task of identifying similarity in personal stories based on empathic resonance is introduced, i.e., the extent to which two people empathize with each others' experiences, as opposed to raw semantic or lexical similarity, as has predominantly been studied in NLP.\"}\nUrl: http://arxiv.org/pdf/2305.14246",
  "Faculty Name: maarten sap\nPaperid: 185ace5661963e2e1eb998e739e4110272a6bb43\nTitle: COBRA Frames: Contextual Reasoning about Effects and Harms of Offensive Statements\nYear: 2023\nAbstract: Warning: This paper contains content that may be offensive or upsetting. Understanding the harms and offensiveness of statements requires reasoning about the social and situational context in which statements are made. For example, the utterance\"your English is very good\"may implicitly signal an insult when uttered by a white man to a non-white colleague, but uttered by an ESL teacher to their student would be interpreted as a genuine compliment. Such contextual factors have been largely ignored by previous approaches to toxic language detection. We introduce COBRA frames, the first context-aware formalism for explaining the intents, reactions, and harms of offensive or biased statements grounded in their social and situational context. We create COBRACORPUS, a dataset of 33k potentially offensive statements paired with machine-generated contexts and free-text explanations of offensiveness, implied biases, speaker intents, and listener reactions.",
  "We create COBRACORPUS, a dataset of 33k potentially offensive statements paired with machine-generated contexts and free-text explanations of offensiveness, implied biases, speaker intents, and listener reactions. To study the contextual dynamics of offensiveness, we train models to generate COBRA explanations, with and without access to the context. We find that explanations by context-agnostic models are significantly worse than by context-aware ones, especially in situations where the context inverts the statement's offensiveness (29% accuracy drop). Our work highlights the importance and feasibility of contextualized NLP by modeling social factors.",
  "We find that explanations by context-agnostic models are significantly worse than by context-aware ones, especially in situations where the context inverts the statement's offensiveness (29% accuracy drop). Our work highlights the importance and feasibility of contextualized NLP by modeling social factors.\nAuthors: Xuhui Zhou, Haojie Zhu, Akhila Yerukola, Thomas Davidson, Jena D. Hwang, Swabha Swayamdipta, Maarten Sap\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'COBRA frames are introduced, the first context-aware formalism for explaining the intents, reactions, and harms of offensive or biased statements grounded in their social and situational context, and the importance and feasibility of contextualized NLP by modeling social factors are highlighted.'}\nUrl: http://arxiv.org/pdf/2306.01985",
  "Faculty Name: maarten sap\nPaperid: 27553f8bd9cbee90f6e65b9cdecadff0e7cc55ee\nTitle: Riveter: Measuring Power and Social Dynamics Between Entities\nYear: 2023\nAbstract: Riveter provides a complete easy-to-use pipeline for analyzing verb connotations associated with entities in text corpora. We prepopulate the package with connotation frames of sentiment, power, and agency, which have demonstrated usefulness for capturing social phenomena, such as gender bias, in a broad range of corpora. For decades, lexical frameworks have been foundational tools in computational social science, digital humanities, and natural language processing, facilitating multifaceted analysis of text corpora. But working with verb-centric lexica specifically requires natural language processing skills, reducing their accessibility to other researchers. By organizing the language processing pipeline, providing complete lexicon scores and visualizations for all entities in a corpus, and providing functionality for users to target specific research questions, Riveter greatly improves the accessibility of verb lexica and can facilitate a broad range of future research.",
  "By organizing the language processing pipeline, providing complete lexicon scores and visualizations for all entities in a corpus, and providing functionality for users to target specific research questions, Riveter greatly improves the accessibility of verb lexica and can facilitate a broad range of future research.\nAuthors: Maria Antoniak, Anjalie Field, Jimin Mun, Melanie Walsh, Lauren F. Klein, Maarten Sap\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Riveter greatly improves the accessibility of verb lexica and can facilitate a broad range of future research by organizing the language processing pipeline, providing complete lexicon scores and visualizations for all entities in a corpus, and providing functionality for users to target specific research questions.'}\nUrl: https://aclanthology.org/2023.acl-demo.36.pdf",
  "Faculty Name: maarten sap\nPaperid: 57d65e85c62aef04dfb2a48380e415fbb790e5ee\nTitle: Don't Take This Out of Context!: On the Need for Contextual Models and Evaluations for Stylistic Rewriting\nYear: 2023\nAbstract: None\nAuthors: Akhila Yerukola, Xuhui Zhou, Elizabeth Clark, Maarten Sap\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: None\nUrl: https://aclanthology.org/2023.emnlp-main.701.pdf",
  "Faculty Name: maarten sap\nPaperid: 85a5ffc509fa50c96b415e09ae87fb6e5f435b37\nTitle: BiasX: \"Thinking Slow\" in Toxic Content Moderation with Explanations of Implied Social Biases\nYear: 2023\nAbstract: Toxicity annotators and content moderators often default to mental shortcuts when making decisions. This can lead to subtle toxicity being missed, and seemingly toxic but harmless content being over-detected. We introduce BiasX, a framework that enhances content moderation setups with free-text explanations of statements' implied social biases, and explore its effectiveness through a large-scale crowdsourced user study. We show that indeed, participants substantially benefit from explanations for correctly identifying subtly (non-)toxic content. The quality of explanations is critical: imperfect machine-generated explanations (+2.4% on hard toxic examples) help less compared to expert-written human explanations (+7.2%). Our results showcase the promise of using free-text explanations to encourage more thoughtful toxicity moderation.",
  "The quality of explanations is critical: imperfect machine-generated explanations (+2.4% on hard toxic examples) help less compared to expert-written human explanations (+7.2%). Our results showcase the promise of using free-text explanations to encourage more thoughtful toxicity moderation.\nAuthors: Yiming Zhang, Sravani Nanduri, Liwei Jiang, Tongshuang Wu, Maarten Sap\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': \"BiasX, a framework that enhances content moderation setups with free-text explanations of statements' implied social biases, is introduced and it is shown that indeed, participants substantially benefit from explanations for correctly identifying subtly (non-)toxic content.\"}\nUrl: http://arxiv.org/pdf/2305.13589",
  "Faculty Name: maarten sap\nPaperid: 9d2dc57903e99f33b9cf727c3903718751d82663\nTitle: Improving Language Models with Advantage-based Offline Policy Gradients\nYear: 2023\nAbstract: Language Models (LMs) achieve substantial language capabilities when finetuned using Reinforcement Learning with Human Feedback (RLHF). However, RLHF is an unstable and data-hungry process that continually requires new high-quality LM-generated data for finetuning. We introduce Advantage-Leftover Lunch RL (A-LoL), a new class of offline policy gradient algorithms that enable RL training on any pre-existing data. By assuming the entire LM output sequence as a single action, A-LoL allows incorporating sequence-level classifiers or human-designed scoring functions as rewards. Subsequently, by using LM's internal sequence-level value estimate, A-LoL filters negative advantage (low-quality) data points during training, making it resilient to noise. Overall, A-LoL is an easy-to-implement LM training recipe that is sample-efficient and stable. We demonstrate the effectiveness of A-LoL and its variants with a set of four different language generation tasks.",
  "Overall, A-LoL is an easy-to-implement LM training recipe that is sample-efficient and stable. We demonstrate the effectiveness of A-LoL and its variants with a set of four different language generation tasks. We compare against both online RL (PPO) and recent preference-based (DPO, PRO) and reward-based (GOLD) offline RL baselines. On the commonly-used RLHF benchmark, Helpful and Harmless Assistant (HHA), LMs trained with A-LoL methods achieve the highest diversity while also being rated more safe and helpful than baselines according to humans. Additionally, in the remaining three tasks, A-LoL could optimize multiple distinct reward functions even when using noisy or suboptimal training data. We also release our experimental code.",
  "Additionally, in the remaining three tasks, A-LoL could optimize multiple distinct reward functions even when using noisy or suboptimal training data. We also release our experimental code. https://github.com/abaheti95/LoL-RL\nAuthors: Ashutosh Baheti, Ximing Lu, Faeze Brahman, Ronan Le Bras, Maarten Sap, Mark O. Riedl\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Advantage-Leftover Lunch RL (A-LoL), a new class of offline policy gradient algorithms that enable RL training on any pre-existing data that assumes the entire LM output sequence as a single action, and allows incorporating sequence-level classifiers or human-designed scoring functions as rewards.'}\nUrl: https://arxiv.org/pdf/2305.14718",
  "Faculty Name: maarten sap\nPaperid: a5731b32060909bfc8848fa5f7e1e14ca3b53240\nTitle: From Dogwhistles to Bullhorns: Unveiling Coded Rhetoric with Language Models\nYear: 2023\nAbstract: Dogwhistles are coded expressions that simultaneously convey one meaning to a broad audience and a second, often hateful or provocative, meaning to a narrow in-group; they are deployed to evade both political repercussions and algorithmic content moderation. For example, the word \u201ccosmopolitan\u201d in a sentence such as \u201cwe need to end the cosmopolitan experiment\u201d can mean \u201cworldly\u201d to many but also secretly mean \u201cJewish\u201d to a select few. We present the first large-scale computational investigation of dogwhistles. We develop a typology of dogwhistles, curate the largest-to-date glossary of over 300 dogwhistles with rich contextual information and examples, and analyze their usage in historical U.S. politicians\u2019 speeches.",
  "We present the first large-scale computational investigation of dogwhistles. We develop a typology of dogwhistles, curate the largest-to-date glossary of over 300 dogwhistles with rich contextual information and examples, and analyze their usage in historical U.S. politicians\u2019 speeches. We then assess whether a large language model (GPT-3) can identify dogwhistles and their meanings, and find that GPT-3\u2019s performance varies widely across types of dogwhistles and targeted groups. Finally, we show that harmful content containing dogwhistles avoids toxicity detection, highlighting online risks presented by such coded language. This work sheds light on the theoretical and applied importance of dogwhistles in both NLP and computational social science, and provides resources to facilitate future research in modeling dogwhistles and mitigating their online harms.\nAuthors: Julia Mendelsohn, Ronan Le Bras, Yejin Choi, Maarten Sap\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: None\nUrl: http://arxiv.org/pdf/2305.17174",
  "Faculty Name: maarten sap\nPaperid: a66ff335f5934fe7503a99d3eb3abed493994df1\nTitle: NLPositionality: Characterizing Design Biases of Datasets and Models\nYear: 2023\nAbstract: Design biases in NLP systems, such as performance differences for different populations, often stem from their creator\u2019s positionality, i.e., views and lived experiences shaped by identity and background. Despite the prevalence and risks of design biases, they are hard to quantify because researcher, system, and dataset positionality is often unobserved. We introduce NLPositionality, a framework for characterizing design biases and quantifying the positionality of NLP datasets and models. Our framework continuously collects annotations from a diverse pool of volunteer participants on LabintheWild, and statistically quantifies alignment with dataset labels and model predictions. We apply NLPositionality to existing datasets and models for two tasks\u2014social acceptability and hate speech detection.",
  "Our framework continuously collects annotations from a diverse pool of volunteer participants on LabintheWild, and statistically quantifies alignment with dataset labels and model predictions. We apply NLPositionality to existing datasets and models for two tasks\u2014social acceptability and hate speech detection. To date, we have collected 16,299 annotations in over a year for 600 instances from 1,096 annotators across 87 countries.We find that datasets and models align predominantly with Western, White, college-educated, and younger populations. Additionally, certain groups, such as non-binary people and non-native English speakers, are further marginalized by datasets and models as they rank least in alignment across all tasks. Finally, we draw from prior literature to discuss how researchers can examine their own positionality and that of their datasets and models, opening the door for more inclusive NLP systems.",
  "Finally, we draw from prior literature to discuss how researchers can examine their own positionality and that of their datasets and models, opening the door for more inclusive NLP systems.\nAuthors: Sebastin Santy, Jenny T Liang, Ronan Le Bras, Katharina Reinecke, Maarten Sap\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'NLPositionality, a framework for characterizing design biases and quantifying the positionality of NLP datasets and models, is introduced and it is found that dataset and models align predominantly with Western, White, college-educated, and younger populations.'}\nUrl: http://arxiv.org/pdf/2306.01943",
  "Faculty Name: maarten sap\nPaperid: a89c30ceca55783a1b2ff843eb6a4793e4a54b66\nTitle: Don't Take This Out of Context! On the Need for Contextual Models and Evaluations for Stylistic Rewriting\nYear: 2023\nAbstract: Most existing stylistic text rewriting methods and evaluation metrics operate on a sentence level, but ignoring the broader context of the text can lead to preferring generic, ambiguous, and incoherent rewrites. In this paper, we investigate integrating the preceding textual context into both the $\\textit{rewriting}$ and $\\textit{evaluation}$ stages of stylistic text rewriting, and introduce a new composite contextual evaluation metric $\\texttt{CtxSimFit}$ that combines similarity to the original sentence with contextual cohesiveness. We comparatively evaluate non-contextual and contextual rewrites in formality, toxicity, and sentiment transfer tasks. Our experiments show that humans significantly prefer contextual rewrites as more fitting and natural over non-contextual ones, yet existing sentence-level automatic metrics (e.g., ROUGE, SBERT) correlate poorly with human preferences ($\\rho$=0--0.3).",
  "Our experiments show that humans significantly prefer contextual rewrites as more fitting and natural over non-contextual ones, yet existing sentence-level automatic metrics (e.g., ROUGE, SBERT) correlate poorly with human preferences ($\\rho$=0--0.3). In contrast, human preferences are much better reflected by both our novel $\\texttt{CtxSimFit}$ ($\\rho$=0.7--0.9) as well as proposed context-infused versions of common metrics ($\\rho$=0.4--0.7). Overall, our findings highlight the importance of integrating context into the generation and especially the evaluation stages of stylistic text rewriting.\nAuthors: Akhila Yerukola, Xuhui Zhou, Maarten Sap\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A new composite contextual evaluation metric is introduced that combines similarity to the original sentence with contextual cohesiveness and highlights the importance of integrating context into the generation and especially the evaluation stages of stylistic text rewriting.'}\nUrl: http://arxiv.org/pdf/2305.14755",
  "Faculty Name: maarten sap\nPaperid: c2850c897a179c07a25023029306600e0ea82f75\nTitle: Queer In AI: A Case Study in Community-Led Participatory AI\nYear: 2023\nAbstract: Queerness and queer people face an uncertain future in the face of ever more widely deployed and invasive artificial intelligence (AI). These technologies have caused numerous harms to queer people, including privacy violations, censoring and downranking queer content, exposing queer people and spaces to harassment by making them hypervisible, deadnaming and outing queer people. More broadly, they have violated core tenets of queerness by classifying and controlling queer identities. In response to this, the queer community in AI has organized Queer in AI, a global, decentralized, volunteer-run grassroots organization that employs intersectional and community-led participatory design to build an inclusive and equitable AI future. In this paper, we present Queer in AI as a case study for community-led participatory design in AI. We examine how participatory design and intersectional tenets started and shaped this community\u2019s programs over the years.",
  "In this paper, we present Queer in AI as a case study for community-led participatory design in AI. We examine how participatory design and intersectional tenets started and shaped this community\u2019s programs over the years. We discuss different challenges that emerged in the process, look at ways this organization has fallen short of operationalizing participatory and intersectional principles, and then assess the organization\u2019s impact. Queer in AI provides important lessons and insights for practitioners and theorists of participatory methods broadly through its rejection of hierarchy in favor of decentralization, success at building aid and programs by and for the queer community, and effort to change actors and institutions outside of the queer community. Finally, we theorize how communities like Queer in AI contribute to the participatory design in AI more broadly by fostering cultures of participation in AI, welcoming and empowering marginalized participants, critiquing poor or exploitative participatory practices, and bringing participation to institutions outside of individual research projects. Queer in AI\u2019s work serves as a case study of grassroots activism and participatory methods within AI, demonstrating the potential of community-led participatory methods and intersectional praxis, while also providing challenges, case studies, and nuanced insights to researchers developing and using participatory methods.",
  "Queer in AI\u2019s work serves as a case study of grassroots activism and participatory methods within AI, demonstrating the potential of community-led participatory methods and intersectional praxis, while also providing challenges, case studies, and nuanced insights to researchers developing and using participatory methods.\nAuthors: AI OrganizersOfQueerin, Anaelia Ovalle, Arjun Subramonian, Ashwin Singh, C. Voelcker, Danica J. Sutherland, Davide Locatelli, Eva Breznik, Filip Klubicka, Hang Yuan, J. Hetvi, Huan Zhang, Jaidev Shriram, Kruno Lehman, Luca Soldaini, Maarten Sap, M. Deisenroth, Maria Leonor Pacheco, Maria Ryskina, Martin Mundt, M. Agarwal, Nyx McLean, Pan Xu, Pranav A, Raj Korpan, Ruchira Ray, Sarah Mathew, Sarthak Arora, S. T. John, Tanvi Anand, Vishakha Agrawal, William Agnew, Yanan Long, Zijie J. Wang, Zeerak Talat, Avijit Ghosh, N.",
  "Ruchira Ray, Sarah Mathew, Sarthak Arora, S. T. John, Tanvi Anand, Vishakha Agrawal, William Agnew, Yanan Long, Zijie J. Wang, Zeerak Talat, Avijit Ghosh, N. Dennler, Michael Noseworthy, Sharvani Jha, Emi Baylor, Aditya Joshi, Natalia Y. Bilenko, Andrew McNamara, Raphael Gontijo-Lopes, Alex Markham, Evyn D\u01d2ng, J. Kay, Manu Saraswat, Nikhil Vytla, Luke Stark\nVenue: Conference on Fairness, Accountability and Transparency\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper examines how participatory design and intersectional tenets started and shaped this community\u2019s programs over the years, and discusses different challenges that emerged in the process, and looks at ways this organization has fallen short of operationalizing participatory and intersectionsal principles.'}",
  "0.0', 'text': 'This paper examines how participatory design and intersectional tenets started and shaped this community\u2019s programs over the years, and discusses different challenges that emerged in the process, and looks at ways this organization has fallen short of operationalizing participatory and intersectionsal principles.'}\nUrl: https://arrow.tudublin.ie/context/scschcomcon/article/1430/viewcontent/Queer_In_AI___A_Case_Study_in_Community_Led_Participatory_AI.pdf",
  "Faculty Name: maarten sap\nPaperid: d655f652d02251b45db43181c5e3c73dfc59cd51\nTitle: Value Kaleidoscope: Engaging AI with Pluralistic Human Values, Rights, and Duties\nYear: 2023\nAbstract: Human values are crucial to human decision-making. Value pluralism is the view that multiple correct values may be held in tension with one another (e.g., when considering lying to a friend to protect their feelings, how does one balance honesty with friendship?). As statistical learners, AI systems fit to averages by default, washing out these potentially irreducible value conflicts. To improve AI systems to better reflect value pluralism, the first-order challenge is to explore the extent to which AI systems can model pluralistic human values, rights, and duties as well as their interaction. We introduce ValuePrism, a large-scale dataset of 218k values, rights, and duties connected to 31k human-written situations. ValuePrism's contextualized values are generated by GPT-4 and deemed high-quality by human annotators 91% of the time.",
  "We introduce ValuePrism, a large-scale dataset of 218k values, rights, and duties connected to 31k human-written situations. ValuePrism's contextualized values are generated by GPT-4 and deemed high-quality by human annotators 91% of the time. We conduct a large-scale study with annotators across diverse social and demographic backgrounds to try to understand whose values are represented. With ValuePrism, we build Kaleido, an open, light-weight, and structured language-based multi-task model that generates, explains, and assesses the relevance and valence (i.e., support or oppose) of human values, rights, and duties within a specific context. Humans prefer the sets of values output by our system over the teacher GPT-4, finding them more accurate and with broader coverage. In addition, we demonstrate that Kaleido can help explain variability in human decision-making by outputting contrasting values. Finally, we show that Kaleido's representations transfer to other philosophical frameworks and datasets, confirming the benefit of an explicit, modular, and interpretable approach to value pluralism.",
  "In addition, we demonstrate that Kaleido can help explain variability in human decision-making by outputting contrasting values. Finally, we show that Kaleido's representations transfer to other philosophical frameworks and datasets, confirming the benefit of an explicit, modular, and interpretable approach to value pluralism. We hope that our work will serve as a step to making more explicit the implicit values behind human decision-making and to steering AI systems to make decisions that are more in accordance with them.\nAuthors: Taylor Sorensen, Liwei Jiang, Jena D. Hwang, Sydney Levine, Valentina Pyatkin, Peter West, Nouha Dziri, Ximing Lu, Kavel Rao, Chandra Bhagavatula, Maarten Sap, J. Tasioulas, Yejin Choi\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Kaleido is built, an open, light-weight, and structured language-based multi-task model that generates, explains, and assesses the relevance and valence of human values, rights, and duties within a specific context and demonstrates that Kaleido can help explain variability in human decision-making by outputting contrasting values.'}",
  "Url: https://arxiv.org/pdf/2309.00779",
  "Faculty Name: maarten sap\nPaperid: ddcd2bcc809bd0c2755a4a9487473d61ac327c50\nTitle: Clever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in Large Language Models\nYear: 2023\nAbstract: The escalating debate on AI's capabilities warrants developing reliable metrics to assess machine\"intelligence\". Recently, many anecdotal examples were used to suggest that newer large language models (LLMs) like ChatGPT and GPT-4 exhibit Neural Theory-of-Mind (N-ToM); however, prior work reached conflicting conclusions regarding those abilities. We investigate the extent of LLMs' N-ToM through an extensive evaluation on 6 tasks and find that while LLMs exhibit certain N-ToM abilities, this behavior is far from being robust. We further examine the factors impacting performance on N-ToM tasks and discover that LLMs struggle with adversarial examples, indicating reliance on shallow heuristics rather than robust ToM abilities. We caution against drawing conclusions from anecdotal examples, limited benchmark testing, and using human-designed psychological tests to evaluate models.",
  "We further examine the factors impacting performance on N-ToM tasks and discover that LLMs struggle with adversarial examples, indicating reliance on shallow heuristics rather than robust ToM abilities. We caution against drawing conclusions from anecdotal examples, limited benchmark testing, and using human-designed psychological tests to evaluate models.\nAuthors: Natalie Shapira, Mosh Levy, S. Alavi, Xuhui Zhou, Yejin Choi, Yoav Goldberg, Maarten Sap, Vered Shwartz\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is found that while LLMs exhibit certain N-ToM abilities, this behavior is far from being robust, indicating reliance on shallow heuristics rather than robust ToM abilities.'}\nUrl: http://arxiv.org/pdf/2305.14763",
  "Faculty Name: maarten sap\nPaperid: ea0585ed23e25d5f8682eb91f20c6ddbeb6a27b4\nTitle: Towards Countering Essentialism through Social Bias Reasoning\nYear: 2023\nAbstract: Essentialist beliefs (i.e., believing that members of the same group are fundamentally alike) play a central role in social stereotypes and can lead to harm when left unchallenged. In our work, we conduct exploratory studies into the task of countering essentialist beliefs (e.g., ``liberals are stupid''). Drawing on prior work from psychology and NLP, we construct five types of counterstatements and conduct human studies on the effectiveness of these different strategies. Our studies also investigate the role in choosing a counterstatement of the level of explicitness with which an essentialist belief is conveyed. We find that statements that broaden the scope of a stereotype (e.g., to other groups, as in ``conservatives can also be stupid'') are the most popular countering strategy.",
  "We find that statements that broaden the scope of a stereotype (e.g., to other groups, as in ``conservatives can also be stupid'') are the most popular countering strategy. We conclude with a discussion of challenges and open questions for future work in this area (e.g., improving factuality, studying community-specific variation) and we emphasize the importance of work at the intersection of NLP and psychology.\nAuthors: Emily Allaway, Nina Taneja, S. Leslie, Maarten Sap\nVenue: arXiv.org\nTldr: None\nUrl: http://arxiv.org/pdf/2303.16173",
  "List of 2023 Open Access papers by maarten sap are:\nModeling Empathic Similarity in Personal Narratives\nCOBRA Frames: Contextual Reasoning about Effects and Harms of Offensive Statements\nRiveter: Measuring Power and Social Dynamics Between Entities\nDon't Take This Out of Context!: On the Need for Contextual Models and Evaluations for Stylistic Rewriting\nBiasX: \"Thinking Slow\" in Toxic Content Moderation with Explanations of Implied Social Biases\nImproving Language Models with Advantage-based Offline Policy Gradients\nFrom Dogwhistles to Bullhorns: Unveiling Coded Rhetoric with Language Models\nNLPositionality: Characterizing Design Biases of Datasets and Models\nDon't Take This Out of Context! On the Need for Contextual Models and Evaluations for Stylistic Rewriting\nQueer In AI: A Case Study in Community-Led Participatory AI\nValue Kaleidoscope: Engaging AI with Pluralistic Human Values, Rights, and Duties\nClever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in Large Language Models\nTowards Countering Essentialism through Social Bias Reasoning",
  "Maarten Sap\nAssistant Professor, Language Technologies Institute\nContact\n6713 \u2014Gates & Hillman Centers\nEmail msap2@andrew.cmu.edu\nResearch Area\nComputational Social Science, Conversational AI, Discourse and Pragmatics, Fairness and Ethics in Language Technology\n\nPersonal Website http://maartensap.com/",
  "List of 2023 Open Access papers by michael shamos are:",
  "Michael Shamos\nDistinguished Career Professor, Language Technologies Institute\nInstitute for Software Research\nContact\n6707 \u2014Gates & Hillman Centers\nEmail shamos@cs.cmu.edu\n412-268-8193\nInstitute for Software Research https://www.cs.cmu.edu/~brassmars/\nPersonal Website http://www.cs.cmu.edu/~jbigham/",
  "Faculty Name: mona diab\nPaperid: 0a94fbb5e1c93513523f00e75d672ef4553861f9\nTitle: Can Large Language Models Infer Causation from Correlation?\nYear: 2023\nAbstract: Causal inference is one of the hallmarks of human intelligence. While the field of CausalNLP has attracted much interest in the recent years, existing causal inference datasets in NLP primarily rely on discovering causality from empirical knowledge (e.g., commonsense knowledge). In this work, we propose the first benchmark dataset to test the pure causal inference skills of large language models (LLMs). Specifically, we formulate a novel task Corr2Cause, which takes a set of correlational statements and determines the causal relationship between the variables. We curate a large-scale dataset of more than 200K samples, on which we evaluate seventeen existing LLMs. Through our experiments, we identify a key shortcoming of LLMs in terms of their causal inference skills, and show that these models achieve almost close to random performance on the task.",
  "We curate a large-scale dataset of more than 200K samples, on which we evaluate seventeen existing LLMs. Through our experiments, we identify a key shortcoming of LLMs in terms of their causal inference skills, and show that these models achieve almost close to random performance on the task. This shortcoming is somewhat mitigated when we try to re-purpose LLMs for this skill via finetuning, but we find that these models still fail to generalize -- they can only perform causal inference in in-distribution settings when variable names and textual expressions used in the queries are similar to those in the training set, but fail in out-of-distribution settings generated by perturbing these queries. Corr2Cause is a challenging task for LLMs, and would be helpful in guiding future research on improving LLMs' pure reasoning skills and generalizability. Our data is at https://huggingface.co/datasets/causalnlp/corr2cause. Our code is at https://github.com/causalNLP/corr2cause.",
  "Our data is at https://huggingface.co/datasets/causalnlp/corr2cause. Our code is at https://github.com/causalNLP/corr2cause.\nAuthors: Zhijing Jin, Jiarui Liu, Zhiheng Lyu, Spencer Poff, Mrinmaya Sachan, Rada Mihalcea, Mona T. Diab, B. Sch\u00f6lkopf\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes the first benchmark dataset to test the pure causal inference skills of large language models (LLMs), and formulates a novel task Corr2Cause, which takes a set of correlational statements and determines the causal relationship between the variables.'}\nUrl: http://arxiv.org/pdf/2306.05836",
  "Faculty Name: mona diab\nPaperid: 11ff985b42649154d87015b8a4c2cf07abf82fef\nTitle: A bleeding bite: crotalinae snake envonamation\nYear: 2023\nAbstract: None\nAuthors: M. Osman, M. A. Diab, B. Mohanakrishnan, M. Elmahi, A. Islam\nVenue: American Journal of the Medical Sciences\nTldr: None\nUrl: N/A",
  "Faculty Name: mona diab\nPaperid: 27b69c63d3ca627e64da78b8e5ef0c49b2840ea6\nTitle: Comparison of the structures and topologies of plasma extracted circulating nuclear and mitochondrial cell-free DNA\nYear: 2023\nAbstract: Introduction: The function, origin and structural features of circulating nuclear DNA (cir-nDNA) and mitochondrial DNA (cir-mtDNA) are poorly known, even though they have been investigated in numerous clinical studies, and are involved in a number of routine clinical applications. Based on our previous report disproving the conventional plasma isolation used for cirDNA analysis, this work enables a direct topological comparison of the circulating structures associated with nuclear DNA and mitochondrial cell-free DNA. Materials and methods: We used a Q-PCR and low-pass whole genome sequencing (LP-WGS) combination approach of cir-nDNA and cir-mtDNA, extracted using a procedure that eliminates platelet activation during the plasma isolation process to prevent mitochondria release in the extracellular milieu. Various physical procedures, such as filtration and differential centrifugation, were employed to infer their circulating structures.",
  "Various physical procedures, such as filtration and differential centrifugation, were employed to infer their circulating structures. Results: DSP-S cir-mtDNA mean size profiles distributed on a slightly shorter range than SSP-S. SSP-S detected 40-fold more low-sized cir-mtDNA fragments (<90 bp/nt) and three-fold less long-sized fragments (>200 bp/nt) than DSP-S. The ratio of the fragment number below 90 bp over the fragment number above 200 bp was very homogenous among both DSP-S and SSP-S profiles, being 134-fold lower with DSP-S than with SSP-S. Cir-mtDNA and cir-nDNA DSP-S and SSP-S mean size profiles of healthy individuals ranged in different intervals with periodic sub-peaks only detectable with cir-nDNA. The very low amount of cir-mtDNA fragments of short size observed suggested that most of the cir-mtDNA is poorly fragmented and appearing longer than \u223c1,000 bp, the readout limit of this LP-WGS method.",
  "The very low amount of cir-mtDNA fragments of short size observed suggested that most of the cir-mtDNA is poorly fragmented and appearing longer than \u223c1,000 bp, the readout limit of this LP-WGS method. Data suggested that cir-nDNA is, among DNA extracted in plasma, associated with \u223c8.6% of large structures (apoptotic bodies, large extracellular vesicles (EVs), cell debris\u2026), \u223c27.7% in chromatin and small EVs and \u223c63.7% mainly in oligo- and mono-nucleosomes. By contrast, cir-mtDNA appeared to be preponderantly (75.7%) associated with extracellular mitochondria, either in its free form or with large EVs; to a lesser extent, it was also associated with other structures: small EVs (\u223c18.4%), and exosomes or protein complexes (\u223c5.9%). Conclusion: This is the first study to directly compare the structural features of cir-nDNA and cir-mtDNA.",
  "Conclusion: This is the first study to directly compare the structural features of cir-nDNA and cir-mtDNA. The significant differences revealed between both are due to the DNA topological structure contained in the nucleus (chromatin) and in the mitochondria (plasmid) that determine their biological stability in blood. Although cir-nDNA and cir-mtDNA are principally associated with mono-nucleosomes and cell-free mitochondria, our study highlights the diversity of the circulating structures associated with cell-free DNA. They consequently have different pharmacokinetics as well as physiological functions. Thus, any accurate evaluation of their biological or diagnostic individual properties must relies on appropriate pre-analytics, and optimally on the isolation or enrichment of one category of their cirDNA associated structures.",
  "They consequently have different pharmacokinetics as well as physiological functions. Thus, any accurate evaluation of their biological or diagnostic individual properties must relies on appropriate pre-analytics, and optimally on the isolation or enrichment of one category of their cirDNA associated structures.\nAuthors: E. Pisareva, Benoit Roch, Cynthia Sanchez, B. Pastor, Alexia Mirandola, M. Diab\u2010Assaf, T. Mazard, C. Pr\u00e9vostel, Zahra Al Amir Dache, Alain R. Thierry\nVenue: Frontiers in Genetics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This is the first study to directly compare the structural features of cir-nDNA and cir-mtDNA, and highlights the diversity of the circulating structures associated with cell-free DNA.'}\nUrl: https://www.frontiersin.org/articles/10.3389/fgene.2023.1104732/pdf",
  "Faculty Name: mona diab\nPaperid: 3503a4c6163197136bbd880c9db514e8c01b6936\nTitle: Cytomegalovirus at the crossroads of immunosenescence and oncogenesis\nYear: 2023\nAbstract: Human cytomegalovirus (HCMV), whose genome is around 235 kb, is a ubiquitous human herpesvirus that infects between 40% and 95% of the population. Though HCMV infection is commonly asymptomatic and leads to subtle clinical symptoms, it can promote robust immune responses and establish lifelong latency. In addition, in immunocompromised hosts, including individuals with acquired immunodeficiency syndrome (AIDS), transplant recipients, and developing fetuses it can lead to severe diseases. Immunosenescence, well-defined as the alterations in the immune system, is linked mainly to aging and has been recently gathering considerable attention.",
  "Immunosenescence, well-defined as the alterations in the immune system, is linked mainly to aging and has been recently gathering considerable attention. Senescence was characterized by an elevated inflammation and hence considered a powerful contributor to \u201cinflammaging\u201d that is measured mainly by tumor necrosis factor-\u03b1 (TNF-\u03b1), interleukin-6 (IL-6), and C-reactive protein (CRP) levels as well as latent viral infections, for instance, cytomegalovirus (CMV). Inflammaging resulted in a senescence-associated secretory phenotype (SASP). HCMV is markedly associated with accelerated aging of the immune system as well as several age-associated diseases that accumulate and subsequently deteriorate the immune responses, thus have been linked to mortality, declined vaccine efficacy, serious diseases, and tumors in the elderly. HCMV triggers or exacerbates immunosenescence; on the other hand, the weakened immune responses and inflammaging favor viral reactivation and highlight the role of HCMV in aging as well as viral-associated tumors. HCMV reactivation resulting in sequential lytic and latent viral cycles could contribute to HCMV genomic variability.",
  "HCMV reactivation resulting in sequential lytic and latent viral cycles could contribute to HCMV genomic variability. Besides the oncomodulatory role and transforming capacities of HCMV, the immune-privileged tumor microenvironment has been considered the main element in tumor progression and aggressiveness. Therefore, the interplay between HCMV, immunosenescence, and cancer will aid in discovering new therapeutic approaches that target HCMV and act as immune response boosters mainly to fight cancers of poor prognosis, particularly in the elderly population.\nAuthors: Fidaa Bouezzedine, Ranim El Baba, S. Morot-Bizot, M. Diab\u2010Assaf, G. Herbein\nVenue: Exploration of Immunology\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The interplay between HCMV, immunosenescence, and cancer will aid in discovering new therapeutic approaches that target H CMV and act as immune response boosters mainly to fight cancers of poor prognosis, particularly in the elderly population.'}\nUrl: https://www.explorationpub.com/uploads/Article/A100386/100386.pdf",
  "Faculty Name: mona diab\nPaperid: 4286d07449447f3bfffc1eeb2ee0de9b00dfadfd\nTitle: ALERT: Adapt Language Models to Reasoning Tasks\nYear: 2023\nAbstract: None\nAuthors: Ping Yu, Tianlu Wang, O. Yu. Golovneva, Badr AlKhamissi, Siddharth Verma, Zhijing Jin, Gargi Ghosh, Mona T. Diab, Asli Celikyilmaz\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The extensive empirical analysis shows that language models learn more reasoning skills such as textual entailment, abductive reasoning, and analogical reasoning during the finetuning stage compared to pretraining stage, but also finds that when language models are finetuned they tend to overfit to the prompt template, which hurts the robustness of models causing generalization problems.'}\nUrl: https://aclanthology.org/2023.acl-long.60.pdf",
  "Faculty Name: mona diab\nPaperid: 45f7ab2dd1bd86703f3fc0f713d35851ae15b038\nTitle: Author Correction: Arabic natural language processing for Qur\u2019anic research: a systematic review\nYear: 2023\nAbstract: None\nAuthors: M. Bashir, Aqil M. Azmi, H. Nawaz, W. Zaghouani, Mona T. Diab, Ala I. Al-Fuqaha, Junaid Qadir\nVenue: Artificial Intelligence Review\nTldr: None\nUrl: https://link.springer.com/content/pdf/10.1007/s10462-023-10390-x.pdf",
  "Faculty Name: mona diab\nPaperid: 4674d83e0c54a9a7b6833121cc2f40cd21f2579c\nTitle: PAMR1 negatively impacts cell proliferation and migration of Human Colon Cancer HT29 Cell Line\nYear: 2023\nAbstract: Colorectal cancer (CRC) is becoming one of the most prevalent cancers worldwide. Among cancers, it ranks the third place in terms of incidence and the second in terms of mortality. Even though immunological test allows fast and easy diagnostic method, there is no specific and reliable methods for early detection of CRC. Despite different treatments, high risk of re-occurrence is associated with advanced and metastatic CRC stages. An exhaustive knowledge on specific biomarkers or molecular actors involved in CRC could help to eradicate tumors or limit cancer recurrence. In this study, we focused on PAMR1 (Peptidase Domain Containing Associated with Muscle Regeneration 1), which is already considered as a tumor suppressor in breast and cervical cancers.",
  "In this study, we focused on PAMR1 (Peptidase Domain Containing Associated with Muscle Regeneration 1), which is already considered as a tumor suppressor in breast and cervical cancers. In silico analysis of RNASeq data showed that PAMR1 was significantly downregulated in CRC tissues compared to their adjacent normal ones, as well as in cervical cancer. Our analysis showed that this downregulation, probably due to promoter hypermethylation, such as in breast cancer tissues, appeared in the four cancer stages as early as the first stage. In consistency with in silico analyses, the expression of PAMR1 was found to be lower at the transcript and protein levels in CRC tissue samples compared to normal ones, as well as in different CRC cell lines (HCT116, HT29, and SW620) compared to normal colon cell line (CCD841CoN).",
  "To understand the role of PAMR1 in CRC cancer, recombinant purified PAMR1 or concentrated secretome from CHO overexpressing PAMR1 were used to exogenously treat CRC cell lines with a focus on HT-29 cells as well as Hela cervical cancer cell line known to be sensitive to PAMR1. Transient or stable transfections were also performed to determine the impact of PAMR1 overexpression in HT29 and/or HeLa cells. In this study, we finally showed that presence of PAMR1 could reduce both cell proliferation and cell migration with a positive correlation between these biological effects and PAMR1\u2019s quantity. This implies that PAMR1 expresses anti-proliferative and anti-migrative effects in CRC. Further studies to be done in order to confirm the tumor suppressive role of PAMR1 in CRC.",
  "This implies that PAMR1 expresses anti-proliferative and anti-migrative effects in CRC. Further studies to be done in order to confirm the tumor suppressive role of PAMR1 in CRC.\nAuthors: Layla Haymour, A. Chaunavel, Mona Diab Assaf, A. Maftah, S\u00e9bastien Legardinier\nVenue: bioRxiv\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is shown that presence of PAMR1 could reduce both cell proliferation and cell migration with a positive correlation between these biological effects and PAMr1\u2019s quantity, which implies that PamR1 expresses anti-proliferative and anti-migrative effects in CRC.'}\nUrl: https://www.biorxiv.org/content/biorxiv/early/2022/09/08/2022.09.07.506931.full.pdf",
  "Faculty Name: mona diab\nPaperid: 4bb86a709eb9f47242f8b7f93e9a9c24bdb74870\nTitle: Aspalathus linearis (Rooibos) Targets Adipocytes and Obesity-Associated Inflammation\nYear: 2023\nAbstract: Excess weight and obesity are the fifth leading cause of death globally, and sustained efforts from health professionals and researchers are required to mitigate this pandemic-scale problem. Polyphenols and flavonoids found in Aspalathus linearis\u2014a plant widely consumed as Rooibos tea\u2014are increasingly being investigated for their positive effects on various health issues including inflammation. The aim of our study was to examine the effect of Rooibos extract on obesity and the associated low-grade chronic inflammatory state by testing antioxidant activity, cytokine secretions, macrophage polarization and the differentiation of human adipocytes through the development of adipospheroids. Rooibos extract significantly decreased ROS production and the secretion of pro-inflammatory cytokines (IFN-\u03b3, IL-12, IL-2 and IL-17a) in human leukocytes.",
  "Rooibos extract significantly decreased ROS production and the secretion of pro-inflammatory cytokines (IFN-\u03b3, IL-12, IL-2 and IL-17a) in human leukocytes. Additionally, Rooibos extract down-regulated LPS-induced macrophage M1 polarization, shown by a significant decrease in the expression of pro-inflammatory cytokines: TNF\u03b1, IL-8, IL-6, IL-1\u03b2 and CXCL10. In addition, Rooibos inhibited intracellular lipid accumulation and reduced adipogenesis by decreasing the expression of PPAR\u03b3, Ap2 and HSL in adipospheroids. A significant decrease in leptin expression was noted and this, more interestingly, was accompanied by a significant increase in adiponectin expression. Using a co-culture system between macrophages and adipocytes, Rooibos extract significantly decreased the expression of all studied pro-inflammatory cytokines and particularly leptin, and increased adiponectin expression. Thus, adding Rooibos tea to the daily diet is likely to prevent the development of obesity associated with chronic low-level inflammation.",
  "Thus, adding Rooibos tea to the daily diet is likely to prevent the development of obesity associated with chronic low-level inflammation.\nAuthors: Rawan Nehme, A. Chervet, C. Decombat, L. Longechamp, A. Rossary, Rebecca Boutin, A. Rousset, F. S\u00e9n\u00e9joux, Caroline Vachias, C. Auxenfans, D. Fraisse, Jean-Baptiste Guyon, E. Filaire, J. Berthon, M. Diab\u2010Assaf, L. Delort, F. Caldefie-Ch\u00e9zet\nVenue: Nutrients\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Rooibos extract significantly decreased the expression of all studied pro-inflammatory cytokines and particularly leptin, and increased adiponectin expression, likely to prevent the development of obesity associated with chronic low-level inflammation.'}\nUrl: https://www.mdpi.com/2072-6643/15/7/1751/pdf?version=1680572571",
  "Faculty Name: mona diab\nPaperid: 5e2f8088647e357bb6440d271ed1fcc4d5ed7e7c\nTitle: Care4Lang at MEDIQA-Chat 2023: Fine-tuning Language Models for Classifying and Summarizing Clinical Dialogues\nYear: 2023\nAbstract: Summarizing medical conversations is one of the tasks proposed by MEDIQA-Chat to promote research on automatic clinical note generation from doctor-patient conversations. In this paper, we present our submission to this task using fine-tuned language models, including T5, BART and BioGPT models. The fine-tuned models are evaluated using ensemble metrics including ROUGE, BERTScore andBLEURT. Among the fine-tuned models, Flan-T5 achieved the highest aggregated score for dialogue summarization.",
  "The fine-tuned models are evaluated using ensemble metrics including ROUGE, BERTScore andBLEURT. Among the fine-tuned models, Flan-T5 achieved the highest aggregated score for dialogue summarization.\nAuthors: Amal AlQahtani, R. Salama, Mona T. Diab, Abdou Youssef\nVenue: Clinical Natural Language Processing Workshop\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper presents their submission to this task using fine-tuned language models, including T5, BART and BioGPT models, and finds Flan-T5 achieved the highest aggregated score for dialogue summarization.'}\nUrl: https://aclanthology.org/2023.clinicalnlp-1.55.pdf",
  "Faculty Name: mona diab\nPaperid: 81513416b80f753166e224b34b599e9385980a97\nTitle: Emerging Therapeutic Approaches to Target the Dark Side of Senescent Cells: New Hopes to Treat Aging as a Disease and to Delay Age-Related Pathologies\nYear: 2023\nAbstract: Life expectancy has drastically increased over the last few decades worldwide, with important social and medical burdens and costs. To stay healthy longer and to avoid chronic disease have become essential issues. Organismal aging is a complex process that involves progressive destruction of tissue functionality and loss of regenerative capacity. One of the most important aging hallmarks is cellular senescence, which is a stable state of cell cycle arrest that occurs in response to cumulated cell stresses and damages. Cellular senescence is a physiological mechanism that has both beneficial and detrimental consequences. Senescence limits tumorigenesis, lifelong tissue damage, and is involved in different biological processes, such as morphogenesis, regeneration, and wound healing.",
  "Cellular senescence is a physiological mechanism that has both beneficial and detrimental consequences. Senescence limits tumorigenesis, lifelong tissue damage, and is involved in different biological processes, such as morphogenesis, regeneration, and wound healing. However, in the elderly, senescent cells increasingly accumulate in several organs and secrete a combination of senescence associated factors, contributing to the development of various age-related diseases, including cancer. Several studies have revealed major molecular pathways controlling the senescent phenotype, as well as the ones regulating its interactions with the immune system. Attenuating the senescence-associated secretory phenotype (SASP) or eliminating senescent cells have emerged as attractive strategies aiming to reverse or delay the onset of aging diseases. Here, we review current senotherapies designed to suppress the deleterious effect of SASP by senomorphics or to selectively kill senescent cells by \u201csenolytics\u201d or by immune system-based approaches. These recent investigations are promising as radical new controls of aging pathologies and associated multimorbidities.",
  "These recent investigations are promising as radical new controls of aging pathologies and associated multimorbidities.\nAuthors: Roula Khalil, M. Diab\u2010Assaf, J. Lema\u00eetre\nVenue: Cells\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Current senotherapies designed to suppress the deleterious effect of SASP by senomorphics or to selectively kill senescent cells by \u201csenolytics\u201d or by immune system-based approaches are reviewed.'}\nUrl: https://www.mdpi.com/2073-4409/12/6/915/pdf?version=1678958147",
  "Faculty Name: mona diab\nPaperid: 99bfe503743c5ec8e16e50ab8438159cdb533a89\nTitle: The Troubling Emergence of Hallucination in Large Language Models - An Extensive Definition, Quantification, and Prescriptive Remediations\nYear: 2023\nAbstract: The recent advancements in Large Language Models (LLMs) have garnered widespread acclaim for their remarkable emerging capabilities. However, the issue of hallucination has parallelly emerged as a by-product, posing significant concerns. While some recent endeavors have been made to identify and mitigate different types of hallucination, there has been a limited emphasis on the nuanced categorization of hallucination and associated mitigation methods. To address this gap, we offer a fine-grained discourse on profiling hallucination based on its degree, orientation, and category, along with offering strategies for alleviation. As such, we define two overarching orientations of hallucination: (i) factual mirage (FM) and (ii) silver lining (SL).",
  "As such, we define two overarching orientations of hallucination: (i) factual mirage (FM) and (ii) silver lining (SL). To provide a more comprehensive understanding, both orientations are further sub-categorized into intrinsic and extrinsic, with three degrees of severity - (i) mild, (ii) moderate, and (iii) alarming. We also meticulously categorize hallucination into six types: (i) acronym ambiguity, (ii) numeric nuisance, (iii) generated golem, (iv) virtual voice, (v) geographic erratum, and (vi) time wrap. Furthermore, we curate HallucInation eLiciTation (HILT), a publicly available dataset comprising of 75,000 samples generated using 15 contemporary LLMs along with human annotations for the aforementioned categories. Finally, to establish a method for quantifying and to offer a comparative spectrum that allows us to evaluate and rank LLMs based on their vulnerability to producing hallucinations, we propose Hallucination Vulnerability Index (HVI). We firmly believe that HVI holds significant value as a tool for the wider NLP community, with the potential to serve as a rubric in AI-related policy-making.",
  "We firmly believe that HVI holds significant value as a tool for the wider NLP community, with the potential to serve as a rubric in AI-related policy-making. In conclusion, we propose two solution strategies for mitigating hallucinations.\nAuthors: Vipula Rawte, Swagata Chakraborty, Agnibh Pathak, Anubhav Sarkar, S.M. Towhidul Islam Tonmoy, Islam Tonmoy, Aman Chadha, Amit P. Sheth, Amitava Das, Paris, A. Sridhar, Erik Visser, Improved, Jianlin Su, Yu Lu, Shengfeng Pan, Ahmed Murtadha, Bo Wen, Yunfeng Liu, Roformer, Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, Tatsunori Hashimoto, Stanford, Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth\u00e9e Lacroix, Baptiste Rozi\u00e8re, Naman Goyal, Eric Hambro,",
  "Percy Liang, Tatsunori Hashimoto, Stanford, Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth\u00e9e Lacroix, Baptiste Rozi\u00e8re, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, R\u00e9mi Louf, Morgan Funtow-icz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, Susan Zhang, Stephen Roller, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher De-wan, Mona T. Diab, Xi Xian Li, Todor Victoria Lin, Myle Ott, Kurt Shuster, Punit Daniel Simig, Singh Koura, Anjali Sridhar, Tianlu Wang,",
  "Moya Chen, Shuohui Chen, Christopher De-wan, Mona T. Diab, Xi Xian Li, Todor Victoria Lin, Myle Ott, Kurt Shuster, Punit Daniel Simig, Singh Koura, Anjali Sridhar, Tianlu Wang, Luke Zettlemoyer. 2022, Daniel M. Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B. Brown, Alec Radford, Dario Amodei, Paul F. Chris-tiano\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work defines two overarching orientations of hallucination and proposes two solution strategies for mitigating hallucinations, and firmly believes that HVI holds significant value as a tool for the wider NLP community, with the potential to serve as a rubric in AI-related policy-making.'}\nUrl: https://arxiv.org/pdf/2310.04988",
  "Faculty Name: mona diab\nPaperid: bcfbcbbe128ee74e39cb8698e5dfd6047b690487\nTitle: Crosstalk of Inflammatory Cytokines within the Breast Tumor Microenvironment\nYear: 2023\nAbstract: Several immune and immunocompetent cells, including dendritic cells, macrophages, adipocytes, natural killer cells, T cells, and B cells, are significantly correlated with the complex discipline of oncology. Cytotoxic innate and adaptive immune cells can block tumor proliferation, and others can prevent the immune system from rejecting malignant cells and provide a favorable environment for tumor progression. These cells communicate with the microenvironment through cytokines, a chemical messenger, in an endocrine, paracrine, or autocrine manner. These cytokines play an important role in health and disease, particularly in host immune responses to infection and inflammation.",
  "These cells communicate with the microenvironment through cytokines, a chemical messenger, in an endocrine, paracrine, or autocrine manner. These cytokines play an important role in health and disease, particularly in host immune responses to infection and inflammation. They include chemokines, interleukins (ILs), adipokines, interferons, colony-stimulating factors (CSFs), and tumor necrosis factor (TNF), which are produced by a wide range of cells, including immune cells, such as macrophages, B-cells, T-cells, and mast cells, as well as endothelial cells, fibroblasts, a variety of stromal cells, and some cancer cells. Cytokines play a crucial role in cancer and cancer-related inflammation, with direct and indirect effects on tumor antagonistic or tumor promoting functions. They have been extensively researched as immunostimulatory mediators to promote the generation, migration and recruitment of immune cells that contribute to an effective antitumor immune response or pro-tumor microenvironment.",
  "They have been extensively researched as immunostimulatory mediators to promote the generation, migration and recruitment of immune cells that contribute to an effective antitumor immune response or pro-tumor microenvironment. Thus, in many cancers such as breast cancer, cytokines including leptin, IL-1B, IL-6, IL-8, IL-23, IL-17, and IL-10 stimulate while others including IL-2, IL-12, and IFN-\u03b3, inhibit cancer proliferation and/or invasion and enhance the body\u2019s anti-tumor defense. Indeed, the multifactorial functions of cytokines in tumorigenesis will advance our understanding of cytokine crosstalk pathways in the tumor microenvironment, such as JAK/STAT, PI3K, AKT, Rac, MAPK, NF-\u03baB, JunB, cFos, and mTOR, which are involved in angiogenesis, cancer proliferation and metastasis. Accordingly, targeting and blocking tumor-promoting cytokines or activating and amplifying tumor-inhibiting cytokines are considered cancer-directed therapies.",
  "Accordingly, targeting and blocking tumor-promoting cytokines or activating and amplifying tumor-inhibiting cytokines are considered cancer-directed therapies. Here, we focus on the role of the inflammatory cytokine system in pro- and anti-tumor immune responses, discuss cytokine pathways involved in immune responses to cancer and some anti-cancer therapeutic applications.\nAuthors: Ola Habanjar, R. Bingula, C. Decombat, M. Diab\u2010Assaf, F. Caldefie-Ch\u00e9zet, L. Delort\nVenue: International Journal of Molecular Sciences\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The role of the inflammatory cytokine system in pro- and anti-tumor immune responses is focused on, and cytokine pathways involved in immune responses to cancer and some anti-cancer therapeutic applications are discussed.'}\nUrl: https://www.mdpi.com/1422-0067/24/4/4002/pdf?version=1676767442",
  "Faculty Name: mona diab\nPaperid: c218cd1772999517b137bbbc9872c4f67e540b7f\nTitle: OPT-R: Exploring the Role of Explanations in Finetuning and Prompting for Reasoning Skills of Large Language Models\nYear: 2023\nAbstract: We conduct a thorough investigation into the reasoning capabilities of Large Language Models (LLMs), focusing specifically on the Open Pretrained Transformers (OPT) models as a representative of such models. Our study entails finetuning three different sizes of OPT on a carefully curated reasoning corpus, resulting in two sets of finetuned models: OPT-R, finetuned without explanations, and OPT-RE, finetuned with explanations. We then evaluate all models on 57 out-of-domain tasks drawn from the Super-NaturalInstructions benchmark, covering 26 distinct reasoning skills, utilizing three prompting techniques. Through a comprehensive grid of 27 configurations and 6,156 test evaluations, we investigate the dimensions of finetuning, prompting, and scale to understand the role of explanations on different reasoning skills.",
  "Through a comprehensive grid of 27 configurations and 6,156 test evaluations, we investigate the dimensions of finetuning, prompting, and scale to understand the role of explanations on different reasoning skills. Our findings reveal that having explanations in the fewshot exemplar has no significant impact on the model\u2019s performance when the model is finetuned, while positively affecting the non-finetuned counterpart. Moreover, we observe a slight yet consistent increase in classification accuracy as we incorporate explanations during prompting and finetuning, respectively. Finally, we offer insights on which reasoning skills benefit the most from incorporating explanations during finetuning and prompting, such as Numerical (+20.4%) and Analogical (+13.9%) reasoning, as well as skills that exhibit negligible or negative effects.",
  "Finally, we offer insights on which reasoning skills benefit the most from incorporating explanations during finetuning and prompting, such as Numerical (+20.4%) and Analogical (+13.9%) reasoning, as well as skills that exhibit negligible or negative effects.\nAuthors: Badr AlKhamissi, Siddharth Verma, Ping Yu, Zhijing Jin, Asli Celikyilmaz, Mona T. Diab\nVenue: NLRSE\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is revealed that having explanations in the fewshot exemplar has no significant impact on the model\u2019s performance when the model is finetuned, while positively affecting the non-finetuned counterpart, and a slight yet consistent increase in classification accuracy as the authors incorporate explanations during prompting and finetuning.'}\nUrl: https://aclanthology.org/2023.nlrse-1.10.pdf",
  "Faculty Name: mona diab\nPaperid: c5849f406e8263806a84e1a407ec0e0fe131bd5c\nTitle: Evaluating Multilingual Speech Translation under Realistic Conditions with Resegmentation and Terminology\nYear: 2023\nAbstract: We present the ACL 60/60 evaluation sets for multilingual translation of ACL 2022 technical presentations into 10 target languages. This dataset enables further research into multilingual speech translation under realistic recording conditions with unsegmented audio and domain-specific terminology, applying NLP tools to text and speech in the technical domain, and evaluating and improving model robustness to diverse speaker demographics.\nAuthors: Elizabeth Salesky, Kareem Darwish, Mohamed Al-Badrashiny, Mona T. Diab, J. Niehues\nVenue: International Workshop on Spoken Language Translation\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This dataset enables further research into multilingual speech translation under realistic recording conditions with unsegmented audio and domain-specific terminology, applying NLP tools to text and speech in the technical domain, and evaluating and improving model robustness to diverse speaker demographics.'}",
  "Url: https://aclanthology.org/2023.iwslt-1.2.pdf",
  "Faculty Name: mona diab\nPaperid: e818b74b7415fb43deeb80c1a33ffd5be76abed4\nTitle: A Combination of Ruthenium Complexes and Photosensitizers to Treat Colorectal Cancer\nYear: 2023\nAbstract: Treatment regimens are regularly evolving alongside novel therapies and drugs. Such evolution is necessary to circumvent resistance mechanisms and to give patients the best possible health care. When dealing with cancer, most regimens involve multiple treatments (surgery, radiation therapy, chemotherapy, immunotherapy, etc.). The purpose of this study was to associate in a single compound metal-based drugs and photosensitizers to combine chemotherapy and photodynamic therapy. Two arene\u2013ruthenium tetrapyridylporphyrin compounds (2H-TPyP-arene-Ru and Zn-TPyP-arene-Ru) have been synthesized and evaluated on two colorectal cancer cell lines (HCT116 and HT-29). Their cytotoxicity and phototoxicity have been evaluated. In addition, the anticancer mechanism and the cell death process mediated by the two compounds were studied.",
  "Their cytotoxicity and phototoxicity have been evaluated. In addition, the anticancer mechanism and the cell death process mediated by the two compounds were studied. The results showed that the two arene\u2013ruthenium photosensitizer-containing complexes have a strong phototoxic effect after photoactivation. The 2H-TPyP-arene-Ru complex induced outstanding cytotoxicity when compared to the Zn-TPyP-arene-Ru analogue. Moreover, under light, these two arene\u2013ruthenium photosensitizers induce an apoptotic process in human colorectal cancer cell lines.\nAuthors: Jacquie Massoud, A. Pinon, M. Gallardo-Villagr\u00e1n, L. Paulus, Catherine Ouk, Claire Carrion, Sayed Antoun, Mona Diab-Assaf, Bruno Therrien, B. Liagre\nVenue: Inorganics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Results showed that the two arene\u2013ruthenium photosensitizer-containing complexes have a strong phototoxic effect after photoactivation, and induce an apoptotic process in human colorectal cancer cell lines.'}",
  "Url: https://www.preprints.org/manuscript/202309.1909/v1/download",
  "Faculty Name: mona diab\nPaperid: f727f928e7e179307d8d4a1da2387393f2bd7915\nTitle: Methods for Measuring, Updating, and Visualizing Factual Beliefs in Language Models\nYear: 2023\nAbstract: Language models can memorize a considerable amount of factual information during pretraining that can be elicited through prompting or finetuning models on tasks like question answering. In this paper, we discuss approaches to measuring model factual beliefs, updating incorrect factual beliefs in models, and visualizing graphical relationships between factual beliefs. Our main contributions include: (1) new metrics for evaluating belief-updating methods focusing on the logical consistency of beliefs, (2) a training objective for Sequential, Local, and Generalizing updates (SLAG) that improves the performance of existing hypernetwork approaches, and (3) the introduction of the belief graph, a new form of visualization for language models that shows relationships between stored model beliefs. Our experiments suggest that models show only limited consistency between factual beliefs, but update methods can both fix incorrect model beliefs and greatly improve their consistency.",
  "Our experiments suggest that models show only limited consistency between factual beliefs, but update methods can both fix incorrect model beliefs and greatly improve their consistency. Although off-the-shelf optimizers are surprisingly strong belief-updating baselines, our learned optimizers can outperform them in more difficult settings than have been considered in past work.\nAuthors: Peter Hase, Mona T. Diab, Asli Celikyilmaz, Xian Li, Zornitsa Kozareva, Veselin Stoyanov, Mohit Bansal, Srini Iyer\nVenue: Conference of the European Chapter of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The experiments suggest that models show only limited consistency between factual beliefs, but update methods can both fix incorrect model beliefs and greatly improve their consistency, and off-the-shelf optimizers can outperform them in more difficult settings than have been considered in past work.'}\nUrl: https://aclanthology.org/2023.eacl-main.199.pdf",
  "List of 2023 Open Access papers by mona diab are:\nCan Large Language Models Infer Causation from Correlation?\nALERT: Adapt Language Models to Reasoning Tasks\nCare4Lang at MEDIQA-Chat 2023: Fine-tuning Language Models for Classifying and Summarizing Clinical Dialogues\nThe Troubling Emergence of Hallucination in Large Language Models - An Extensive Definition, Quantification, and Prescriptive Remediations\nOPT-R: Exploring the Role of Explanations in Finetuning and Prompting for Reasoning Skills of Large Language Models\nMethods for Measuring, Updating,",
  "Quantification, and Prescriptive Remediations\nOPT-R: Exploring the Role of Explanations in Finetuning and Prompting for Reasoning Skills of Large Language Models\nMethods for Measuring, Updating, and Visualizing Factual Beliefs in Language Models\nComparison of the structures and topologies of plasma extracted circulating nuclear and mitochondrial cell-free DNA\nCytomegalovirus at the crossroads of immunosenescence and oncogenesis\nAspalathus linearis (Rooibos) Targets Adipocytes and Obesity-Associated Inflammation\nEmerging Therapeutic Approaches to Target the Dark Side of Senescent Cells: New Hopes to Treat Aging as a Disease and to Delay Age-Related Pathologies\nCrosstalk of Inflammatory Cytokines within the Breast Tumor Microenvironment\nAuthor Correction: Arabic natural language processing for Qur\u2019anic research: a systematic review\nEvaluating Multilingual Speech Translation under Realistic Conditions with Resegmentation and Terminology\nA bleeding bite: crotalinae snake envonamation\nPAMR1 negatively impacts cell proliferation and migration of Human Colon Cancer HT29 Cell Line\nA Combination of Ruthenium Complexes and Photosensitizers to Treat Colorectal Cancer",
  "Mona Diab\nLTI Director and Tenured Professor, Language Technologies Institute\nResearch Area : Fairness and Ethics in Language Technology\nContact: 5723 Gates & Hillman Centers\nEmail : mdiab@andrew.cmu.edu\nPhone : 412-268-3669\nAddress\n5000 Forbes Avenue\nPittsburgh, PA 15213",
  "List of 2023 Open Access papers by ralf brown are: 0",
  "Faculty Bio : Ralf Brown\nSenior Systems Scientist/Chair of Admissions, Language Technologies Institute\nResearch Area : Information Extraction, Summarization and Question Answering, Information Retrieval, Text Mining and Analytics, Machine Translation, Natural Language Processing and Computational Linguistics\n\nResearch:\nMy research interests primarily revolve around multilingual processing, with sidelines in text categorization and information extraction:\nMachine Translation\nI have worked primarily on example-based machine translation (EBMT), a data-driven translation approach that originated a few years before statistical machine translation characterized by the use of individual examples from the training corpus during translation. I have also applied my EBMT system to cross-language information retrieval and speech-to-speech translation.\n\nDigital Forensics\nI have worked on reconstructing corrupted ZIP archives and on extracting text in arbitrary encodings from files and raw disk images. As part of this work, I developed language identification for more than 1,300 languages, and am continuing to improve the accuracy with which languages can be identified.\n\nInformation Extraction\nMy current work focuses on extracting actions and affected components from aircraft maintenance records.",
  "As part of this work, I developed language identification for more than 1,300 languages, and am continuing to improve the accuracy with which languages can be identified.\n\nInformation Extraction\nMy current work focuses on extracting actions and affected components from aircraft maintenance records.\n\nPersonal Website: https://www.cs.cmu.edu/~ralf/\nContact: 5711 Gates & Hillman Centers\nEmail: ralf@andrew.cmu.edu\nPhone: 412-268-8298",
  "Faculty Name: rita singh\nPaperid: 1de2dcb5de694920f50f000a3795eb0ca54d57ab\nTitle: LoFT: Local Proxy Fine-tuning For Improving Transferability Of Adversarial Attacks Against Large Language Model\nYear: 2023\nAbstract: It has been shown that Large Language Model (LLM) alignments can be circumvented by appending specially crafted attack suffixes with harmful queries to elicit harmful responses. To conduct attacks against private target models whose characterization is unknown, public models can be used as proxies to fashion the attack, with successful attacks being transferred from public proxies to private target models. The success rate of attack depends on how closely the proxy model approximates the private model. We hypothesize that for attacks to be transferrable, it is sufficient if the proxy can approximate the target model in the neighborhood of the harmful query. Therefore, in this paper, we propose \\emph{Local Fine-Tuning (LoFT)}, \\textit{i.e.}, fine-tuning proxy models on similar queries that lie in the lexico-semantic neighborhood of harmful queries to decrease the divergence between the proxy and target models.",
  "Therefore, in this paper, we propose \\emph{Local Fine-Tuning (LoFT)}, \\textit{i.e.}, fine-tuning proxy models on similar queries that lie in the lexico-semantic neighborhood of harmful queries to decrease the divergence between the proxy and target models. First, we demonstrate three approaches to prompt private target models to obtain similar queries given harmful queries. Next, we obtain data for local fine-tuning by eliciting responses from target models for the generated similar queries. Then, we optimize attack suffixes to generate attack prompts and evaluate the impact of our local fine-tuning on the attack's success rate. Experiments show that local fine-tuning of proxy models improves attack transferability and increases attack success rate by $39\\%$, $7\\%$, and $0.5\\%$ (absolute) on target models ChatGPT, GPT-4, and Claude respectively.",
  "Experiments show that local fine-tuning of proxy models improves attack transferability and increases attack success rate by $39\\%$, $7\\%$, and $0.5\\%$ (absolute) on target models ChatGPT, GPT-4, and Claude respectively.\nAuthors: Muhammad Ahmed Shah, Roshan Sharma, Hira Dhamyal, R. Olivier, Ankit Shah, Dareen Alharthi, Hazim T Bukhari, Massa Baali, Soham Deshmukh, Michael Kuhlmann, Bhiksha Raj, Rita Singh\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Local fine-tuning of proxy models improves attack transferability and increases attack success rate by $39, $7, and $0.5$ (absolute) on target models ChatGPT, GPT-4, and Claude respectively.'}\nUrl: https://arxiv.org/pdf/2310.04445",
  "Faculty Name: rita singh\nPaperid: 255bad49d29202e2d255926ab0983c125dcce835\nTitle: Evaluating Speech Synthesis by Training Recognizers on Synthetic Speech\nYear: 2023\nAbstract: Modern speech synthesis systems have improved significantly, with synthetic speech being indistinguishable from real speech. However, efficient and holistic evaluation of synthetic speech still remains a significant challenge. Human evaluation using Mean Opinion Score (MOS) is ideal, but inefficient due to high costs. Therefore, researchers have developed auxiliary automatic metrics like Word Error Rate (WER) to measure intelligibility. Prior works focus on evaluating synthetic speech based on pre-trained speech recognition models, however, this can be limiting since this approach primarily measures speech intelligibility. In this paper, we propose an evaluation technique involving the training of an ASR model on synthetic speech and assessing its performance on real speech. Our main assumption is that by training the ASR model on the synthetic speech, the WER on real speech reflects the similarity between distributions, a broader assessment of synthetic speech quality beyond intelligibility.",
  "Our main assumption is that by training the ASR model on the synthetic speech, the WER on real speech reflects the similarity between distributions, a broader assessment of synthetic speech quality beyond intelligibility. Our proposed metric demonstrates a strong correlation with both MOS naturalness and MOS intelligibility when compared to SpeechLMScore and MOSNet on three recent Text-to-Speech (TTS) systems: MQTTS, StyleTTS, and YourTTS.\nAuthors: Dareen Alharthi, Roshan Sharma, Hira Dhamyal, Soumi Maiti, Bhiksha Raj, Rita Singh\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper proposes an evaluation technique involving the training of an ASR model on synthetic speech and assessing its performance on real speech, and demonstrates a strong correlation with both MOS naturalness and MOS intelligibility when compared to SpeechLMScore and MosNet on three recent Text-to-Speech systems.'}\nUrl: https://arxiv.org/pdf/2310.00706",
  "Faculty Name: rita singh\nPaperid: 2a8f592c31d8de9906183b081095b9842025f792\nTitle: Rethinking Audiovisual Segmentation with Semantic Quantization and Decomposition\nYear: 2023\nAbstract: Audiovisual segmentation (AVS) is a challenging task that aims to segment visual objects in videos based on their associated acoustic cues. With multiple sound sources involved, establishing robust correspondences between audio and visual contents poses unique challenges due to its (1) intricate entanglement across sound sources and (2) frequent shift among sound events. Assuming sound events occur independently, the multi-source semantic space (which encompasses all possible semantic categories) can be represented as the Cartesian product of single-source sub-spaces. This motivates us to decompose the multi-source audio semantics into single-source semantics, enabling more effective interaction with visual content. Specifically, we propose a semantic decomposition method based on product quantization, where the multi-source semantics can be decomposed and represented by several quantized single-source semantics.",
  "This motivates us to decompose the multi-source audio semantics into single-source semantics, enabling more effective interaction with visual content. Specifically, we propose a semantic decomposition method based on product quantization, where the multi-source semantics can be decomposed and represented by several quantized single-source semantics. Furthermore, we introduce a global-to-local quantization mechanism, which distills knowledge from stable global (clip-level) features into local (frame-level) ones, to handle the constant shift of audio semantics. Extensive experiments demonstrate that semantically quantized and decomposed audio representation significantly improves AVS performance, e.g., +21.2% mIoU on the most challenging AVS-Semantic benchmark.\nAuthors: Xiang Li, Jinglu Wang, Xiaohao Xu, Xiulian Peng, Rita Singh, Yan Lu, Bhiksha Raj\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes a semantic decomposition method based on product quantization, where the multi-source semantics can be decomposed and represented by several quantized single-source semantics, enabling more effective interaction with visual content.'}",
  "Url: https://arxiv.org/pdf/2310.00132",
  "Faculty Name: rita singh\nPaperid: 37e8e07d3ecfa43a1e64d48202c73f597e6f9fee\nTitle: Towards Noise-Tolerant Speech-Referring Video Object Segmentation: Bridging Speech and Text\nYear: 2023\nAbstract: None\nAuthors: Xiang Li, Jinglu Wang, Xiaohao Xu, Muqiao Yang, Fan Yang, Yizhou Zhao, Rita Singh, Bhiksha Raj\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: None\nUrl: https://aclanthology.org/2023.emnlp-main.140.pdf",
  "Faculty Name: rita singh\nPaperid: 3bd320ddb25886417ae90011b00f13f5d558097b\nTitle: BASS: Block-wise Adaptation for Speech Summarization\nYear: 2023\nAbstract: End-to-end speech summarization has been shown to improve performance over cascade baselines. However, such models are difficult to train on very large inputs (dozens of minutes or hours) owing to compute restrictions and are hence trained with truncated model inputs. Truncation leads to poorer models, and a solution to this problem rests in block-wise modeling, i.e., processing a portion of the input frames at a time. In this paper, we develop a method that allows one to train summarization models on very long sequences in an incremental manner. Speech summarization is realized as a streaming process, where hypothesis summaries are updated every block based on new acoustic information. We devise and test strategies to pass semantic context across the blocks. Experiments on the How2 dataset demonstrate that the proposed block-wise training method improves by 3 points absolute on ROUGE-L over a truncated input baseline.",
  "We devise and test strategies to pass semantic context across the blocks. Experiments on the How2 dataset demonstrate that the proposed block-wise training method improves by 3 points absolute on ROUGE-L over a truncated input baseline.\nAuthors: Roshan Sharma, Kenneth Zheng, Siddhant Arora, Shinji Watanabe, Rita Singh, B. Raj\nVenue: Interspeech\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper develops a method that allows one to train summarization models on very long sequences in an incremental manner and devise and test strategies to pass semantic context across the blocks.'}\nUrl: https://arxiv.org/pdf/2307.08217",
  "Faculty Name: rita singh\nPaperid: 45b7d6e09d11e496e941481056177cf0164b5278\nTitle: GPT-Sentinel: Distinguishing Human and ChatGPT Generated Content\nYear: 2023\nAbstract: This paper presents a novel approach for detecting ChatGPT-generated vs. human-written text using language models. To this end, we first collected and released a pre-processed dataset named OpenGPTText, which consists of rephrased content generated using ChatGPT. We then designed, implemented, and trained two different models for text classification, using Robustly Optimized BERT Pretraining Approach (RoBERTa) and Text-to-Text Transfer Transformer (T5), respectively. Our models achieved remarkable results, with an accuracy of over 97% on the test dataset, as evaluated through various metrics. Furthermore, we conducted an interpretability study to showcase our model's ability to extract and differentiate key features between human-written and ChatGPT-generated text. Our findings provide important insights into the effective use of language models to detect generated text.",
  "Furthermore, we conducted an interpretability study to showcase our model's ability to extract and differentiate key features between human-written and ChatGPT-generated text. Our findings provide important insights into the effective use of language models to detect generated text.\nAuthors: Yutian Chen, Hao Kang, Vivian Zhai, Liang Li, Rita Singh, B. Ramakrishnan\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper designed, implemented, and trained two different models for text classification, using Robustly Optimized BERT Pretraining Approach (RoBERTa) and Text-to-Text Transfer Transformer (T5), respectively, and achieved remarkable results, with an accuracy of over 97% on the test dataset.'}\nUrl: http://arxiv.org/pdf/2305.07969",
  "Faculty Name: rita singh\nPaperid: 47b70ad4c09a3195d24f926279afd5f35badbe86\nTitle: Comparison of freeze-thaw and sonication cycle-based methods for extracting AMR-associated metabolites from Staphylococcus aureus\nYear: 2023\nAbstract: Emerging antimicrobial resistance (AMR) among Gram-positive pathogens, specifically in Staphylococcus aureus (S. aureus), is becoming a leading public health concern demanding effective therapeutics. Metabolite modulation can improve the efficacy of existing antibiotics and facilitate the development of effective therapeutics. However, it remained unexplored for drug-resistant S. aureus (gentamicin and methicillin-resistant), primarily due to the dearth of optimal metabolite extraction protocols including a protocol for AMR-associated metabolites. Therefore, in this investigation, we have compared the performance of the two most widely used methods, i.e., freeze-thaw cycle (FTC) and sonication cycle (SC), alone and in combination (FTC\u2009+\u2009SC), and identified the optimal method for this purpose.",
  "Therefore, in this investigation, we have compared the performance of the two most widely used methods, i.e., freeze-thaw cycle (FTC) and sonication cycle (SC), alone and in combination (FTC\u2009+\u2009SC), and identified the optimal method for this purpose. A total of 116, 119, and 99 metabolites were identified using the FTC, SC, and FTC\u2009+\u2009SC methods, respectively, leading to the identification of 163 metabolites cumulatively. Out of 163, 69 metabolites were found to be associated with AMR in published literature consisting of the highest number of metabolites identified by FTC (57) followed by SC (54) and FTC\u2009+\u2009SC (40). Thus, the performances of FTC and SC methods were comparable with no additional benefits of combining both. Moreover, each method showed biasness toward specific metabolite(s) or class of metabolites, suggesting that the choice of metabolite extraction method shall be decided based on the metabolites of interest in the investigation.",
  "Thus, the performances of FTC and SC methods were comparable with no additional benefits of combining both. Moreover, each method showed biasness toward specific metabolite(s) or class of metabolites, suggesting that the choice of metabolite extraction method shall be decided based on the metabolites of interest in the investigation.\nAuthors: Rita Singh, Lovnish Thakur, Anil Kumar, Sevaram Singh, S Kumar, M. Kumar, Yashwant Kumar, Niraj Kumar\nVenue: Frontiers in Microbiology\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The performances of FTC and SC methods were comparable with no additional benefits of combining both, and each method showed biasness toward specific metabolite(s) or class of metabolites, suggesting that the choice of metabolite extraction method shall be decided based on the metabolites of interest in the investigation.'}\nUrl: https://www.frontiersin.org/articles/10.3389/fmicb.2023.1152162/pdf",
  "Faculty Name: rita singh\nPaperid: 49e173279a64a1e6b849cbfcd002cf3f0dbb1948\nTitle: Plant-Avian Frugivory in the Urban Ecosystem of Delhi\nYear: 2023\nAbstract: Plant-frugivore interactions are important ecological processes that play a vital role in maintaining the dynamics of the ecosystem. Birds are very important frugivores and very little is known about the plant-avian interaction matrix in the urban ecosystems of India. The present study endeavours to understand and document the plant\u2013avian frugivory interactions in the human-dominated green spaces which is a mosaic of selectively planted exotic and native tree species in Delhi. A total of thirty avian frugivore species were recorded feeding on twenty-two focal tree species using phyto-centric approach. Characteristic traits of fruits like fruit diameter, colour and type and their interacting avian species were studied based on their fruit handling behaviour. The highest number of avian frugivore species were observed on native Ficus tree species in urban Delhi ecosystem, thereby providing evident proof of being an important food resource for avian disperser communities.",
  "The highest number of avian frugivore species were observed on native Ficus tree species in urban Delhi ecosystem, thereby providing evident proof of being an important food resource for avian disperser communities. The study suggests to introduce more native fig tree species in the city plantations to enhance and sustain the avian diversity in the novel fragmented urban ecosystems.\nAuthors: Divya, Rita Singh, Sanjay Keshari Das\nVenue: Ecology, environment & conservation\nTldr: None\nUrl: https://doi.org/10.53550/eec.2023.v29i04s.026",
  "Faculty Name: rita singh\nPaperid: 5a3307b2e64bbcaff1202e261b8a83f7d03418a8\nTitle: Rethinking Voice-Face Correlation: A Geometry View\nYear: 2023\nAbstract: Previous works on voice-face matching and voice-guided face synthesis demonstrate strong correlations between voice and face, but mainly rely on coarse semantic cues such as gender, age, and emotion. In this paper, we aim to investigate the capability of reconstructing the 3D facial shape from voice from a geometry perspective without any semantic information. We propose a voice-anthropometric measurement (AM)-face paradigm, which identifies predictable facial AMs from the voice and uses them to guide 3D face reconstruction. By leveraging AMs as a proxy to link the voice and face geometry, we can eliminate the influence of unpredictable AMs and make the face geometry tractable. Our approach is evaluated on our proposed dataset with ground-truth 3D face scans and corresponding voice recordings, and we find significant correlations between voice and specific parts of the face geometry, such as the nasal cavity and cranium.",
  "Our approach is evaluated on our proposed dataset with ground-truth 3D face scans and corresponding voice recordings, and we find significant correlations between voice and specific parts of the face geometry, such as the nasal cavity and cranium. Our work offers a new perspective on voice-face correlation and can serve as a good empirical study for anthropometry science.\nAuthors: Xiang Li, Yandong Wen, Muqiao Yang, Jinglu Wang, Rita Singh, B. Raj\nVenue: ACM Multimedia\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes a voice-anthropometric measurement (AM)-face paradigm, which identifies predictable facial AMs from the voice and uses them to guide 3D face reconstruction and finds significant correlations between voice and specific parts of the face geometry, such as the nasal cavity and cranium.'}\nUrl: https://arxiv.org/pdf/2307.13948",
  "Faculty Name: rita singh\nPaperid: 63a4150c9ad87c003de43b32828c8ceec6bb4468\nTitle: A Gene-Based Algorithm for Identifying Factors That May Affect a Speaker\u2019s Voice\nYear: 2023\nAbstract: Over the past decades, many machine-learning- and artificial-intelligence-based technologies have been created to deduce biometric or bio-relevant parameters of speakers from their voice. These voice profiling technologies have targeted a wide range of parameters, from diseases to environmental factors, based largely on the fact that they are known to influence voice. Recently, some have also explored the prediction of parameters whose influence on voice is not easily observable through data-opportunistic biomarker discovery techniques. However, given the enormous range of factors that can possibly influence voice, more informed methods for selecting those that may be potentially deducible from voice are needed. To this end, this paper proposes a simple path-finding algorithm that attempts to find links between vocal characteristics and perturbing factors using cytogenetic and genomic data. The links represent reasonable selection criteria for use by computational by profiling technologies only, and are not intended to establish any unknown biological facts.",
  "To this end, this paper proposes a simple path-finding algorithm that attempts to find links between vocal characteristics and perturbing factors using cytogenetic and genomic data. The links represent reasonable selection criteria for use by computational by profiling technologies only, and are not intended to establish any unknown biological facts. The proposed algorithm is validated using a simple example from medical literature\u2014that of the clinically observed effects of specific chromosomal microdeletion syndromes on the vocal characteristics of affected people. In this example, the algorithm attempts to link the genes involved in these syndromes to a single example gene (FOXP2) that is known to play a broad role in voice production. We show that in cases where strong links are exposed, vocal characteristics of the patients are indeed reported to be correspondingly affected. Validation experiments and subsequent analyses confirm that the methodology could be potentially useful in predicting the existence of vocal signatures in na\u00efve cases where their existence has not been otherwise observed.",
  "We show that in cases where strong links are exposed, vocal characteristics of the patients are indeed reported to be correspondingly affected. Validation experiments and subsequent analyses confirm that the methodology could be potentially useful in predicting the existence of vocal signatures in na\u00efve cases where their existence has not been otherwise observed.\nAuthors: Rita Singh\nVenue: Entropy\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A simple path-finding algorithm that attempts to find links between vocal characteristics and perturbing factors using cytogenetic and genomic data and shows that in cases where strong links are exposed, vocal characteristics of the patients are indeed reported to be correspondingly affected.'}\nUrl: https://www.mdpi.com/1099-4300/25/6/897/pdf?version=1685718244",
  "Faculty Name: rita singh\nPaperid: 721b39472c801124b5e3102edffe9d6f0754e1c2\nTitle: Deriving Vocal Fold Oscillation Information from Recorded Voice Signals Using Models of Phonation\nYear: 2023\nAbstract: During phonation, the vocal folds exhibit a self-sustained oscillatory motion, which is influenced by the physical properties of the speaker\u2019s vocal folds and driven by the balance of bio-mechanical and aerodynamic forces across the glottis. Subtle changes in the speaker\u2019s physical state can affect voice production and alter these oscillatory patterns. Measuring these can be valuable in developing computational tools that analyze voice to infer the speaker\u2019s state. Traditionally, vocal fold oscillations (VFOs) are measured directly using physical devices in clinical settings. In this paper, we propose a novel analysis-by-synthesis approach that allows us to infer the VFOs directly from recorded speech signals on an individualized, speaker-by-speaker basis.",
  "Traditionally, vocal fold oscillations (VFOs) are measured directly using physical devices in clinical settings. In this paper, we propose a novel analysis-by-synthesis approach that allows us to infer the VFOs directly from recorded speech signals on an individualized, speaker-by-speaker basis. The approach, called the ADLES-VFT algorithm, is proposed in the context of a joint model that combines a phonation model (with a glottal flow waveform as the output) and a vocal tract acoustic wave propagation model such that the output of the joint model is an estimated waveform. The ADLES-VFT algorithm is a forward-backward algorithm which minimizes the error between the recorded waveform and the output of this joint model to estimate its parameters. Once estimated, these parameter values are used in conjunction with a phonation model to obtain its solutions. Since the parameters correlate with the physical properties of the vocal folds of the speaker, model solutions obtained using them represent the individualized VFOs for each speaker. The approach is flexible and can be applied to various phonation models. In addition to presenting the methodology, we show how the VFOs can be quantified from a dynamical systems perspective for classification purposes.",
  "The approach is flexible and can be applied to various phonation models. In addition to presenting the methodology, we show how the VFOs can be quantified from a dynamical systems perspective for classification purposes. Mathematical derivations are provided in an appendix for better readability.\nAuthors: Wayne Zhao, Rita Singh\nVenue: Entropy\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A novel analysis-by-synthesis approach that allows us to infer the VFOs directly from recorded speech signals on an individualized, speaker- by-speaker basis is proposed and it is shown how the V FOs can be quantified from a dynamical systems perspective for classification purposes.'}\nUrl: https://www.mdpi.com/1099-4300/25/7/1039/pdf?version=1689132568",
  "Faculty Name: rita singh\nPaperid: 7a25aa397ae2a7f82df87a936ce6ff7f03b7ac4c\nTitle: Token Prediction as Implicit Classification to Identify LLM-Generated Text\nYear: 2023\nAbstract: This paper introduces a novel approach for identifying the possible large language models (LLMs) involved in text generation. Instead of adding an additional classification layer to a base LM, we reframe the classification task as a next-token prediction task and directly fine-tune the base LM to perform it. We utilize the Text-to-Text Transfer Transformer (T5) model as the backbone for our experiments. We compared our approach to the more direct approach of utilizing hidden states for classification. Evaluation shows the exceptional performance of our method in the text classification task, highlighting its simplicity and efficiency. Furthermore, interpretability studies on the features extracted by our model reveal its ability to differentiate distinctive writing styles among various LLMs even in the absence of an explicit classifier.",
  "Evaluation shows the exceptional performance of our method in the text classification task, highlighting its simplicity and efficiency. Furthermore, interpretability studies on the features extracted by our model reveal its ability to differentiate distinctive writing styles among various LLMs even in the absence of an explicit classifier. We also collected a dataset named OpenLLMText, containing approximately 340k text samples from human and LLMs, including GPT3.5, PaLM, LLaMA, and GPT2.\nAuthors: Yutian Chen, Hao Kang, Vivian Zhai, Liangze Li, Rita Singh, Bhiksha Raj\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Evaluation shows the exceptional performance of the method in the text classification task, highlighting its simplicity and efficiency, and interpretability studies on the features extracted by the model reveal its ability to differentiate distinctive writing styles among various LLMs even in the absence of an explicit classifier.'}\nUrl: https://aclanthology.org/2023.emnlp-main.810.pdf",
  "Faculty Name: rita singh\nPaperid: 7ce9a6ad52408b9ab0113d0ae9b413585fe2accc\nTitle: Effect of myo-inositol and di-chiro inositol plus vitamin D supplementation during pregnancy on prevention of gestational diabetes: a multi-centric, prospective, randomized, double-blind clinical trial\nYear: 2023\nAbstract: Background: Aim of study was to evaluate the impact of myoinositol and D-chiro inositol plus vitamin D supplementation on the prevention of gestational diabetes mellitus (GDM) in pregnant women.\nMethods: In the multi-centric, prospective, randomised, double-blind clinical trial, either vitamin D alone (group I) or myoinositol and D-chiro inositol plus Vitamin D (group II) were administered to pregnant women from 12 weeks of gestation. The administration was continued until delivery to primigravids who were normoglycemic at 12 weeks of gestation and consented. From October 2018 to December 2019.",
  "The administration was continued until delivery to primigravids who were normoglycemic at 12 weeks of gestation and consented. From October 2018 to December 2019. A total of 1250 women were enrolled, and randomly allocated to either of the groups: 630 women in Group I and 620 in Group II. The allocation was blinded. The primary outcome was the rate of GDM as assessed by oral glucose tolerance test (OGTT) recommended by diabetes in pregnancy Study Group India (DIPSI), International Federation of Gynecology and Obstetrics (FIGO) and the Government of India, at first antenatal visit followed by at weeks 24 to 28 in both the groups.\nResults: The rate of GDM was found more in group I as compared to group II treated with myoinositol and D-chiro Inositol plus vitamin D, but the difference was not statistically significant (5.08% in group I and 3.22% in group II).",
  "Results: The rate of GDM was found more in group I as compared to group II treated with myoinositol and D-chiro Inositol plus vitamin D, but the difference was not statistically significant (5.08% in group I and 3.22% in group II).\nConclusions: In conclusion, an improved trend has been noticed in the reduction of the rate of GDM with myoinositol and D-chiro inositol plus vitamin D as compared to vitamin D alone. Myoinositol and D-chiro inositol plus vitamin D supplementation may be a good option for pregnant women to prevent the GDM occurrence especially in women having positive risk factors for GDM.",
  "Myoinositol and D-chiro inositol plus vitamin D supplementation may be a good option for pregnant women to prevent the GDM occurrence especially in women having positive risk factors for GDM.\n\u00a0\nAuthors: H. Divakar, Sheetal S Joshi, V. Thobbi, Shobha Bembalgi, S. Gupte, V. Bhat, Rita Singh, Poorni Narayanan, Bhagyashri Kulkarni, Prachi Ahire, D. V., I. Manyonda\nVenue: International Journal of Reproduction Contraception Obstetrics and Gynecology\nTldr: {'model': 'tldr@v2.0.0', 'text': 'An improved trend has been noticed in the reduction of the rate of GDM with myoinositol and D-chiro inositol plus vitamin D as compared to vitamin D alone, which may be a good option for pregnant women to prevent the GDM occurrence.'}\nUrl: https://www.ijrcog.org/index.php/ijrcog/article/download/13237/8254",
  "Faculty Name: rita singh\nPaperid: 7de69ba0381aa265803b79ccaedf247d266d19ab\nTitle: Utilization of the Whole Cowpea Pod and Barley Husk in The Production of Nutritionally Enriched Composite Flour\nYear: 2023\nAbstract: Background: Cowpea is a climbing annual crop from Fabaceae family which is grown for its edible seeds and pods. Cowpea is rich in various nutrients such as fibre, protein, iron, potassium and is low in fat and calories. It has been observed that non-Communicable diseases are increasing at a rapid rate in India as well as globally. The need of the hour is to control the rate of diseases through modification in dietary practices. This study has focused on formulation of whole cowpea pod enriched composite flour by including more fibre and various nutrients in the diet. Methods: In the study, composite flour using whole cowpea pod flour, barley husk flour and whole wheat flour was developed. The nutritional characteristics of composite flour and barley husk were analyzed. Storage study with two different packaging materials was also done.",
  "Methods: In the study, composite flour using whole cowpea pod flour, barley husk flour and whole wheat flour was developed. The nutritional characteristics of composite flour and barley husk were analyzed. Storage study with two different packaging materials was also done. Result: The composite flour was found to have good nutritional properties as it contained valuable amount of protein, energy and crude fibre. It was also found that the flour had higher content of iron, magnesium and calcium while barley husk had higher content of manganese. Laminated aluminium pouches found to be more suitable for use as a packaging material.\n\nAuthors: Urvashi, Anuradha Dutta, R. Raghuvanshi, Y. Singh, Nivedita, S. Tilara, D. Joshi\nVenue: Asian Journal of Dairy and Food Research\nTldr: None\nUrl: https://arccarticles.s3.amazonaws.com/OnlinePublish/Final-article-attachemnt-with-doi-DR-1986-6089603e9087340b9bdcbbb1.pdf",
  "Faculty Name: rita singh\nPaperid: 8665c864d71df1e918d2010778fc06712f4e5550\nTitle: Imprecise Label Learning: A Unified Framework for Learning with Various Imprecise Label Configurations\nYear: 2023\nAbstract: Learning with reduced labeling standards, such as noisy label, partial label, and multiple label candidates, which we generically refer to as \\textit{imprecise} labels, is a commonplace challenge in machine learning tasks. Previous methods tend to propose specific designs for every emerging imprecise label configuration, which is usually unsustainable when multiple configurations of imprecision coexist. In this paper, we introduce imprecise label learning (ILL), a framework for the unification of learning with various imprecise label configurations. ILL leverages expectation-maximization (EM) for modeling the imprecise label information, treating the precise labels as latent variables.Instead of approximating the correct labels for training, it considers the entire distribution of all possible labeling entailed by the imprecise information.",
  "ILL leverages expectation-maximization (EM) for modeling the imprecise label information, treating the precise labels as latent variables.Instead of approximating the correct labels for training, it considers the entire distribution of all possible labeling entailed by the imprecise information. We demonstrate that ILL can seamlessly adapt to partial label learning, semi-supervised learning, noisy label learning, and, more importantly, a mixture of these settings. Notably, ILL surpasses the existing specified techniques for handling imprecise labels, marking the first unified framework with robust and effective performance across various challenging settings. We hope our work will inspire further research on this topic, unleashing the full potential of ILL in wider scenarios where precise labels are expensive and complicated to obtain.",
  "We hope our work will inspire further research on this topic, unleashing the full potential of ILL in wider scenarios where precise labels are expensive and complicated to obtain.\nAuthors: Hao Chen, Ankit Shah, Jindong Wang, R. Tao, Yidong Wang, Xingxu Xie, Masashi Sugiyama, Rita Singh, B. Raj\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Imprecise label learning (ILL) is introduced, a framework for the unification of learning with various imprecise label configurations, marking the first unified framework with robust and effective performance across various challenging settings.'}\nUrl: https://arxiv.org/pdf/2305.12715",
  "Faculty Name: rita singh\nPaperid: 8aac453851c7b6178e2aea7c4d53f070380c25e2\nTitle: APPLIED ASPECT OF SATVAVAJAYA CHIKITSA\nYear: 2023\nAbstract: The human being is a tripod having three pillars, Satva (mind), Atma (soul) and Sharira (body). Here, Satva is a connecting link between Atma and Sharira, which is otherwise called Manas. It has an immense influence on the health and ill health of the individual. \u2018Prasanna\u2019 Manah is a sign of a healthy life. \nIn Ayurvedic contexts, Chikitsa is classified into two parts based on resources (Vyapashraya Bheden): 1. Daivvyapashray Chikitsa 2. Yuktivyapashray Chikitsa.",
  "In Ayurvedic contexts, Chikitsa is classified into two parts based on resources (Vyapashraya Bheden): 1. Daivvyapashray Chikitsa 2. Yuktivyapashray Chikitsa. Daivvyapashray Chikitsa refers to Mantra, Ausadhi, Mani, Mangala, Bali, Upahara, Home, Niyam, Prayashchita, Upvasa, Swastyayanapatha, Pranipata, Gamana etc. Yuktivyapashrya Chikitsa refers to Samsodhana (Vamanadi) and Upshamana (Pachanadi). In another context, Acharya Charak and Acharya Vagbhat explained Trividham Ausdham as; 1. Daivvyapashray Chikitsa, 2. Yuktivyapashrya Chikitsa 3. Satvavajaya Chikitsa.",
  "Daivvyapashray Chikitsa, 2. Yuktivyapashrya Chikitsa 3. Satvavajaya Chikitsa. Their Satvavajaya Chikitsa further explained, \"Aiming to control the mind or is a method of restraining the mind from unwholesome objects.\u201d Satvavajaya Chikitsa is that typical Ayurvedic approach that prevents the impaired Dhi, Dhriti and Smriti and brings them back to a normal state. Hence, it plays a significant role in maintaining a harmonious state between these three factors, ultimately leading to a happy and healthy state of the individual.\nAuthors: Rita Singh, C. B. Singjh, Yogesh Kumar, Ajay Kumar, Shailendra Singh\nVenue: International Ayurvedic Medical Journal\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Satvavajaya Chikitsa is that typical Ayurvedic approach that prevents the impaired Dhi, Dhriti and Smriti, and brings them back to a normal state.'}",
  "Url: https://doi.org/10.46607/iamj2011112023",
  "Faculty Name: rita singh\nPaperid: a6e3a10a6286967413e3406374bbeea533640030\nTitle: The Hidden Dance of Phonemes and Visage: Unveiling the Enigmatic Link between Phonemes and Facial Features\nYear: 2023\nAbstract: This work unveils the enigmatic link between phonemes and facial features. Traditional studies on voice-face correlations typically involve using a long period of voice input, including generating face images from voices and reconstructing 3D face meshes from voices. However, in situations like voice-based crimes, the available voice evidence may be short and limited. Additionally, from a physiological perspective, each segment of speech -- phoneme -- corresponds to different types of airflow and movements in the face. Therefore, it is advantageous to discover the hidden link between phonemes and face attributes. In this paper, we propose an analysis pipeline to help us explore the voice-face relationship in a fine-grained manner, i.e., phonemes v.s. facial anthropometric measurements (AM). We build an estimator for each phoneme-AM pair and evaluate the correlation through hypothesis testing.",
  "In this paper, we propose an analysis pipeline to help us explore the voice-face relationship in a fine-grained manner, i.e., phonemes v.s. facial anthropometric measurements (AM). We build an estimator for each phoneme-AM pair and evaluate the correlation through hypothesis testing. Our results indicate that AMs are more predictable from vowels compared to consonants, particularly with plosives. Additionally, we observe that if a specific AM exhibits more movement during phoneme pronunciation, it is more predictable. Our findings support those in physiology regarding correlation and lay the groundwork for future research on speech-face multimodal learning.\nAuthors: Liao Qu, X. Zou, Xiang Li, Yandong Wen, Rita Singh, B. Raj\nVenue: Interspeech\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes an analysis pipeline to help explore the voice-face relationship in a fine-grained manner, i.s. phonemes v. facial anthropometric measurements (AM), and indicates that AMs are more predictable from vowels compared to consonants, particularly with plosives.'}\nUrl: https://arxiv.org/pdf/2307.13953",
  "Faculty Name: rita singh\nPaperid: ad22af138fa1d1490cda0301abf8159a7c30c5a2\nTitle: Pengi: An Audio Language Model for Audio Tasks\nYear: 2023\nAbstract: In the domain of audio processing, Transfer Learning has facilitated the rise of Self-Supervised Learning and Zero-Shot Learning techniques. These approaches have led to the development of versatile models capable of tackling a wide array of tasks, while delivering state-of-the-art performance. However, current models inherently lack the capacity to produce the requisite language for open-ended tasks, such as Audio Captioning or Audio Question&Answering. We introduce Pengi, a novel Audio Language Model that leverages Transfer Learning by framing all audio tasks as text-generation tasks. It takes as input, an audio recording, and text, and generates free-form text as output. The input audio is represented as a sequence of continuous embeddings by an audio encoder. A text encoder does the same for the corresponding text input. Both sequences are combined as a prefix to prompt a pre-trained frozen language model.",
  "The input audio is represented as a sequence of continuous embeddings by an audio encoder. A text encoder does the same for the corresponding text input. Both sequences are combined as a prefix to prompt a pre-trained frozen language model. The unified architecture of Pengi enables open-ended tasks and close-ended tasks without any additional fine-tuning or task-specific extensions. When evaluated on 22 downstream tasks, our approach yields state-of-the-art performance in several of them. Our results show that connecting language models with audio models is a major step towards general-purpose audio understanding\nAuthors: Soham Deshmukh, Benjamin Elizalde, Rita Singh, Huaming Wang\nVenue: Neural Information Processing Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Pengi is introduced, a novel Audio Language Model that leverages Transfer Learning by framing all audio tasks as text-generation tasks, and shows that connecting language models with audio models is a major step towards general-purpose audio understanding.'}\nUrl: http://arxiv.org/pdf/2305.11834",
  "Faculty Name: rita singh\nPaperid: b5d8e7e1e1543cf39b84cd894a6a899e086e058b\nTitle: Mean Platelet Volume in Type 2 Diabetes: Correlation with Poor Glycaemic Control\nYear: 2023\nAbstract: Background: Diabetes is a global pandemic. Mean platelet volume (MPV) is an indicator of increased platelet activity, which is considered to play a role in the development of vascular complications in diabetes. Platelet volume is strongly and independently related with glycaemic control in Type 2 diabetes (T2D).\n\nAim: To study the MPV in patients with T2D, and its correlation with HbA1c, duration of T2D, and microvascular complications.\n\nMethodology: This was a cross-sectional, observational study conducted at the Department of Medicine, Gandhi Medical College, Bhopal, India, during a period of 18 months on 300 patients with T2D. Blood glucose, HbA1c, MPV, fundoscopy, and 24-hour urine protein were done.",
  "Blood glucose, HbA1c, MPV, fundoscopy, and 24-hour urine protein were done. Data were represented as mean+/-standard deviation and statistical analysis was done using SPSS software (IBM, Armonk, New York, USA).\n\nResults: The mean age of patients was 56.64\u00b18.69 years, with 52% of the patients being females. Of these patients, 18.3% had HbA1c between 6.5\u20138.0%, 51.7% between 8.1\u201310.0% and the rest above 10.0%. A total of 51% of the patients had diabetes for 6\u201310 years of duration and 30% for more than 10 years. Patients with higher HbA1c level and prolonged duration of diabetes had higher MPV (p<0.001). Patients with advanced diabetic retinopathy changes and nephropathy also had higher MPV (p<0.05).",
  "Patients with higher HbA1c level and prolonged duration of diabetes had higher MPV (p<0.001). Patients with advanced diabetic retinopathy changes and nephropathy also had higher MPV (p<0.05).\n\nConclusion: Measurement of MPV in patients with T2D can be a useful and easily available prognostic marker, and hence assist clinicians to anticipate the occurrence of microvascular complications associated with the disease, especially in resource-poor settings, and reduce the burden of cost for the patient.\nAuthors: Avarna Agarwal, Anita Arya, R. Saxena, Simmi Dube\nVenue: EMJ Diabetes\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Measurement of MPV in patients with T2D can be a useful and easily available prognostic marker, and hence assist clinicians to anticipate the occurrence of microvascular complications associated with the disease, especially in resource-poor settings, and reduce the burden of cost for the patient.'}\nUrl: https://www.emjreviews.com/wp-content/uploads/2023/11/Mean-Platelet-Volume-in-Type-2-Diabetes.pdf",
  "Faculty Name: rita singh\nPaperid: b7e2074934985b6112b6bce8c3680b14e621fdfe\nTitle: Importance of negative sampling in weak label learning\nYear: 2023\nAbstract: Weak-label learning is a challenging task that requires learning from data\"bags\"containing positive and negative instances, but only the bag labels are known. The pool of negative instances is usually larger than positive instances, thus making selecting the most informative negative instance critical for performance. Such a selection strategy for negative instances from each bag is an open problem that has not been well studied for weak-label learning. In this paper, we study several sampling strategies that can measure the usefulness of negative instances for weak-label learning and select them accordingly. We test our method on CIFAR-10 and AudioSet datasets and show that it improves the weak-label classification performance and reduces the computational cost compared to random sampling methods. Our work reveals that negative instances are not all equally irrelevant, and selecting them wisely can benefit weak-label learning.",
  "We test our method on CIFAR-10 and AudioSet datasets and show that it improves the weak-label classification performance and reduces the computational cost compared to random sampling methods. Our work reveals that negative instances are not all equally irrelevant, and selecting them wisely can benefit weak-label learning.\nAuthors: Ankit Shah, Fuyu Tang, Zelin Ye, Rita Singh, Bhiksha Raj\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work reveals that negative instances are not all equally irrelevant, and selecting them wisely can benefit weak-label learning, and reduces the computational cost compared to random sampling methods.'}\nUrl: https://arxiv.org/pdf/2309.13227",
  "Faculty Name: rita singh\nPaperid: d77d82c224bf953cf67cb94e1c65b69497859fbb\nTitle: Implementing International Federation of Gynecology and Obstetrics Nutrition Checklist for Pregnant Women: Opportunities and Challenges in Low- and Middle-income Countries\nYear: 2023\nAbstract: None\nAuthors: Rita Singh, Richa Mishra, Sheetal S Joshi, H. Divakar, Gubbi Venkatasubbaiah Divakar, Bhagyashri Kulkarni, Poorni Narayanan\nVenue: Journal of South Asian Federation of Obstetrics and Gynaecology\nTldr: None\nUrl: N/A",
  "Faculty Name: rita singh\nPaperid: d7911ff6f80bd9f053ef8d304f15791f510f5cda\nTitle: Completing Visual Objects via Bridging Generation and Segmentation\nYear: 2023\nAbstract: This paper presents a novel approach to object completion, with the primary goal of reconstructing a complete object from its partially visible components. Our method, named MaskComp, delineates the completion process through iterative stages of generation and segmentation. In each iteration, the object mask is provided as an additional condition to boost image generation, and, in return, the generated images can lead to a more accurate mask by fusing the segmentation of images. We demonstrate that the combination of one generation and one segmentation stage effectively functions as a mask denoiser. Through alternation between the generation and segmentation stages, the partial object mask is progressively refined, providing precise shape guidance and yielding superior object completion results. Our experiments demonstrate the superiority of MaskComp over existing approaches, e.g., ControlNet and Stable Diffusion, establishing it as an effective solution for object completion.",
  "Through alternation between the generation and segmentation stages, the partial object mask is progressively refined, providing precise shape guidance and yielding superior object completion results. Our experiments demonstrate the superiority of MaskComp over existing approaches, e.g., ControlNet and Stable Diffusion, establishing it as an effective solution for object completion.\nAuthors: Xiang Li, Yinpeng Chen, Chung-Ching Lin, Rita Singh, Bhiksha Raj, Zicheng Liu\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The method, named MaskComp, delineates the completion process through iterative stages of generation and segmentation, and demonstrates that the combination of one generation and one segmentation stage effectively functions as a mask denoiser.'}\nUrl: https://arxiv.org/pdf/2310.00808",
  "Faculty Name: rita singh\nPaperid: e2572e0adacfb116b19b25691e7f6b3749490a88\nTitle: Training Audio Captioning Models without Audio\nYear: 2023\nAbstract: Automated Audio Captioning (AAC) is the task of generating natural language descriptions given an audio stream. A typical AAC system requires manually curated training data of audio segments and corresponding text caption annotations. The creation of these audio-caption pairs is costly, resulting in general data scarcity for the task. In this work, we address this major limitation and propose an approach to train AAC systems using only text. Our approach leverages the multimodal space of contrastively trained audio-text models, such as CLAP. During training, a decoder generates captions conditioned on the pretrained CLAP text encoder. During inference, the text encoder is replaced with the pretrained CLAP audio encoder. To bridge the modality gap between text and audio embeddings, we propose the use of noise injection or a learnable adapter, during training. We find that the proposed text-only framework performs competitively with state-of-the-art models trained with paired audio, showing that efficient text-to-audio transfer is possible.",
  "To bridge the modality gap between text and audio embeddings, we propose the use of noise injection or a learnable adapter, during training. We find that the proposed text-only framework performs competitively with state-of-the-art models trained with paired audio, showing that efficient text-to-audio transfer is possible. Finally, we showcase both stylized audio captioning and caption enrichment while training without audio or human-created text captions.\nAuthors: Soham Deshmukh, Benjamin Elizalde, Dimitra Emmanouilidou, Bhiksha Raj, Rita Singh, Huaming Wang\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes an approach to train AAC systems using only text, and finds that the proposed text-only framework performs competitively with state-of-the-art models trained with paired audio, showing that efficient text-to-audio transfer is possible.'}\nUrl: https://arxiv.org/pdf/2309.07372",
  "Faculty Name: rita singh\nPaperid: f5b88ca9d74e8ddc679adcd07a292bd8481062fa\nTitle: Prompting Audios Using Acoustic Properties For Emotion Representation\nYear: 2023\nAbstract: Emotions lie on a continuum, but current models treat emotions as a finite valued discrete variable. This representation does not capture the diversity in the expression of emotion. To better represent emotions we propose the use of natural language descriptions (or prompts). In this work, we address the challenge of automatically generating these prompts and training a model to better learn emotion representations from audio and prompt pairs. We use acoustic properties that are correlated to emotion like pitch, intensity, speech rate, and articulation rate to automatically generate prompts i.e. 'acoustic prompts'. We use a contrastive learning objective to map speech to their respective acoustic prompts. We evaluate our model on Emotion Audio Retrieval and Speech Emotion Recognition. Our results show that the acoustic prompts significantly improve the model's performance in EAR, in various Precision@K metrics. In SER, we observe a 3.8% relative accuracy improvement on the Ravdess dataset.",
  "We evaluate our model on Emotion Audio Retrieval and Speech Emotion Recognition. Our results show that the acoustic prompts significantly improve the model's performance in EAR, in various Precision@K metrics. In SER, we observe a 3.8% relative accuracy improvement on the Ravdess dataset.\nAuthors: Hira Dhamyal, Benjamin Elizalde, Soham Deshmukh, Huaming Wang, Bhiksha Raj, Rita Singh\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work addresses the challenge of automatically generating prompts and training a model to better learn emotion representations from audio and prompt pairs by using acoustic properties that are correlated to emotion like pitch, intensity, speech rate, and articulation rate to automatically generate prompts.'}\nUrl: https://arxiv.org/pdf/2310.02298",
  "Faculty Name: rita singh\nPaperid: f969f059b01be02f9995396b6cc397959b574635\nTitle: Pairwise Similarity Learning is SimPLE\nYear: 2023\nAbstract: In this paper, we focus on a general yet important learning problem, pairwise similarity learning (PSL). PSL subsumes a wide range of important applications, such as open-set face recognition, speaker verification, image retrieval and person re-identification. The goal of PSL is to learn a pairwise similarity function assigning a higher similarity score to positive pairs (i.e., a pair of samples with the same label) than to negative pairs (i.e., a pair of samples with different label). We start by identifying a key desideratum for PSL, and then discuss how existing methods can achieve this desideratum. We then propose a surprisingly simple proxy-free method, called SimPLE, which requires neither feature/proxy normalization nor angular margin and yet is able to generalize well in open-set recognition. We apply the proposed method to three challenging PSL tasks: open-set face recognition, image retrieval and speaker verification.",
  "We then propose a surprisingly simple proxy-free method, called SimPLE, which requires neither feature/proxy normalization nor angular margin and yet is able to generalize well in open-set recognition. We apply the proposed method to three challenging PSL tasks: open-set face recognition, image retrieval and speaker verification. Comprehensive experimental results on large-scale benchmarks show that our method performs significantly better than current state-of-the-art methods. Our project page is available at simple.is.tue.mpg.de.\nAuthors: Yandong Wen, Weiyang Liu, Yao Feng, Bhiksha Raj, Rita Singh, Adrian Weller, Michael J. Black, Bernhard Sch\u00f6lkopf\nVenue: IEEE International Conference on Computer Vision\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work identifies a key desideratum for PSL, and proposes a surprisingly simple proxy-free method, called SimPLE, which requires neither feature/proxy normalization nor angular margin and yet is able to generalize well in open-set recognition.'}\nUrl: https://arxiv.org/pdf/2310.09449",
  "Faculty Name: rita singh\nPaperid: fcddb888f01eae5c5530b2d1533d6064f207ea2b\nTitle: Gonadotropin Receptor Cross-Talk and Altered Functions in Gonadal and Non-Gonadal Tissues\nYear: 2023\nAbstract: Reproduction depends on the responses of gonadotropins through their specific receptors. The gonadotropin family has three members; Follicle Stimulating Hormone (FSH), Luteinizing Hormone (LH), and Human Chorionic Gonadotropin (hCG). These glycoprotein hormones comprise two subunits, an identical \u03b1-subunit and a hormone-specific-\u03b2 subunit. Their cognate receptors (FSHR and LHCGR) are two adrenergic receptor-like family A/rhodopsin-like G-Protein Coupled Receptors (GPCRs) with structurally distinct ligand binding domains. The hCG binds to LHCGR but has a longer half-life and higher affinity to LHCGR.",
  "The hCG binds to LHCGR but has a longer half-life and higher affinity to LHCGR. The expression of FSHR and LHCGR is observed in both gonadal and nongonadal cells. In this review, we will be emphasizing the differential expression of gonadotropin receptors in different cells of the human body, their specific responses through cross-talk, and how a defect in the expression and activity of FSHR and LHCGR may alter the responses of FSH and LH/hCG leading to diseases like PCOS, cancer and metabolic disorders.\nAuthors: Rita Singh, Anjali Pathak\nVenue: Journal of Endocrinology & Reproduction\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This review will be emphasizing the differential expression of gonadotropin receptors in different cells of the human body, their specific responses through cross-talk, and how a defect in the expression and activity of FSHR and LHCGR may alter the responses of F SH and LH/hCG leading to diseases like PCOS, cancer and metabolic disorders.'}\nUrl: https://informaticsjournals.com/index.php/jer/article/download/34991/22766",
  "List of 2023 Open Access papers by rita singh are:\nImplementing International Federation of Gynecology and Obstetrics Nutrition Checklist for Pregnant Women: Opportunities and Challenges in Low- and Middle-income Countries\nMean Platelet Volume in Type 2 Diabetes: Correlation with Poor Glycaemic Control\nGonadotropin Receptor Cross-Talk and Altered Functions in Gonadal and Non-Gonadal Tissues\nBASS: Block-wise Adaptation for Speech Summarization\nRethinking Voice-Face Correlation: A Geometry View\nA Gene-Based Algorithm for Identifying Factors That May Affect a Speaker\u2019s Voice\nDeriving Vocal Fold Oscillation Information from Recorded Voice Signals Using Models of Phonation\nImprecise Label Learning: A Unified Framework for Learning with Various Imprecise Label Configurations\nThe Hidden Dance of Phonemes and Visage: Unveiling the Enigmatic Link between Phonemes and Facial Features\nPengi: An Audio Language Model for Audio Tasks\nGPT-Sentinel: Distinguishing Human and ChatGPT Generated Content\nToken Prediction as Implicit Classification to Identify LLM-Generated Text\nEffect of myo-inositol and di-chiro inositol plus vitamin D supplementation during pregnancy on",
  "An Audio Language Model for Audio Tasks\nGPT-Sentinel: Distinguishing Human and ChatGPT Generated Content\nToken Prediction as Implicit Classification to Identify LLM-Generated Text\nEffect of myo-inositol and di-chiro inositol plus vitamin D supplementation during pregnancy on prevention of gestational diabetes: a multi-centric, prospective, randomized,",
  "Distinguishing Human and ChatGPT Generated Content\nToken Prediction as Implicit Classification to Identify LLM-Generated Text\nEffect of myo-inositol and di-chiro inositol plus vitamin D supplementation during pregnancy on prevention of gestational diabetes: a multi-centric, prospective, randomized, double-blind clinical trial\nPlant-Avian Frugivory in the Urban Ecosystem of Delhi\nLoFT: Local Proxy Fine-tuning For Improving Transferability Of Adversarial Attacks Against Large Language Model\nEvaluating Speech Synthesis by Training Recognizers on Synthetic Speech\nRethinking Audiovisual Segmentation with Semantic Quantization and Decomposition\nTowards Noise-Tolerant Speech-Referring Video Object Segmentation: Bridging Speech and Text\nImportance of negative sampling in weak label learning\nCompleting Visual Objects via Bridging Generation and Segmentation\nTraining Audio Captioning Models without Audio\nPrompting Audios Using Acoustic Properties For Emotion Representation\nPairwise Similarity Learning is SimPLE\nComparison of freeze-thaw and sonication cycle-based methods for extracting AMR-associated metabolites from Staphylococcus aureus\nAPPLIED ASPECT OF SATVAVAJAYA CHIKITSA\nUtilization of the Whole Cowpea Pod and Barley Husk in The Production of Nutritionally Enriched Composite Flour",
  "Rita Singh\nAssociate Research Professor, Language Technologies Institute\nContact\n6703 \u2014Gates & Hillman Centers\nEmail rsingh@cs.cmu.edu\n412-268-9859",
  "Faculty Name: robert frederking\nPaperid: 42f711ca3491d4bf33b35683944d9b8f5bc1c558\nTitle: Reconstructing ice force-displacement development in structural assessments of freshwater, polycrystalline ice impacts\nYear: 2023\nAbstract: None\nAuthors: Ekaterina Kim, K. H\u00f8yland, R. Frederking\nVenue: International Journal of Impact Engineering\nTldr: None\nUrl: N/A",
  "List of 2023 Open Access papers by robert frederking are:\nReconstructing ice force-displacement development in structural assessments of freshwater, polycrystalline ice impacts",
  "Robert Frederking\nAssociate Dean for PhD Programs and Chair for MLT Program, Language Technologies Institute\nContact 6515 \u2014Gates & Hillman Centers\nEmail ref@cs.cmu.edu\nPhone 412-268-6656",
  "Faculty Name: scott fahlman\nPaperid: 13922d438c437cea443b6c4747c54a29a8bdd742\nTitle: Score: A Rule Engine for the Scone Knowledge Base System\nYear: 2023\nAbstract: We present Score, a rule engine designed and implemented for the Scone knowledge base system. Scone is a knowledge base system designed for storing and manipulating rich representations of general knowledge in symbolic form. It represents knowledge in the form of nodes and links in a network structure, and it can perform basic inference about the relationships between different elements efficiently. On its own, Scone acts as a sort of\"smart memory\"that can interface with other software systems. One area of improvement for Scone is how useful it can be in supplying knowledge to an intelligent agent that can use the knowledge to perform actions and update the knowledge base with its observations. We augment the Scone system with a production rule engine that automatically performs simple inference based on existing and newly-added structures in Scone's knowledge base, potentially improving the capabilities of any planning systems built on top of Scone.",
  "We augment the Scone system with a production rule engine that automatically performs simple inference based on existing and newly-added structures in Scone's knowledge base, potentially improving the capabilities of any planning systems built on top of Scone. Production rule systems consist of\"if-then\"production rules that try to match their predicates to existing knowledge and fire their actions when their predicates are satisfied. We propose two kinds of production rules, if-added and if-needed rules, that differ in how they are checked and fired to cover multiple use cases. We then implement methods to efficiently check and fire these rules in a large knowledge base. The new rule engine is not meant to be a complex stand-alone planner, so we discuss how it fits into the context of Scone and future work on planning systems.\nAuthors: Jeffrey Chen, S. Fahlman\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': \"The Scone system is augmented with a production rule engine that automatically performs simple inference based on existing and newly-added structures in Scone's knowledge base, potentially improving the capabilities of any planning systems built on top of Scone.\"}",
  "Url: http://arxiv.org/pdf/2305.04154",
  "List of 2023 Open Access papers by scott fahlman are:\nScore: A Rule Engine for the Scone Knowledge Base System",
  "Scott Fahlman\nProfessor Emeritus, Language Technologies Institute\nComputer Science Department\nResearch Area\nAI, Knowledge Representation and Reasoning, Natural Language Processing and Computational Linguistics\nResearch\nI am interested in artificial intelligence and its application to real-world problems. Over the years, I have worked in many areas of AI, including knowledge representation, planning, image processing, machine learning, massively parallel approaches to search and inference, and the development of improved learning algorithms for artificial neural networks.\nMy current project is Scone, an open-source knowledge representation system and inference engine that can be used as a component in a variety of knowledge-based systems. Scone puts particular emphasis on efficiency, scalability (up to millions of entities and statements) and ease of use. One goal of our research is to support natural-language understanding, all the way from text or speech to a language-independent representation that we can reason about. This requires extensive use of background knowledge not included in the text itself. We are also working to extend Scone's capabilities for \"episodic\" representation and reasoning, by which we mean actions, events, sequences of actions, plans, goals and explanations.",
  "This requires extensive use of background knowledge not included in the text itself. We are also working to extend Scone's capabilities for \"episodic\" representation and reasoning, by which we mean actions, events, sequences of actions, plans, goals and explanations.\nI have also worked on programming languages and software-development environments that support an incremental, evolutionary software-development style. This work has been done in Common Lisp, Dylan and Java.\n\nContact:\n6417 \u2014Gates & Hillman Centers\nEmail: sef@cs.cmu.edu\nPhone: 412-268-2575",
  "List of 2023 Open Access papers by sean welleck are:\nSelf-Refine: Iterative Refinement with Self-Feedback\nInference-Time Policy Adapters (IPA): Tailoring Extreme-Scale LMs without Fine-tuning",
  "Sean Welleck\nAssistant Professor, Language Technologies Institute\nContact\nEmail swelleck@andrew.cmu.edu\nAddress\n5000 Forbes Avenue\nPittsburgh, PA 15213",
  "Faculty Name: shinji watanabe\nPaperid: 00542e510058b11d1faf612de9b45fa0d4d3f4e5\nTitle: Saturation time of exposure interval for cross-neutralization response to SARS-CoV-2: Implications for vaccine dose interval\nYear: 2023\nAbstract: None\nAuthors: Sho Miyamoto, Y. Kuroda, T. Kanno, A. Ueno, N. Shiwa-Sudo, N. Iwata-Yoshikawa, Yusuke Sakai, N. Nagata, T. Arashiro, A. Ainai, Saya Moriyama, N. Kishida, Shinji Watanabe, K. Nojima, Y. Seki, T. Mizukami, H. Hasegawa, H. Ebihara, S. Fukushi, Yoshimasa Takahashi, Maeda Ken, Tadaki Suzuki\nVenue: iScience\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The results highlight the importance of vaccine dosage intervals of 4 months or longer,",
  "S. Fukushi, Yoshimasa Takahashi, Maeda Ken, Tadaki Suzuki\nVenue: iScience\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The results highlight the importance of vaccine dosage intervals of 4 months or longer, regardless of the antigenicity of the exposed antigen, to maximize the breadth of serum cross-neutralization covering SARS-CoV-2 Omicron lineages.'}\nUrl: http://www.cell.com/article/S258900422300771X/pdf",
  "Faculty Name: shinji watanabe\nPaperid: 01a819f7155bb87c32f1e4c13d9439c080e6aa97\nTitle: Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning\nYear: 2023\nAbstract: Multilingual self-supervised learning (SSL) has often lagged behind state-of-the-art (SOTA) methods due to the expenses and complexity required to handle many languages. This further harms the reproducibility of SSL, which is already limited to few research groups due to its resource usage. We show that more powerful techniques can actually lead to more efficient pre-training, opening SSL to more research groups. We propose WavLabLM, which extends WavLM\u2019s joint prediction and denoising to 40k hours of data across 136 languages. To build WavLabLM, we devise a novel multi-stage pre-training method, designed to address the language imbalance of multilingual data. WavLabLM achieves comparable performance to XLS-R on ML-SUPERB with less than $10 \\%$ of the training data, making SSL realizable with academic compute.",
  "WavLabLM achieves comparable performance to XLS-R on ML-SUPERB with less than $10 \\%$ of the training data, making SSL realizable with academic compute. We show that further efficiency can be achieved with a vanilla HuBERT Base model, which can maintain $94 \\%$ of XLS-R\u2019s performance with only $3 \\%$ of the data, 4 GPUs, and limited trials. We open-source all code and models in ESPnet.\nAuthors: William Chen, Jiatong Shi, Brian Yan, Dan Berrebbi, Wangyou Zhang, Yifan Peng, Xuankai Chang, Soumi Maiti, Shinji Watanabe\nVenue: Automatic Speech Recognition & Understanding\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes WavLabLM, which extends WavLM\u2019s joint prediction and denoising to 40k hours of data across 136 languages, and devise a novel multi-stage pre-training method, designed to address the language imbalance of multilingual data.'}\nUrl: https://arxiv.org/pdf/2309.15317",
  "Faculty Name: shinji watanabe\nPaperid: 0534fd0ed04acaa60f820b730bf3c4816767fa43\nTitle: Tensor decomposition for minimization of E2E SLU model toward on-device processing\nYear: 2023\nAbstract: Spoken Language Understanding (SLU) is a critical speech recognition application and is often deployed on edge devices. Consequently, on-device processing plays a significant role in the practical implementation of SLU. This paper focuses on the end-to-end (E2E) SLU model due to its small latency property, unlike a cascade system, and aims to minimize the computational cost. We reduce the model size by applying tensor decomposition to the Conformer and E-Branchformer architectures used in our E2E SLU models. We propose to apply singular value decomposition to linear layers and the Tucker decomposition to convolution layers, respectively. We also compare COMP/PARFAC decomposition and Tensor-Train decomposition to the Tucker decomposition. Since the E2E model is represented by a single neural network, our tensor decomposition can flexibly control the number of parameters without changing feature dimensions.",
  "We also compare COMP/PARFAC decomposition and Tensor-Train decomposition to the Tucker decomposition. Since the E2E model is represented by a single neural network, our tensor decomposition can flexibly control the number of parameters without changing feature dimensions. On the STOP dataset, we achieved 70.9% exact match accuracy under the tight constraint of only 15 million parameters.\nAuthors: Yosuke Kashiwagi, Siddhant Arora, Hayato Futami, Jessica Huynh, Shih-Lun Wu, Yifan Peng, Brian Yan, E. Tsunoo, Shinji Watanabe\nVenue: Interspeech\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper aims to minimize the computational cost of the end-to-end (E2E) SLU model due to its small latency property, unlike a cascade system, and reduces the model size by applying tensor decomposition to the Conformer and E-Branchformer architectures used in the E2E SLU models.'}\nUrl: https://arxiv.org/pdf/2306.01247",
  "Faculty Name: shinji watanabe\nPaperid: 06353e1b7e7c8dc701ac76dcd4db5061b24468c9\nTitle: Decoder-only Architecture for Speech Recognition with CTC Prompts and Text Data Augmentation\nYear: 2023\nAbstract: Collecting audio-text pairs is expensive; however, it is much easier to access text-only data. Unless using shallow fusion, end-to-end automatic speech recognition (ASR) models require architecture modifications or additional training schemes to use text-only data. Inspired by recent advances in decoder-only language models (LMs), such as GPT-3 and PaLM adopted for speech-processing tasks, we propose using a decoder-only architecture for ASR with simple text augmentation. To provide audio information, encoder features compressed by CTC prediction are used as prompts for the decoder, which can be regarded as refining CTC prediction using the decoder-only model. Because the decoder architecture is the same as an autoregressive LM, it is simple to enhance the model by leveraging external text data with LM training.",
  "Because the decoder architecture is the same as an autoregressive LM, it is simple to enhance the model by leveraging external text data with LM training. An experimental comparison using LibriSpeech and Switchboard shows that our proposed models with text augmentation training reduced word error rates from ordinary CTC by 0.3% and 1.4% on LibriSpeech test-clean and testother set, respectively, and 2.9% and 5.0% on Switchboard and CallHome. The proposed model had advantage on computational efficiency compared with conventional encoder-decoder ASR models with a similar parameter setup, and outperformed them on the LibriSpeech 100h and Switchboard training scenarios.",
  "The proposed model had advantage on computational efficiency compared with conventional encoder-decoder ASR models with a similar parameter setup, and outperformed them on the LibriSpeech 100h and Switchboard training scenarios.\nAuthors: E. Tsunoo, Hayato Futami, Yosuke Kashiwagi, Siddhant Arora, Shinji Watanabe\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes using a decoder-only architecture for ASR with simple text augmentation training that had advantage on computational efficiency compared with conventional encoder-decoder ASR models with a similar parameter setup, and outperformed them on the LibriSpeech 100h and Switchboard training scenarios.'}\nUrl: https://arxiv.org/pdf/2309.08876",
  "Faculty Name: shinji watanabe\nPaperid: 083cf10c0cbf75dd5755a6a2cd971f39e7da75c2\nTitle: UniverSLU: Universal Spoken Language Understanding for Diverse Classification and Sequence Generation Tasks with a Single Network\nYear: 2023\nAbstract: Recent studies have demonstrated promising outcomes by employing large language models with multi-tasking capabilities. They utilize prompts to guide the model's behavior and surpass performance of task-specific models. Motivated by this, we ask: can we build a single model that jointly perform various spoken language understanding (SLU) tasks? To address this, we utilize pre-trained automatic speech recognition (ASR) models and employ various task and dataset specifiers as discrete prompts. We demonstrate efficacy of our single multi-task learning (MTL) model\"UniverSLU\"for 12 different speech classification and sequence generation tasks across 17 datasets and 9 languages. Results show that UniverSLU achieves competitive performance and even surpasses task-specific models.",
  "We demonstrate efficacy of our single multi-task learning (MTL) model\"UniverSLU\"for 12 different speech classification and sequence generation tasks across 17 datasets and 9 languages. Results show that UniverSLU achieves competitive performance and even surpasses task-specific models. We also conduct preliminary investigations into enabling human-interpretable natural phrases instead of task specifiers as discrete prompts and test the model's generalization capabilities to new paraphrases.\nAuthors: Siddhant Arora, Hayato Futami, Jee-weon Jung, Yifan Peng, Roshan Sharma, Yosuke Kashiwagi, E. Tsunoo, Shinji Watanabe\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work utilizes pre-trained automatic speech recognition (ASR) models and employs various task and dataset specifiers as discrete prompts to build a single model that jointly perform various spoken language understanding (SLU) tasks.'}\nUrl: https://arxiv.org/pdf/2310.02973",
  "Faculty Name: shinji watanabe\nPaperid: 090b284b2f8fc93ac3e7a92fc9f91bf4965ba75c\nTitle: ML-SUPERB: Multilingual Speech Universal PERformance Benchmark\nYear: 2023\nAbstract: Speech processing Universal PERformance Benchmark (SUPERB) is a leaderboard to benchmark the performance of Self-Supervised Learning (SSL) models on various speech processing tasks. However, SUPERB largely considers English speech in its evaluation. This paper presents multilingual SUPERB (ML-SUPERB), covering 143 languages (ranging from high-resource to endangered), and considering both automatic speech recognition and language identification. Following the concept of SUPERB, ML-SUPERB utilizes frozen SSL features and employs a simple framework for multilingual tasks by learning a shallow downstream model. Similar to the SUPERB benchmark, we find speech SSL models can significantly improve performance compared to FBANK features. Furthermore, we find that multilingual models do not always perform better than their monolingual counterparts. We will release ML-SUPERB as a challenge with organized datasets and reproducible training scripts for future multilingual representation research.",
  "Furthermore, we find that multilingual models do not always perform better than their monolingual counterparts. We will release ML-SUPERB as a challenge with organized datasets and reproducible training scripts for future multilingual representation research.\nAuthors: Jiatong Shi, Dan Berrebbi, William Chen, Ho-Lam Chung, En-Pei Hu, Wei Huang, Xuankai Chang, Shang-Wen Li, Abdel-rahman Mohamed, Hung-yi Lee, Shinji Watanabe\nVenue: Interspeech\nTldr: {'model': 'tldr@v2.0.0', 'text': None}\nUrl: https://arxiv.org/pdf/2305.10615",
  "Faculty Name: shinji watanabe\nPaperid: 0b234f749c6aebf5b1ec61fa0b2ac0d348ad08ed\nTitle: TorchAudio 2.1: Advancing Speech Recognition, Self-Supervised Learning, and Audio Processing Components for Pytorch\nYear: 2023\nAbstract: TorchAudio is an open-source audio and speech processing library built for PyTorch. It aims to accelerate the research and development of audio and speech technologies by providing well-designed, easy-to-use, and performant PyTorch components. Its contributors routinely engage with users to understand their needs and fulfill them by developing impactful features. Here, we survey TorchAudio\u2019s development principles and contents and highlight key features we include in its latest version (2.1): self-supervised learning pre-trained pipelines and training recipes, high-performance CTC decoders, speech recognition models and training recipes, advanced media I/O capabilities, and tools for performing forced alignment, multi-channel speech enhancement, and reference-less speech assessment. For a selection of these features, through empirical studies, we demonstrate their efficacy and show that they achieve competitive or state-of-the-art performance.",
  "For a selection of these features, through empirical studies, we demonstrate their efficacy and show that they achieve competitive or state-of-the-art performance.\nAuthors: Jeff Hwang, Moto Hira, Caroline Chen, Xiaohui Zhang, Zhaoheng Ni, Guangzhi Sun, Pingchuan Ma, Ruizhe Huang, Vineel Pratap, Yuekai Zhang, Anurag Kumar, Chin-Yun Yu, Chuang Zhu, Chunxi Liu, Jacob Kahn, M. Ravanelli, Peng Sun, Shinji Watanabe, Yangyang Shi, Yumeng Tao, Robin Scheibler, Samuele Cornell, Sean Kim, Stavros Petridis\nVenue: Automatic Speech Recognition & Understanding\nTldr: {'model': 'tldr@v2.0.0', 'text': 'TorchAudio\u2019s development principles and contents are surveyed and key features included in its latest version (2.1) are highlighted: self-supervised learning pre-trained pipelines and training recipes, high-performance CTC decoders, speech recognition models and training recipes, advanced media I/O capabilities, and tools for performing forced alignment, multi-channel speech enhancement, and reference-less speech assessment.'}",
  "Url: https://arxiv.org/pdf/2310.17864",
  "Faculty Name: shinji watanabe\nPaperid: 0c7018db4a00df1792a7b3de3cb0b48aa19ca041\nTitle: Integrating Pretrained ASR and LM to Perform Sequence Generation for Spoken Language Understanding\nYear: 2023\nAbstract: There has been an increased interest in the integration of pretrained speech recognition (ASR) and language models (LM) into the SLU framework. However, prior methods often struggle with a vocabulary mismatch between pretrained models, and LM cannot be directly utilized as they diverge from its NLU formulation. In this study, we propose a three-pass end-to-end (E2E) SLU system that effectively integrates ASR and LM subnetworks into the SLU formulation for sequence generation tasks. In the first pass, our architecture predicts ASR transcripts using the ASR subnetwork. This is followed by the LM subnetwork, which makes an initial SLU prediction. Finally, in the third pass, the deliberation subnetwork conditions on representations from the ASR and LM subnetworks to make the final prediction.",
  "This is followed by the LM subnetwork, which makes an initial SLU prediction. Finally, in the third pass, the deliberation subnetwork conditions on representations from the ASR and LM subnetworks to make the final prediction. Our proposed three-pass SLU system shows improved performance over cascaded and E2E SLU models on two benchmark SLU datasets, SLURP and SLUE, especially on acoustically challenging utterances.\nAuthors: Siddhant Arora, Hayato Futami, Yosuke Kashiwagi, E. Tsunoo, Brian Yan, Shinji Watanabe\nVenue: Interspeech\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This study proposes a three-pass end-to-end (E2E) SLU system that effectively integrates ASR and LM subnetworks into the SLU formulation for sequence generation tasks and shows improved performance over cascaded and E2E SLU models on two benchmark SLU datasets, SLURP and SLUE.'}\nUrl: https://arxiv.org/pdf/2307.11005",
  "Faculty Name: shinji watanabe\nPaperid: 1028bf42a4c792acefd3be9da45e58f2b1620fe3\nTitle: Structured Pruning of Self-Supervised Pre-Trained Models for Speech Recognition and Understanding\nYear: 2023\nAbstract: Self-supervised speech representation learning (SSL) has shown to be effective in various downstream tasks, but SSL models are usually large and slow. Model compression techniques such as pruning aim to reduce the model size and computation without degradation in accuracy. Prior studies focus on the pruning of Transformers; however, speech models not only utilize a stack of Transformer blocks, but also combine a frontend network based on multiple convolutional layers for low-level feature representation learning. This frontend has a small size but a heavy computational cost. In this work, we propose three task-specific structured pruning methods to deal with such heterogeneous networks. Experiments on LibriSpeech and SLURP show that the proposed method is more accurate than the original wav2vec2-base with 10% to 30% less computation, and is able to reduce the computation by 40% to 50% without any degradation.",
  "Experiments on LibriSpeech and SLURP show that the proposed method is more accurate than the original wav2vec2-base with 10% to 30% less computation, and is able to reduce the computation by 40% to 50% without any degradation.\nAuthors: Yifan Peng, Kwangyoun Kim, Felix Wu, Prashant Sridhar, Shinji Watanabe\nVenue: IEEE International Conference on Acoustics, Speech, and Signal Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes three task-specific structured pruning methods to deal with heterogeneous speech models that not only utilize a stack of Transformer blocks, but also combine a frontend network based on multiple convolutional layers for low-level feature representation learning.'}\nUrl: https://arxiv.org/pdf/2302.14132",
  "Faculty Name: shinji watanabe\nPaperid: 10e8dc07ea256c6a88d7043cf135417402ed38f4\nTitle: Prompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot Task Generalization\nYear: 2023\nAbstract: We investigate the emergent abilities of the recently proposed web-scale speech model Whisper, by adapting it to unseen tasks with prompt engineering. We selected three tasks: audio-visual speech recognition (AVSR), code-switched speech recognition (CS-ASR), and speech translation (ST) on unseen language pairs. We design task-specific prompts, by either leveraging another large-scale model, or simply manipulating the special tokens in the default prompts. Experiments show that compared to the default prompts, our proposed prompts improve performance by 10% to 45% on the three zero-shot tasks, and even outperform SotA supervised models on some datasets. In addition, our experiments reveal many interesting properties of Whisper, including its robustness to prompts, bias on accents, and the multilingual understanding in its latent space.",
  "In addition, our experiments reveal many interesting properties of Whisper, including its robustness to prompts, bias on accents, and the multilingual understanding in its latent space. Code is available at https://github.com/jasonppy/PromptingWhisper\nAuthors: Puyuan Peng, Brian Yan, Shinji Watanabe, David F. Harwath\nVenue: Interspeech\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work investigates the emergent abilities of the recently proposed web-scale speech model Whisper, by adapting it to unseen tasks with prompt engineering, and designs task-specific prompts that improve performance on the three zero-shot tasks and even outperform SotA supervised models on some datasets.'}\nUrl: https://arxiv.org/pdf/2305.11095",
  "Faculty Name: shinji watanabe\nPaperid: 14f5fd91d75bc10d9fff53dfe7ee73484fc4273b\nTitle: A Comparative Study on E-Branchformer vs Conformer in Speech Recognition, Translation, and Understanding Tasks\nYear: 2023\nAbstract: Conformer, a convolution-augmented Transformer variant, has become the de facto encoder architecture for speech processing due to its superior performance in various tasks, including automatic speech recognition (ASR), speech translation (ST) and spoken language understanding (SLU). Recently, a new encoder called E-Branchformer has outperformed Conformer in the LibriSpeech ASR benchmark, making it promising for more general speech applications. This work compares E-Branchformer and Conformer through extensive experiments using different types of end-to-end sequence-to-sequence models. Results demonstrate that E-Branchformer achieves comparable or better performance than Conformer in almost all evaluation sets across 15 ASR, 2 ST, and 3 SLU benchmarks, while being more stable during training. We will release our training configurations and pre-trained models for reproducibility, which can benefit the speech community.",
  "We will release our training configurations and pre-trained models for reproducibility, which can benefit the speech community.\nAuthors: Yifan Peng, Kwangyoun Kim, Felix Wu, Brian Yan, Siddhant Arora, William Chen, Jiyang Tang, Suwon Shon, Prashant Sridhar, Shinji Watanabe\nVenue: Interspeech\nTldr: {'model': 'tldr@v2.0.0', 'text': 'E-Branchformer achieves comparable or better performance than Conformer in almost all evaluation sets across 15 ASR, 2 ST, and 3 SLU benchmarks, while being more stable during training.'}\nUrl: http://arxiv.org/pdf/2305.11073",
  "Faculty Name: shinji watanabe\nPaperid: 16fbcf340648b302ad8d4e6ed34c7ab5ad346db9\nTitle: Efficient Sequence Transduction by Jointly Predicting Tokens and Durations\nYear: 2023\nAbstract: This paper introduces a novel Token-and-Duration Transducer (TDT) architecture for sequence-to-sequence tasks. TDT extends conventional RNN-Transducer architectures by jointly predicting both a token and its duration, i.e. the number of input frames covered by the emitted token. This is achieved by using a joint network with two outputs which are independently normalized to generate distributions over tokens and durations. During inference, TDT models can skip input frames guided by the predicted duration output, which makes them significantly faster than conventional Transducers which process the encoder output frame by frame. TDT models achieve both better accuracy and significantly faster inference than conventional Transducers on different sequence transduction tasks. TDT models for Speech Recognition achieve better accuracy and up to 2.82X faster inference than conventional Transducers.",
  "TDT models achieve both better accuracy and significantly faster inference than conventional Transducers on different sequence transduction tasks. TDT models for Speech Recognition achieve better accuracy and up to 2.82X faster inference than conventional Transducers. TDT models for Speech Translation achieve an absolute gain of over 1 BLEU on the MUST-C test compared with conventional Transducers, and its inference is 2.27X faster. In Speech Intent Classification and Slot Filling tasks, TDT models improve the intent accuracy by up to over 1% (absolute) over conventional Transducers, while running up to 1.28X faster. Our implementation of the TDT model will be open-sourced with the NeMo (https://github.com/NVIDIA/NeMo) toolkit.\nAuthors: Hainan Xu, Fei Jia, Somshubra Majumdar, Hengguan Huang, Shinji Watanabe, Boris Ginsburg\nVenue: International Conference on Machine Learning\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A novel Token-and-Duration Transducer architecture for sequence-to-sequence tasks by jointly predicting both a token and its duration, i.e.",
  "the number of input frames covered by the emitted token.'}\nUrl: http://arxiv.org/pdf/2304.06795",
  "Faculty Name: shinji watanabe\nPaperid: 1ac784bfd7c64b35d4914b80d7974038e3dd092a\nTitle: Effect of medium-chain triglycerides supplements and walking on health-related quality of life in sedentary, healthy middle-aged, and older adults with low BMIs: a randomized, double-blind, placebo-controlled, parallel-group trial\nYear: 2023\nAbstract: Introduction To extend individuals\u2019 healthy life expectancies, the improvement of subjective health and quality of life (QOL) has been increasingly prioritized, alongside the improvement of their physical functioning. Reports have indicated that intake of medium-chain triglycerides (MCTs) benefits the physical health of older individuals requiring nursing care, and athletes, and healthy individuals. But there are few studies investigating the effects of MCTs on subjective health and QOL. The present study sought to evaluate the combined effects of 12-week MCTs supplements and moderate-intensity walking exercise on the subjective health and QOL of middle-aged and older adults aged 60\u201374 with low BMIs (< 24\u2009kg/m2) and who had no exercise habits.",
  "The present study sought to evaluate the combined effects of 12-week MCTs supplements and moderate-intensity walking exercise on the subjective health and QOL of middle-aged and older adults aged 60\u201374 with low BMIs (< 24\u2009kg/m2) and who had no exercise habits. Methods A placebo-controlled, double-blind, parallel-group trial was conducted. Three MCTs supplement groups with different doses and fatty acid compositions were compared with a control group. The study used the SF-36v2 questionnaire to assess subjective health and health-related QOL (HRQOL). Results The result showed significant improvements in the scores on subscales of the physical QOL, such as Physical functioning and General health, and summary scores on the mental QOL, compared to the control. Conclusion It is estimated that the combination of continuous intake of MCTs and walking exercise may affect HRQOL and improve subjective physical and mental health in sedentary, healthy, middle-aged and older adults. Clinical trial registration https://rctportal.niph.go.jp/s/detail/um?trial_id=UMIN000046861, UMIN000046861.",
  "Clinical trial registration https://rctportal.niph.go.jp/s/detail/um?trial_id=UMIN000046861, UMIN000046861.\nAuthors: Haruna Ishikawa, Keiichi Kojima, Shinji Watanabe, N. Nosaka, Tatsushi Mutoh\nVenue: Frontiers in Nutrition\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is estimated that the combination of continuous intake of MCTs and walking exercise may affect HRQOL and improve subjective physical and mental health in sedentary, healthy, middle-aged and older adults.'}\nUrl: https://www.frontiersin.org/articles/10.3389/fnut.2023.1296896/pdf?isPublishedV2=False",
  "Faculty Name: shinji watanabe\nPaperid: 1dc2d0f43df7f7a7847817203411357eca79a5b3\nTitle: Reducing Barriers to Self-Supervised Learning: HuBERT Pre-training with Academic Compute\nYear: 2023\nAbstract: Self-supervised learning (SSL) has led to great strides in speech processing. However, the resources needed to train these models has become prohibitively large as they continue to scale. Currently, only a few groups with substantial resources are capable of creating SSL models, which harms reproducibility. In this work, we optimize HuBERT SSL to fit in academic constraints. We reproduce HuBERT independently from the original implementation, with no performance loss. Our code and training optimizations make SSL feasible with only 8 GPUs, instead of the 32 used in the original work. We also explore a semi-supervised route, using an ASR model to skip the first pre-training iteration. Within one iteration of pre-training, our models improve over HuBERT on several tasks. Furthermore, our HuBERT Large variant requires only 8 GPUs, achieving similar performance to the original trained on 128.",
  "Within one iteration of pre-training, our models improve over HuBERT on several tasks. Furthermore, our HuBERT Large variant requires only 8 GPUs, achieving similar performance to the original trained on 128. As our contribution to the community, all models, configurations, and code are made open-source in ESPnet.\nAuthors: William Chen, Xuankai Chang, Yifan Peng, Zhaoheng Ni, Soumi Maiti, Shinji Watanabe\nVenue: Interspeech\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work optimizing HuBERT SSL to fit in academic constraints, and reproducibility, and explores a semi-supervised route, using an ASR model to skip the first pre-training iteration.'}\nUrl: http://arxiv.org/pdf/2306.06672",
  "Faculty Name: shinji watanabe\nPaperid: 2126b5497eb51926d0baac655a1e0f88f0d1ec00\nTitle: Antiviral efficacy against and replicative fitness of an XBB.1.9.1 clinical isolate\nYear: 2023\nAbstract: None\nAuthors: R. Uraki, Mutsumi Ito, Maki Kiso, S. Yamayoshi, K. Iwatsuki-Horimoto, Yuko Sakai-Tagawa, Masaki Imai, M. Koga, Shinya Yamamoto, E. Adachi, Makoto Saito, T. Tsutsumi, Amato Otani, S. Fukushi, Shinji Watanabe, Tadaki Suzuki, Tetsuhiro Kikuchi, H. Yotsuyanagi, Maeda Ken, Yoshihiro Kawaoka\nVenue: iScience\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The results suggest that XBB.1.9.2.1 and X BB.1-CoV-2 have similar antigenicity and replicative ability,",
  "Yoshihiro Kawaoka\nVenue: iScience\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The results suggest that XBB.1.9.2.1 and X BB.1-CoV-2 have similar antigenicity and replicative ability, and that the currently available COVID-19 antivirals remain effective against XBB, even at the highest concentration used.'}\nUrl: N/A",
  "Faculty Name: shinji watanabe\nPaperid: 2567a34501c1b258c102a07e737b87e556af0809\nTitle: Speech Summarization of Long Spoken Document: Improving Memory Efficiency of Speech/Text Encoders\nYear: 2023\nAbstract: Speech summarization requires processing several minute-long speech sequences to allow exploiting the whole context of a spoken document. A conventional approach is a cascade of automatic speech recognition (ASR) and text summarization (TS). However, the cascade systems are sensitive to ASR errors. Moreover, the cascade system cannot be optimized for input speech and utilize para-linguistic information. Recently, there has been an increased interest in end-to-end (E2E) approaches optimized to output summaries directly from speech. Such systems can thus mitigate the ASR errors of cascade approaches. However, E2E speech summarization requires massive computational resources because it needs to encode long speech sequences. We propose a speech summarization system that enables E2E summarization from 100 seconds, which is the limit of the conventional method, to up to 10 minutes (i.e., the duration of typical instructional videos on YouTube).",
  "We propose a speech summarization system that enables E2E summarization from 100 seconds, which is the limit of the conventional method, to up to 10 minutes (i.e., the duration of typical instructional videos on YouTube). However, the modeling capability of this model for minute-long speech sequences is weaker than the conventional approach. We thus exploit auxiliary text information from ASR transcriptions to improve the modeling capabilities. The resultant system consists of a dual speech/text encoder decoder-based summarization system. We perform experiments on the How2 dataset showing the proposed system improved METEOR scores by up to 2.7 points by fully exploiting the long spoken documents.",
  "The resultant system consists of a dual speech/text encoder decoder-based summarization system. We perform experiments on the How2 dataset showing the proposed system improved METEOR scores by up to 2.7 points by fully exploiting the long spoken documents.\nAuthors: Takatomo Kano, A. Ogawa, Marc Delcroix, Roshan Sharma, Kohei Matsuura, Shinji Watanabe\nVenue: IEEE International Conference on Acoustics, Speech, and Signal Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes a speech summarization system that enables E2E summarization from 100 seconds, which is the limit of the conventional method, to up to 10 minutes (i.e., the duration of typical instructional videos on YouTube), and exploits auxiliary text information from ASR transcriptions to improve the modeling capabilities.'}\nUrl: N/A",
  "Faculty Name: shinji watanabe\nPaperid: 25b28a08a75ad0e6c8ed27f48c59199fba15fcbd\nTitle: FindAdaptNet: Find and Insert Adapters by Learned Layer Importance\nYear: 2023\nAbstract: Adapters are lightweight bottleneck modules introduced to assist pre-trained self-supervised learning (SSL) models to be customized to new tasks. However, searching the appropriate layers to insert adapters on large models has become difficult due to the large number of possible layers and thus a vast search space (2N possibilities for N layers). In this paper, we propose a technique that achieves automatic insertion of adapters for downstream automatic speech recognition (ASR) and spoken language understanding (SLU) tasks. Our approach is based on two-stage training. First, we train our model for a specific downstream task with additional shallow learnable layers and weight parameters to obtain the weighted summation over the output of each layer in SSL. This training method is established by the SUPERB baseline [1]. This first-stage training determines the most important layers given their respective weights.",
  "This training method is established by the SUPERB baseline [1]. This first-stage training determines the most important layers given their respective weights. In the second stage, we proceed to insert adapters to the most important layers, retaining both performance and neural architecture search efficiency. On the CommonVoice dataset[2] we obtain 20.6% absolute improvement in Word Error Rate (WER) on the Welsh language against the conventional method, which inserts the adapter modules into the highest layers without search. In the SLURP SLU task, our method yields 4.0% intent accuracy improvement against the same conventional baseline.\nAuthors: Junwei Huang, Karthik Ganesan, Soumi Maiti, Young Min Kim, Xuankai Chang, Paul Liang, Shinji Watanabe\nVenue: IEEE International Conference on Acoustics, Speech, and Signal Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper proposes a technique that achieves automatic insertion of adapters for downstream automatic speech recognition (ASR) and spoken language understanding (SLU) tasks, based on two-stage training based on a weighted summation over the output of each layer in SSL.'}",
  "Url: N/A",
  "Faculty Name: shinji watanabe\nPaperid: 25c399a231364f4a77d1dc4b59927585e63f5f11\nTitle: UNSSOR: Unsupervised Neural Speech Separation by Leveraging Over-determined Training Mixtures\nYear: 2023\nAbstract: In reverberant conditions with multiple concurrent speakers, each microphone acquires a mixture signal of multiple speakers at a different location. In over-determined conditions where the microphones out-number speakers, we can narrow down the solutions to speaker images and realize unsupervised speech separation by leveraging each mixture signal as a constraint (i.e., the estimated speaker images at a microphone should add up to the mixture). Equipped with this insight, we propose UNSSOR, an algorithm for $\\textbf{u}$nsupervised $\\textbf{n}$eural $\\textbf{s}$peech $\\textbf{s}$eparation by leveraging $\\textbf{o}$ver-determined training mixtu$\\textbf{r}$es.",
  "At each training step, we feed an input mixture to a deep neural network (DNN) to produce an intermediate estimate for each speaker, linearly filter the estimates, and optimize a loss so that, at each microphone, the filtered estimates of all the speakers can add up to the mixture to satisfy the above constraint. We show that this loss can promote unsupervised separation of speakers. The linear filters are computed in each sub-band based on the mixture and DNN estimates through the forward convolutive prediction (FCP) algorithm. To address the frequency permutation problem incurred by using sub-band FCP, a loss term based on minimizing intra-source magnitude scattering is proposed. Although UNSSOR requires over-determined training mixtures, we can train DNNs to achieve under-determined separation (e.g., unsupervised monaural speech separation). Evaluation results on two-speaker separation in reverberant conditions show the effectiveness and potential of UNSSOR.",
  "Although UNSSOR requires over-determined training mixtures, we can train DNNs to achieve under-determined separation (e.g., unsupervised monaural speech separation). Evaluation results on two-speaker separation in reverberant conditions show the effectiveness and potential of UNSSOR.\nAuthors: Zhong-Qiu Wang, Shinji Watanabe\nVenue: Neural Information Processing Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Evaluation results on two-speaker separation in reverberant conditions show the effectiveness and potential of UNSSOR, an algorithm for over-determined training mixtures that can promote unsupervised separation of speakers.'}\nUrl: http://arxiv.org/pdf/2305.20054",
  "Faculty Name: shinji watanabe\nPaperid: 2f9860ab7979516fe2d4b503bb4b0bcdbd045bf2\nTitle: Antigenic drift and subtype interference shape A(H3N2) epidemic dynamics in the United States\nYear: 2023\nAbstract: Influenza viruses continually evolve new antigenic variants, through mutations in epitopes of their major surface proteins, hemagglutinin (HA) and neuraminidase (NA). Antigenic drift potentiates the reinfection of previously infected individuals, but the contribution of this process to variability in annual epidemics is not well understood. Here we link influenza A(H3N2) virus evolution to regional epidemic dynamics in the United States during 1997-2019. We integrate phenotypic measures of HA antigenic drift and sequence-based measures of HA and NA fitness to infer antigenic and genetic distances between viruses circulating in successive seasons.",
  "Here we link influenza A(H3N2) virus evolution to regional epidemic dynamics in the United States during 1997-2019. We integrate phenotypic measures of HA antigenic drift and sequence-based measures of HA and NA fitness to infer antigenic and genetic distances between viruses circulating in successive seasons. We estimate the magnitude, severity, timing, transmission rate, age-specific patterns, and subtype dominance of each regional outbreak and find that genetic distance based on broad sets of epitope sites is the strongest evolutionary predictor of A(H3N2) virus epidemiology. Increased HA and NA epitope distance between seasons correlates with larger, more intense epidemics, higher transmission, greater A(H3N2) subtype dominance, and a greater proportion of cases in adults relative to children, consistent with increased population susceptibility. Based on random forest models, A(H1N1) incidence impacts A(H3N2) epidemics to a greater extent than viral evolution, suggesting that subtype interference is a major driver of influenza A virus infection dynamics, presumably via heterosubtypic cross-immunity.",
  "Based on random forest models, A(H1N1) incidence impacts A(H3N2) epidemics to a greater extent than viral evolution, suggesting that subtype interference is a major driver of influenza A virus infection dynamics, presumably via heterosubtypic cross-immunity.\nAuthors: A. Perofsky, John Huddleston, Chelsea Hansen, John R. Barnes, Thomas Rowe, Xiyan Xu, Rebecca J. Kondor, D. Wentworth, Nicola S. Lewis, L. Whittaker, B. Ermetal, Ruth Harvey, Monica Galiano, R. S. Daniels, John W McCauley, Seiichiro Fujisaki, Kazuya Nakamura, Noriko Kishida, Shinji Watanabe, Hideki Hasegawa, Sheena G. Sullivan, Ian G. Barr, Kanta Subbarao, F. Krammer, Trevor Bedford, C\u00e9cile Viboud\nVenue: medRxiv\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Increased HA and NA epitope distance between seasons correlates with larger, more intense epidemics, higher transmission, greater A(H3N2) subtype dominance, and a greater proportion of cases in adults relative to children, consistent with increased population susceptibility.'}",
  "Url: N/A",
  "Faculty Name: shinji watanabe\nPaperid: 331af9b7193e563b021e8e6892e7cb3030decd38\nTitle: Segment-Level Vectorized Beam Search Based on Partially Autoregressive Inference\nYear: 2023\nAbstract: Attention-based encoder-decoder models with autoregressive (AR) decoding have proven to be the dominant approach for automatic speech recognition (ASR) due to their superior accuracy. However, they often suffer from slow inference. This is primarily attributed to the incremental calculation of the decoder. This work proposes a partially AR framework, which employs segment-level vectorized beam search for improving the inference speed of an ASR model based on the hybrid connectionist temporal classification (CTC) attention-based architecture. It first generates an initial hypothesis using greedy CTC decoding, identifying low-confidence tokens based on their output probabilities. We then utilize the decoder to perform segment-level vectorized beam search on these tokens, re-predicting in parallel with minimal decoder calculations. Experimental results show that our method is 12 to 13 times faster in inference on the LibriSpeech corpus over AR decoding whilst preserving high accuracy.",
  "We then utilize the decoder to perform segment-level vectorized beam search on these tokens, re-predicting in parallel with minimal decoder calculations. Experimental results show that our method is 12 to 13 times faster in inference on the LibriSpeech corpus over AR decoding whilst preserving high accuracy.\nAuthors: Masao Someki, N. Eng, Yosuke Higuchi, Shinji Watanabe\nVenue: Automatic Speech Recognition & Understanding\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A partially AR framework, which employs segment-level vectorized beam search for improving the inference speed of an ASR model based on the hybrid connectionist temporal classification (CTC) attention-based architecture, which is 12 to 13 times faster in inference on the LibriSpeech corpus over AR decoding whilst preserving high accuracy.'}\nUrl: https://arxiv.org/pdf/2309.14922",
  "Faculty Name: shinji watanabe\nPaperid: 3b93dd5f2d2512a4b58f6c776af59f74a90764a5\nTitle: Unsupervised Data Selection for TTS: Using Arabic Broadcast News as a Case Study\nYear: 2023\nAbstract: .\nAuthors: Massa Baali, Tomoki Hayashi, Hamdy Mubarak, Soumi Maiti, Shinji Watanabe, W. El-Hajj, Ahmed Ali\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': None}\nUrl: http://arxiv.org/pdf/2301.09099",
  "Faculty Name: shinji watanabe\nPaperid: 3bd320ddb25886417ae90011b00f13f5d558097b\nTitle: BASS: Block-wise Adaptation for Speech Summarization\nYear: 2023\nAbstract: End-to-end speech summarization has been shown to improve performance over cascade baselines. However, such models are difficult to train on very large inputs (dozens of minutes or hours) owing to compute restrictions and are hence trained with truncated model inputs. Truncation leads to poorer models, and a solution to this problem rests in block-wise modeling, i.e., processing a portion of the input frames at a time. In this paper, we develop a method that allows one to train summarization models on very long sequences in an incremental manner. Speech summarization is realized as a streaming process, where hypothesis summaries are updated every block based on new acoustic information. We devise and test strategies to pass semantic context across the blocks. Experiments on the How2 dataset demonstrate that the proposed block-wise training method improves by 3 points absolute on ROUGE-L over a truncated input baseline.",
  "We devise and test strategies to pass semantic context across the blocks. Experiments on the How2 dataset demonstrate that the proposed block-wise training method improves by 3 points absolute on ROUGE-L over a truncated input baseline.\nAuthors: Roshan Sharma, Kenneth Zheng, Siddhant Arora, Shinji Watanabe, Rita Singh, B. Raj\nVenue: Interspeech\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper develops a method that allows one to train summarization models on very long sequences in an incremental manner and devise and test strategies to pass semantic context across the blocks.'}\nUrl: https://arxiv.org/pdf/2307.08217",
  "Faculty Name: shinji watanabe\nPaperid: 3c01b59cd923192913bb96849a892c5732c40d3d\nTitle: CMU\u2019s IWSLT 2023 Simultaneous Speech Translation System\nYear: 2023\nAbstract: This paper describes CMU\u2019s submission to the IWSLT 2023 simultaneous speech translation shared task for translating English speech to both German text and speech in a streaming fashion. We first build offline speech-to-text (ST) models using the joint CTC/attention framework. These models also use WavLM front-end features and mBART decoder initialization. We adapt our offline ST models for simultaneous speech-to-text translation (SST) by 1) incrementally encoding chunks of input speech, re-computing encoder states for each new chunk and 2) incrementally decoding output text, pruning beam search hypotheses to 1-best after processing each chunk. We then build text-to-speech (TTS) models using the VITS framework and achieve simultaneous speech-to-speech translation (SS2ST) by cascading our SST and TTS models.",
  "We then build text-to-speech (TTS) models using the VITS framework and achieve simultaneous speech-to-speech translation (SS2ST) by cascading our SST and TTS models.\nAuthors: Brian Yan, Jiatong Shi, Soumi Maiti, William Chen, Xinjian Li, Yifan Peng, Siddhant Arora, Shinji Watanabe\nVenue: International Workshop on Spoken Language Translation\nTldr: {'model': 'tldr@v2.0.0', 'text': 'CMU\u2019s submission to the IWSLT 2023 simultaneous speech translation shared task for translating English speech to both German text and speech in a streaming fashion is described.'}\nUrl: https://aclanthology.org/2023.iwslt-1.20.pdf",
  "Faculty Name: shinji watanabe\nPaperid: 3fb0c9a82c0d9c01448b37600efefb780e5362fe\nTitle: Crystalline electric field and magnetic anisotropy in Dy-based icosahedral quasicrystal and approximant\nYear: 2023\nAbstract: The lack of the theory of the crystalline electric field (CEF) in rare-earth based quasicrystal (QC) and approximant crystal (AC) has prevented us from understanding the electronic states. Recent success of the formulation of the CEF theory on the basis of the point charge model has made it possible to analyze the CEF microscopically. Here, by applying this formulation to the QC Au-SM-Dy (SM=Si, Ge, Al, and Ga) and AC, we theoretically analyze the CEF. In the Dy$^{3+}$ ion with $4f^9$ configuration, the CEF Hamiltonian is diagonalized by the basis set for the total angular momentum $J=15/2$.",
  "In the Dy$^{3+}$ ion with $4f^9$ configuration, the CEF Hamiltonian is diagonalized by the basis set for the total angular momentum $J=15/2$. The ratio of the valences of the screened ligand ions $\\alpha=Z_{\\rm SM}/Z_{\\rm Au}$ plays an important role in characterizing the CEF ground state. For $0\\le\\alpha<0.30$, the magnetic easy axis for the CEF ground state is shown to be perpendicular to the mirror plane. On the other hand, for $\\alpha>0.30$, the magnetic easy axis is shown to be lying in the mirror plane and as $\\alpha$ increases, the easy axis rotates to the clockwise direction in the mirror plane at the Dy site and tends to approach the pseudo 5 fold axis. Possible relevance of these results to experiments is discussed.\nAuthors: S. Watanabe, T. Iwasaki\nVenue: Physical review B\nTldr: None\nUrl: https://arxiv.org/pdf/2307.11633",
  "Faculty Name: shinji watanabe\nPaperid: 47ba7df38e24da9bad9266d2b58abbb2b70db6e5\nTitle: Exploration of Efficient End-to-End ASR using Discretized Input from Self-Supervised Learning\nYear: 2023\nAbstract: Self-supervised learning (SSL) of speech has shown impressive results in speech-related tasks, particularly in automatic speech recognition (ASR). While most methods employ the output of intermediate layers of the SSL model as real-valued features for downstream tasks, there is potential in exploring alternative approaches that use discretized token sequences. This approach offers benefits such as lower storage requirements and the ability to apply techniques from natural language processing. In this paper, we propose a new protocol that utilizes discretized token sequences in ASR tasks, which includes de-duplication and sub-word modeling to enhance the input sequence. It reduces computational cost by decreasing the length of the sequence. Our experiments on the LibriSpeech dataset demonstrate that our proposed protocol performs competitively with conventional ASR systems using continuous input features, while reducing computational and storage costs.",
  "It reduces computational cost by decreasing the length of the sequence. Our experiments on the LibriSpeech dataset demonstrate that our proposed protocol performs competitively with conventional ASR systems using continuous input features, while reducing computational and storage costs.\nAuthors: Xuankai Chang, Brian Yan, Yuya Fujita, Takashi Maekaku, Shinji Watanabe\nVenue: Interspeech\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper proposes a new protocol that utilizes discretized token sequences in ASR tasks, which includes de-duplication and sub-word modeling to enhance the input sequence and reduces computational cost by decreasing the length of the sequence.'}\nUrl: http://arxiv.org/pdf/2305.18108",
  "Faculty Name: shinji watanabe\nPaperid: 48c6318dbcf9908cabe0023b8817566f34d0b466\nTitle: I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition\nYear: 2023\nAbstract: Transformer-based end-to-end speech recognition has achieved great success. However, the large footprint and computational overhead make it difficult to deploy these models in some real-world applications. Model compression techniques can reduce the model size and speed up inference, but the compressed model has a fixed architecture which might be suboptimal. We propose a novel Transformer encoder with Input-Dependent Dynamic Depth (I3D) to achieve strong performance-efficiency trade-offs. With a similar number of layers at inference time, I3D-based models outperform the vanilla Transformer and the static pruned model via iterative layer pruning. We also present interesting analysis on the gate probabilities and the input-dependency, which helps us better understand deep encoders.",
  "With a similar number of layers at inference time, I3D-based models outperform the vanilla Transformer and the static pruned model via iterative layer pruning. We also present interesting analysis on the gate probabilities and the input-dependency, which helps us better understand deep encoders.\nAuthors: Yifan Peng, Jaesong Lee, Shinji Watanabe\nVenue: IEEE International Conference on Acoustics, Speech, and Signal Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A novel Transformer encoder with Input-Dependent Dynamic Depth (I3D) to achieve strong performance-efficiency trade-offs and interesting analysis on the gate probabilities and the input-dependency, which helps to better understand deep encoders.'}\nUrl: https://arxiv.org/pdf/2303.07624",
  "Faculty Name: shinji watanabe\nPaperid: 4b8d3ede673ddeab9dfb5184da6b748d7a526754\nTitle: A Vector Quantized Approach for Text to Speech Synthesis on Real-World Spontaneous Speech\nYear: 2023\nAbstract: Recent Text-to-Speech (TTS) systems trained on reading or acted corpora have achieved near human-level naturalness. The diversity of human speech, however, often goes beyond the coverage of these corpora. We believe the ability to handle such diversity is crucial for AI systems to achieve human-level communication. Our work explores the use of more abundant real-world data for building speech synthesizers. We train TTS systems using real-world speech from YouTube and podcasts. We observe the mismatch between training and inference alignments in mel-spectrogram based autoregressive models, leading to unintelligible synthesis, and demonstrate that learned discrete codes within multiple code groups effectively resolves this issue. We introduce our MQTTS system whose architecture is designed for multiple code generation and monotonic alignment, along with the use of a clean silence prompt to improve synthesis quality.",
  "We introduce our MQTTS system whose architecture is designed for multiple code generation and monotonic alignment, along with the use of a clean silence prompt to improve synthesis quality. We conduct ablation analyses to identify the efficacy of our methods. We show that MQTTS outperforms existing TTS systems in several objective and subjective measures.\nAuthors: Li-Wei Chen, Shinji Watanabe, Alexander I. Rudnicky\nVenue: AAAI Conference on Artificial Intelligence\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work introduces the MQTTS system, a Text-to-Speech system whose architecture is designed for multiple code generation and monotonic alignment, along with the use of a clean silence prompt to improve synthesis quality, and shows that MqTTS outperforms existing TTS systems in several objective and subjective measures.'}\nUrl: http://arxiv.org/pdf/2302.04215",
  "Faculty Name: shinji watanabe\nPaperid: 4c6bb748e22e2e599faf8fd30821ee03053579b7\nTitle: A Randomized, Double-Blind, Controlled Trial Assessing If Medium-Chain Triglycerides in Combination with Moderate-Intensity Exercise Increase Muscle Strength in Healthy Middle-Aged and Older Adults\nYear: 2023\nAbstract: An adequate nutritional intake is recommended for the prevention of physical frailty and sarcopenia. In particular, medium-chain fatty acids (MCFAs) are reportedly important for muscle strength in nursing home residents. However, the effects of MCFAs on healthy adults at risk for frailty remain unknown. Hence, a randomized, placebo-controlled study was conducted to investigate the effects of 12 weeks of medium-chain triglycerides (MCTs) intake and walking on muscle mass and function in healthy, sedentary, middle-aged and older adults with a low body mass index. Three MCT intake groups with different amounts of octanoic and decanoic acid intake were compared with a control group.",
  "Three MCT intake groups with different amounts of octanoic and decanoic acid intake were compared with a control group. After 12 weeks, knee extension strength increased in all groups, with the increases in all MCT intake groups being significantly higher than those in the control group (p < 0.05). Grip strength significantly increased from baseline in the MCT 6 g/day intake group (p < 0.05). The combination of aerobic exercise and MCT intake may be effective in preventing decline in muscle strength and promoting increase in muscle strength as they can improve muscle energy production, thereby contributing to the maintenance of good health for middle-aged and older adults at high risk for frailty and sarcopenia.",
  "The combination of aerobic exercise and MCT intake may be effective in preventing decline in muscle strength and promoting increase in muscle strength as they can improve muscle energy production, thereby contributing to the maintenance of good health for middle-aged and older adults at high risk for frailty and sarcopenia.\nAuthors: K. Kojima, Haruna Ishikawa, Shinji Watanabe, N. Nosaka, Tatsushi Mutoh\nVenue: Nutrients\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The combination of aerobic exercise and MCT intake may be effective in preventing decline in muscle strength and promoting increase in Muscle strength as they can improve muscle energy production, thereby contributing to the maintenance of good health for middle-aged and older adults at high risk for frailty and sarcopenia.'}\nUrl: https://www.mdpi.com/2072-6643/15/14/3275/pdf?version=1690245983",
  "Faculty Name: shinji watanabe\nPaperid: 4d35540aaf993c8fa7e1fa5fc6a990f1eb830263\nTitle: A New Benchmark of Aphasia Speech Recognition and Detection Based on E-Branchformer and Multi-task Learning\nYear: 2023\nAbstract: Aphasia is a language disorder that affects the speaking ability of millions of patients. This paper presents a new benchmark for Aphasia speech recognition and detection tasks using state-of-the-art speech recognition techniques with the AphsiaBank dataset. Specifically, we introduce two multi-task learning methods based on the CTC/Attention architecture to perform both tasks simultaneously. Our system achieves state-of-the-art speaker-level detection accuracy (97.3%), and a relative WER reduction of 11% for moderate Aphasia patients. In addition, we demonstrate the generalizability of our approach by applying it to another disordered speech database, the DementiaBank Pitt corpus. We will make our all-in-one recipes and pre-trained model publicly available to facilitate reproducibility. Our standardized data preprocessing pipeline and open-source recipes enable researchers to compare results directly, promoting progress in disordered speech processing.",
  "We will make our all-in-one recipes and pre-trained model publicly available to facilitate reproducibility. Our standardized data preprocessing pipeline and open-source recipes enable researchers to compare results directly, promoting progress in disordered speech processing.\nAuthors: Jiyang Tang, William Chen, Xuankai Chang, Shinji Watanabe, B. MacWhinney\nVenue: Interspeech\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A new benchmark for Aphasia speech recognition and detection tasks using state-of-the-art speech recognition techniques with the AphsiaBank dataset is presented and two multi-task learning methods based on the CTC/Attention architecture are introduced to perform both tasks simultaneously.'}\nUrl: http://arxiv.org/pdf/2305.13331",
  "Faculty Name: shinji watanabe\nPaperid: 52d2c8d36c4ace01d8c440a44e1a7fdea04ec482\nTitle: Antiviral Susceptibilities of Distinct Lineages of Influenza C and D Viruses\nYear: 2023\nAbstract: The emergence and spread of antiviral-resistant influenza viruses are of great concern. To minimize the public health risk, it is important to monitor antiviral susceptibilities of influenza viruses. Analyses of the antiviral susceptibilities of influenza A and B viruses have been conducted globally; however, those of influenza C and D viruses are limited. Here, we determined the susceptibilities of influenza C viruses representing all six lineages (C/Taylor, C/Yamagata, C/Sao Paulo, C/Aichi, C/Kanagawa, and C/Mississippi) and influenza D viruses representing four lineages (D/OK, D/660, D/Yama2016, and D/Yama2019) to RNA polymerase inhibitors (baloxavir and favipiravir) by using a focus reduction assay.",
  "All viruses tested were susceptible to both drugs. We then performed a genetic analysis to check for amino acid substitutions associated with baloxavir and favipiravir resistance and found that none of the viruses tested possessed these substitutions. Use of the focus reduction assay with the genotypic assay has proven valuable for monitoring the antiviral susceptibilities of influenza C and D viruses as well as influenza A and B viruses. Antiviral susceptibility monitoring of all influenza virus types should continue in order to assess the public health risks posed by these viruses.\nAuthors: E. Takashita, S. Murakami, Y. Matsuzaki, Seiichiro Fujisaki, H. Morita, Shiho Nagata, Misa Katayama, K. Mizuta, H. Nishimura, Shinji Watanabe, T. Horimoto, H. Hasegawa\nVenue: Viruses\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Use of the focus reduction assay with the genotypic assay has proven valuable for monitoring the antiviral susceptibilities of influenza C and D viruses as well as influenza A and B viruses.'}",
  "Url: https://www.mdpi.com/1999-4915/15/1/244/pdf?version=1674098063",
  "Faculty Name: shinji watanabe\nPaperid: 611f9ee6eef0936462cd78f371798d0699951c59\nTitle: Paaploss: A Phonetic-Aligned Acoustic Parameter Loss for Speech Enhancement\nYear: 2023\nAbstract: Despite rapid advancement in recent years, current speech enhancement models often produce speech that differs in perceptual quality from real clean speech. We propose a learning objective that formalizes differences in perceptual quality, by using domain knowledge of acoustic-phonetics. We identify temporal acoustic parameters \u2013 such as spectral tilt, spectral flux, shimmer, etc. \u2013 that are non-differentiable, and we develop a neural network estimator that can accurately predict their time-series values across an utterance. We also model phoneme-specific weights for each feature, as the acoustic parameters are known to show different behavior in different phonemes. We can add this criterion as an auxiliary loss to any model that produces speech, to optimize speech outputs to match the values of clean speech in these features. Experimentally we show that it improves speech enhancement workflows in both time-domain and time-frequency domain, as measured by standard evaluation metrics.",
  "We can add this criterion as an auxiliary loss to any model that produces speech, to optimize speech outputs to match the values of clean speech in these features. Experimentally we show that it improves speech enhancement workflows in both time-domain and time-frequency domain, as measured by standard evaluation metrics. We also provide an analysis of phoneme-dependent improvement on acoustic parameters, demonstrating the additional interpretability that our method provides. This analysis can suggest which features are currently the bottleneck for improvement.\nAuthors: Muqiao Yang, Joseph Konan, David Bick, YUNYANG ZENG, Shuo Han, Anurag Kumar, Shinji Watanabe, B. Raj\nVenue: IEEE International Conference on Acoustics, Speech, and Signal Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A learning objective is proposed that formalizes differences in perceptual quality, by using domain knowledge of acoustic-phonetics, and a neural network estimator is developed that can accurately predict their time-series values across an utterance.'}\nUrl: https://arxiv.org/pdf/2302.08095",
  "Faculty Name: shinji watanabe\nPaperid: 659be1ff350634f50cc066d258ee6a45e697e552\nTitle: SigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing\nYear: 2023\nAbstract: In our submission to the SIGMORPHON 2023 Shared Task on interlinear glossing (IGT), we explore approaches to data augmentation and modeling across seven low-resource languages. For data augmentation, we explore two approaches: creating artificial data from the provided training data and utilizing existing IGT resources in other languages. On the modeling side, we test an enhanced version of the provided token classification baseline as well as a pretrained multilingual seq2seq model. Additionally, we apply post-correction using a dictionary for Gitksan, the language with the smallest amount of data. We find that our token classification models are the best performing, with the highest word-level accuracy for Arapaho and highest morpheme-level accuracy for Gitksan out of all submissions. We also show that data augmentation is an effective strategy, though applying artificial data pretraining has very different effects across both models tested.",
  "We find that our token classification models are the best performing, with the highest word-level accuracy for Arapaho and highest morpheme-level accuracy for Gitksan out of all submissions. We also show that data augmentation is an effective strategy, though applying artificial data pretraining has very different effects across both models tested.\nAuthors: Taiqi He, Lindia Tjuatja, Nathaniel R. Robinson, Shinji Watanabe, David R. Mortensen, Graham Neubig, L. Levin\nVenue: Special Interest Group on Computational Morphology and Phonology Workshop\nTldr: {'model': 'tldr@v2.0.0', 'text': 'In this submission to the SIGMORPHON 2023 Shared Task on interlinear glossing (IGT), approaches to data augmentation and modeling across seven low-resource languages are explored and token classification models are found to be the best performing.'}\nUrl: https://aclanthology.org/2023.sigmorphon-1.22.pdf",
  "Faculty Name: shinji watanabe\nPaperid: 6c2b800cd03ad064922c8596a18d784ce25d47ac\nTitle: Integration of Frame- and Label-synchronous Beam Search for Streaming Encoder-decoder Speech Recognition\nYear: 2023\nAbstract: Although frame-based models, such as CTC and transducers, have an affinity for streaming automatic speech recognition, their decoding uses no future knowledge, which could lead to incorrect pruning. Conversely, label-based attention encoder-decoder mitigates this issue using soft attention to the input, while it tends to overestimate labels biased towards its training domain, unlike CTC. We exploit these complementary attributes and propose to integrate the frame- and label-synchronous (F-/L-Sync) decoding alternately performed within a single beam-search scheme. F-Sync decoding leads the decoding for block-wise processing, while L-Sync decoding provides the prioritized hypotheses using look-ahead future frames within a block. We maintain the hypotheses from both decoding methods to perform effective pruning. Experiments demonstrate that the proposed search algorithm achieves lower error rates compared to the other search methods, while being robust against out-of-domain situations.",
  "We maintain the hypotheses from both decoding methods to perform effective pruning. Experiments demonstrate that the proposed search algorithm achieves lower error rates compared to the other search methods, while being robust against out-of-domain situations.\nAuthors: E. Tsunoo, Hayato Futami, Yosuke Kashiwagi, Siddhant Arora, Shinji Watanabe\nVenue: Interspeech\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes to integrate the frame- and label-synchronous (F-/L-Sync) decoding alternately performed within a single beam-search scheme and maintains the hypotheses from both decoding methods to perform effective pruning.'}\nUrl: https://arxiv.org/pdf/2307.12767",
  "Faculty Name: shinji watanabe\nPaperid: 6c33625c7b0ffc37955921a145531d9d4eaee713\nTitle: Exploring the Integration of Speech Separation and Recognition with Self-Supervised Learning Representation\nYear: 2023\nAbstract: Neural speech separation has made remarkable progress and its integration with automatic speech recognition (ASR) is an important direction towards realizing multi-speaker ASR. This work provides an insightful investigation of speech separation in reverberant and noisy-reverberant scenarios as an ASR front-end. In detail, we explore multi-channel separation methods, mask-based beamforming and complex spectral mapping, as well as the best features to use in the ASR back-end model. We employ the recent self-supervised learning representation (SSLR) as a feature and improve the recognition performance from the case with filterbank features. To further improve multi-speaker recognition performance, we present a carefully designed training strategy for integrating speech separation and recognition with SSLR. The proposed integration using TF-GridNet-based complex spectral mapping and WavLM-based SSLR achieves a 2.5% word error rate in reverberant WHAMR!",
  "The proposed integration using TF-GridNet-based complex spectral mapping and WavLM-based SSLR achieves a 2.5% word error rate in reverberant WHAMR! test set, significantly outperforming an existing mask-based MVDR beamforming and filterbank integration (28.9%).\nAuthors: Yoshiki Masuyama, Xuankai Chang, Wangyou Zhang, Samuele Cornell, Zhongqiu Wang, Nobutaka Ono, Y. Qian, Shinji Watanabe\nVenue: IEEE Workshop on Applications of Signal Processing to Audio and Acoustics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work provides an insightful investigation of speech separation in reverberant and noisy-reverberant scenarios as an ASR front-end, and employs the recent self-supervised learning representation (SSLR) as a feature and improves the recognition performance from the case with filterbank features.'}\nUrl: https://arxiv.org/pdf/2307.12231",
  "Faculty Name: shinji watanabe\nPaperid: 725cdb03a3d443c1698f6b98966cc78eaa53809b\nTitle: Software Design and User Interface of ESPnet-SE++: Speech Enhancement for Robust Speech Processing\nYear: 2023\nAbstract: None\nAuthors: Yen-Ju Lu, Xuankai Chang, Chenda Li, Wangyou Zhang, Samuele Cornell, Zhaoheng Ni, Yoshiki Masuyama, Brian Yan, Robin Scheibler, Zhong-Qiu Wang, Yu Tsao, Yanmin Qian, Shinji Watanabe\nVenue: Journal of Open Source Software\nTldr: None\nUrl: https://joss.theoj.org/papers/10.21105/joss.05403.pdf",
  "Faculty Name: shinji watanabe\nPaperid: 786294f4008732a5dac9895a8507bc4c80450075\nTitle: Dynamic-SUPERB: Towards A Dynamic, Collaborative, and Comprehensive Instruction-Tuning Benchmark for Speech\nYear: 2023\nAbstract: Text language models have shown remarkable zero-shot capability in generalizing to unseen tasks when provided with well-formulated instructions. However, existing studies in speech processing primarily focus on limited or specific tasks. Moreover, the lack of standardized benchmarks hinders a fair comparison across different approaches. Thus, we present Dynamic-SUPERB, a benchmark designed for building universal speech models capable of leveraging instruction tuning to perform multiple tasks in a zero-shot fashion. To achieve comprehensive coverage of diverse speech tasks and harness instruction tuning, we invite the community to collaborate and contribute, facilitating the dynamic growth of the benchmark. To initiate, Dynamic-SUPERB features 55 evaluation instances by combining 33 tasks and 22 datasets. This spans a broad spectrum of dimensions, providing a comprehensive platform for evaluation. Additionally, we propose several approaches to establish benchmark baselines.",
  "To initiate, Dynamic-SUPERB features 55 evaluation instances by combining 33 tasks and 22 datasets. This spans a broad spectrum of dimensions, providing a comprehensive platform for evaluation. Additionally, we propose several approaches to establish benchmark baselines. These include the utilization of speech models, text language models, and the multimodal encoder. Evaluation results indicate that while these baselines perform reasonably on seen tasks, they struggle with unseen ones. We also conducted an ablation study to assess the robustness and seek improvements in the performance. We release all materials to the public and welcome researchers to collaborate on the project, advancing technologies in the field together.",
  "Evaluation results indicate that while these baselines perform reasonably on seen tasks, they struggle with unseen ones. We also conducted an ablation study to assess the robustness and seek improvements in the performance. We release all materials to the public and welcome researchers to collaborate on the project, advancing technologies in the field together.\nAuthors: Chien-yu Huang, Ke-Han Lu, Shi Wang, Chi-Yuan Hsiao, Chun-Yi Kuan, Haibin Wu, Siddhant Arora, Kai-Wei Chang, Jiatong Shi, Yifan Peng, Roshan Sharma, Shinji Watanabe, Bhiksha Ramakrishnan, Shady Shehata, Hung-yi Lee\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work presents Dynamic-SUPERB, a benchmark designed for building universal speech models capable of leveraging instruction tuning to perform multiple tasks in a zero-shot fashion, and invites the community to collaborate and contribute, facilitating the dynamic growth of the benchmark.'}\nUrl: https://arxiv.org/pdf/2309.09510",
  "Faculty Name: shinji watanabe\nPaperid: 7d4ad68dedff8c81e0fd9c08ea76b220a7e05d69\nTitle: Speaker-Independent Acoustic-to-Articulatory Speech Inversion\nYear: 2023\nAbstract: To build speech processing methods that can handle speech as naturally as humans, researchers have explored multiple ways of building an invertible mapping from speech to an interpretable space. The articulatory space is a promising inversion target, since this space captures the mechanics of speech production. To this end, we build an acoustic-to-articulatory inversion (AAI) model that leverages autoregression, adversarial training, and self supervision to generalize to unseen speakers. Our approach obtains 0.784 correlation on an electromagnetic articulography (EMA) dataset, improving the state-of-the-art by 12.5%. Additionally, we show the interpretability of these representations through directly com-paring the behavior of estimated representations with speech production behavior. Finally, we propose a resynthesis-based AAI evaluation metric that does not rely on articulatory labels, demonstrating its efficacy with an 18-speaker dataset.",
  "Additionally, we show the interpretability of these representations through directly com-paring the behavior of estimated representations with speech production behavior. Finally, we propose a resynthesis-based AAI evaluation metric that does not rely on articulatory labels, demonstrating its efficacy with an 18-speaker dataset.\nAuthors: Peter Wu, Li-Wei Chen, Cheol Jun Cho, Shinji Watanabe, L. Goldstein, A. Black, G. Anumanchipalli\nVenue: IEEE International Conference on Acoustics, Speech, and Signal Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work builds an acoustic-to-articulatory inversion (AAI) model that leverages autoregression, adversarial training, and self supervision to generalize to unseen speakers, and proposes a resynthesis-based AAI evaluation metric that does not rely on articulatory labels.'}\nUrl: https://arxiv.org/pdf/2302.06774",
  "Faculty Name: shinji watanabe\nPaperid: 7f995454efda9f660d2258f59f6e19a2125e688e\nTitle: Towards Practical and Efficient Image-to-Speech Captioning with Vision-Language Pre-training and Multi-modal Tokens\nYear: 2023\nAbstract: In this paper, we propose methods to build a powerful and efficient Image-to-Speech captioning (Im2Sp) model. To this end, we start with importing the rich knowledge related to image comprehension and language modeling from a large-scale pre-trained vision-language model into Im2Sp. We set the output of the proposed Im2Sp as discretized speech units, i.e., the quantized speech features of a self-supervised speech model. The speech units mainly contain linguistic information while suppressing other characteristics of speech. This allows us to incorporate the language modeling capability of the pre-trained vision-language model into the spoken language modeling of Im2Sp. With the vision-language pre-training strategy, we set new state-of-the-art Im2Sp performances on two widely used benchmark databases, COCO and Flickr8k. Then, we further improve the efficiency of the Im2Sp model.",
  "With the vision-language pre-training strategy, we set new state-of-the-art Im2Sp performances on two widely used benchmark databases, COCO and Flickr8k. Then, we further improve the efficiency of the Im2Sp model. Similar to the speech unit case, we convert the original image into image units, which are derived through vector quantization of the raw image. With these image units, we can drastically reduce the required data storage for saving image data to just 0.8% when compared to the original image data in terms of bits. Demo page: https://ms-dot-k.github.io/Image-to-Speech-Captioning.\nAuthors: Minsu Kim, J. Choi, Soumi Maiti, Jeong Hun Yeo, Shinji Watanabe, Y. Ro\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper starts with importing the rich knowledge related to image comprehension and language modeling from a large-scale pre-trained vision-language model into Im2Sp, and sets the output of the proposed Im2 Sp as discretized speech units, i.e., the quantized speech features of a self-supervised speech model.'}",
  "Url: https://arxiv.org/pdf/2309.08531",
  "Faculty Name: shinji watanabe\nPaperid: 8402d64fde12cafaf8a1daa60de0acd1abedbffb\nTitle: Enhancing Speech-To-Speech Translation with Multiple TTS Targets\nYear: 2023\nAbstract: It has been known that direct speech-to-speech translation (S2ST) models usually suffer from the data scarcity issue because of the limited existing parallel materials for both source and target speech. Therefore to train a direct S2ST system, previous works usually utilize text-to-speech (TTS) systems to generate samples in the target language by augmenting the data from speech-to-text translation (S2TT). However, there is a limited investigation into how the synthesized target speech would affect the S2ST models. In this work, we analyze the effect of changing synthesized target speech for direct S2ST models. We find that simply combining the target speech from different TTS systems can potentially improve the S2ST performances. Following that, we also propose a multi-task framework that jointly optimizes the S2ST system with multiple targets from different TTS systems.",
  "We find that simply combining the target speech from different TTS systems can potentially improve the S2ST performances. Following that, we also propose a multi-task framework that jointly optimizes the S2ST system with multiple targets from different TTS systems. Extensive experiments demonstrate that our proposed framework achieves consistent improvements (2.8 BLEU) over the baselines on the Fisher Spanish-English dataset.\nAuthors: Jiatong Shi, Yun Tang, Ann Lee, H. Inaguma, Changhan Wang, J. Pino, Shinji Watanabe\nVenue: IEEE International Conference on Acoustics, Speech, and Signal Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is found that simply combining the target speech from different TTS systems can potentially improve the S2ST performances, and a multi-task framework is proposed that jointly optimizes the S1ST system with multiple targets from differentTTS systems.'}\nUrl: https://arxiv.org/pdf/2304.04618",
  "Faculty Name: shinji watanabe\nPaperid: 8bc617c9139648d7a92991d70c671230bac7b2e2\nTitle: AudioGPT: Understanding and Generating Speech, Music, Sound, and Talking Head\nYear: 2023\nAbstract: Large language models (LLMs) have exhibited remarkable capabilities across a variety of domains and tasks, challenging our understanding of learning and cognition. Despite the recent success, current LLMs are not capable of processing complex audio information or conducting spoken conversations (like Siri or Alexa). In this work, we propose a multi-modal AI system named AudioGPT, which complements LLMs (i.e., ChatGPT) with 1) foundation models to process complex audio information and solve numerous understanding and generation tasks; and 2) the input/output interface (ASR, TTS) to support spoken dialogue. With an increasing demand to evaluate multi-modal LLMs of human intention understanding and cooperation with foundation models, we outline the principles and processes and test AudioGPT in terms of consistency, capability, and robustness.",
  "With an increasing demand to evaluate multi-modal LLMs of human intention understanding and cooperation with foundation models, we outline the principles and processes and test AudioGPT in terms of consistency, capability, and robustness. Experimental results demonstrate the capabilities of AudioGPT in solving AI tasks with speech, music, sound, and talking head understanding and generation in multi-round dialogues, which empower humans to create rich and diverse audio content with unprecedented ease. Our system is publicly available at \\url{https://github.com/AIGC-Audio/AudioGPT}.",
  "Our system is publicly available at \\url{https://github.com/AIGC-Audio/AudioGPT}.\nAuthors: Rongjie Huang, Mingze Li, Dongchao Yang, Jiatong Shi, Xuankai Chang, Zhenhui Ye, Yuning Wu, Zhiqing Hong, Jia-Bin Huang, Jinglin Liu, Yixiang Ren, Zhou Zhao, Shinji Watanabe\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A multi-modal AI system named AudioGPT is proposed, which complements LLMs with 1) foundation models to process complex audio information and solve numerous understanding and generation tasks; and 2) the input/output interface (ASR, TTS) to support spoken dialogue.'}\nUrl: http://arxiv.org/pdf/2304.12995",
  "Faculty Name: shinji watanabe\nPaperid: 8f0a24d1678e4d0e584b0932196cd257d5c53c7d\nTitle: Improving Audio Captioning Models with Fine-grained Audio Features, Text Embedding Supervision, and LLM Mix-up Augmentation\nYear: 2023\nAbstract: Automated audio captioning (AAC) aims to generate informative descriptions for various sounds from nature and/or human activities. In recent years, AAC has quickly attracted research interest, with state-of-the-art systems now relying on a sequence-to-sequence (seq2seq) backbone powered by strong models such as Transformers. Following the macro-trend of applied machine learning research, in this work, we strive to improve the performance of seq2seq AAC models by extensively leveraging pretrained models and large language models (LLMs). Specifically, we utilize BEATs to extract fine-grained audio features. Then, we employ Instructor LLM to fetch text embeddings of captions, and infuse their language-modality knowledge into BEATs audio features via an auxiliary InfoNCE loss function.",
  "Specifically, we utilize BEATs to extract fine-grained audio features. Then, we employ Instructor LLM to fetch text embeddings of captions, and infuse their language-modality knowledge into BEATs audio features via an auxiliary InfoNCE loss function. Moreover, we propose a novel data augmentation method that uses ChatGPT to produce caption mix-ups (i.e., grammatical and compact combinations of two captions) which, together with the corresponding audio mixtures, increase not only the amount but also the complexity and diversity of training data. During inference, we propose to employ nucleus sampling and a hybrid reranking algorithm, which has not been explored in AAC research. Combining our efforts, our model achieves a new state-of-the-art 32.6 SPIDEr-FL score on the Clotho evaluation split, and wins the 2023 DCASE AAC challenge.",
  "Combining our efforts, our model achieves a new state-of-the-art 32.6 SPIDEr-FL score on the Clotho evaluation split, and wins the 2023 DCASE AAC challenge.\nAuthors: Shih-Lun Wu, Xuankai Chang, G. Wichern, Jee-weon Jung, Franccois G. Germain, Jonathan Le Roux, Shinji Watanabe\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work utilizes BEATs to extract fine-grained audio features and proposes a novel data augmentation method that uses ChatGPT to produce caption mix-ups which increase not only the amount but also the complexity and diversity of training data.'}\nUrl: https://arxiv.org/pdf/2309.17352",
  "Faculty Name: shinji watanabe\nPaperid: 91a06713cbccbfb1b5e1b9f7b62a1fba348616c3\nTitle: Voxtlm: unified decoder-only models for consolidating speech recognition/synthesis and speech/text continuation tasks\nYear: 2023\nAbstract: We propose a decoder-only language model, VoxtLM, that can perform four tasks: speech recognition, speech synthesis, text generation, and speech continuation. VoxtLM integrates text vocabulary with discrete speech tokens from self-supervised speech features and uses special tokens to enable multitask learning. Compared to a single-task model, VoxtLM exhibits a significant improvement in speech synthesis, with improvements in both speech intelligibility from 28.9 to 5.6 and objective quality from 2.68 to 3.90. VoxtLM also improves speech generation and speech recognition performance over the single-task counterpart. Further, VoxtLM is trained with publicly available data and training recipes and model checkpoints are open-sourced to make fully reproducible work.",
  "VoxtLM also improves speech generation and speech recognition performance over the single-task counterpart. Further, VoxtLM is trained with publicly available data and training recipes and model checkpoints are open-sourced to make fully reproducible work.\nAuthors: Soumi Maiti, Yifan Peng, Shukjae Choi, Jee-weon Jung, Xuankai Chang, Shinji Watanabe\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A decoder-only language model that can perform four tasks: speech recognition, speech synthesis, text generation, and speech continuation, VoxtLM is proposed, which exhibits a significant improvement in speech synthesis and improves speech intelligibility and objective quality.'}\nUrl: https://arxiv.org/pdf/2309.07937",
  "Faculty Name: shinji watanabe\nPaperid: 92b3753e56f5d85fd57a32084f52476839cc7221\nTitle: One model to rule them all ? Towards End-to-End Joint Speaker Diarization and Speech Recognition\nYear: 2023\nAbstract: This paper presents a novel framework for joint speaker diarization (SD) and automatic speech recognition (ASR), named SLIDAR (sliding-window diarization-augmented recognition). SLIDAR can process arbitrary length inputs and can handle any number of speakers, effectively solving ``who spoke what, when'' concurrently. SLIDAR leverages a sliding window approach and consists of an end-to-end diarization-augmented speech transcription (E2E DAST) model which provides, locally, for each window: transcripts, diarization and speaker embeddings. The E2E DAST model is based on an encoder-decoder architecture and leverages recent techniques such as serialized output training and ``Whisper-style\"prompting. The local outputs are then combined to get the final SD+ASR result by clustering the speaker embeddings to get global speaker identities.",
  "The E2E DAST model is based on an encoder-decoder architecture and leverages recent techniques such as serialized output training and ``Whisper-style\"prompting. The local outputs are then combined to get the final SD+ASR result by clustering the speaker embeddings to get global speaker identities. Experiments performed on monaural recordings from the AMI corpus confirm the effectiveness of the method in both close-talk and far-field speech scenarios.\nAuthors: Samuele Cornell, Jee-weon Jung, Shinji Watanabe, S. Squartini\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': \"SLIDAR (sliding-window diarization-augmented recognition) can process arbitrary length inputs and can handle any number of speakers, effectively solving ``who spoke what, when'' concurrently.\"}\nUrl: https://arxiv.org/pdf/2310.01688",
  "Faculty Name: shinji watanabe\nPaperid: 95aac8fe824bd0c83de594af0bf9d259e2416f53\nTitle: Learning to Speak from Text: Zero-Shot Multilingual Text-to-Speech with Unsupervised Text Pretraining\nYear: 2023\nAbstract: While neural text-to-speech (TTS) has achieved human-like natural synthetic speech, multilingual TTS systems are limited to resource-rich languages due to the need for paired text and studio-quality audio data. This paper proposes a method for zero-shot multilingual TTS using text-only data for the target language. The use of text-only data allows the development of TTS systems for low-resource languages for which only textual resources are available, making TTS accessible to thousands of languages. Inspired by the strong cross-lingual transferability of multilingual language models, our framework first performs masked language model pretraining with multilingual text-only data. Then we train this model with a paired data in a supervised manner, while freezing a language-aware embedding layer. This allows inference even for languages not included in the paired data but present in the text-only data.",
  "Then we train this model with a paired data in a supervised manner, while freezing a language-aware embedding layer. This allows inference even for languages not included in the paired data but present in the text-only data. Evaluation results demonstrate highly intelligible zero-shot TTS with a character error rate of less than 12% for an unseen language.\nAuthors: Takaaki Saeki, Soumi Maiti, Xinjian Li, Shinji Watanabe, Shinnosuke Takamichi, H. Saruwatari\nVenue: International Joint Conference on Artificial Intelligence\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Inspired by the strong cross-lingual transferability of multilingual language models, this framework first performs masked language model pretraining with multilingual text-only data, and trains this model with a paired data in a supervised manner, while freezing a language-aware embedding layer.'}\nUrl: http://arxiv.org/pdf/2301.12596",
  "Faculty Name: shinji watanabe\nPaperid: 9733b69b98142d2383f72ed1ebc3bd1d54138234\nTitle: Assessment of the frequency of SARS-CoV-2 Omicron variant escape from RNA-dependent RNA polymerase inhibitors and 3C-like protease inhibitors.\nYear: 2023\nAbstract: None\nAuthors: E. Takashita, Seiichiro Fujisaki, H. Morita, Shiho Nagata, H. Miura, M. Nagashima, Shinji Watanabe, M. Takeda, Y. Kawaoka, H. Hasegawa\nVenue: Antiviral Research\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The findings suggest that the frequency of SARS-CoV-2 mutant escape from RdRP inhibitors is lower than that from 3CLpro inhibitors, and that Delta variants were more likely to acquire amino acid substitutions associated with resistance to 3CL Pro inhibitors under the selective pressure of this drug compared with Omicron variants.'}\nUrl: N/A",
  "Faculty Name: shinji watanabe\nPaperid: 9cbd933c04218c9b642c15a49f8470d54524d9fb\nTitle: FNeural Speech Enhancement with Very Low Algorithmic Latency and Complexity via Integrated full- and sub-band Modeling\nYear: 2023\nAbstract: We propose FSB-LSTM, a novel long short-term memory (LSTM) based architecture that integrates full- and sub-band (FSB) modeling, for single- and multi-channel speech enhancement in the short-time Fourier transform (STFT) domain. The model maintains an information highway to flow an over-complete input representation through multiple FSB-LSTM modules. Each FSB-LSTM module consists of a full-band block to model spectro-temporal patterns at all frequencies and a sub-band block to model patterns within each sub-band, where each of the two blocks takes a down-sampled representation as input and returns an up-sampled discriminative representation to be added to the block input via a residual connection.",
  "The model is designed to have a low algorithmic complexity, a small run-time buffer and a very low algorithmic latency, at the same time producing a strong enhancement performance on a noisy-reverberant speech enhancement task even if the hop size is as low as 2 ms.\nAuthors: Zhongqiu Wang, Samuele Cornell, Shukjae Choi, Younglo Lee, Byeonghak Kim, Shinji Watanabe\nVenue: IEEE International Conference on Acoustics, Speech, and Signal Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The proposed FSB-LSTM model is designed to have a low algorithmic complexity, a small run-time buffer and a very lowgorithmic latency, at the same time producing a strong enhancement performance on a noisy-reverberant speech enhancement task even if the hop size is as low as 2 ms.'}\nUrl: N/A",
  "Faculty Name: shinji watanabe\nPaperid: 9dcfb422f6057725b1585caf820e128c91d6dbb3\nTitle: Improving Massively Multilingual ASR with Auxiliary CTC Objectives\nYear: 2023\nAbstract: Multilingual Automatic Speech Recognition (ASR) models have extended the usability of speech technologies to a wide variety of languages. With how many languages these models have to handle, however, a key to understanding their imbalanced performance across different languages is to examine if the model actually knows which language it should transcribe. In this paper, we introduce our work on improving performance on FLEURS, a 102-language open ASR benchmark, by conditioning the entire model on language identity (LID). We investigate techniques inspired from recent Connectionist Temporal Classification (CTC) studies to help the model handle the large number of languages, conditioning on the LID predictions of auxiliary tasks. Our experimental results demonstrate the effectiveness of our technique over standard CTC/Attention-based hybrid models.",
  "We investigate techniques inspired from recent Connectionist Temporal Classification (CTC) studies to help the model handle the large number of languages, conditioning on the LID predictions of auxiliary tasks. Our experimental results demonstrate the effectiveness of our technique over standard CTC/Attention-based hybrid models. Furthermore, our state-of-the-art systems using self-supervised models with the Conformer architecture improve over the results of prior work on FLEURS by a relative 28.4% CER. Trained models are reproducible recipes are available at https://github.com/espnet/espnet/tree/master/egs2/fleurs/asr1.",
  "Trained models are reproducible recipes are available at https://github.com/espnet/espnet/tree/master/egs2/fleurs/asr1.\nAuthors: William Chen, Brian Yan, Jiatong Shi, Yifan Peng, Soumi Maiti, Shinji Watanabe\nVenue: IEEE International Conference on Acoustics, Speech, and Signal Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work introduces work on improving performance on FLEURS, a 102-language open ASR benchmark, by conditioning the entire model on language identity (LID), and investigates techniques inspired from recent Connectionist Temporal Classification studies to help the model handle the large number of languages.'}\nUrl: https://arxiv.org/pdf/2302.12829",
  "Faculty Name: shinji watanabe\nPaperid: a2a5830e49b94349f4ff7d672fa6693888e54b82\nTitle: Magnetism and topological property in icosahedral quasicrystal\nYear: 2023\nAbstract: Quasicrystal (QC) has no periodicity but has a unique rotational symmetry forbidden in periodic crystals. Lack of microscopic theory of the crystalline electric field (CEF) in the QC and approximant crystal (AC) has prevented us from understanding the electric property, especially the magnetism. By developing the general formulation of the CEF in the rare-earth based QC and AC, we have analyzed the CEF in the QC Au-SM-Tb and AC (SM=Si, Ge, and Ga). The magnetic anisotropy arising from the CEF plays an important role in realizing unique magnetic states on the icosahedron (IC). By constructing the minimal model with the magnetic anisotropy, we have analyzed the ground-state properties of the IC, 1/1 AC, and QC.",
  "By constructing the minimal model with the magnetic anisotropy, we have analyzed the ground-state properties of the IC, 1/1 AC, and QC. The hedgehog state is characterized by the topological charge of one and the whirling-moment state is characterized by the topological charge of three. The uniform arrangement of the ferrimagnetic state is stabilized in the QC with the ferromagnetic (FM) interaction, which is a candidate for the magnetic structure recently observed FM long-range order in the QC Au-Ga-Tb. The uniform arrangement of the hedgehog state is stabilized in the QC with the antiferromagnetic interaction, which suggests the possibility of the topological magnetic long-range order.\nAuthors: S. Watanabe\nVenue: Journal of Physics: Conference Series\nTldr: None\nUrl: https://iopscience.iop.org/article/10.1088/1742-6596/2461/1/012011/pdf",
  "Faculty Name: shinji watanabe\nPaperid: a5ab124e57d1f26436821588aacd7d75b831259c\nTitle: Toward Universal Speech Enhancement For Diverse Input Conditions\nYear: 2023\nAbstract: The past decade has witnessed substantial growth of data-driven speech enhancement (SE) techniques thanks to deep learning. While existing approaches have shown impressive performance in some common datasets, most of them are designed only for a single condition (e.g., single-channel, multi-channel, or a fixed sampling frequency) or only consider a single task (e.g., denoising or dereverberation). Currently, there is no universal SE approach that can effectively handle diverse input conditions with a single model. In this paper, we make the first attempt to investigate this line of research. First, we devise a single SE model that is independent of microphone channels, signal lengths, and sampling frequencies. Second, we design a universal SE benchmark by combining existing public corpora with multiple conditions. Our experiments on a wide range of datasets show that the proposed single model can successfully handle diverse conditions with strong performance.",
  "Second, we design a universal SE benchmark by combining existing public corpora with multiple conditions. Our experiments on a wide range of datasets show that the proposed single model can successfully handle diverse conditions with strong performance.\nAuthors: Wangyou Zhang, Kohei Saijo, Zhong-Qiu Wang, Shinji Watanabe, Yanmin Qian\nVenue: Automatic Speech Recognition & Understanding\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper devise a single SE model that is independent of microphone channels, signal lengths, and sampling frequencies, and designs a universal SE benchmark by combining existing public corpora with multiple conditions.'}\nUrl: https://arxiv.org/pdf/2309.17384",
  "Faculty Name: shinji watanabe\nPaperid: a60faa964c4dc744938c0b7812f7f3701a1250b8\nTitle: A Single Speech Enhancement Model Unifying Dereverberation, Denoising, Speaker Counting, Separation, And Extraction\nYear: 2023\nAbstract: We propose a multi-task universal speech enhancement (MUSE) model that can perform five speech enhancement (SE) tasks: dereverberation, denoising, speech separation (SS), target speaker extraction (TSE), and speaker counting. This is achieved by integrating two modules into an SE model: 1) an internal separation module that does both speaker counting and separation; and 2) a TSE module that extracts the target speech from the internal separation outputs using target speaker cues. The model is trained to perform TSE if the target speaker cue is given and SS otherwise. By training the model to remove noise and reverberation, we allow the model to tackle the five tasks mentioned above with a single model, which has not been accomplished yet. Evaluation results demonstrate that the proposed MUSE model can successfully handle multiple tasks with a single model.",
  "By training the model to remove noise and reverberation, we allow the model to tackle the five tasks mentioned above with a single model, which has not been accomplished yet. Evaluation results demonstrate that the proposed MUSE model can successfully handle multiple tasks with a single model.\nAuthors: Kohei Saijo, Wangyou Zhang, Zhong-Qiu Wang, Shinji Watanabe, Tetsunori Kobayashi, Tetsuji Ogawa\nVenue: Automatic Speech Recognition & Understanding\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Evaluation results demonstrate that the proposed MUSE model can successfully handle multiple tasks with a single model, which has not been accomplished yet.'}\nUrl: https://arxiv.org/pdf/2310.08277",
  "Faculty Name: shinji watanabe\nPaperid: ab84b84b4a9641a172f9874108fee07a9f92f988\nTitle: E-Branchformer-Based E2E SLU Toward Stop on-Device Challenge\nYear: 2023\nAbstract: In this paper, we report our team\u2019s study on track 2 of the Spoken Language Understanding Grand Challenge, which is a component of the ICASSP Signal Processing Grand Challenge 2023. The task is intended for on-device processing and involves estimating semantic parse labels from speech using a model with 15 million parameters. We use E2E E-Branchformer-based spoken language understanding model, which is more parameter controllable than cascade models, and reduced the parameter size through sequential distillation and tensor decomposition techniques. On the STOP dataset, we achieved an exact match accuracy of 70.9% under the tight constraint of 15 million parameters.",
  "On the STOP dataset, we achieved an exact match accuracy of 70.9% under the tight constraint of 15 million parameters.\nAuthors: Yosuke Kashiwagi, Siddhant Arora, Hayato Futami, Jessica Huynh, Shih-Lun Wu, Yifan Peng, Brian Yan, E. Tsunoo, Shinji Watanabe\nVenue: IEEE International Conference on Acoustics, Speech, and Signal Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'E2E E-Branchformer-based spoken language understanding model is used, which is more parameter controllable than cascade models, and the parameter size is reduced through sequential distillation and tensor decomposition techniques.'}\nUrl: N/A",
  "Faculty Name: shinji watanabe\nPaperid: b4855ff933fb80846638469a1b43c1766df85d78\nTitle: The Pipeline System of ASR and NLU with MLM-based data Augmentation Toward Stop Low-Resource Challenge\nYear: 2023\nAbstract: This paper describes our system for the low-resource domain adaptation track (Track 3) in Spoken Language Understanding Grand Challenge, which is a part of ICASSP Signal Processing Grand Challenge 2023. In the track, we adopt a pipeline approach of ASR and NLU. For ASR, we fine-tune Whisper for each domain with upsampling. For NLU, we fine-tune BART on all the Track3 data and then on low-resource domain data. We apply masked LM (MLM) -based data augmentation, where some of input tokens and corresponding target labels are replaced using MLM. We also apply a retrieval-based approach, where model input is augmented with similar training samples.",
  "We apply masked LM (MLM) -based data augmentation, where some of input tokens and corresponding target labels are replaced using MLM. We also apply a retrieval-based approach, where model input is augmented with similar training samples. As a result, we achieved exact match (EM) accuracy 63.3/75.0 (average: 69.15) for reminder/weather domain, and won the 1st place at the challenge.\nAuthors: Hayato Futami, Jessica Huynh, Siddhant Arora, Shih-Lun Wu, Yosuke Kashiwagi, Yifan Peng, Brian Yan, E. Tsunoo, Shinji Watanabe\nVenue: IEEE International Conference on Acoustics, Speech, and Signal Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This system for the low-resource domain adaptation track (Track 3) in Spoken Language Understanding Grand Challenge, which is a part of ICASSP Signal Processing Grand Challenge 2023, adopts a pipeline approach of ASR and NLU and applies masked LM (MLM) -based data augmentation.'}",
  "Url: https://arxiv.org/pdf/2305.01194",
  "Faculty Name: shinji watanabe\nPaperid: b524ec331cd9708b125fad70d95d36189fa0d7b6\nTitle: A Study on the Integration of Pipeline and E2E SLU Systems for Spoken Semantic Parsing Toward Stop Quality Challenge\nYear: 2023\nAbstract: Recently there have been efforts to introduce new benchmark tasks for spoken language understanding (SLU), like semantic parsing. In this paper, we describe our proposed spoken semantic parsing system for the quality track (Track 1) in Spoken Language Understanding Grand Challenge which is part of ICASSP Signal Processing Grand Challenge 2023. We experiment with both end-to-end and pipeline systems for this task. Strong automatic speech recognition (ASR) models like Whisper and pretrained Language models (LM) like BART are utilized inside our SLU framework to boost performance. We also investigate the output level combination of various models to get an exact match accuracy of 80.8, which won the 1st place at the challenge.",
  "We also investigate the output level combination of various models to get an exact match accuracy of 80.8, which won the 1st place at the challenge.\nAuthors: Siddhant Arora, Hayato Futami, Shih-Lun Wu, Jessica Huynh, Yifan Peng, Yosuke Kashiwagi, E. Tsunoo, Brian Yan, Shinji Watanabe\nVenue: IEEE International Conference on Acoustics, Speech, and Signal Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper describes the proposed spoken semantic parsing system for the quality track (Track 1) in Spoken Language Understanding Grand Challenge which is part of ICASSP Signal Processing Grand Challenge 2023.'}\nUrl: https://arxiv.org/pdf/2305.01620",
  "Faculty Name: shinji watanabe\nPaperid: b88a84fb2d35eecb5149caa3d0596942ae0a5a54\nTitle: A community cluster of influenza A(H3N2) virus infection with reduced susceptibility to baloxavir due to a PA E199G substitution in Japan, February to March 2023\nYear: 2023\nAbstract: A community cluster of influenza A(H3N2) caused by viruses with an E199G substitution in PA was detected in Nara, Japan, between February and March 2023. The three patients with these mutant viruses had not received antiviral treatment before specimen collection but patients in the same hospital had. The sequences of the mutant viruses were closely related, suggesting clonal spread in Nara. They showed reduced susceptibility to baloxavir in vitro; however, the clinical significance of the PA E199G substitution remains unclear.",
  "The sequences of the mutant viruses were closely related, suggesting clonal spread in Nara. They showed reduced susceptibility to baloxavir in vitro; however, the clinical significance of the PA E199G substitution remains unclear.\nAuthors: E. Takashita, Seiichiro Fujisaki, H. Morita, Shiho Nagata, H. Miura, Yuki Matsuura, Saya Yamamoto, Shoko Chiba, Yumiko Inoue, Iori Minami, Sayaka Yoshikawa, Seiko Yamazaki, N. Kishida, Kazuya Nakamura, Masayuki Shirakura, Shinji Watanabe, Hideki Hasegawa\nVenue: Euro surveillance : bulletin Europeen sur les maladies transmissibles = European communicable disease bulletin\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A community cluster of influenza A(H3N2) caused by viruses with an E199G substitution in PA was detected in Nara, Japan, between February and March 2023 and showed reduced susceptibility to baloxavir in vitro; however, the clinical significance remains unclear.'}",
  "Url: https://www.eurosurveillance.org/deliver/fulltext/eurosurveillance/28/39/eurosurv-28-39-1.pdf?itemId=%2Fcontent%2F10.2807%2F1560-7917.ES.2023.28.39.2300501&mimeType=pdf&containerItemId=content/eurosurveillance",
  "Faculty Name: shinji watanabe\nPaperid: bb4c59fc93d5be6b3d85dfde9d08e3dab80db9b7\nTitle: Exploring Speech Recognition, Translation, and Understanding with Discrete Speech Units: A Comparative Study\nYear: 2023\nAbstract: Speech signals, typically sampled at rates in the tens of thousands per second, contain redundancies, evoking inefficiencies in sequence modeling. High-dimensional speech features such as spectrograms are often used as the input for the subsequent model. However, they can still be redundant. Recent investigations proposed the use of discrete speech units derived from self-supervised learning representations, which significantly compresses the size of speech data. Applying various methods, such as de-duplication and subword modeling, can further compress the speech sequence length. Hence, training time is significantly reduced while retaining notable performance. In this study, we undertake a comprehensive and systematic exploration into the application of discrete units within end-to-end speech processing models.",
  "Hence, training time is significantly reduced while retaining notable performance. In this study, we undertake a comprehensive and systematic exploration into the application of discrete units within end-to-end speech processing models. Experiments on 12 automatic speech recognition, 3 speech translation, and 1 spoken language understanding corpora demonstrate that discrete units achieve reasonably good results in almost all the settings. We intend to release our configurations and trained models to foster future research efforts.\nAuthors: Xuankai Chang, Brian Yan, Kwanghee Choi, Jee-weon Jung, Yichen Lu, Soumi Maiti, Roshan Sharma, Jiatong Shi, Jinchuan Tian, Shinji Watanabe, Yuya Fujita, Takashi Maekaku, Pengcheng Guo, Yao-Fei Cheng, Pavel Denisov, Kohei Saijo, Hsiu-Hsuan Wang\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This study undertake a comprehensive and systematic exploration into the application of discrete units within end-to-end speech processing models, demonstrating that discrete units achieve reasonably good results in almost all the settings.'}",
  "Url: https://arxiv.org/pdf/2309.15800",
  "Faculty Name: shinji watanabe\nPaperid: bc3690edd40cc9946f8162727b357b926d1127bc\nTitle: Joint Modelling of Spoken Language Understanding Tasks with Integrated Dialog History\nYear: 2023\nAbstract: Most human interactions occur in the form of spoken conversations where the semantic meaning of a given utterance depends on the context. Each utterance in spoken conversation can be represented by many semantic and speaker attributes, and there has been an interest in building Spoken Language Understanding (SLU) systems for automatically predicting these attributes. Recent work has shown that incorporating dialogue history can help advance SLU performance. However, separate models are used for each SLU task, leading to an increase in inference time and computation cost. Motivated by this, we aim to ask: can we jointly model all the SLU tasks while incorporating context to facilitate low-latency and lightweight inference? To answer this, we propose a novel model architecture that learns dialog context to jointly predict the intent, dialog act, speaker role, and emotion for the spoken utterance.",
  "To answer this, we propose a novel model architecture that learns dialog context to jointly predict the intent, dialog act, speaker role, and emotion for the spoken utterance. Note that our joint prediction is based on an autoregressive model and we need to decide the prediction order of dialog attributes, which is not trivial. To mitigate the issue, we also propose an order agnostic training method. Our experiments show that our joint model achieves similar results to task-specific classifiers and can effectively integrate dialog context to further improve the SLU performance.1\nAuthors: Siddhant Arora, Hayato Futami, E. Tsunoo, Brian Yan, Shinji Watanabe\nVenue: IEEE International Conference on Acoustics, Speech, and Signal Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A novel model architecture is proposed that learns dialog context to jointly predict the intent, dialog act, speaker role, and emotion for the spoken utterance and achieves similar results to task-specific classifiers and can effectively integrateDialog context to further improve the SLU performance.'}\nUrl: https://arxiv.org/pdf/2305.00926",
  "Faculty Name: shinji watanabe\nPaperid: bdf9ea3a67691e1b6a362f4019bf80c9cf31cecd\nTitle: Findings of the 2023 ML-Superb Challenge: Pre-Training And Evaluation Over More Languages And Beyond\nYear: 2023\nAbstract: The 2023 Multilingual Speech Universal Performance Benchmark (ML-SUPERB) Challenge expands upon the acclaimed SUPERB framework, emphasizing self-supervised models in multilingual speech recognition and language identification. The challenge comprises a research track focused on applying ML-SUPERB to specific multilingual subjects, a Challenge Track for model submissions, and a New Language Track where language resource researchers can contribute and evaluate their low-resource language data in the context of the latest progress in multilingual speech recognition. The challenge garnered 12 model submissions and 54 language corpora, resulting in a comprehensive benchmark encompassing 154 languages. The findings indicate that merely scaling models is not the definitive solution for multilingual speech tasks, and a variety of speech/voice types present significant challenges in multilingual speech processing.",
  "The challenge garnered 12 model submissions and 54 language corpora, resulting in a comprehensive benchmark encompassing 154 languages. The findings indicate that merely scaling models is not the definitive solution for multilingual speech tasks, and a variety of speech/voice types present significant challenges in multilingual speech processing.\nAuthors: Jiatong Shi, William Chen, Dan Berrebbi, Hsiu-Hsuan Wang, Wei-Ping Huang, En-Pei Hu, Ho-Lam Chuang, Xuankai Chang, Yuxun Tang, Shang-Wen Li, Abdelrahman Mohamed, Hung-yi Lee, Shinji Watanabe\nVenue: Automatic Speech Recognition & Understanding\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The 2023 Multilingual Speech Universal Performance Benchmark (ML-SUPERB) Challenge expands upon the acclaimed SUPERB framework, emphasizing self-supervised models in multilingual speech recognition and language identification, resulting in a comprehensive benchmark encompassing 154 languages.'}\nUrl: https://arxiv.org/pdf/2310.05513",
  "Faculty Name: shinji watanabe\nPaperid: c2745e86ecc9bec372690cced53ccfdf44f407f8\nTitle: Enhancing End-to-End Conversational Speech Translation Through Target Language Context Utilization\nYear: 2023\nAbstract: Incorporating longer context has been shown to benefit machine translation, but the inclusion of context in end-to-end speech translation (E2E-ST) remains under-studied. To bridge this gap, we introduce target language context in E2E-ST, enhancing coherence and overcoming memory constraints of extended audio segments. Additionally, we propose context dropout to ensure robustness to the absence of context, and further improve performance by adding speaker information. Our proposed contextual E2E-ST outperforms the isolated utterance-based E2E-ST approach. Lastly, we demonstrate that in conversational speech, contextual information primarily contributes to capturing context style, as well as resolving anaphora and named entities.",
  "Our proposed contextual E2E-ST outperforms the isolated utterance-based E2E-ST approach. Lastly, we demonstrate that in conversational speech, contextual information primarily contributes to capturing context style, as well as resolving anaphora and named entities.\nAuthors: A. Hussein, Brian Yan, Antonios Anastasopoulos, Shinji Watanabe, S. Khudanpur\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work introduces target language context in E2E-ST, enhancing coherence and overcoming memory constraints of extended audio segments, and proposes context dropout to ensure robustness to the absence of context, and improves performance by adding speaker information.'}\nUrl: https://arxiv.org/pdf/2309.15686",
  "Faculty Name: shinji watanabe\nPaperid: c6f5da5eb57457457a49256f1434bf1db23d1898\nTitle: Challenges of Corporate Alliance CLOMA toward Plastic Litter\nYear: 2023\nAbstract: None\nAuthors: Shinji Watanabe\nVenue: Oleoscience\nTldr: None\nUrl: https://www.jstage.jst.go.jp/article/oleoscience/23/1/23_29/_pdf",
  "Faculty Name: shinji watanabe\nPaperid: c823c04a6488673f936d72906130f170017288d0\nTitle: The Multimodal Information Based Speech Processing (MISP) 2023 Challenge: Audio-Visual Target Speaker Extraction\nYear: 2023\nAbstract: Previous Multimodal Information based Speech Processing (MISP) challenges mainly focused on audio-visual speech recognition (AVSR) with commendable success. However, the most advanced back-end recognition systems often hit performance limits due to the complex acoustic environments. This has prompted a shift in focus towards the Audio-Visual Target Speaker Extraction (AVTSE) task for the MISP 2023 challenge in ICASSP 2024 Signal Processing Grand Challenges. Unlike existing audio-visual speech enhance-ment challenges primarily focused on simulation data, the MISP 2023 challenge uniquely explores how front-end speech processing, combined with visual clues, impacts back-end tasks in real-world scenarios. This pioneering effort aims to set the first benchmark for the AVTSE task, offering fresh insights into enhancing the ac-curacy of back-end speech recognition systems through AVTSE in challenging and real acoustic environments.",
  "This pioneering effort aims to set the first benchmark for the AVTSE task, offering fresh insights into enhancing the ac-curacy of back-end speech recognition systems through AVTSE in challenging and real acoustic environments. This paper delivers a thorough overview of the task setting, dataset, and baseline system of the MISP 2023 challenge. It also includes an in-depth analysis of the challenges participants may encounter. The experimental results highlight the demanding nature of this task, and we look forward to the innovative solutions participants will bring forward.",
  "It also includes an in-depth analysis of the challenges participants may encounter. The experimental results highlight the demanding nature of this task, and we look forward to the innovative solutions participants will bring forward.\nAuthors: Shilong Wu, Chenxi Wang, Hang Chen, Yusheng Dai, Chenyue Zhang, Ruoyu Wang, Hongbo Lan, Jun Du, Chin-Hui Lee, Jingdong Chen, Shinji Watanabe, Sabato Marco Siniscalchi, O. Scharenborg, Zhong-Qiu Wang, Jia Pan, Jianqing Gao\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A thorough overview of the task setting, dataset, and baseline system of the MISP 2023 challenge is delivered, offering fresh insights into enhancing the ac-curacy of back-end speech recognition systems through AVTSE in challenging and real acoustic environments.'}\nUrl: https://arxiv.org/pdf/2309.08348",
  "Faculty Name: shinji watanabe\nPaperid: d24d60719e90e69749a75c160cb760d1d9fca44a\nTitle: Incremental Blockwise Beam Search for Simultaneous Speech Translation with Controllable Quality-Latency Tradeoff\nYear: 2023\nAbstract: Blockwise self-attentional encoder models have recently emerged as one promising end-to-end approach to simultaneous speech translation. These models employ a blockwise beam search with hypothesis reliability scoring to determine when to wait for more input speech before translating further. However, this method maintains multiple hypotheses until the entire speech input is consumed -- this scheme cannot directly show a single \\textit{incremental} translation to users. Further, this method lacks mechanisms for \\textit{controlling} the quality vs. latency tradeoff. We propose a modified incremental blockwise beam search incorporating local agreement or hold-$n$ policies for quality-latency control. We apply our framework to models trained for online or offline translation and demonstrate that both types can be effectively used in online mode.",
  "latency tradeoff. We propose a modified incremental blockwise beam search incorporating local agreement or hold-$n$ policies for quality-latency control. We apply our framework to models trained for online or offline translation and demonstrate that both types can be effectively used in online mode. Experimental results on MuST-C show 0.6-3.6 BLEU improvement without changing latency or 0.8-1.4 s latency improvement without changing quality.\nAuthors: Peter Pol\u00e1k, Brian Yan, Shinji Watanabe, A. Waibel, Ondrej Bojar\nVenue: Interspeech\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A modified incremental blockwise beam search incorporating local agreement or hold-$n$ policies for quality-latency control is proposed and applied to models trained for online or offline translation and it is demonstrated that both types can be effectively used in online mode.'}\nUrl: https://arxiv.org/pdf/2309.11379",
  "Faculty Name: shinji watanabe\nPaperid: d2897d70e1bceaf4799937e4b4aab0a45fc6e20c\nTitle: Bayes Risk Transducer: Transducer with Controllable Alignment Prediction\nYear: 2023\nAbstract: Automatic speech recognition (ASR) based on transducers is widely used. In training, a transducer maximizes the summed posteriors of all paths. The path with the highest posterior is commonly defined as the predicted alignment between the speech and the transcription. While the vanilla transducer does not have a prior preference for any of the valid paths, this work intends to enforce the preferred paths and achieve controllable alignment prediction. Specifically, this work proposes Bayes Risk Transducer (BRT), which uses a Bayes risk function to set lower risk values to the preferred paths so that the predicted alignment is more likely to satisfy specific desired properties. We further demonstrate that these predicted alignments with intentionally designed properties can provide practical advantages over the vanilla transducer. Experimentally, the proposed BRT saves inference cost by up to 46% for non-streaming ASR and reduces overall system latency by 41% for streaming ASR.",
  "We further demonstrate that these predicted alignments with intentionally designed properties can provide practical advantages over the vanilla transducer. Experimentally, the proposed BRT saves inference cost by up to 46% for non-streaming ASR and reduces overall system latency by 41% for streaming ASR.\nAuthors: Jinchuan Tian, Jianwei Yu, Hangting Chen, Brian Yan, Chao Weng, Dong Yu, Shinji Watanabe\nVenue: Interspeech\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes Bayes Risk Transducer (BRT), which uses a Bayes risk function to set lower risk values to the preferred paths so that the predicted alignment is more likely to satisfy specific desired properties.'}\nUrl: https://arxiv.org/pdf/2308.10107",
  "Faculty Name: shinji watanabe\nPaperid: d43338451cd8676548811e1ff8f9c92ea987c5bd\nTitle: Reproducing Whisper-Style Training Using An Open-Source Toolkit And Publicly Available Data\nYear: 2023\nAbstract: Pre-training speech models on large volumes of data has achieved remarkable success. OpenAI Whisper is a multilingual multitask model trained on 680k hours of supervised speech data. It generalizes well to various speech recognition and translation benchmarks even in a zero-shot setup. However, the full pipeline for developing such models (from data collection to training) is not publicly accessible, which makes it difficult for researchers to further improve its performance and address training-related issues such as efficiency, robustness, fairness, and bias. This work presents an Open Whisper-style Speech Model (OWSM), which reproduces Whisperstyle training using an open-source toolkit and publicly available data. OWSM even supports more translation directions and can be more efficient to train. We will publicly release all scripts used for data preparation, training, inference, and scoring as well as pretrained models and training logs to promote open science.",
  "OWSM even supports more translation directions and can be more efficient to train. We will publicly release all scripts used for data preparation, training, inference, and scoring as well as pretrained models and training logs to promote open science. 11https://github.com/espnet/espnet\nAuthors: Yifan Peng, Jinchuan Tian, Brian Yan, Dan Berrebbi, Xuankai Chang, Xinjian Li, Jiatong Shi, Siddhant Arora, William Chen, Roshan Sharma, Wangyou Zhang, Yui Sudo, Muhammad Shakeel, Jee-weon Jung, Soumi Maiti, Shinji Watanabe\nVenue: Automatic Speech Recognition & Understanding\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work presents an Open Whisper-style Speech Model (OWSM), which reproduces Whisperstyle training using an open-source toolkit and publicly available data and even supports more translation directions and can be more efficient to train.'}\nUrl: https://arxiv.org/pdf/2309.13876",
  "Faculty Name: shinji watanabe\nPaperid: d4d5fe4a35e9de845877015075f727415e83d18f\nTitle: The CHiME-7 DASR Challenge: Distant Meeting Transcription with Multiple Devices in Diverse Scenarios\nYear: 2023\nAbstract: The CHiME challenges have played a significant role in the development and evaluation of robust automatic speech recognition (ASR) systems. We introduce the CHiME-7 distant ASR (DASR) task, within the 7th CHiME challenge. This task comprises joint ASR and diarization in far-field settings with multiple, and possibly heterogeneous, recording devices. Different from previous challenges, we evaluate systems on 3 diverse scenarios: CHiME-6, DiPCo, and Mixer 6. The goal is for participants to devise a single system that can generalize across different array geometries and use cases with no a-priori information. Another departure from earlier CHiME iterations is that participants are allowed to use open-source pre-trained models and datasets. In this paper, we describe the challenge design, motivation, and fundamental research questions in detail.",
  "Another departure from earlier CHiME iterations is that participants are allowed to use open-source pre-trained models and datasets. In this paper, we describe the challenge design, motivation, and fundamental research questions in detail. We also present the baseline system, which is fully array-topology agnostic and features multi-channel diarization, channel selection, guided source separation and a robust ASR model that leverages self-supervised speech representations (SSLR).",
  "We also present the baseline system, which is fully array-topology agnostic and features multi-channel diarization, channel selection, guided source separation and a robust ASR model that leverages self-supervised speech representations (SSLR).\nAuthors: Samuele Cornell, Matthew Wiesner, Shinji Watanabe, Desh Raj, Xuankai Chang, Paola Garc\u00eda, Yoshiki Masuyama, Zhong-Qiu Wang, S. Squartini, S. Khudanpur\nVenue: 7th International Workshop on Speech Processing in Everyday Environments (CHiME 2023)\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The ChiME-7 distant ASR (DASR) task, within the 7th CHiME challenge, is introduced and the baseline system is presented, which is fully array-topology agnostic and features multi-channel diarization, channel selection, guided source separation and a robust ASR model that leverages self-supervised speech representations (SSLR).'}\nUrl: https://arxiv.org/pdf/2306.13734",
  "Faculty Name: shinji watanabe\nPaperid: d8728d62b238b09630309c1df723036db84bac10\nTitle: Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing\nYear: 2023\nAbstract: Recent works in end-to-end speech-to-text translation (ST) have proposed multi-tasking methods with soft parameter sharing which leverage machine translation (MT) data via secondary encoders that map text inputs to an eventual cross-modal representation. In this work, we instead propose a ST/MT multi-tasking framework with hard parameter sharing in which all model parameters are shared cross-modally. Our method reduces the speech-text modality gap via a pre-processing stage which converts speech and text inputs into two discrete token sequences of similar length -- this allows models to indiscriminately process both modalities simply using a joint vocabulary. With experiments on MuST-C, we demonstrate that our multi-tasking framework improves attentional encoder-decoder, Connectionist Temporal Classification (CTC), transducer, and joint CTC/attention models by an average of +0.5 BLEU without any external MT data.",
  "With experiments on MuST-C, we demonstrate that our multi-tasking framework improves attentional encoder-decoder, Connectionist Temporal Classification (CTC), transducer, and joint CTC/attention models by an average of +0.5 BLEU without any external MT data. Further, we show that this framework incorporates external MT data, yielding +0.8 BLEU, and also improves transfer learning from pre-trained textual models, yielding +1.8 BLEU.\nAuthors: Brian Yan, Xuankai Chang, Antonios Anastasopoulos, Yuya Fujita, Shinji Watanabe\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes a ST/MT multi-tasking framework with hard parameter sharing in which all model parameters are shared cross-modally and reduces the speech-text modality gap via a pre-processing stage which converts speech and text inputs into two discrete token sequences of similar length.'}\nUrl: https://arxiv.org/pdf/2309.15826",
  "Faculty Name: shinji watanabe\nPaperid: dab8e7dc79085774eea58bcb9ea2ed0ee20377eb\nTitle: ESPnet-ST-v2: Multipurpose Spoken Language Translation Toolkit\nYear: 2023\nAbstract: ESPnet-ST-v2 is a revamp of the open-source ESPnet-ST toolkit necessitated by the broadening interests of the spoken language translation community. ESPnet-ST-v2 supports 1) offline speech-to-text translation (ST), 2) simultaneous speech-to-text translation (SST), and 3) offline speech-to-speech translation (S2ST) \u2013 each task is supported with a wide variety of approaches, differentiating ESPnet-ST-v2 from other open source spoken language translation toolkits. This toolkit offers state-of-the-art architectures such as transducers, hybrid CTC/attention, multi-decoders with searchable intermediates, time-synchronous blockwise CTC/attention, Translatotron models, and direct discrete unit models.",
  "This toolkit offers state-of-the-art architectures such as transducers, hybrid CTC/attention, multi-decoders with searchable intermediates, time-synchronous blockwise CTC/attention, Translatotron models, and direct discrete unit models. In this paper, we describe the overall design, example models for each task, and performance benchmarking behind ESPnet-ST-v2, which is publicly available at https://github.com/espnet/espnet.\nAuthors: Brian Yan, Jiatong Shi, Yun Tang, H. Inaguma, Yifan Peng, Siddharth Dalmia, Peter Pol'ak, Patrick Fernandes, Dan Berrebbi, Tomoki Hayashi, Xiaohui Zhang, Zhaoheng Ni, Moto Hira, Soumi Maiti, J. Pino, Shinji Watanabe\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The overall design, example models for each task, and performance benchmarking behind ESPnet-ST-v2 are described, which is publicly available at https://github.com/espnet/esp net.'}",
  "Url: https://arxiv.org/pdf/2304.04596",
  "Faculty Name: shinji watanabe\nPaperid: dd5d797b837005fac464bb19b9396bddba61c0d8\nTitle: Multi-Channel Target Speaker Extraction with Refinement: The WavLab Submission to the Second Clarity Enhancement Challenge\nYear: 2023\nAbstract: This paper describes our submission to the Second Clarity Enhancement Challenge (CEC2), which consists of target speech enhancement for hearing-aid (HA) devices in noisy-reverberant environments with multiple interferers such as music and competing speakers. Our approach builds upon the powerful iterative neural/beamforming enhancement (iNeuBe) framework introduced in our recent work, and this paper extends it for target speaker extraction. We therefore name the proposed approach as iNeuBe-X, where the X stands for extraction.",
  "Our approach builds upon the powerful iterative neural/beamforming enhancement (iNeuBe) framework introduced in our recent work, and this paper extends it for target speaker extraction. We therefore name the proposed approach as iNeuBe-X, where the X stands for extraction. To address the challenges encountered in the CEC2 setting, we introduce four major novelties: (1) we extend the state-of-the-art TF-GridNet model, originally designed for monaural speaker separation, for multi-channel, causal speech enhancement, and large improvements are observed by replacing the TCNDenseNet used in iNeuBe with this new architecture; (2) we leverage a recent dual window size approach with future-frame prediction to ensure that iNueBe-X satisfies the 5 ms constraint on algorithmic latency required by CEC2; (3) we introduce a novel speaker-conditioning branch for TF-GridNet to achieve target speaker extraction; (4) we propose a fine-tuning step, where we compute an additional loss with respect to the target speaker signal compensated with the listener audiogram.",
  "Without using external data, on the official development set our best model reaches a hearing-aid speech perception index (HASPI) score of 0.942 and a scale-invariant signal-to-distortion ratio improvement (SI-SDRi) of 18.8 dB. These results are promising given the fact that the CEC2 data is extremely challenging (e.g., on the development set the mixture SI-SDR is -12.3 dB). A demo of our submitted system is available at WAVLab CEC2 demo.\nAuthors: Samuele Cornell, Zhongqiu Wang, Yoshiki Masuyama, Shinji Watanabe, Manuel Pariente, Nobutaka Ono\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The approach builds upon the powerful iterative neural/beamforming enhancement (iNeuBe) framework introduced in recent work, and this paper extends it for target speaker extraction, and is named as iNeu be-X, where the X stands for extraction.'}\nUrl: http://arxiv.org/pdf/2302.07928",
  "Faculty Name: shinji watanabe\nPaperid: debb65ab30ceef2faef0e4af560a67f2abd03d14\nTitle: Fully Unsupervised Topic Clustering of Unlabelled Spoken Audio Using Self-Supervised Representation Learning and Topic Model\nYear: 2023\nAbstract: Unsupervised topic clustering of spoken audio is an important research topic for zero-resourced unwritten languages. A classical approach is to find a set of spoken terms from only the audio based on dynamic time warping or generative modeling (e.g., hidden Markov model), and apply a topic model to classify topics. The spoken term discovery is the most important and difficult part. In this paper, we propose to combine self-supervised representation learning (SSRL) methods as a component of spoken term discovery and probabilistic topic models. Most SSRL methods pre-train a model which predicts high-quality pseudo labels generated from an audio-only corpus. These pseudo labels can be used to produce a sequence of pseudo subwords by applying deduplication and a subword model.",
  "Most SSRL methods pre-train a model which predicts high-quality pseudo labels generated from an audio-only corpus. These pseudo labels can be used to produce a sequence of pseudo subwords by applying deduplication and a subword model. Then, we apply a topic model based on latent Dirichlet allocation for these pseudo-subword sequences in an unsupervised manner. The clustering performance is evaluated on the Fisher corpus using normalized mutual information. We confirm the improvement of the proposed method and its effectiveness compared to an existing approach using dynamic time warping and topic models although the experimental setups are not directly comparable.\nAuthors: Takashi Maekaku, Yuya Fujita, Xuankai Chang, Shinji Watanabe\nVenue: IEEE International Conference on Acoustics, Speech, and Signal Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper proposes to combine self-supervised representation learning (SSRL) methods as a component of spoken term discovery and probabilistic topic models and confirms the improvement of the proposed method and its effectiveness compared to an existing approach using dynamic time warping and topic models.'}\nUrl: N/A",
  "Faculty Name: shinji watanabe\nPaperid: e146e5221c124d93f69516c5ae7e1b7b1822848e\nTitle: TAPLoss: A Temporal Acoustic Parameter Loss for Speech Enhancement\nYear: 2023\nAbstract: Speech enhancement models have greatly progressed in recent years, but still show limits in perceptual quality of their speech outputs. We propose an objective for perceptual quality based on temporal acoustic parameters. These are fundamental speech features that play an essential role in various applications, including speaker recognition and paralinguistic analysis. We provide a differentiable estimator for four categories of low-level acoustic descriptors involving: frequency-related parameters, energy or amplitude-related parameters, spectral balance parameters, and temporal features. Un-like prior work that looks at aggregated acoustic parameters or a few categories of acoustic parameters, our temporal acoustic parameter (TAP) loss enables auxiliary optimization and improvement of many fine-grained speech characteristics in enhancement workflows. We show that adding TAPLoss as an auxiliary objective in speech enhancement produces speech with improved perceptual quality and intelligibility.",
  "We show that adding TAPLoss as an auxiliary objective in speech enhancement produces speech with improved perceptual quality and intelligibility. We use data from the Deep Noise Suppression 2020 Challenge to demonstrate that both time-domain models and time-frequency domain models can benefit from our method.\nAuthors: YUNYANG ZENG, Joseph Konan, Shuo Han, David Bick, Muqiao Yang, Anurag Kumar, Shinji Watanabe, B. Raj\nVenue: IEEE International Conference on Acoustics, Speech, and Signal Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work shows that adding TAPLoss as an auxiliary objective in speech enhancement produces speech with improved perceptual quality and intelligibility and uses data from the Deep Noise Suppression 2020 Challenge to demonstrate that both time-domain models and time-frequency domain models can benefit from the method.'}\nUrl: https://arxiv.org/pdf/2302.08088",
  "Faculty Name: shinji watanabe\nPaperid: e25f6a60211aa74ecfde8001a5939ff206102de4\nTitle: End-to-End Speech Recognition: A Survey\nYear: 2023\nAbstract: In the last decade of automatic speech recognition (ASR) research, the introduction of deep learning has brought considerable reductions in word error rate of more than 50% relative, compared to modeling without deep learning. In the wake of this transition, a number of all-neural ASR architectures have been introduced. These so-called end-to-end (E2E) models provide highly integrated, completely neural ASR models, which rely strongly on general machine learning knowledge, learn more consistently from data, with lower dependence on ASR domain-specific experience. The success and enthusiastic adoption of deep learning, accompanied by more generic model architectures has led to E2E models now becoming the prominent ASR approach. The goal of this survey is to provide a taxonomy of E2E ASR models and corresponding improvements, and to discuss their properties and their relationship to classical hidden Markov model (HMM) based ASR architectures.",
  "The goal of this survey is to provide a taxonomy of E2E ASR models and corresponding improvements, and to discuss their properties and their relationship to classical hidden Markov model (HMM) based ASR architectures. All relevant aspects of E2E ASR are covered in this work: modeling, training, decoding, and external language model integration, discussions of performance and deployment opportunities, as well as an outlook into potential future developments.\nAuthors: Rohit Prabhavalkar, Takaaki Hori, Tara N. Sainath, R. Schluter, Shinji Watanabe\nVenue: IEEE/ACM Transactions on Audio Speech and Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A taxonomy of E2E ASR models and corresponding improvements is provided, and their properties and their relationship to classical hidden Markov model (HMM) based ASR architectures are discussed.'}\nUrl: https://ieeexplore.ieee.org/ielx7/6570655/6633080/10301513.pdf",
  "Faculty Name: shinji watanabe\nPaperid: e2826002978af39afce7529f172ffdc222342651\nTitle: The Multimodal Information Based Speech Processing (Misp) 2022 Challenge: Audio-Visual Diarization And Recognition\nYear: 2023\nAbstract: The Multi-modal Information based Speech Processing (MISP) challenge aims to extend the application of signal processing technology in specific scenarios by promoting the research into wake-up words, speaker diarization, speech recognition, and other technologies. The MISP2022 challenge has two tracks: 1) audio-visual speaker diarization (AVSD), aiming to solve \"who spoken when\" using both audio and visual data; 2) a novel audio-visual diarization and recognition (AVDR) task that focuses on addressing \"who spoken what when\" with audio-visual speaker diarization results. Both tracks focus on the Chinese language, and use far-field audio and video in real home-tv scenarios: 2-6 people communicating each other with TV noise in the background. This paper introduces the dataset, track settings, and baselines of the MISP2022 challenge.",
  "Both tracks focus on the Chinese language, and use far-field audio and video in real home-tv scenarios: 2-6 people communicating each other with TV noise in the background. This paper introduces the dataset, track settings, and baselines of the MISP2022 challenge. Our analyses of experiments and examples indicate the good performance of AVDR baseline system, and the potential difficulties in this challenge due to, e.g., the far-field video quality, the presence of TV noise in the background, and the indistinguishable speakers.",
  "Our analyses of experiments and examples indicate the good performance of AVDR baseline system, and the potential difficulties in this challenge due to, e.g., the far-field video quality, the presence of TV noise in the background, and the indistinguishable speakers.\nAuthors: Zhe Wang, Shilong Wu, Hang Chen, Maokui He, Jun Du, Chin-Hui Lee, Jingdong Chen, Shinji Watanabe, Sabato Marco Siniscalchi, O. Scharenborg, Diyuan Liu, Baocai Yin, Jia Pan, Jianqing Gao, Cong Liu\nVenue: IEEE International Conference on Acoustics, Speech, and Signal Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The dataset, track settings, and baselines of the MISP2022 challenge are introduced, and analyses of experiments and examples indicate the good performance of AVDR baseline system, and the potential difficulties in this challenge due to, e.g., the far-field video quality, the presence of TV noise in the background, andThe indistinguishable speakers.'}",
  "Url: https://repository.tudelft.nl/islandora/object/uuid%3A3e54aaa0-46f8-4411-a5ca-351a314d73ce/datastream/OBJ/download",
  "Faculty Name: shinji watanabe\nPaperid: e4f2d75856ce149b994f079ae50fd33ca47245d3\nTitle: DPHuBERT: Joint Distillation and Pruning of Self-Supervised Speech Models\nYear: 2023\nAbstract: Self-supervised learning (SSL) has achieved notable success in many speech processing tasks, but the large model size and heavy computational cost hinder the deployment. Knowledge distillation trains a small student model to mimic the behavior of a large teacher model. However, the student architecture usually needs to be manually designed and will remain fixed during training, which requires prior knowledge and can lead to suboptimal performance. Inspired by recent success of task-specific structured pruning, we propose DPHuBERT, a novel task-agnostic compression method for speech SSL based on joint distillation and pruning. Experiments on SUPERB show that DPHuBERT outperforms pure distillation methods in almost all tasks. Moreover, DPHuBERT requires little training time and performs well with limited training data, making it suitable for resource-constrained applications. Our method can also be applied to various speech SSL models.",
  "Moreover, DPHuBERT requires little training time and performs well with limited training data, making it suitable for resource-constrained applications. Our method can also be applied to various speech SSL models. Our code and models will be publicly available.\nAuthors: Yifan Peng, Yui Sudo, Muhammad Shakeel, Shinji Watanabe\nVenue: Interspeech\nTldr: {'model': 'tldr@v2.0.0', 'text': 'DPHuBERT is proposed, a novel task-agnostic compression method for speech SSL based on joint distillation and pruning that requires little training time and performs well with limited training data, making it suitable for resource-constrained applications.'}\nUrl: http://arxiv.org/pdf/2305.17651",
  "Faculty Name: shinji watanabe\nPaperid: e64d4b29a4a6ccac3673b4cedbefa1e54e774c20\nTitle: An external quality assessment feasibility study; cross laboratory comparison of haemagglutination inhibition assay and microneutralization assay performance for seasonal influenza serology testing: A FLUCOP study\nYear: 2023\nAbstract: Introduction External Quality Assessment (EQA) schemes are designed to provide a snapshot of laboratory proficiency, identifying issues and providing feedback to improve laboratory performance and inter-laboratory agreement in testing. Currently there are no international EQA schemes for seasonal influenza serology testing. Here we present a feasibility study for conducting an EQA scheme for influenza serology methods. Methods We invited participant laboratories from industry, contract research organizations (CROs), academia and public health institutions who regularly conduct hemagglutination inhibition (HAI) and microneutralization (MN) assays and have an interest in serology standardization. In total 16 laboratories returned data including 19 data sets for HAI assays and 9 data sets for MN assays.",
  "In total 16 laboratories returned data including 19 data sets for HAI assays and 9 data sets for MN assays. Results Within run analysis demonstrated good laboratory performance for HAI, with intrinsically higher levels of intra-assay variation for MN assays. Between run analysis showed laboratory and strain specific issues, particularly with B strains for HAI, whilst MN testing was consistently good across labs and strains. Inter-laboratory variability was higher for MN assays than HAI, however both assays showed a significant reduction in inter-laboratory variation when a human sera pool is used as a standard for normalization. Discussion This study has received positive feedback from participants, highlighting the benefit such an EQA scheme would have on improving laboratory performance, reducing inter laboratory variation and raising awareness of both harmonized protocol use and the benefit of biological standards for seasonal influenza serology testing.\nAuthors: J. Waldock, C. Weiss, Wei Wang, M. Levine, Stacie N. Jefferson, S. Ho, K. Hoschler, B. Londt, E. Masat, Louise A. Carolan, Stephany S\u00e1nchez-Ovando, A. Fox, Shinji Watanabe, Miki Akimoto, Aya Sato, N.",
  "Levine, Stacie N. Jefferson, S. Ho, K. Hoschler, B. Londt, E. Masat, Louise A. Carolan, Stephany S\u00e1nchez-Ovando, A. Fox, Shinji Watanabe, Miki Akimoto, Aya Sato, N. Kishida, A. Buys, Lorens Maake, Cardia Fourie, Catherine Caillet, Sandrine Raynaud, R. Webby, J. Debeauchamp, R. Cox, Sarah Lartey, C. Trombetta, S. Marchi, E. Montomoli, I. Sanz-Mu\u00f1oz, J. Eiros, Javier S\u00e1nchez-Mart\u00ednez, D. Duijsings, O. Engelhardt\nVenue: Frontiers in Immunology\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A feasibility study for conducting an EQA scheme for influenza serology methods showing good laboratory performance for HAI, with intrinsically higher levels of intra-assay variation for MN assays, and a significant reduction in inter-laboratory variation when a human sera pool is used as a standard for normalization.'}",
  "with intrinsically higher levels of intra-assay variation for MN assays, and a significant reduction in inter-laboratory variation when a human sera pool is used as a standard for normalization.'}\nUrl: https://www.frontiersin.org/articles/10.3389/fimmu.2023.1129765/pdf",
  "Faculty Name: shinji watanabe\nPaperid: eadca5a91a755c9e8dbc1843c435b9c5ab930477\nTitle: Magnetic dynamics and nonreciprocal excitation in uniform hedgehog order in icosahedral 1/1 approximant crystal\nYear: 2023\nAbstract: None\nAuthors: Shinji Watanabe\nVenue: Scientific Reports\nTldr: None\nUrl: https://www.nature.com/articles/s41598-023-41292-1.pdf",
  "Faculty Name: shinji watanabe\nPaperid: ebb75ff5b5e55ba15e4239ed0ffa6ff2ad00b721\nTitle: Multi-Channel Speaker Extraction with Adversarial Training: The Wavlab Submission to The Clarity ICASSP 2023 Grand Challenge\nYear: 2023\nAbstract: In this work we detail our submission to the Clarity ICASSP 2023 grand challenge, in which participants have to develop a strong target speech enhancement system for hearing-aid (HA) devices in noisy-reverberant environments. Our system builds on our previous submission at the Second Clarity Enhancement Challenge (CEC2): iNeuBe-X, which consists in an iterative neural/conventional beamforming enhancement pipeline, guided by an enrollment utterance from the target speaker. This model, which won by a large margin the CEC2, is an extension of the state-of-the-art TF-GridNet model for multi-channel, streamable target-speaker speech enhancement. Here, this approach is extended and further improved by leveraging generative adversarial training, which we show proves especially useful when the training data is limited.",
  "Here, this approach is extended and further improved by leveraging generative adversarial training, which we show proves especially useful when the training data is limited. Using only the official 6k training scenes data, our best model achieves 0.80 hearing-aid speech perception index (HASPI) and 0.41 hearing-aid speech quality index (HASQI) scores on the synthetic evaluation set. However, our model generalized poorly on the semi-real evaluation set. This highlights the fact that our community should focus more on real-world evaluation and less on fully synthetic datasets.",
  "However, our model generalized poorly on the semi-real evaluation set. This highlights the fact that our community should focus more on real-world evaluation and less on fully synthetic datasets.\nAuthors: Samuele Cornell, Zhongqiu Wang, Yoshiki Masuyama, Shinji Watanabe, Manuel Pariente, Nobutaka Ono, S. Squartini\nVenue: IEEE International Conference on Acoustics, Speech, and Signal Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work details the submission to the Clarity ICASSP 2023 grand challenge, in which participants have to develop a strong target speech enhancement system for hearing-aid (HA) devices in noisy-reverberant environments, and builds on the previous submission at the Second Clarity Enhancement Challenge (CEC2): iNeuBe-X.'}\nUrl: N/A",
  "Faculty Name: shinji watanabe\nPaperid: ef567580e167c3e7c546345df93d644be5d4f66f\nTitle: AV-SUPERB: A Multi-Task Evaluation Benchmark for Audio-Visual Representation Models\nYear: 2023\nAbstract: Audio-visual representation learning aims to develop systems with human-like perception by utilizing correlation between auditory and visual information. However, current models often focus on a limited set of tasks, and generalization abilities of learned representations are unclear. To this end, we propose the AV-SUPERB benchmark that enables general-purpose evaluation of unimodal audio/visual and bimodal fusion representations on 7 datasets covering 5 audio-visual tasks in speech and audio processing. We evaluate 5 recent self-supervised models and show that none of these models generalize to all tasks, emphasizing the need for future study on improving universal model performance. In addition, we show that representations may be improved with intermediate-task fine-tuning and audio event classification with AudioSet serves as a strong intermediate task. We release our benchmark with evaluation code and a model submission platform to encourage further research in audio-visual learning.",
  "In addition, we show that representations may be improved with intermediate-task fine-tuning and audio event classification with AudioSet serves as a strong intermediate task. We release our benchmark with evaluation code and a model submission platform to encourage further research in audio-visual learning.\nAuthors: Yuan Tseng, Layne Berry, Yi-Ting Chen, I-Hsiang Chiu, Hsuan-Hao Lin, Max Liu, Puyuan Peng, Yi-Jen Shih, Hung-Yu Wang, Haibin Wu, Po-Yao Huang, Chun-Mao Lai, Shang-Wen Li, David F. Harwath, Yu Tsao, Shinji Watanabe, Abdel-rahman Mohamed, Chi-Luen Feng, Hung-yi Lee\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The AV-SUPERB benchmark is proposed that enables general-purpose evaluation of unimodal audio/visual and bimodal fusion representations on 7 datasets covering 5 audio-visual tasks in speech and audio processing and shows that representations may be improved with intermediate-task fine-tuning and audio event classification with AudioSet serves as a strong intermediate task.'}",
  "Url: https://arxiv.org/pdf/2309.10787",
  "Faculty Name: shinji watanabe\nPaperid: ef8b095292a8e38e9b8f56c54cbf3c67c3ed425d\nTitle: Improving Cascaded Unsupervised Speech Translation with Denoising Back-translation\nYear: 2023\nAbstract: Most of the speech translation models heavily rely on parallel data, which is hard to collect especially for low-resource languages. To tackle this issue, we propose to build a cascaded speech translation system without leveraging any kind of paired data. We use fully unpaired data to train our unsupervised systems and evaluate our results on CoVoST 2 and CVSS. The results show that our work is comparable with some other early supervised methods in some language pairs. While cascaded systems always suffer from severe error propagation problems, we proposed denoising back-translation (DBT), a novel approach to building robust unsupervised neural machine translation (UNMT). DBT successfully increases the BLEU score by 0.7--0.9 in all three translation directions. Moreover, we simplified the pipeline of our cascaded system to reduce inference latency and conducted a comprehensive analysis of every part of our work.",
  "DBT successfully increases the BLEU score by 0.7--0.9 in all three translation directions. Moreover, we simplified the pipeline of our cascaded system to reduce inference latency and conducted a comprehensive analysis of every part of our work. We also demonstrate our unsupervised speech translation results on the established website.\nAuthors: Yu-Kuan Fu, Liang-Hsuan Tseng, Jiatong Shi, Chen-An Li, Tsung-Yuan Hsu, Shinji Watanabe, Hung-yi Lee\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposed denoising back-translation (DBT), a novel approach to building robust unsupervised neural machine translation (UNMT), which successfully increases the BLEU score by 0.7--0.9 in all three translation directions.'}\nUrl: http://arxiv.org/pdf/2305.07455",
  "Faculty Name: shinji watanabe\nPaperid: f53b6f5a85f2d74deb32022795b5dab0aa753cf4\nTitle: Deep Speech Synthesis from MRI-Based Articulatory Representations\nYear: 2023\nAbstract: In this paper, we study articulatory synthesis, a speech synthesis method using human vocal tract information that offers a way to develop efficient, generalizable and interpretable synthesizers. While recent advances have enabled intelligible articulatory synthesis using electromagnetic articulography (EMA), these methods lack critical articulatory information like excitation and nasality, limiting generalization capabilities. To bridge this gap, we propose an alternative MRI-based feature set that covers a much more extensive articulatory space than EMA. We also introduce normalization and denoising procedures to enhance the generalizability of deep learning methods trained on MRI data. Moreover, we propose an MRI-to-speech model that improves both computational efficiency and speech fidelity. Finally, through a series of ablations, we show that the proposed MRI representation is more comprehensive than EMA and identify the most suitable MRI feature subset for articulatory synthesis.",
  "Moreover, we propose an MRI-to-speech model that improves both computational efficiency and speech fidelity. Finally, through a series of ablations, we show that the proposed MRI representation is more comprehensive than EMA and identify the most suitable MRI feature subset for articulatory synthesis.\nAuthors: Peter Wu, Tingle Li, Yijingxiu Lu, Yubin Zhang, Jiachen Lian, A. Black, L. Goldstein, Shinji Watanabe, G. Anumanchipalli\nVenue: Interspeech\nTldr: {'model': 'tldr@v2.0.0', 'text': 'An MRI-to-speech model that improves both computational efficiency and speech fidelity is proposed and the proposed MRI representation is more comprehensive than EMA and the most suitable MRI feature subset for articulatory synthesis is identified.'}\nUrl: https://arxiv.org/pdf/2307.02471",
  "Faculty Name: shinji watanabe\nPaperid: f7e995c3cae465963ecaa8c9b4ce8b9b4323a71b\nTitle: FINDINGS OF THE IWSLT 2023 EVALUATION CAMPAIGN\nYear: 2023\nAbstract: This paper reports on the shared tasks organized by the 20th IWSLT Conference. The shared tasks address 9 scientific challenges in spoken language translation: simultaneous and offline translation, automatic subtitling and dubbing, speech-to-speech translation, multilingual, dialect and low-resource speech translation, and formality control. The shared tasks attracted a total of 38 submissions by 31 teams. The growing interest towards spoken language translation is also witnessed by the constantly increasing number of shared task organizers and contributors to the overview paper, almost evenly distributed across industry and academia.",
  "The shared tasks attracted a total of 38 submissions by 31 teams. The growing interest towards spoken language translation is also witnessed by the constantly increasing number of shared task organizers and contributors to the overview paper, almost evenly distributed across industry and academia.\nAuthors: Sweta Agrawal, Antonios Anastasopoulos, L. Bentivogli, Ondrej Bojar, Claudia Borg, Marine Carpuat, R. Cattoni, Mauro Cettolo, Mingda Chen, William Chen, K. Choukri, Alexandra Chronopoulou, Anna Currey, T. Declerck, Qianqian Dong, Kevin Duh, Y. Est\u00e8ve, Marcello Federico, Souhir Gahbiche, B. Haddow, B. Hsu, Phu Mon Htut, H. Inaguma, D\u00e1vid Javorsk\u00fd, J. Judge, Yasumasa Kano, Tom Ko, Rishu Kumar, Peng Li, Xutai Ma, Prashant Mathur, E. Matusov, Paul McNamee, John P. McCrae, Kenton Murray, Maria Nadejde, Satoshi Nakamura, Matteo Negri, H. Nguyen, J. Niehues, Xing Niu, Atul Kr.",
  "Ojha, John E. Ortega, Proyag Pal, J. Pino, Lonneke van der Plas, Peter Pol\u00e1k, Elijah Matthew Rippeth, Elizabeth Salesky, Jiatong Shi, Matthias Sperber, Sebastian St\u00fcker, Katsuhito Sudoh, Yun Tang, Brian Thompson, Ke M. Tran, Marco Turchi, A. Waibel, Mingxuan Wang, Shinji Watanabe, Rodolfo Zevallos\nVenue: International Workshop on Spoken Language Translation\nTldr: {'model': 'tldr@v2.0.0', 'text': None}\nUrl: https://aclanthology.org/2023.iwslt-1.1.pdf",
  "Faculty Name: shinji watanabe\nPaperid: f80c354908efd4d5617878e36e35446016534190\nTitle: Semi-Autoregressive Streaming ASR With Label Context\nYear: 2023\nAbstract: Non-autoregressive (NAR) modeling has gained significant interest in speech processing since these models achieve dramatically lower inference time than autoregressive (AR) models while also achieving good transcription accuracy. Since NAR automatic speech recognition (ASR) models must wait for the completion of the entire utterance before processing, some works explore streaming NAR models based on blockwise attention for low-latency applications. However, streaming NAR models significantly lag in accuracy compared to streaming AR and non-streaming NAR models. To address this, we propose a streaming\"semi-autoregressive\"ASR model that incorporates the labels emitted in previous blocks as additional context using a Language Model (LM) subnetwork. We also introduce a novel greedy decoding algorithm that addresses insertion and deletion errors near block boundaries while not significantly increasing the inference time.",
  "We also introduce a novel greedy decoding algorithm that addresses insertion and deletion errors near block boundaries while not significantly increasing the inference time. Experiments show that our method outperforms the existing streaming NAR model by 19% relative on Tedlium2, 16%/8% on Librispeech-100 clean/other test sets, and 19%/8% on the Switchboard(SWB)/Callhome(CH) test sets. It also reduced the accuracy gap with streaming AR and non-streaming NAR models while achieving 2.5x lower latency. We also demonstrate that our approach can effectively utilize external text data to pre-train the LM subnetwork to further improve streaming ASR accuracy.\nAuthors: Siddhant Arora, G. Saon, Shinji Watanabe, Brian Kingsbury\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes a streaming\"semi-autoregressive\"ASR model that incorporates the labels emitted in previous blocks as additional context using a Language Model (LM) subnetwork and introduces a novel greedy decoding algorithm that addresses insertion and deletion errors near block boundaries while not significantly increasing the inference time.'}",
  "Url: https://arxiv.org/pdf/2309.10926",
  "Faculty Name: shinji watanabe\nPaperid: fa5ebb425c57f6c4f1c36a7200ef1da867346e8c\nTitle: Speech collage: code-switched audio generation by collaging monolingual corpora\nYear: 2023\nAbstract: Designing effective automatic speech recognition (ASR) systems for Code-Switching (CS) often depends on the availability of the transcribed CS resources. To address data scarcity, this paper introduces Speech Collage, a method that synthesizes CS data from monolingual corpora by splicing audio segments. We further improve the smoothness quality of audio generation using an overlap-add approach. We investigate the impact of generated data on speech recognition in two scenarios: using in-domain CS text and a zero-shot approach with synthesized CS text. Empirical results highlight up to 34.4% and 16.2% relative reductions in Mixed-Error Rate and Word-Error Rate for in-domain and zero-shot scenarios, respectively. Lastly, we demonstrate that CS augmentation bolsters the model's code-switching inclination and reduces its monolingual bias.",
  "Empirical results highlight up to 34.4% and 16.2% relative reductions in Mixed-Error Rate and Word-Error Rate for in-domain and zero-shot scenarios, respectively. Lastly, we demonstrate that CS augmentation bolsters the model's code-switching inclination and reduces its monolingual bias.\nAuthors: A. Hussein, Dorsa Zeinali, Ondrej Klejch, Matthew Wiesner, Brian Yan, Shammur A. Chowdhury, Ahmed Ali, Shinji Watanabe, S. Khudanpur\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': \"Speech Collage is introduced, a method that synthesizes CS data from monolingual corpora by splicing audio segments that improves the smoothness quality of audio generation using an overlap-add approach and demonstrates that CS augmentation bolsters the model's code-switching inclination and reduces itsmonolingual bias.\"}\nUrl: https://arxiv.org/pdf/2309.15674",
  "Faculty Name: shinji watanabe\nPaperid: fa75ef55e04e3b25b8af56435478c2fd17403ce8\nTitle: Exploration on HuBERT with Multiple Resolutions\nYear: 2023\nAbstract: Hidden-unit BERT (HuBERT) is a widely-used self-supervised learning (SSL) model in speech processing. However, we argue that its fixed 20ms resolution for hidden representations would not be optimal for various speech-processing tasks since their attributes (e.g., speaker characteristics and semantics) are based on different time scales. To address this limitation, we propose utilizing HuBERT representations at multiple resolutions for downstream tasks. We explore two approaches, namely the parallel and hierarchical approaches, for integrating HuBERT features with different resolutions. Through experiments, we demonstrate that HuBERT with multiple resolutions outperforms the original model. This highlights the potential of utilizing multiple resolutions in SSL models like HuBERT to capture diverse information from speech signals.",
  "We explore two approaches, namely the parallel and hierarchical approaches, for integrating HuBERT features with different resolutions. Through experiments, we demonstrate that HuBERT with multiple resolutions outperforms the original model. This highlights the potential of utilizing multiple resolutions in SSL models like HuBERT to capture diverse information from speech signals.\nAuthors: Jiatong Shi, Yun Tang, H. Inaguma, Hongyu Gong, J. Pino, Shinji Watanabe\nVenue: Interspeech\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Through experiments, it is demonstrated that HuBERT with multiple resolutions outperforms the original model, highlighting the potential of utilizing multiple resolutions in SSL models like HuberT to capture diverse information from speech signals.'}\nUrl: http://arxiv.org/pdf/2306.01084",
  "List of 2023 Open Access papers by shinji watanabe are:\nCrystalline electric field and magnetic anisotropy in Dy-based icosahedral quasicrystal and approximant\nMagnetism and topological property in icosahedral quasicrystal\nAssessment of the frequency of SARS-CoV-2 Omicron variant escape from RNA-dependent RNA polymerase inhibitors and 3C-like protease inhibitors.\nSaturation time of exposure interval for cross-neutralization response to SARS-CoV-2: Implications for vaccine dose interval\nJoint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning\nTensor decomposition for minimization of E2E SLU model toward on-device processing\nDecoder-only Architecture for Speech Recognition with CTC Prompts and Text Data Augmentation\nML-SUPERB: Multilingual Speech Universal PERformance Benchmark\nStructured Pruning of Self-Supervised Pre-Trained Models for Speech Recognition and Understanding\nPrompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot Task Generalization\nA Comparative Study on E-Branchformer vs Conformer in Speech Recognition, Translation,",
  "Translation, and Understanding Tasks\nEfficient Sequence Transduction by Jointly Predicting Tokens and Durations\nSpeech Summarization of Long Spoken Document: Improving Memory Efficiency of Speech/Text Encoders\nUNSSOR: Unsupervised Neural Speech Separation by Leveraging Over-determined Training Mixtures\nSegment-Level Vectorized Beam Search Based on Partially Autoregressive Inference\nUnsupervised Data Selection for TTS: Using Arabic Broadcast News as a Case Study\nBASS: Block-wise Adaptation for Speech Summarization\nI3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition\nA Vector Quantized Approach for Text to Speech Synthesis on Real-World Spontaneous Speech\nA New Benchmark of Aphasia Speech Recognition and Detection Based on E-Branchformer and Multi-task Learning\nAntiviral Susceptibilities of Distinct Lineages of Influenza C and D Viruses\nPaaploss: A Phonetic-Aligned Acoustic Parameter Loss for Speech Enhancement\nSigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing\nExploring the Integration of Speech Separation and Recognition with Self-Supervised Learning Representation\nDynamic-SUPERB: Towards A Dynamic, Collaborative,",
  "Collaborative, and Comprehensive Instruction-Tuning Benchmark for Speech\nSpeaker-Independent Acoustic-to-Articulatory Speech Inversion\nTowards Practical and Efficient Image-to-Speech Captioning with Vision-Language Pre-training and Multi-modal Tokens\nEnhancing Speech-To-Speech Translation with Multiple TTS Targets\nAudioGPT: Understanding and Generating Speech, Music, Sound, and Talking Head\nImproving Audio Captioning Models with Fine-grained Audio Features, Text Embedding Supervision,",
  "Music, Sound, and Talking Head\nImproving Audio Captioning Models with Fine-grained Audio Features, Text Embedding Supervision, and LLM Mix-up Augmentation\nVoxtlm: unified decoder-only models for consolidating speech recognition/synthesis and speech/text continuation tasks\nLearning to Speak from Text: Zero-Shot Multilingual Text-to-Speech with Unsupervised Text Pretraining\nFNeural Speech Enhancement with Very Low Algorithmic Latency and Complexity via Integrated full- and sub-band Modeling\nImproving Massively Multilingual ASR with Auxiliary CTC Objectives\nToward Universal Speech Enhancement For Diverse Input Conditions\nThe Pipeline System of ASR and NLU with MLM-based data Augmentation Toward Stop Low-Resource Challenge\nA Study on the Integration of Pipeline and E2E SLU Systems for Spoken Semantic Parsing Toward Stop Quality Challenge\nA community cluster of influenza A(H3N2) virus infection with reduced susceptibility to baloxavir due to a PA E199G substitution in Japan, February to March 2023\nExploring Speech Recognition, Translation, and Understanding with Discrete Speech Units: A Comparative Study\nJoint Modelling of Spoken Language Understanding Tasks with Integrated Dialog History\nEnhancing End-to-End Conversational",
  "February to March 2023\nExploring Speech Recognition, Translation, and Understanding with Discrete Speech Units: A Comparative Study\nJoint Modelling of Spoken Language Understanding Tasks with Integrated Dialog History\nEnhancing End-to-End Conversational Speech Translation Through Target Language Context Utilization\nChallenges of Corporate Alliance CLOMA toward Plastic Litter\nThe Multimodal Information Based Speech Processing (MISP) 2023 Challenge: Audio-Visual Target Speaker Extraction\nReproducing Whisper-Style Training Using An Open-Source Toolkit And Publicly Available Data\nThe CHiME-7 DASR Challenge: Distant Meeting Transcription with Multiple Devices in Diverse Scenarios\nCross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing\nESPnet-ST-v2: Multipurpose Spoken Language Translation Toolkit\nMulti-Channel Target Speaker Extraction with Refinement: The WavLab Submission to the Second Clarity Enhancement Challenge\nFully Unsupervised Topic Clustering of Unlabelled Spoken Audio Using Self-Supervised Representation Learning and Topic Model\nTAPLoss: A Temporal Acoustic Parameter Loss for Speech Enhancement\nEnd-to-End Speech Recognition: A Survey\nThe Multimodal Information Based Speech Processing (Misp)",
  "Challenge\nFully Unsupervised Topic Clustering of Unlabelled Spoken Audio Using Self-Supervised Representation Learning and Topic Model\nTAPLoss: A Temporal Acoustic Parameter Loss for Speech Enhancement\nEnd-to-End Speech Recognition: A Survey\nThe Multimodal Information Based Speech Processing (Misp) 2022 Challenge: Audio-Visual Diarization And Recognition\nDPHuBERT: Joint Distillation and Pruning of Self-Supervised Speech Models\nAn external quality assessment feasibility study;",
  "Speech Enhancement\nEnd-to-End Speech Recognition: A Survey\nThe Multimodal Information Based Speech Processing (Misp) 2022 Challenge: Audio-Visual Diarization And Recognition\nDPHuBERT: Joint Distillation and Pruning of Self-Supervised Speech Models\nAn external quality assessment feasibility study; cross laboratory comparison of haemagglutination inhibition assay and microneutralization assay performance for seasonal influenza serology testing: A FLUCOP study\nMulti-Channel Speaker Extraction with Adversarial Training: The Wavlab Submission to The Clarity ICASSP 2023 Grand Challenge\nAV-SUPERB: A Multi-Task Evaluation Benchmark for Audio-Visual Representation Models\nImproving Cascaded Unsupervised Speech Translation with Denoising Back-translation\nDeep Speech Synthesis from MRI-Based Articulatory Representations\nFINDINGS OF THE IWSLT 2023 EVALUATION CAMPAIGN\nSpeech collage: code-switched audio generation by collaging monolingual corpora\nExploration on HuBERT with Multiple Resolutions\nA Randomized, Double-Blind,",
  "Double-Blind, Controlled Trial Assessing If Medium-Chain Triglycerides in Combination with Moderate-Intensity Exercise Increase Muscle Strength in Healthy Middle-Aged and Older Adults\nSemi-Autoregressive Streaming ASR With Label Context\nIntegrating Pretrained ASR and LM to Perform Sequence Generation for Spoken Language Understanding\nReducing Barriers to Self-Supervised Learning: HuBERT Pre-training with Academic Compute\nFindAdaptNet: Find and Insert Adapters by Learned Layer Importance\nCMU\u2019s IWSLT 2023 Simultaneous Speech Translation System\nExploration of Efficient End-to-End ASR using Discretized Input from Self-Supervised Learning\nIntegration of Frame- and Label-synchronous Beam Search for Streaming Encoder-decoder Speech Recognition\nE-Branchformer-Based E2E SLU Toward Stop on-Device Challenge\nIncremental Blockwise Beam Search for Simultaneous Speech Translation with Controllable Quality-Latency Tradeoff\nBayes Risk Transducer: Transducer with Controllable Alignment Prediction\nUniverSLU: Universal Spoken Language Understanding for Diverse Classification and Sequence Generation Tasks with a Single Network\nOne model to rule them all ?",
  "Towards End-to-End Joint Speaker Diarization and Speech Recognition\nAntiviral efficacy against and replicative fitness of an XBB.1.9.1 clinical isolate\nSoftware Design and User Interface of ESPnet-SE++: Speech Enhancement for Robust Speech Processing\nA Single Speech Enhancement Model Unifying Dereverberation, Denoising, Speaker Counting, Separation, And Extraction\nAntigenic drift and subtype interference shape A(H3N2) epidemic dynamics in the United States\nFindings of the 2023 ML-Superb Challenge: Pre-Training And Evaluation Over More Languages And Beyond\nMagnetic dynamics and nonreciprocal excitation in uniform hedgehog order in icosahedral 1/1 approximant crystal\nTorchAudio 2.1: Advancing Speech Recognition, Self-Supervised Learning, and Audio Processing Components for Pytorch\nEffect of medium-chain triglycerides supplements and walking on health-related quality of life in sedentary, healthy middle-aged, and older adults with low BMIs: a randomized, double-blind, placebo-controlled, parallel-group trial",
  "Shinji Watanabe\nAssociate Professor, Language Technologies Institute\nContact\n6405 \u2014Gates & Hillman Centers\nEmail swatanab@andrew.cmu.edu\n412-268-3687\nResearch Area\nNatural Language Processing and Computational Linguistics, Speech Processing\n\nPersonal Website https://sites.google.com/view/shinjiwatanabe?pli=1",
  "Faculty Name: teruko mitamura\nPaperid: 444737639aeea4e1e616509e368afb0bae8f89d6\nTitle: Language-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA\nYear: 2023\nAbstract: The DialDoc 2023 shared task has expanded the document-grounded dialogue task to encompass multiple languages, despite having limited annotated data. This paper assesses the effectiveness of both language-agnostic and language-aware paradigms for multilingual pre-trained transformer models in a bi-encoder-based dense passage retriever (DPR), concluding that the language-agnostic approach is superior. Additionally, the study investigates the impact of query rewriting techniques using large language models, such as ChatGPT, on multilingual, document-grounded question-answering systems. The experiments conducted demonstrate that, for the examples examined, query rewriting does not enhance performance compared to the original queries. This failure is due to topic switching in final dialogue turns and irrelevant topics being considered for query rewriting.",
  "The experiments conducted demonstrate that, for the examples examined, query rewriting does not enhance performance compared to the original queries. This failure is due to topic switching in final dialogue turns and irrelevant topics being considered for query rewriting.\nAuthors: Srinivas Gowriraj, Soham Dinesh Tiwari, Mitali Potnis, Srijan Bansal, T. Mitamura, Eric Nyberg\nVenue: Workshop on Document-grounded Dialogue and Conversational Question Answering\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper assesses the effectiveness of both language-agnostic and language-aware paradigms for multilingual pre-trained transformer models in a bi-encoder-based dense passage retriever (DPR), concluding that the language-gnostic approach is superior.'}\nUrl: https://aclanthology.org/2023.dialdoc-1.11.pdf",
  "Faculty Name: teruko mitamura\nPaperid: ff77105b2c345f54e1a87f4fbb3a701201f0c1a8\nTitle: Hierarchical Event Grounding\nYear: 2023\nAbstract: Event grounding aims at linking mention references in text corpora to events from a knowledge base (KB). Previous work on this task focused primarily on linking to a single KB event, thereby overlooking the hierarchical aspects of events. Events in documents are typically described at various levels of spatio-temporal granularity. These hierarchical relations are utilized in downstream tasks of narrative understanding and schema construction. In this work, we present an extension to the event grounding task that requires tackling hierarchical event structures from the KB. Our proposed task involves linking a mention reference to a set of event labels from a subevent hierarchy in the KB. We propose a retrieval methodology that leverages event hierarchy through an auxiliary hierarchical loss. On an automatically created multilingual dataset from Wikipedia and Wikidata, our experiments demonstrate the effectiveness of the hierarchical loss against retrieve and re-rank baselines. Furthermore, we demonstrate the systems' ability to aid hierarchical discovery among unseen events.",
  "On an automatically created multilingual dataset from Wikipedia and Wikidata, our experiments demonstrate the effectiveness of the hierarchical loss against retrieve and re-rank baselines. Furthermore, we demonstrate the systems' ability to aid hierarchical discovery among unseen events. Code is available at https://github.com/JefferyO/Hierarchical-Event-Grounding\nAuthors: Jiefu Ou, Adithya Pratapa, Rishubh Gupta, T. Mitamura\nVenue: AAAI Conference on Artificial Intelligence\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work presents an extension to the event grounding task that requires tackling hierarchical event structures from the KB, and proposes a retrieval methodology that leverages event hierarchy through an auxiliary hierarchical loss.'}\nUrl: http://arxiv.org/pdf/2302.04197",
  "List of 2023 Open Access papers by teruko mitamura are:\nLanguage-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA\nHierarchical Event Grounding",
  "Teruko Mitamura\nResearch Professor, Language Technologies Institute\nResearch Area\nInformation Extraction, Summarization and Question Answering, Information Retrieval, Text Mining and Analytics, Language Technologies for Education, Natural Language Processing and Computational Linguistics\n\nhttps://www.cs.cmu.edu/~teruko/\n6711 \u2014Gates & Hillman Centers\nteruko@cs.cmu.edu\ntel:412-268-6596",
  "List of 2023 Open Access papers by yang yiming are:\nFunctional targeted therapy for glioma based on platelet membrane-coated nanogels\nDual Responsive Magnetic Drug Delivery Nanomicelles with Tumor Targeting for Enhanced Cancer Chemo/Magnetothermal Synergistic Therapy\nExpression of ALCAM in Clinical Colon Cancer and Relationship With Patients\u2019 Treatment Responses\nClaudin-10 in the Blood Brain Barrier Function of Cerebral Endothelial Cells and Transendothelial Invasion of Breast Cancer Cells\nAccelerating Diffusion-based Combinatorial Optimization Solvers by Progressive Distillation\nAutomatic synchrotron tomographic alignment schemes based on genetic algorithms and human-in-the-loop software\nHigh CD8+tumor-infiltrating lymphocytes indicate severe exhaustion and poor prognosis in angioimmunoblastic T-cell lymphoma\nNumerical Investigation of Fatigue Crack Propagation Behaviour of 550E High-Performance Steel\nAssociation between albumin-to-globulin ratio and the risk of overall survival in advanced non-small cell lung cancer patients with anlotinib treatment: a retrospective cohort study\nAnalysis of Volatile Components in Dried Fruits and Branch Exudates of Schisandra chinensis with Different Fruit Colors Using GC-IMS Technology\nSecreted",
  "ratio and the risk of overall survival in advanced non-small cell lung cancer patients with anlotinib treatment: a retrospective cohort study\nAnalysis of Volatile Components in Dried Fruits and Branch Exudates of Schisandra chinensis with Different Fruit Colors Using GC-IMS Technology\nSecreted endogenous macrosomes reduce A\u03b2 burden and ameliorate Alzheimer\u2019s disease\nDIFUSCO: Graph-based Diffusion Solvers for Combinatorial Optimization\nBalancing Exploration and Exploitation in Hierarchical Reinforcement Learning via Latent Landmark Graphs\nAligning Large Multimodal Models with Factually Augmented RLHF\nAn Experimental Study on Secondary Transfer Performances of Prestress after Anchoring Failure of Steel Wire Strands\nMRI Features for Predicting Microvascular Invasion and Postoperative Recurrence in Hepatocellular Carcinoma Without Peritumoral Hypointensity\nImpact of local governments\u2019 construction land allocation strategies on innovation-driven development of China\n16p11.2 CNV gene Doc2\u03b1 functions in neurodevelopment and social behaviors through interaction with Secretagogin.",
  "and Postoperative Recurrence in Hepatocellular Carcinoma Without Peritumoral Hypointensity\nImpact of local governments\u2019 construction land allocation strategies on innovation-driven development of China\n16p11.2 CNV gene Doc2\u03b1 functions in neurodevelopment and social behaviors through interaction with Secretagogin.\nChinese EFL learners different from English natives in cataphora resolution: Evidence from eye-tracking studies\nStrain-driven Kovacs-like memory effect in glasses\nThe Relationship between the Serum NLRP1 Level and Coronary Lesions in Patients with Coronary Artery Disease\nMatrine induces ferroptosis in cervical cancer through activation of piezo1 channel.\nLet's Sample Step by Step: Adaptive-Consistency for Efficient Reasoning with LLMs\nTRPML1 as a potential therapeutic target for triple-negative breast cancer: a review\nGenome- and transcriptome-wide identification of trehalose-6-phosphate phosphatases (TPP) gene family and their expression patterns under abiotic stress and exogenous trehalose in soybean\nSynergistic Interface Engineering of RuO2/Co3O4 Heterostructures for Enhanced Overall Water Splitting in Acidic Media\nNumerical Analysis on the Influence of Joint Density",
  "(TPP) gene family and their expression patterns under abiotic stress and exogenous trehalose in soybean\nSynergistic Interface Engineering of RuO2/Co3O4 Heterostructures for Enhanced Overall Water Splitting in Acidic Media\nNumerical Analysis on the Influence of Joint Density on the Stability of Complex Jointed Roadway Surrounding Rock\nExperimental Study on Secondary Anchorage Bond Performance of Residual Stress after Corrosion Fracture at Ends of Prestressed Steel Strands\nImaging Field\u2010Driven Melting of a Molecular Solid at the Atomic Scale\nA Wideband Reconfigurable Intelligent Surface for 5G Millimeter-Wave Applications\nA Via-Less Fully Screen-Printed Reconfigurable Intelligent Surface for 5G Millimeter Wave Communication\nSALMON: Self-Alignment with Principle-Following Reward Models\nWidely Targeted Metabolomics Was Used to Reveal the Differences between Non-Volatile Compounds in Different Wines and Their Associations with Sensory Properties\nCardsformer: Grounding Language to Learn a Generalizable Policy in Hearthstone\nApproximation and interpolation with neural network\nA Graphene Geometric Diode with the Highest Asymmetry Ratio and Three States Gate\u2010Tunable Rectification",
  "Non-Volatile Compounds in Different Wines and Their Associations with Sensory Properties\nCardsformer: Grounding Language to Learn a Generalizable Policy in Hearthstone\nApproximation and interpolation with neural network\nA Graphene Geometric Diode with the Highest Asymmetry Ratio and Three States Gate\u2010Tunable Rectification Ability\nDe novo assembling a high-quality genome sequence of Amur grape (Vitis amurensis Rupr.) gives insight into Vitis divergence and sex determination\nInference of single cell profiles from histology stains with the Single-Cell omics from Histology Analysis Framework (SCHAF)\nRecent Advances in the Ecology of Bloom-Forming Raphidiopsis (Cylindrospermopsis) raciborskii: Expansion in China, Intraspecific Heterogeneity and Critical Factors for Invasion\nAn Ultra-Low-Power Analog Multiplier\u2013Divider Compatible with Digital Code for RRAM-Based Computing-in-Memory Macros\nExtension of Pt\u2013Ag cluster units by incorporating silver salts\nOptimization of Critical Factors Affecting Dynamic Membrane Formation in a Gravity-Driven Self-Forming Dynamic Membrane Bioreactor towards Low-Cost and Low-Maintenance Wastewater Treatment\nPESCO: Prompt-enhanced Self",
  "Macros\nExtension of Pt\u2013Ag cluster units by incorporating silver salts\nOptimization of Critical Factors Affecting Dynamic Membrane Formation in a Gravity-Driven Self-Forming Dynamic Membrane Bioreactor towards Low-Cost and Low-Maintenance Wastewater Treatment\nPESCO: Prompt-enhanced Self Contrastive Learning for Zero-shot Text Classification\nLearning Performance-Improving Code Edits\nGeneration-driven Contrastive Self-training for Zero-shot Text Classification with Instruction-tuned GPT\nSelf-Refine: Iterative Refinement with Self-Feedback\nLong-tailed Extreme Multi-label Text Classification by the Retrieval of Generated Pseudo Label Descriptions\nLearning a Fourier Transform for Linear Relative Positional Encodings in Transformers\nEfficient Temporal Sentence Grounding in Videos with Multi-Teacher Knowledge Distillation\nActive Retrieval Augmented Generation\nRetrieval-Enhanced Generative Model for Large-Scale Knowledge Graph Completion\nLet's Sample Step by Step: Adaptive-Consistency for Efficient Reasoning and Coding with LLMs\nPrinciple-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision\nPolicy Representation via Diffusion Probability Model for Reinforcement Learning\nA Neural PDE Solver with Temporal Stencil Modeling\nResearch on Comprehensive Performance Optimization Method",
  "Adaptive-Consistency for Efficient Reasoning and Coding with LLMs\nPrinciple-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision\nPolicy Representation via Diffusion Probability Model for Reinforcement Learning\nA Neural PDE Solver with Temporal Stencil Modeling\nResearch on Comprehensive Performance Optimization Method of Explosives and Propellants Oriented to the Whole Process",
  "Yiming Yang\nProfessor, Language Technologies Institute\nContact\n6717 \u2014Gates & Hillman Centers\nEmail yiming@cs.cmu.edu\n412-268-1364\nResearch\nMy research has centered on statistical learning methods/algorithms and application to very-large-scale text categorization, web-mining for concept graph discovery, semi-supervised clustering, multitask learning, novelty-based information retrieval, large-scale optimization for online advertising, social network analysis for personalized email prioritization, etc. My recent research focuses on the following topics:\n\nLarge-Scale Structured Learning for Hierarchical Classification  (Gopal & Yang, KDD 2013;  Gopal & Yang, ICML 2013 & Supplementary  ;  Gopal et al., NIPS 2012)\n\nProviding organizational views of multi-source Big Data (e.g., Wikipedia, online shops, Coursera)\nState-of-the-art classifiers for large-scale classification over hundreds of thousands of categories\nScalable variational inference for joint optimization of one trillion (4 TB) model parameters\nScalable Machine Learning for Time Series Analysis (Topic Detection and Tracking)\n\nFrom scientific literature, news stories, sensor signals, maintenance reports, etc.",
  "Modeling multi-source and multi-scale evidence of dynamic chances in temporal sequences. (On-going NSF project; Gopal, PhD Thesis)\nA new family of Bayesian von Mices Fischer (vMF) clustering techniques (Gopal & Yang, ICML 2014 & Supplementary)\nUnsupervised clustering and semi-supervised metric learning and supervised classification (Gopal & Yang, UAI 2014 & Supplimentary).\nConcept Graph Learning for Online Education (NSF project; Yang et al., WSDM 2015)\n\nMapping online course materials to Wikipedia categories as the Interlingua (universal concepts)\nPredicting conceptual dependencies among courses based on partially observed prerequisites\nPlanning customized curriculum for individuals based on backgrounds and goals\nMacro-Level Information Fusion for Events and Entities (joint effort with Jaime Carbonell in the DARPA DEFT project)\n\nDetecting entities and events of interest in various forms of mentions in text to enable high-precision, semi-structured information fusion and summarization. Using a corporate acquisition event as an example, different (and partially redundant) sentences can mention acquirer, price, date, approvals, joint-management, etc.",
  "Using a corporate acquisition event as an example, different (and partially redundant) sentences can mention acquirer, price, date, approvals, joint-management, etc. This multi-aspect information needs to be jointly extracted into a unified structured form for this event type, with uncertainty estimates in the aggregated representation. \nPersonal Website http://www.cs.cmu.edu/~yiming/",
  "Faculty Name: yonatan bisk\nPaperid: 376f494126d1ea4f571ea0263c43ac2b6331800a\nTitle: SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs\nYear: 2023\nAbstract: In this work, we introduce Semantic Pyramid AutoEncoder (SPAE) for enabling frozen LLMs to perform both understanding and generation tasks involving non-linguistic modalities such as images or videos. SPAE converts between raw pixels and interpretable lexical tokens (or words) extracted from the LLM's vocabulary. The resulting tokens capture both the semantic meaning and the fine-grained details needed for visual reconstruction, effectively translating the visual content into a language comprehensible to the LLM, and empowering it to perform a wide array of multimodal tasks. Our approach is validated through in-context learning experiments with frozen PaLM 2 and GPT 3.5 on a diverse set of image understanding and generation tasks. Our method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%.",
  "Our method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%.\nAuthors: Lijun Yu, Yong Cheng, Zhiruo Wang, Vivek Kumar, Wolfgang Macherey, Yanping Huang, David A. Ross, Irfan Essa, Yonatan Bisk, Ming Yang, K. Murphy, A. Hauptmann, Lu Jiang\nVenue: Neural Information Processing Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%.'}\nUrl: http://arxiv.org/pdf/2306.17842",
  "Faculty Name: yonatan bisk\nPaperid: 3b0c02955e88f5862e61b560c7f70ba8cf235b1d\nTitle: HomeRobot: Open-Vocabulary Mobile Manipulation\nYear: 2023\nAbstract: HomeRobot (noun): An affordable compliant robot that navigates homes and manipulates a wide range of objects in order to complete everyday tasks. Open-Vocabulary Mobile Manipulation (OVMM) is the problem of picking any object in any unseen environment, and placing it in a commanded location. This is a foundational challenge for robots to be useful assistants in human environments, because it involves tackling sub-problems from across robotics: perception, language understanding, navigation, and manipulation are all essential to OVMM. In addition, integration of the solutions to these sub-problems poses its own substantial challenges. To drive research in this area, we introduce the HomeRobot OVMM benchmark, where an agent navigates household environments to grasp novel objects and place them on target receptacles.",
  "In addition, integration of the solutions to these sub-problems poses its own substantial challenges. To drive research in this area, we introduce the HomeRobot OVMM benchmark, where an agent navigates household environments to grasp novel objects and place them on target receptacles. HomeRobot has two components: a simulation component, which uses a large and diverse curated object set in new, high-quality multi-room home environments; and a real-world component, providing a software stack for the low-cost Hello Robot Stretch to encourage replication of real-world experiments across labs. We implement both reinforcement learning and heuristic (model-based) baselines and show evidence of sim-to-real transfer. Our baselines achieve a 20% success rate in the real world; our experiments identify ways future research work improve performance. See videos on our website: https://ovmm.github.io/.",
  "We implement both reinforcement learning and heuristic (model-based) baselines and show evidence of sim-to-real transfer. Our baselines achieve a 20% success rate in the real world; our experiments identify ways future research work improve performance. See videos on our website: https://ovmm.github.io/.\nAuthors: Sriram Yenamandra, A. Ramachandran, Karmesh Yadav, Austin S. Wang, Mukul Khanna, Th\u00e9ophile Gervet, Tsung-Yen Yang, Vidhi Jain, Alexander Clegg, John Turner, Z. Kira, M. Savva, Angel X. Chang, Devendra Singh Chaplot, Dhruv Batra, Roozbeh Mottaghi, Yonatan Bisk, Chris Paxton\nVenue: Conference on Robot Learning\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The HomeRobot OVMM benchmark is introduced, where an agent navigates household environments to grasp novel objects and place them on target receptacles, and baselines achieve a 20% success rate in the real world; the experiments identify ways future research work improve performance.'}",
  "Url: http://arxiv.org/pdf/2306.11565",
  "Faculty Name: yonatan bisk\nPaperid: 5ce2f1dff23a5620f77f9b11f1e534422ab8ff3f\nTitle: Plan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents\nYear: 2023\nAbstract: Pre-trained large language models (LLMs) capture procedural knowledge about the world. Recent work has leveraged LLM's ability to generate abstract plans to simplify challenging control tasks, either by action scoring, or action modeling (fine-tuning). However, the transformer architecture inherits several constraints that make it difficult for the LLM to directly serve as the agent: e.g. limited input lengths, fine-tuning inefficiency, bias from pre-training, and incompatibility with non-text environments. To maintain compatibility with a low-level trainable actor, we propose to instead use the knowledge in LLMs to simplify the control problem, rather than solving it. We propose the Plan, Eliminate, and Track (PET) framework. The Plan module translates a task description into a list of high-level sub-tasks.",
  "We propose the Plan, Eliminate, and Track (PET) framework. The Plan module translates a task description into a list of high-level sub-tasks. The Eliminate module masks out irrelevant objects and receptacles from the observation for the current sub-task. Finally, the Track module determines whether the agent has accomplished each sub-task. On the AlfWorld instruction following benchmark, the PET framework leads to a significant 15% improvement over SOTA for generalization to human goal specifications.\nAuthors: Yue Wu, So Yeon Min, Yonatan Bisk, R. Salakhutdinov, A. Azaria, Yuan-Fang Li, Tom M. Mitchell, Shrimai Prabhumoye\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A framework to use the knowledge in LLMs to simplify the control problem, rather than solving it is proposed, which leads to a significant 15% improvement over SOTA for generalization to human goal specifications.'}\nUrl: http://arxiv.org/pdf/2305.02412",
  "Faculty Name: yonatan bisk\nPaperid: 69b8cd15966c4c9c3e44e71769e557f1c87fb3f9\nTitle: MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception\nYear: 2023\nAbstract: A holistic understanding of object properties across diverse sensory modalities (e.g., visual, audio, and haptic) is essential for tasks ranging from object categorization to complex manipulation. Drawing inspiration from cognitive science studies that emphasize the significance of multi-sensory integration in human perception, we introduce MOSAIC (Multimodal Object property learning with Self-Attention and Interactive Comprehension), a novel framework designed to facilitate the learning of unified multi-sensory object property representations. While it is undeniable that visual information plays a prominent role, we acknowledge that many fundamental object properties extend beyond the visual domain to encompass attributes like texture, mass distribution, or sounds, which significantly influence how we interact with objects. In MOSAIC, we leverage this profound insight by distilling knowledge from multimodal foundation models and aligning these representations not only across vision but also haptic and auditory sensory modalities.",
  "In MOSAIC, we leverage this profound insight by distilling knowledge from multimodal foundation models and aligning these representations not only across vision but also haptic and auditory sensory modalities. Through extensive experiments on a dataset where a humanoid robot interacts with 100 objects across 10 exploratory behaviors, we demonstrate the versatility of MOSAIC in two task families: object categorization and object-fetching tasks. Our results underscore the efficacy of MOSAIC's unified representations, showing competitive performance in category recognition through a simple linear probe setup and excelling in the fetch object task under zero-shot transfer conditions. This work pioneers the application of sensory grounding in foundation models for robotics, promising a significant leap in multi-sensory perception capabilities for autonomous systems. We have released the code, datasets, and additional results: https://github.com/gtatiya/MOSAIC.",
  "This work pioneers the application of sensory grounding in foundation models for robotics, promising a significant leap in multi-sensory perception capabilities for autonomous systems. We have released the code, datasets, and additional results: https://github.com/gtatiya/MOSAIC.\nAuthors: Gyan Tatiya, Jonathan M Francis, Ho-Hsiang Wu, Yonatan Bisk, Jivko Sinapov\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work pioneers the application of sensory grounding in foundation models for robotics, promising a significant leap in multi-sensory perception capabilities for autonomous systems.'}\nUrl: https://arxiv.org/pdf/2309.08508",
  "Faculty Name: yonatan bisk\nPaperid: 8035a247980cb18abf2bb7b9d96e7d4c63622ef2\nTitle: Reasoning about the Unseen for Efficient Outdoor Object Navigation\nYear: 2023\nAbstract: Robots should exist anywhere humans do: indoors, outdoors, and even unmapped environments. In contrast, the focus of recent advancements in Object Goal Navigation(OGN) has targeted navigating in indoor environments by leveraging spatial and semantic cues that do not generalize outdoors. While these contributions provide valuable insights into indoor scenarios, the broader spectrum of real-world robotic applications often extends to outdoor settings. As we transition to the vast and complex terrains of outdoor environments, new challenges emerge. Unlike the structured layouts found indoors, outdoor environments lack clear spatial delineations and are riddled with inherent semantic ambiguities. Despite this, humans navigate with ease because we can reason about the unseen. We introduce a new task OUTDOOR, a new mechanism for Large Language Models (LLMs) to accurately hallucinate possible futures, and a new computationally aware success metric for pushing research forward in this more complex domain.",
  "Despite this, humans navigate with ease because we can reason about the unseen. We introduce a new task OUTDOOR, a new mechanism for Large Language Models (LLMs) to accurately hallucinate possible futures, and a new computationally aware success metric for pushing research forward in this more complex domain. Additionally, we show impressive results on both a simulated drone and physical quadruped in outdoor environments. Our agent has no premapping and our formalism outperforms naive LLM-based approaches\nAuthors: Quanting Xie, Tianyi Zhang, Kedi Xu, M. Johnson-Roberson, Yonatan Bisk\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A new task OUTDOOR is introduced, a new mechanism for Large Language Models (LLMs) to accurately hallucinate possible futures, and a new computationally aware success metric for pushing research forward in this more complex domain are introduced.'}\nUrl: https://arxiv.org/pdf/2309.10103",
  "Faculty Name: yonatan bisk\nPaperid: b777aa86b5a1d49ce8eababc5c2ee56d3562801e\nTitle: The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment\nYear: 2023\nAbstract: Increased focus on the computational efficiency of NLP systems has motivated the design of efficient model architectures and improvements to underlying hardware accelerators. However, the resulting increases in computational throughput and reductions in floating point operations have not directly translated to improvements in wall-clock inference latency. We demonstrate that these discrepancies can be largely attributed to bottlenecks introduced by deep learning frameworks. We denote this phenomenon as the \\textit{framework tax}, and observe that the disparity is growing as hardware speed increases over time. In this work, we examine this phenomenon through a series of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency. Code is available at https://github.com/JaredFern/Framework-Tax.",
  "In this work, we examine this phenomenon through a series of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency. Code is available at https://github.com/JaredFern/Framework-Tax.\nAuthors: Jared Fernandez, Jacob Kahn, Clara Na, Yonatan Bisk, Emma Strubell\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work examines the effects of model design decisions, framework paradigms, and hardware platforms on total model latency through a series of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency.'}\nUrl: http://arxiv.org/pdf/2302.06117",
  "Faculty Name: yonatan bisk\nPaperid: e41482f4ee984f17382f6cdd900df094d928be06\nTitle: WebArena: A Realistic Web Environment for Building Autonomous Agents\nYear: 2023\nAbstract: With advances in generative AI, there is now potential for autonomous agents to manage daily tasks via natural language commands. However, current agents are primarily created and tested in simplified synthetic environments, leading to a disconnect with real-world scenarios. In this paper, we build an environment for language-guided agents that is highly realistic and reproducible. Specifically, we focus on agents that perform tasks on the web, and create an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management. Our environment is enriched with tools (e.g., a map) and external knowledge bases (e.g., user manuals) to encourage human-like task-solving. Building upon our environment, we release a set of benchmark tasks focusing on evaluating the functional correctness of task completions. The tasks in our benchmark are diverse, long-horizon, and designed to emulate tasks that humans routinely perform on the internet.",
  "Building upon our environment, we release a set of benchmark tasks focusing on evaluating the functional correctness of task completions. The tasks in our benchmark are diverse, long-horizon, and designed to emulate tasks that humans routinely perform on the internet. We experiment with several baseline agents, integrating recent techniques such as reasoning before acting. The results demonstrate that solving complex tasks is challenging: our best GPT-4-based agent only achieves an end-to-end task success rate of 14.41%, significantly lower than the human performance of 78.24%. These results highlight the need for further development of robust agents, that current state-of-the-art large language models are far from perfect performance in these real-life tasks, and that WebArena can be used to measure such progress.",
  "These results highlight the need for further development of robust agents, that current state-of-the-art large language models are far from perfect performance in these real-life tasks, and that WebArena can be used to measure such progress.\nAuthors: Shuyan Zhou, Frank F. Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, Yonatan Bisk, Daniel Fried, Uri Alon, Graham Neubig\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper builds an environment for language-guided agents that is highly realistic and reproducible, and creates an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management.'}\nUrl: https://arxiv.org/pdf/2307.13854",
  "Faculty Name: yonatan bisk\nPaperid: e7b3b692b0816821aafc0d354749bc3802cbf6ac\nTitle: Computational Language Acquisition with Theory of Mind\nYear: 2023\nAbstract: Unlike current state-of-the-art language models, young children actively acquire language through interactions with their surrounding environment and caretakers. One mechanism that has been argued to be critical to language learning is the ability to infer the mental states of other agents in social environments, coined Theory of Mind (ToM) by Premack&Woodruff (1978). Drawing inspiration from the modern operationalized versions of ToM implemented in Rabinowitz et al. (2018) and Zhu et al. (2021), we build language-learning agents equipped with ToM, and measure its effects on the learning process. We model ToM by giving the speaker agent an internal listener model that is trained alongside the speaker and used to rerank potential utterances. We experiment with varying task difficulty, hypothesizing that models will acquire more complex language to adapt to stronger environmental pressures.",
  "We model ToM by giving the speaker agent an internal listener model that is trained alongside the speaker and used to rerank potential utterances. We experiment with varying task difficulty, hypothesizing that models will acquire more complex language to adapt to stronger environmental pressures. We find that training speakers with a highly weighted ToM listener component leads to performance gains in our image referential game setting. We also find some evidence that increasing task difficulty in the training process results in more fluent and precise utterances in evaluation. This suggests the potential utility of further incorporating ToM, as well as other insights from child language acquisition, into computational models of language acquisition.\nAuthors: Andy T. Liu, Hao Zhu, Emmy Liu, Yonatan Bisk, Graham Neubig\nVenue: International Conference on Learning Representations\nTldr: {'model': 'tldr@v2.0.0', 'text': \"It is found that training speakers with a highly weighted ToM listener component leads to performance gains in the authors' image referential game setting, and suggests the potential utility of further incorporating ToM, as well as other insights from child language acquisition, into computational models of language acquisition.\"}",
  "Url: http://arxiv.org/pdf/2303.01502",
  "List of 2023 Open Access papers by yonatan bisk are:\nSPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs\nHomeRobot: Open-Vocabulary Mobile Manipulation\nPlan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents\nMOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception\nReasoning about the Unseen for Efficient Outdoor Object Navigation\nThe Framework Tax: Disparities Between Inference Efficiency in Research and Deployment\nWebArena: A Realistic Web Environment for Building Autonomous Agents\nComputational Language Acquisition with Theory of Mind",
  "Faculty Bio: Yonatan Bisk\nAssistant Professor, Language Technologies Institute\nResearch Area : Embodiment, Grounding, RoboNLP, Unsupervised Learning, Vision and Language\nResearch: My work broadly falls into: 1. Uncovering the latent structures of natural language, 2. Modeling the semantics of the physical world, and 3. Connecting language to perception and control.\nPersonal Website : https://talkingtorobots.com/yonatanbisk.html\nContact: 6703 Gates & Hillman Centers\nEmail : ybisk@cs.cmu.edu"
]