PROMPT=====
{'question': "What is Yonatan Bisk's position?", 'context': 'yonatan bisk is an assistant professor, language technologies institute at CMU.\nralf brown is the senior systems scientist/chair of admissions, language technologies institute at CMU.\njamie callan is a professor, language technologies institute at CMU.\njustine cassel is a professor (on leave), language technologies institute at CMU.\nmona diab is the lti director and tenured professor, language technologies institute at CMU.\nfernando diaz is an associate professor, language technologies institute at CMU.\nscott fahlman is the professor emeritus, language technologies institute at CMU.\nrobert frederking is the associate dean for PhD programs and chair for MLT program, language technologies institute at CMU.\ndaniel fried is an assistant professor, language technologies institute at CMU.\nalexander hauptmann is a research professor, language technologies institute at CMU.\ndaphne ippolito is an assistant professor, language technologies institute at CMU.\nlori levin is a research professor, language technologies institute at CMU.\nlei li is an assistant professor, language technologies institute at CMU.\nteruko mitamura is a research professor, language technologies institute at CMU.\nlouis-philippe morency is the leonardo associate professor of computer science (on leave), language technologies institute at CMU.\ndavid mortensen is an assistant research professor, language technologies institute at CMU.\ngraham neubig is an associate professor, language technologies institute at CMU.\neric nyberg is a professor, language technologies institute at CMU.\nkemal oflazer is a teaching professor, language technologies institute at CMU.\nbhiksha raj is a professor, language technologies institute at CMU.\ncarolyn rose is a professor, language technologies institute at CMU.\nalexander rudnicky is the "research professor emeritus", language technologies institute at CMU.\nmaarten sap is an assistant professor, language technologies institute at CMU.\nmichael shamos is the "distinguished career professor", language technologies institute at CMU.\nrita singh is an associate research professor, language technologies institute at CMU.\nemma strubell is an assistant professor, language technologies institute at CMU.\nalexander waibel is a professor (on leave), language technologies institute at CMU.\nshinji watanabe is an associate professor, language technologies institute at CMU.\nsean welleck is an assistant professor, language technologies institute at CMU.\neric xing is the professor (on leave), language technologies institute at CMU.\nchenyan xiong is an associate professor, language technologies institute at CMU.\nyiming yang is a professor, language technologies institute at CMU.\n'}
LLAMA-7B PREDICTED ANSWER=====
  Yonatan Bisk is an Assistant Professor at the Language Technologies Institute at CMU.
PROMPT=====
{'question': 'What title does Ralf Brown hold?', 'context': 'yonatan bisk is an assistant professor, language technologies institute at CMU.\nralf brown is the senior systems scientist/chair of admissions, language technologies institute at CMU.\njamie callan is a professor, language technologies institute at CMU.\njustine cassel is a professor (on leave), language technologies institute at CMU.\nmona diab is the lti director and tenured professor, language technologies institute at CMU.\nfernando diaz is an associate professor, language technologies institute at CMU.\nscott fahlman is the professor emeritus, language technologies institute at CMU.\nrobert frederking is the associate dean for PhD programs and chair for MLT program, language technologies institute at CMU.\ndaniel fried is an assistant professor, language technologies institute at CMU.\nalexander hauptmann is a research professor, language technologies institute at CMU.\ndaphne ippolito is an assistant professor, language technologies institute at CMU.\nlori levin is a research professor, language technologies institute at CMU.\nlei li is an assistant professor, language technologies institute at CMU.\nteruko mitamura is a research professor, language technologies institute at CMU.\nlouis-philippe morency is the leonardo associate professor of computer science (on leave), language technologies institute at CMU.\ndavid mortensen is an assistant research professor, language technologies institute at CMU.\ngraham neubig is an associate professor, language technologies institute at CMU.\neric nyberg is a professor, language technologies institute at CMU.\nkemal oflazer is a teaching professor, language technologies institute at CMU.\nbhiksha raj is a professor, language technologies institute at CMU.\ncarolyn rose is a professor, language technologies institute at CMU.\nalexander rudnicky is the "research professor emeritus", language technologies institute at CMU.\nmaarten sap is an assistant professor, language technologies institute at CMU.\nmichael shamos is the "distinguished career professor", language technologies institute at CMU.\nrita singh is an associate research professor, language technologies institute at CMU.\nemma strubell is an assistant professor, language technologies institute at CMU.\nalexander waibel is a professor (on leave), language technologies institute at CMU.\nshinji watanabe is an associate professor, language technologies institute at CMU.\nsean welleck is an assistant professor, language technologies institute at CMU.\neric xing is the professor (on leave), language technologies institute at CMU.\nchenyan xiong is an associate professor, language technologies institute at CMU.\nyiming yang is a professor, language technologies institute at CMU.\n'}
LLAMA-7B PREDICTED ANSWER=====
  Ralf Brown holds the position of Senior Systems Scientist and Chair of Admissions at the Language Technologies Institute at CMU.
PROMPT=====
{'question': 'Who are the professors currently on leave?', 'context': 'yonatan bisk is an assistant professor, language technologies institute at CMU.\nralf brown is the senior systems scientist/chair of admissions, language technologies institute at CMU.\njamie callan is a professor, language technologies institute at CMU.\njustine cassel is a professor (on leave), language technologies institute at CMU.\nmona diab is the lti director and tenured professor, language technologies institute at CMU.\nfernando diaz is an associate professor, language technologies institute at CMU.\nscott fahlman is the professor emeritus, language technologies institute at CMU.\nrobert frederking is the associate dean for PhD programs and chair for MLT program, language technologies institute at CMU.\ndaniel fried is an assistant professor, language technologies institute at CMU.\nalexander hauptmann is a research professor, language technologies institute at CMU.\ndaphne ippolito is an assistant professor, language technologies institute at CMU.\nlori levin is a research professor, language technologies institute at CMU.\nlei li is an assistant professor, language technologies institute at CMU.\nteruko mitamura is a research professor, language technologies institute at CMU.\nlouis-philippe morency is the leonardo associate professor of computer science (on leave), language technologies institute at CMU.\ndavid mortensen is an assistant research professor, language technologies institute at CMU.\ngraham neubig is an associate professor, language technologies institute at CMU.\neric nyberg is a professor, language technologies institute at CMU.\nkemal oflazer is a teaching professor, language technologies institute at CMU.\nbhiksha raj is a professor, language technologies institute at CMU.\ncarolyn rose is a professor, language technologies institute at CMU.\nalexander rudnicky is the "research professor emeritus", language technologies institute at CMU.\nmaarten sap is an assistant professor, language technologies institute at CMU.\nmichael shamos is the "distinguished career professor", language technologies institute at CMU.\nrita singh is an associate research professor, language technologies institute at CMU.\nemma strubell is an assistant professor, language technologies institute at CMU.\nalexander waibel is a professor (on leave), language technologies institute at CMU.\nshinji watanabe is an associate professor, language technologies institute at CMU.\nsean welleck is an assistant professor, language technologies institute at CMU.\neric xing is the professor (on leave), language technologies institute at CMU.\nchenyan xiong is an associate professor, language technologies institute at CMU.\nyiming yang is a professor, language technologies institute at CMU.\n'}
LLAMA-7B PREDICTED ANSWER=====
  Justine Cassel, Louis-Philippe Morency, and Alexander Waibel are the professors currently on leave from the Language Technologies Institute at CMU.
PROMPT=====
{'question': 'Who is the LTI Director and tenured professor?', 'context': 'yonatan bisk is an assistant professor, language technologies institute at CMU.\nralf brown is the senior systems scientist/chair of admissions, language technologies institute at CMU.\njamie callan is a professor, language technologies institute at CMU.\njustine cassel is a professor (on leave), language technologies institute at CMU.\nmona diab is the lti director and tenured professor, language technologies institute at CMU.\nfernando diaz is an associate professor, language technologies institute at CMU.\nscott fahlman is the professor emeritus, language technologies institute at CMU.\nrobert frederking is the associate dean for PhD programs and chair for MLT program, language technologies institute at CMU.\ndaniel fried is an assistant professor, language technologies institute at CMU.\nalexander hauptmann is a research professor, language technologies institute at CMU.\ndaphne ippolito is an assistant professor, language technologies institute at CMU.\nlori levin is a research professor, language technologies institute at CMU.\nlei li is an assistant professor, language technologies institute at CMU.\nteruko mitamura is a research professor, language technologies institute at CMU.\nlouis-philippe morency is the leonardo associate professor of computer science (on leave), language technologies institute at CMU.\ndavid mortensen is an assistant research professor, language technologies institute at CMU.\ngraham neubig is an associate professor, language technologies institute at CMU.\neric nyberg is a professor, language technologies institute at CMU.\nkemal oflazer is a teaching professor, language technologies institute at CMU.\nbhiksha raj is a professor, language technologies institute at CMU.\ncarolyn rose is a professor, language technologies institute at CMU.\nalexander rudnicky is the "research professor emeritus", language technologies institute at CMU.\nmaarten sap is an assistant professor, language technologies institute at CMU.\nmichael shamos is the "distinguished career professor", language technologies institute at CMU.\nrita singh is an associate research professor, language technologies institute at CMU.\nemma strubell is an assistant professor, language technologies institute at CMU.\nalexander waibel is a professor (on leave), language technologies institute at CMU.\nshinji watanabe is an associate professor, language technologies institute at CMU.\nsean welleck is an assistant professor, language technologies institute at CMU.\neric xing is the professor (on leave), language technologies institute at CMU.\nchenyan xiong is an associate professor, language technologies institute at CMU.\nyiming yang is a professor, language technologies institute at CMU.\n'}
LLAMA-7B PREDICTED ANSWER=====
  Maarten Sap
PROMPT=====
{'question': "What is Fernando Diaz's role?", 'context': 'yonatan bisk is an assistant professor, language technologies institute at CMU.\nralf brown is the senior systems scientist/chair of admissions, language technologies institute at CMU.\njamie callan is a professor, language technologies institute at CMU.\njustine cassel is a professor (on leave), language technologies institute at CMU.\nmona diab is the lti director and tenured professor, language technologies institute at CMU.\nfernando diaz is an associate professor, language technologies institute at CMU.\nscott fahlman is the professor emeritus, language technologies institute at CMU.\nrobert frederking is the associate dean for PhD programs and chair for MLT program, language technologies institute at CMU.\ndaniel fried is an assistant professor, language technologies institute at CMU.\nalexander hauptmann is a research professor, language technologies institute at CMU.\ndaphne ippolito is an assistant professor, language technologies institute at CMU.\nlori levin is a research professor, language technologies institute at CMU.\nlei li is an assistant professor, language technologies institute at CMU.\nteruko mitamura is a research professor, language technologies institute at CMU.\nlouis-philippe morency is the leonardo associate professor of computer science (on leave), language technologies institute at CMU.\ndavid mortensen is an assistant research professor, language technologies institute at CMU.\ngraham neubig is an associate professor, language technologies institute at CMU.\neric nyberg is a professor, language technologies institute at CMU.\nkemal oflazer is a teaching professor, language technologies institute at CMU.\nbhiksha raj is a professor, language technologies institute at CMU.\ncarolyn rose is a professor, language technologies institute at CMU.\nalexander rudnicky is the "research professor emeritus", language technologies institute at CMU.\nmaarten sap is an assistant professor, language technologies institute at CMU.\nmichael shamos is the "distinguished career professor", language technologies institute at CMU.\nrita singh is an associate research professor, language technologies institute at CMU.\nemma strubell is an assistant professor, language technologies institute at CMU.\nalexander waibel is a professor (on leave), language technologies institute at CMU.\nshinji watanabe is an associate professor, language technologies institute at CMU.\nsean welleck is an assistant professor, language technologies institute at CMU.\neric xing is the professor (on leave), language technologies institute at CMU.\nchenyan xiong is an associate professor, language technologies institute at CMU.\nyiming yang is a professor, language technologies institute at CMU.\n'}
LLAMA-7B PREDICTED ANSWER=====
  Fernando Diaz is an associate professor at the Language Technologies Institute at CMU.
PROMPT=====
{'question': 'Who holds the title of Professor Emeritus?', 'context': 'yonatan bisk is an assistant professor, language technologies institute at CMU.\nralf brown is the senior systems scientist/chair of admissions, language technologies institute at CMU.\njamie callan is a professor, language technologies institute at CMU.\njustine cassel is a professor (on leave), language technologies institute at CMU.\nmona diab is the lti director and tenured professor, language technologies institute at CMU.\nfernando diaz is an associate professor, language technologies institute at CMU.\nscott fahlman is the professor emeritus, language technologies institute at CMU.\nrobert frederking is the associate dean for PhD programs and chair for MLT program, language technologies institute at CMU.\ndaniel fried is an assistant professor, language technologies institute at CMU.\nalexander hauptmann is a research professor, language technologies institute at CMU.\ndaphne ippolito is an assistant professor, language technologies institute at CMU.\nlori levin is a research professor, language technologies institute at CMU.\nlei li is an assistant professor, language technologies institute at CMU.\nteruko mitamura is a research professor, language technologies institute at CMU.\nlouis-philippe morency is the leonardo associate professor of computer science (on leave), language technologies institute at CMU.\ndavid mortensen is an assistant research professor, language technologies institute at CMU.\ngraham neubig is an associate professor, language technologies institute at CMU.\neric nyberg is a professor, language technologies institute at CMU.\nkemal oflazer is a teaching professor, language technologies institute at CMU.\nbhiksha raj is a professor, language technologies institute at CMU.\ncarolyn rose is a professor, language technologies institute at CMU.\nalexander rudnicky is the "research professor emeritus", language technologies institute at CMU.\nmaarten sap is an assistant professor, language technologies institute at CMU.\nmichael shamos is the "distinguished career professor", language technologies institute at CMU.\nrita singh is an associate research professor, language technologies institute at CMU.\nemma strubell is an assistant professor, language technologies institute at CMU.\nalexander waibel is a professor (on leave), language technologies institute at CMU.\nshinji watanabe is an associate professor, language technologies institute at CMU.\nsean welleck is an assistant professor, language technologies institute at CMU.\neric xing is the professor (on leave), language technologies institute at CMU.\nchenyan xiong is an associate professor, language technologies institute at CMU.\nyiming yang is a professor, language technologies institute at CMU.\n'}
LLAMA-7B PREDICTED ANSWER=====
  Professor Emeritus: Eric Xing
PROMPT=====
{'question': 'Who is the Associate Dean for PhD Programs?', 'context': 'yonatan bisk is an assistant professor, language technologies institute at CMU.\nralf brown is the senior systems scientist/chair of admissions, language technologies institute at CMU.\njamie callan is a professor, language technologies institute at CMU.\njustine cassel is a professor (on leave), language technologies institute at CMU.\nmona diab is the lti director and tenured professor, language technologies institute at CMU.\nfernando diaz is an associate professor, language technologies institute at CMU.\nscott fahlman is the professor emeritus, language technologies institute at CMU.\nrobert frederking is the associate dean for PhD programs and chair for MLT program, language technologies institute at CMU.\ndaniel fried is an assistant professor, language technologies institute at CMU.\nalexander hauptmann is a research professor, language technologies institute at CMU.\ndaphne ippolito is an assistant professor, language technologies institute at CMU.\nlori levin is a research professor, language technologies institute at CMU.\nlei li is an assistant professor, language technologies institute at CMU.\nteruko mitamura is a research professor, language technologies institute at CMU.\nlouis-philippe morency is the leonardo associate professor of computer science (on leave), language technologies institute at CMU.\ndavid mortensen is an assistant research professor, language technologies institute at CMU.\ngraham neubig is an associate professor, language technologies institute at CMU.\neric nyberg is a professor, language technologies institute at CMU.\nkemal oflazer is a teaching professor, language technologies institute at CMU.\nbhiksha raj is a professor, language technologies institute at CMU.\ncarolyn rose is a professor, language technologies institute at CMU.\nalexander rudnicky is the "research professor emeritus", language technologies institute at CMU.\nmaarten sap is an assistant professor, language technologies institute at CMU.\nmichael shamos is the "distinguished career professor", language technologies institute at CMU.\nrita singh is an associate research professor, language technologies institute at CMU.\nemma strubell is an assistant professor, language technologies institute at CMU.\nalexander waibel is a professor (on leave), language technologies institute at CMU.\nshinji watanabe is an associate professor, language technologies institute at CMU.\nsean welleck is an assistant professor, language technologies institute at CMU.\neric xing is the professor (on leave), language technologies institute at CMU.\nchenyan xiong is an associate professor, language technologies institute at CMU.\nyiming yang is a professor, language technologies institute at CMU.\n'}
LLAMA-7B PREDICTED ANSWER=====
  Robert Frederking
PROMPT=====
{'question': 'Is Daniel Fried an associate or assistant professor?', 'context': 'yonatan bisk is an assistant professor, language technologies institute at CMU.\nralf brown is the senior systems scientist/chair of admissions, language technologies institute at CMU.\njamie callan is a professor, language technologies institute at CMU.\njustine cassel is a professor (on leave), language technologies institute at CMU.\nmona diab is the lti director and tenured professor, language technologies institute at CMU.\nfernando diaz is an associate professor, language technologies institute at CMU.\nscott fahlman is the professor emeritus, language technologies institute at CMU.\nrobert frederking is the associate dean for PhD programs and chair for MLT program, language technologies institute at CMU.\ndaniel fried is an assistant professor, language technologies institute at CMU.\nalexander hauptmann is a research professor, language technologies institute at CMU.\ndaphne ippolito is an assistant professor, language technologies institute at CMU.\nlori levin is a research professor, language technologies institute at CMU.\nlei li is an assistant professor, language technologies institute at CMU.\nteruko mitamura is a research professor, language technologies institute at CMU.\nlouis-philippe morency is the leonardo associate professor of computer science (on leave), language technologies institute at CMU.\ndavid mortensen is an assistant research professor, language technologies institute at CMU.\ngraham neubig is an associate professor, language technologies institute at CMU.\neric nyberg is a professor, language technologies institute at CMU.\nkemal oflazer is a teaching professor, language technologies institute at CMU.\nbhiksha raj is a professor, language technologies institute at CMU.\ncarolyn rose is a professor, language technologies institute at CMU.\nalexander rudnicky is the "research professor emeritus", language technologies institute at CMU.\nmaarten sap is an assistant professor, language technologies institute at CMU.\nmichael shamos is the "distinguished career professor", language technologies institute at CMU.\nrita singh is an associate research professor, language technologies institute at CMU.\nemma strubell is an assistant professor, language technologies institute at CMU.\nalexander waibel is a professor (on leave), language technologies institute at CMU.\nshinji watanabe is an associate professor, language technologies institute at CMU.\nsean welleck is an assistant professor, language technologies institute at CMU.\neric xing is the professor (on leave), language technologies institute at CMU.\nchenyan xiong is an associate professor, language technologies institute at CMU.\nyiming yang is a professor, language technologies institute at CMU.\n'}
LLAMA-7B PREDICTED ANSWER=====
  Daniel Fried is an Assistant Professor at the Language Technologies Institute at CMU.
PROMPT=====
{'question': 'Who is named as a research professor?', 'context': 'yonatan bisk is an assistant professor, language technologies institute at CMU.\nralf brown is the senior systems scientist/chair of admissions, language technologies institute at CMU.\njamie callan is a professor, language technologies institute at CMU.\njustine cassel is a professor (on leave), language technologies institute at CMU.\nmona diab is the lti director and tenured professor, language technologies institute at CMU.\nfernando diaz is an associate professor, language technologies institute at CMU.\nscott fahlman is the professor emeritus, language technologies institute at CMU.\nrobert frederking is the associate dean for PhD programs and chair for MLT program, language technologies institute at CMU.\ndaniel fried is an assistant professor, language technologies institute at CMU.\nalexander hauptmann is a research professor, language technologies institute at CMU.\ndaphne ippolito is an assistant professor, language technologies institute at CMU.\nlori levin is a research professor, language technologies institute at CMU.\nlei li is an assistant professor, language technologies institute at CMU.\nteruko mitamura is a research professor, language technologies institute at CMU.\nlouis-philippe morency is the leonardo associate professor of computer science (on leave), language technologies institute at CMU.\ndavid mortensen is an assistant research professor, language technologies institute at CMU.\ngraham neubig is an associate professor, language technologies institute at CMU.\neric nyberg is a professor, language technologies institute at CMU.\nkemal oflazer is a teaching professor, language technologies institute at CMU.\nbhiksha raj is a professor, language technologies institute at CMU.\ncarolyn rose is a professor, language technologies institute at CMU.\nalexander rudnicky is the "research professor emeritus", language technologies institute at CMU.\nmaarten sap is an assistant professor, language technologies institute at CMU.\nmichael shamos is the "distinguished career professor", language technologies institute at CMU.\nrita singh is an associate research professor, language technologies institute at CMU.\nemma strubell is an assistant professor, language technologies institute at CMU.\nalexander waibel is a professor (on leave), language technologies institute at CMU.\nshinji watanabe is an associate professor, language technologies institute at CMU.\nsean welleck is an assistant professor, language technologies institute at CMU.\neric xing is the professor (on leave), language technologies institute at CMU.\nchenyan xiong is an associate professor, language technologies institute at CMU.\nyiming yang is a professor, language technologies institute at CMU.\n'}
LLAMA-7B PREDICTED ANSWER=====
  Ralf Brown
PROMPT=====
{'question': 'How many assistant professors are mentioned?', 'context': 'yonatan bisk is an assistant professor, language technologies institute at CMU.\nralf brown is the senior systems scientist/chair of admissions, language technologies institute at CMU.\njamie callan is a professor, language technologies institute at CMU.\njustine cassel is a professor (on leave), language technologies institute at CMU.\nmona diab is the lti director and tenured professor, language technologies institute at CMU.\nfernando diaz is an associate professor, language technologies institute at CMU.\nscott fahlman is the professor emeritus, language technologies institute at CMU.\nrobert frederking is the associate dean for PhD programs and chair for MLT program, language technologies institute at CMU.\ndaniel fried is an assistant professor, language technologies institute at CMU.\nalexander hauptmann is a research professor, language technologies institute at CMU.\ndaphne ippolito is an assistant professor, language technologies institute at CMU.\nlori levin is a research professor, language technologies institute at CMU.\nlei li is an assistant professor, language technologies institute at CMU.\nteruko mitamura is a research professor, language technologies institute at CMU.\nlouis-philippe morency is the leonardo associate professor of computer science (on leave), language technologies institute at CMU.\ndavid mortensen is an assistant research professor, language technologies institute at CMU.\ngraham neubig is an associate professor, language technologies institute at CMU.\neric nyberg is a professor, language technologies institute at CMU.\nkemal oflazer is a teaching professor, language technologies institute at CMU.\nbhiksha raj is a professor, language technologies institute at CMU.\ncarolyn rose is a professor, language technologies institute at CMU.\nalexander rudnicky is the "research professor emeritus", language technologies institute at CMU.\nmaarten sap is an assistant professor, language technologies institute at CMU.\nmichael shamos is the "distinguished career professor", language technologies institute at CMU.\nrita singh is an associate research professor, language technologies institute at CMU.\nemma strubell is an assistant professor, language technologies institute at CMU.\nalexander waibel is a professor (on leave), language technologies institute at CMU.\nshinji watanabe is an associate professor, language technologies institute at CMU.\nsean welleck is an assistant professor, language technologies institute at CMU.\neric xing is the professor (on leave), language technologies institute at CMU.\nchenyan xiong is an associate professor, language technologies institute at CMU.\nyiming yang is a professor, language technologies institute at CMU.\n'}
LLAMA-7B PREDICTED ANSWER=====
  There are 24 assistant professors mentioned in the text.
PROMPT=====
{'question': "What is a focus of Yiming Yang's recent research?", 'context': 'Yiming Yang\nProfessor, Language Technologies Institute\nContact\n6717 —Gates & Hillman Centers\nEmail yiming@cs.cmu.edu\n412-268-1364\nResearch\nMy research has centered on statistical learning methods/algorithms and application to very-large-scale text categorization, web-mining for concept graph discovery, semi-supervised clustering, multitask learning, novelty-based information retrieval, large-scale optimization for online advertising, social network analysis for personalized email prioritization, etc. My recent research focuses on the following topics:\n\nLarge-Scale Structured Learning for Hierarchical Classification  (Gopal & Yang, KDD 2013;  Gopal & Yang, ICML 2013 & Supplementary  ;  Gopal et al., NIPS 2012)\n\nProviding organizational views of multi-source Big Data (e.g., Wikipedia, online shops, Coursera)\nState-of-the-art classifiers for large-scale classification over hundreds of thousands of categories\nScalable variational inference for joint optimization of one trillion (4 TB) model parameters\nScalable Machine Learning for Time Series Analysis (Topic Detection and Tracking)\n\nFrom scientific literature, news stories, sensor signals, maintenance reports, etc.\nModeling multi-source and multi-scale evidence of dynamic chances in temporal sequences. (On-going NSF project; Gopal, PhD Thesis)\nA new family of Bayesian von Mices Fischer (vMF) clustering techniques (Gopal & Yang, ICML 2014 & Supplementary)\nUnsupervised clustering and semi-supervised metric learning and supervised classification (Gopal & Yang, UAI 2014 & Supplimentary).\nConcept Graph Learning for Online Education (NSF project; Yang et al., WSDM 2015)\n\nMapping online course materials to Wikipedia categories as the Interlingua (universal concepts)\nPredicting conceptual dependencies among courses based on partially observed prerequisites\nPlanning customized curriculum for individuals based on backgrounds and goals\nMacro-Level Information Fusion for Events and Entities (joint effort with Jaime Carbonell in the DARPA DEFT project)\n\nDetecting entities and events of interest in various forms of mentions in text to enable high-precision, semi-structured information fusion and summarization. Using a corporate acquisition event as an example, different (and partially redundant) sentences can mention acquirer, price, date, approvals, joint-management, etc. This multi-aspect information needs to be jointly extracted into a unified structured form for this event type, with uncertainty estimates in the aggregated representation. \nPersonal Website http://www.cs.cmu.edu/~yiming/\n'}
LLAMA-7B PREDICTED ANSWER=====
  Large-Scale Structured Learning for Hierarchical Classification
PROMPT=====
{'question': "Yiming Yang's research area in web-mining?", 'context': 'Yiming Yang\nProfessor, Language Technologies Institute\nContact\n6717 —Gates & Hillman Centers\nEmail yiming@cs.cmu.edu\n412-268-1364\nResearch\nMy research has centered on statistical learning methods/algorithms and application to very-large-scale text categorization, web-mining for concept graph discovery, semi-supervised clustering, multitask learning, novelty-based information retrieval, large-scale optimization for online advertising, social network analysis for personalized email prioritization, etc. My recent research focuses on the following topics:\n\nLarge-Scale Structured Learning for Hierarchical Classification  (Gopal & Yang, KDD 2013;  Gopal & Yang, ICML 2013 & Supplementary  ;  Gopal et al., NIPS 2012)\n\nProviding organizational views of multi-source Big Data (e.g., Wikipedia, online shops, Coursera)\nState-of-the-art classifiers for large-scale classification over hundreds of thousands of categories\nScalable variational inference for joint optimization of one trillion (4 TB) model parameters\nScalable Machine Learning for Time Series Analysis (Topic Detection and Tracking)\n\nFrom scientific literature, news stories, sensor signals, maintenance reports, etc.\nModeling multi-source and multi-scale evidence of dynamic chances in temporal sequences. (On-going NSF project; Gopal, PhD Thesis)\nA new family of Bayesian von Mices Fischer (vMF) clustering techniques (Gopal & Yang, ICML 2014 & Supplementary)\nUnsupervised clustering and semi-supervised metric learning and supervised classification (Gopal & Yang, UAI 2014 & Supplimentary).\nConcept Graph Learning for Online Education (NSF project; Yang et al., WSDM 2015)\n\nMapping online course materials to Wikipedia categories as the Interlingua (universal concepts)\nPredicting conceptual dependencies among courses based on partially observed prerequisites\nPlanning customized curriculum for individuals based on backgrounds and goals\nMacro-Level Information Fusion for Events and Entities (joint effort with Jaime Carbonell in the DARPA DEFT project)\n\nDetecting entities and events of interest in various forms of mentions in text to enable high-precision, semi-structured information fusion and summarization. Using a corporate acquisition event as an example, different (and partially redundant) sentences can mention acquirer, price, date, approvals, joint-management, etc. This multi-aspect information needs to be jointly extracted into a unified structured form for this event type, with uncertainty estimates in the aggregated representation. \nPersonal Website http://www.cs.cmu.edu/~yiming/\n'}
LLAMA-7B PREDICTED ANSWER=====
  Web mining
PROMPT=====
{'question': 'Which conference did Yiming Yang present on hierarchical classification?', 'context': 'Yiming Yang\nProfessor, Language Technologies Institute\nContact\n6717 —Gates & Hillman Centers\nEmail yiming@cs.cmu.edu\n412-268-1364\nResearch\nMy research has centered on statistical learning methods/algorithms and application to very-large-scale text categorization, web-mining for concept graph discovery, semi-supervised clustering, multitask learning, novelty-based information retrieval, large-scale optimization for online advertising, social network analysis for personalized email prioritization, etc. My recent research focuses on the following topics:\n\nLarge-Scale Structured Learning for Hierarchical Classification  (Gopal & Yang, KDD 2013;  Gopal & Yang, ICML 2013 & Supplementary  ;  Gopal et al., NIPS 2012)\n\nProviding organizational views of multi-source Big Data (e.g., Wikipedia, online shops, Coursera)\nState-of-the-art classifiers for large-scale classification over hundreds of thousands of categories\nScalable variational inference for joint optimization of one trillion (4 TB) model parameters\nScalable Machine Learning for Time Series Analysis (Topic Detection and Tracking)\n\nFrom scientific literature, news stories, sensor signals, maintenance reports, etc.\nModeling multi-source and multi-scale evidence of dynamic chances in temporal sequences. (On-going NSF project; Gopal, PhD Thesis)\nA new family of Bayesian von Mices Fischer (vMF) clustering techniques (Gopal & Yang, ICML 2014 & Supplementary)\nUnsupervised clustering and semi-supervised metric learning and supervised classification (Gopal & Yang, UAI 2014 & Supplimentary).\nConcept Graph Learning for Online Education (NSF project; Yang et al., WSDM 2015)\n\nMapping online course materials to Wikipedia categories as the Interlingua (universal concepts)\nPredicting conceptual dependencies among courses based on partially observed prerequisites\nPlanning customized curriculum for individuals based on backgrounds and goals\nMacro-Level Information Fusion for Events and Entities (joint effort with Jaime Carbonell in the DARPA DEFT project)\n\nDetecting entities and events of interest in various forms of mentions in text to enable high-precision, semi-structured information fusion and summarization. Using a corporate acquisition event as an example, different (and partially redundant) sentences can mention acquirer, price, date, approvals, joint-management, etc. This multi-aspect information needs to be jointly extracted into a unified structured form for this event type, with uncertainty estimates in the aggregated representation. \nPersonal Website http://www.cs.cmu.edu/~yiming/\n'}
LLAMA-7B PREDICTED ANSWER=====
  Hierarchical classification was presented at KDD 2013 and ICML 2013 by Yiming Yang.
PROMPT=====
{'question': 'What position does Chenyan Xiong hold at CMU?', 'context': 'Chenyan Xiong\nAssociate Professor, Language Technologies Institute\nContact\nEmail cx@andrew.cmu.edu\nAddress\n5000 Forbes Avenue\nPittsburgh, PA 15213\n\n'}
LLAMA-7B PREDICTED ANSWER=====
  Associate Professor
PROMPT=====
{'question': 'How to contact Chenyan Xiong via email?', 'context': 'Chenyan Xiong\nAssociate Professor, Language Technologies Institute\nContact\nEmail cx@andrew.cmu.edu\nAddress\n5000 Forbes Avenue\nPittsburgh, PA 15213\n\n'}
LLAMA-7B PREDICTED ANSWER=====
  Sure! Here is the answer to your question in 5 words or less:
Email cx@andrew.cmu.edu
PROMPT=====
{'question': 'Which institute is Chenyan Xiong associated with?', 'context': 'Chenyan Xiong\nAssociate Professor, Language Technologies Institute\nContact\nEmail cx@andrew.cmu.edu\nAddress\n5000 Forbes Avenue\nPittsburgh, PA 15213\n\n'}
LLAMA-7B PREDICTED ANSWER=====
  Language Technologies Institute
PROMPT=====
{'question': "What is Eric P. Xing's current status at CMU?", 'context': 'Eric P. Xing\nProfessor (On Leave), Language Technologies Institute\nContact\n8101 —Gates & Hillman Centers\nEmail epxing@andrew.cmu.edu\n412-268-2559\nResearch\nThe major theme of Professor Xing\'s research lies in the development of machine learning and statistical methodology; especially for building quantitative models and predictive understandings of the evolutionary mechanism, regulatory circuitry, and developmental processes of biological systems; and for building intelligent systems for a wide range of applications in vision, IR and NLP that involves computational learning and reasoning under uncertainty.\n\nFoundations of Statistical Learning, including theory and algorithms for: 1) Time/space varying-coefficient models with evolving structures; 2) Sparse structured input/output models in high-dimensional problems; 3) Nonparametric Bayesian techniques for infinite-dimensional models; 4) RKHS embedding, nonparametric inference, and spectral methods for graphical models; 5) Distributed and online algorithms for optimization, approximate inference, and sampling on massive data.\n\nLarge-scale Information & Intelligent System: 1) Development of scalable parallel architecture, protocol, programming interface, generic algorithms and models, for Big Learning; 2) Multi-view latent space models, topics models, and sparse coding for image/text/relational data mining; 3) Evolving structure, stable metrics, and prediction for dynamic social networks, goal-driven network design and optimization; 4) Web-scale image understanding, search, prediction, and storyline synthesis; 5) Information visualization, indexing and storage, web/mobile app development.\n\nComputational Biology: 1) Understanding genome-microenvironment interactions in cancer and embryogenesis via joint analysis of genomic, proteomic, and pathway signaling data; 2) Genetic analysis of population variation, demography and evolution; 3) Statistical inference of genome-transcriptome-phenome association in complex diseases; 4) Personalized diagnosis and treatment of spectrum diseases via next generation sequencing and computational "omic" analysis; 5) Biological image and text mining.\n\nhttp://www.cs.cmu.edu/~epxing/\n'}
LLAMA-7B PREDICTED ANSWER=====
  Professor Xing is on leave from Carnegie Mellon University.
PROMPT=====
{'question': "Eric P. Xing's primary research focus?", 'context': 'Eric P. Xing\nProfessor (On Leave), Language Technologies Institute\nContact\n8101 —Gates & Hillman Centers\nEmail epxing@andrew.cmu.edu\n412-268-2559\nResearch\nThe major theme of Professor Xing\'s research lies in the development of machine learning and statistical methodology; especially for building quantitative models and predictive understandings of the evolutionary mechanism, regulatory circuitry, and developmental processes of biological systems; and for building intelligent systems for a wide range of applications in vision, IR and NLP that involves computational learning and reasoning under uncertainty.\n\nFoundations of Statistical Learning, including theory and algorithms for: 1) Time/space varying-coefficient models with evolving structures; 2) Sparse structured input/output models in high-dimensional problems; 3) Nonparametric Bayesian techniques for infinite-dimensional models; 4) RKHS embedding, nonparametric inference, and spectral methods for graphical models; 5) Distributed and online algorithms for optimization, approximate inference, and sampling on massive data.\n\nLarge-scale Information & Intelligent System: 1) Development of scalable parallel architecture, protocol, programming interface, generic algorithms and models, for Big Learning; 2) Multi-view latent space models, topics models, and sparse coding for image/text/relational data mining; 3) Evolving structure, stable metrics, and prediction for dynamic social networks, goal-driven network design and optimization; 4) Web-scale image understanding, search, prediction, and storyline synthesis; 5) Information visualization, indexing and storage, web/mobile app development.\n\nComputational Biology: 1) Understanding genome-microenvironment interactions in cancer and embryogenesis via joint analysis of genomic, proteomic, and pathway signaling data; 2) Genetic analysis of population variation, demography and evolution; 3) Statistical inference of genome-transcriptome-phenome association in complex diseases; 4) Personalized diagnosis and treatment of spectrum diseases via next generation sequencing and computational "omic" analysis; 5) Biological image and text mining.\n\nhttp://www.cs.cmu.edu/~epxing/\n'}
LLAMA-7B PREDICTED ANSWER=====
  Professor Xing's research focuses on developing machine learning and statistical methodologies for understanding biological systems, building intelligent systems, and analyzing large-scale data.
PROMPT=====
{'question': 'How to contact Eric P. Xing via email?', 'context': 'Eric P. Xing\nProfessor (On Leave), Language Technologies Institute\nContact\n8101 —Gates & Hillman Centers\nEmail epxing@andrew.cmu.edu\n412-268-2559\nResearch\nThe major theme of Professor Xing\'s research lies in the development of machine learning and statistical methodology; especially for building quantitative models and predictive understandings of the evolutionary mechanism, regulatory circuitry, and developmental processes of biological systems; and for building intelligent systems for a wide range of applications in vision, IR and NLP that involves computational learning and reasoning under uncertainty.\n\nFoundations of Statistical Learning, including theory and algorithms for: 1) Time/space varying-coefficient models with evolving structures; 2) Sparse structured input/output models in high-dimensional problems; 3) Nonparametric Bayesian techniques for infinite-dimensional models; 4) RKHS embedding, nonparametric inference, and spectral methods for graphical models; 5) Distributed and online algorithms for optimization, approximate inference, and sampling on massive data.\n\nLarge-scale Information & Intelligent System: 1) Development of scalable parallel architecture, protocol, programming interface, generic algorithms and models, for Big Learning; 2) Multi-view latent space models, topics models, and sparse coding for image/text/relational data mining; 3) Evolving structure, stable metrics, and prediction for dynamic social networks, goal-driven network design and optimization; 4) Web-scale image understanding, search, prediction, and storyline synthesis; 5) Information visualization, indexing and storage, web/mobile app development.\n\nComputational Biology: 1) Understanding genome-microenvironment interactions in cancer and embryogenesis via joint analysis of genomic, proteomic, and pathway signaling data; 2) Genetic analysis of population variation, demography and evolution; 3) Statistical inference of genome-transcriptome-phenome association in complex diseases; 4) Personalized diagnosis and treatment of spectrum diseases via next generation sequencing and computational "omic" analysis; 5) Biological image and text mining.\n\nhttp://www.cs.cmu.edu/~epxing/\n'}
LLAMA-7B PREDICTED ANSWER=====
  Sure! Here is how you can contact Eric P. Xing via email:
epxing@andrew.cmu.edu
PROMPT=====
{'question': 'What position does Sean Welleck hold at CMU?', 'context': 'Sean Welleck\nAssistant Professor, Language Technologies Institute\nContact\nEmail swelleck@andrew.cmu.edu\nAddress\n5000 Forbes Avenue\nPittsburgh, PA 15213\n\n'}
LLAMA-7B PREDICTED ANSWER=====
  Assistant Professor
PROMPT=====
{'question': 'How to contact Sean Welleck via email?', 'context': 'Sean Welleck\nAssistant Professor, Language Technologies Institute\nContact\nEmail swelleck@andrew.cmu.edu\nAddress\n5000 Forbes Avenue\nPittsburgh, PA 15213\n\n'}
LLAMA-7B PREDICTED ANSWER=====
  swelleck@andrew.cmu.edu
PROMPT=====
{'question': 'Which institute is Sean Welleck associated with?', 'context': 'Sean Welleck\nAssistant Professor, Language Technologies Institute\nContact\nEmail swelleck@andrew.cmu.edu\nAddress\n5000 Forbes Avenue\nPittsburgh, PA 15213\n\n'}
LLAMA-7B PREDICTED ANSWER=====
  The Language Technologies Institute (LTI)
PROMPT=====
{'question': "What is Shinji Watanabe's area of expertise?", 'context': 'Shinji Watanabe\nAssociate Professor, Language Technologies Institute\nContact\n6405 —Gates & Hillman Centers\nEmail swatanab@andrew.cmu.edu\n412-268-3687\nResearch Area\nNatural Language Processing and Computational Linguistics, Speech Processing\n\nPersonal Website https://sites.google.com/view/shinjiwatanabe?pli=1\n'}
LLAMA-7B PREDICTED ANSWER=====
  Natural Language Processing and Computational Linguistics
PROMPT=====
{'question': 'How to contact Shinji Watanabe via email?', 'context': 'Shinji Watanabe\nAssociate Professor, Language Technologies Institute\nContact\n6405 —Gates & Hillman Centers\nEmail swatanab@andrew.cmu.edu\n412-268-3687\nResearch Area\nNatural Language Processing and Computational Linguistics, Speech Processing\n\nPersonal Website https://sites.google.com/view/shinjiwatanabe?pli=1\n'}
LLAMA-7B PREDICTED ANSWER=====
  swatanab@andrew.cmu.edu
PROMPT=====
{'question': "Shinji Watanabe's position at CMU?", 'context': 'Shinji Watanabe\nAssociate Professor, Language Technologies Institute\nContact\n6405 —Gates & Hillman Centers\nEmail swatanab@andrew.cmu.edu\n412-268-3687\nResearch Area\nNatural Language Processing and Computational Linguistics, Speech Processing\n\nPersonal Website https://sites.google.com/view/shinjiwatanabe?pli=1\n'}
LLAMA-7B PREDICTED ANSWER=====
  Associate Professor, Language Technologies Institute
PROMPT=====
{'question': 'What is Alexander Waibel known for?', 'context': 'Alexander Waibel\nProfessor (On Leave), Language Technologies Institute\nContact\n205 —407 South Craig Street\nEmail waibel@cs.cmu.edu\n412-268-7676\nResearch Area\nMachine Learning, Machine Translation, Multimodal Computing and Interaction, Neural Networks, Speech Processing, Spoken Interfaces and Dialogue Processing, Spoken Language Translation\n\nBio\nDr. Alexander Waibel is a Professor of Computer Science at Carnegie Mellon University, Pittsburgh and at the Karlsruhe Institute of Technology, Germany. He is the director of the International Center for Advanced Communication Technologies (interACT). The Center works in a network with eight of the world’s top research institutions. The Center’s mission is to develop advanced machine learning algorithms to improve human-human and human-machine communication technologies.  Prof. Waibel and his team developed many statistical and neural network learning  algorithms that made such communication breakthroughs possible. Most notably, the “Time-Delay Neural Network” (1987) (the first “convolutional” neural network) now is at the heart of many of today’s AI technologies. System breakthroughs at Waibel’s lab included early multimodal interfaces, speech and language interfaces, the first speech translation system in Europe & USA (1990/1991), the first simultaneous lecture translation system (2005), and Jibbigo, the first commercial speech translator on a phone (2009).\n\nDr. Waibel founded and served as chairmen of C-STAR, the Consortium for Speech Translation Advanced Research in 1991. He directed many research programs in speech, translation, multimodal interfaces and machine learning in the US, Europe and Asia. He served as director of EU-Bridge (2012-2015) and CHIL (2004-2007), two large European multi-site Integrated Project initiatives on intelligent assistants and speech translation services. He also was co-director of IMMI, a joint venture between KIT, CNRS & RWTH.\n\nDr. Waibel is an IEEE Fellow and received many awards for his work on multilingual and multimodal communication  and translation. He published extensively (>750 publications, >25,000 citations, h-index 80) in the field and received/filed numerous patents. Waibel was elected to the National Academy of Sciences of Germany in 2017, and was named Honorary Senator of the Hochschulrektorenkonferenz (Representation of German Universities).\n\nDuring his career, Dr. Waibel founded and built ten successful companies. Following the acquisition of Jibbigo by Facebook, Waibel served as founding director of the Language Technology Group at FB. He also deployed speech translation technologies in humanitarian and disaster relief missions. His team recently deployed the first simultaneous interpretation service for lectures at Universities and interpretation tools at the European Parliament. \n\nEducation\nDr. Waibel received his BS, MS and PhD degrees at Massachusetts Institute of Technology and CMU, respectively.\nPersonal Website https://www.cs.cmu.edu/~ahw/\n\n'}
LLAMA-7B PREDICTED ANSWER=====
  Alexander Waibel is known for his work in machine learning, machine translation, and multimodal computing and interaction, particularly through his development of the "Time-Delay Neural Network" and his leadership in various research initiatives and companies.
PROMPT=====
{'question': 'How to contact Alexander Waibel via email?', 'context': 'Alexander Waibel\nProfessor (On Leave), Language Technologies Institute\nContact\n205 —407 South Craig Street\nEmail waibel@cs.cmu.edu\n412-268-7676\nResearch Area\nMachine Learning, Machine Translation, Multimodal Computing and Interaction, Neural Networks, Speech Processing, Spoken Interfaces and Dialogue Processing, Spoken Language Translation\n\nBio\nDr. Alexander Waibel is a Professor of Computer Science at Carnegie Mellon University, Pittsburgh and at the Karlsruhe Institute of Technology, Germany. He is the director of the International Center for Advanced Communication Technologies (interACT). The Center works in a network with eight of the world’s top research institutions. The Center’s mission is to develop advanced machine learning algorithms to improve human-human and human-machine communication technologies.  Prof. Waibel and his team developed many statistical and neural network learning  algorithms that made such communication breakthroughs possible. Most notably, the “Time-Delay Neural Network” (1987) (the first “convolutional” neural network) now is at the heart of many of today’s AI technologies. System breakthroughs at Waibel’s lab included early multimodal interfaces, speech and language interfaces, the first speech translation system in Europe & USA (1990/1991), the first simultaneous lecture translation system (2005), and Jibbigo, the first commercial speech translator on a phone (2009).\n\nDr. Waibel founded and served as chairmen of C-STAR, the Consortium for Speech Translation Advanced Research in 1991. He directed many research programs in speech, translation, multimodal interfaces and machine learning in the US, Europe and Asia. He served as director of EU-Bridge (2012-2015) and CHIL (2004-2007), two large European multi-site Integrated Project initiatives on intelligent assistants and speech translation services. He also was co-director of IMMI, a joint venture between KIT, CNRS & RWTH.\n\nDr. Waibel is an IEEE Fellow and received many awards for his work on multilingual and multimodal communication  and translation. He published extensively (>750 publications, >25,000 citations, h-index 80) in the field and received/filed numerous patents. Waibel was elected to the National Academy of Sciences of Germany in 2017, and was named Honorary Senator of the Hochschulrektorenkonferenz (Representation of German Universities).\n\nDuring his career, Dr. Waibel founded and built ten successful companies. Following the acquisition of Jibbigo by Facebook, Waibel served as founding director of the Language Technology Group at FB. He also deployed speech translation technologies in humanitarian and disaster relief missions. His team recently deployed the first simultaneous interpretation service for lectures at Universities and interpretation tools at the European Parliament. \n\nEducation\nDr. Waibel received his BS, MS and PhD degrees at Massachusetts Institute of Technology and CMU, respectively.\nPersonal Website https://www.cs.cmu.edu/~ahw/\n\n'}
LLAMA-7B PREDICTED ANSWER=====
  Email: waibel@cs.cmu.edu
PROMPT=====
{'question': "Alexander Waibel's research areas include?", 'context': 'Alexander Waibel\nProfessor (On Leave), Language Technologies Institute\nContact\n205 —407 South Craig Street\nEmail waibel@cs.cmu.edu\n412-268-7676\nResearch Area\nMachine Learning, Machine Translation, Multimodal Computing and Interaction, Neural Networks, Speech Processing, Spoken Interfaces and Dialogue Processing, Spoken Language Translation\n\nBio\nDr. Alexander Waibel is a Professor of Computer Science at Carnegie Mellon University, Pittsburgh and at the Karlsruhe Institute of Technology, Germany. He is the director of the International Center for Advanced Communication Technologies (interACT). The Center works in a network with eight of the world’s top research institutions. The Center’s mission is to develop advanced machine learning algorithms to improve human-human and human-machine communication technologies.  Prof. Waibel and his team developed many statistical and neural network learning  algorithms that made such communication breakthroughs possible. Most notably, the “Time-Delay Neural Network” (1987) (the first “convolutional” neural network) now is at the heart of many of today’s AI technologies. System breakthroughs at Waibel’s lab included early multimodal interfaces, speech and language interfaces, the first speech translation system in Europe & USA (1990/1991), the first simultaneous lecture translation system (2005), and Jibbigo, the first commercial speech translator on a phone (2009).\n\nDr. Waibel founded and served as chairmen of C-STAR, the Consortium for Speech Translation Advanced Research in 1991. He directed many research programs in speech, translation, multimodal interfaces and machine learning in the US, Europe and Asia. He served as director of EU-Bridge (2012-2015) and CHIL (2004-2007), two large European multi-site Integrated Project initiatives on intelligent assistants and speech translation services. He also was co-director of IMMI, a joint venture between KIT, CNRS & RWTH.\n\nDr. Waibel is an IEEE Fellow and received many awards for his work on multilingual and multimodal communication  and translation. He published extensively (>750 publications, >25,000 citations, h-index 80) in the field and received/filed numerous patents. Waibel was elected to the National Academy of Sciences of Germany in 2017, and was named Honorary Senator of the Hochschulrektorenkonferenz (Representation of German Universities).\n\nDuring his career, Dr. Waibel founded and built ten successful companies. Following the acquisition of Jibbigo by Facebook, Waibel served as founding director of the Language Technology Group at FB. He also deployed speech translation technologies in humanitarian and disaster relief missions. His team recently deployed the first simultaneous interpretation service for lectures at Universities and interpretation tools at the European Parliament. \n\nEducation\nDr. Waibel received his BS, MS and PhD degrees at Massachusetts Institute of Technology and CMU, respectively.\nPersonal Website https://www.cs.cmu.edu/~ahw/\n\n'}
LLAMA-7B PREDICTED ANSWER=====
  Sure! Here is the answer to your question in 10 words or less:
Alexander Waibel's research areas include machine learning, machine translation, and multimodal computing.
PROMPT=====
{'question': 'What position does Emma Strubell hold at CMU?', 'context': 'Emma Strubell\nAssistant Professor, Language Technologies Institute\nContact\n6709 —Gates Hillman \nEmail estrubel@andrew.cmu.edu\nPersonal Website https://strubell.github.io/\n'}
LLAMA-7B PREDICTED ANSWER=====
  Assistant Professor
PROMPT=====
{'question': 'How to contact Emma Strubell via email?', 'context': 'Emma Strubell\nAssistant Professor, Language Technologies Institute\nContact\n6709 —Gates Hillman \nEmail estrubel@andrew.cmu.edu\nPersonal Website https://strubell.github.io/\n'}
LLAMA-7B PREDICTED ANSWER=====
  Sure! Here is the answer to your question in 5 words or less:
Email estrubel@andrew.cmu.edu
PROMPT=====
{'question': "Emma Strubell's professional website?", 'context': 'Emma Strubell\nAssistant Professor, Language Technologies Institute\nContact\n6709 —Gates Hillman \nEmail estrubel@andrew.cmu.edu\nPersonal Website https://strubell.github.io/\n'}
LLAMA-7B PREDICTED ANSWER=====
  Emma Strubell's personal website: <https://strubell.github.io/>
PROMPT=====
{'question': "What is Rita Singh's title at CMU?", 'context': 'Rita Singh\nAssociate Research Professor, Language Technologies Institute\nContact\n6703 —Gates & Hillman Centers\nEmail rsingh@cs.cmu.edu\n412-268-9859\n'}
LLAMA-7B PREDICTED ANSWER=====
  Associate Research Professor
PROMPT=====
{'question': 'How to contact Rita Singh via email?', 'context': 'Rita Singh\nAssociate Research Professor, Language Technologies Institute\nContact\n6703 —Gates & Hillman Centers\nEmail rsingh@cs.cmu.edu\n412-268-9859\n'}
LLAMA-7B PREDICTED ANSWER=====
  Email rsingh@cs.cmu.edu
PROMPT=====
{'question': 'How to contact Michael Shamos via email?', 'context': 'Michael Shamos\nDistinguished Career Professor, Language Technologies Institute\nInstitute for Software Research\nContact\n6707 —Gates & Hillman Centers\nEmail shamos@cs.cmu.edu\n412-268-8193\nInstitute for Software Research https://www.cs.cmu.edu/~brassmars/\nPersonal Website http://www.cs.cmu.edu/~jbigham/\n'}
LLAMA-7B PREDICTED ANSWER=====
  Email: shamos@cs.cmu.edu
PROMPT=====
{'question': 'Michael Shamos is affiliated with which institute?', 'context': 'Michael Shamos\nDistinguished Career Professor, Language Technologies Institute\nInstitute for Software Research\nContact\n6707 —Gates & Hillman Centers\nEmail shamos@cs.cmu.edu\n412-268-8193\nInstitute for Software Research https://www.cs.cmu.edu/~brassmars/\nPersonal Website http://www.cs.cmu.edu/~jbigham/\n'}
LLAMA-7B PREDICTED ANSWER=====
  Institute for Software Research
PROMPT=====
{'question': "What is Maarten Sap's research focus?", 'context': 'Maarten Sap\nAssistant Professor, Language Technologies Institute\nContact\n6713 —Gates & Hillman Centers\nEmail msap2@andrew.cmu.edu\nResearch Area\nComputational Social Science, Conversational AI, Discourse and Pragmatics, Fairness and Ethics in Language Technology\n\nPersonal Website http://maartensap.com/\n'}
LLAMA-7B PREDICTED ANSWER=====
  Computational Social Science
PROMPT=====
{'question': 'How to contact Maarten Sap via email?', 'context': 'Maarten Sap\nAssistant Professor, Language Technologies Institute\nContact\n6713 —Gates & Hillman Centers\nEmail msap2@andrew.cmu.edu\nResearch Area\nComputational Social Science, Conversational AI, Discourse and Pragmatics, Fairness and Ethics in Language Technology\n\nPersonal Website http://maartensap.com/\n'}
LLAMA-7B PREDICTED ANSWER=====
  msap2@andrew.cmu.edu
PROMPT=====
{'question': "Maarten Sap's professional website?", 'context': 'Maarten Sap\nAssistant Professor, Language Technologies Institute\nContact\n6713 —Gates & Hillman Centers\nEmail msap2@andrew.cmu.edu\nResearch Area\nComputational Social Science, Conversational AI, Discourse and Pragmatics, Fairness and Ethics in Language Technology\n\nPersonal Website http://maartensap.com/\n'}
LLAMA-7B PREDICTED ANSWER=====
  Maarten Sap's personal website: <http://maartensap.com/>
PROMPT=====
{'question': "Alexander Rudnicky's research focuses on what aspect of technology?", 'context': "Alexander Rudnicky\nResearch Professor Emeritus, Language Technologies Institute\nContact\n6511 —Gates & Hillman Centers\nEmail alex.rudnicky@cs.cmu.edu\n412-268-2622\nResearch Area\nMultimodal Computing and Interaction, Speech Processing, Spoken Interfaces and Dialogue Processing\n\nResearch\nMy research centers on interactive systems that use speech. I am currently interested in the following problems:\n\nImplicit Learning : Human-computer interaction generates information that the system could use to modify its behavior. For example, a speech recognition error that is repaired leaves information about a misclassification that could be used to improve subsequent accuracy. Exploiting such situations (and in fact contriving to create them) can provide a rich set of experiences that drive self-improving systems\n\nAutomatic detection and recovery from error: Humans easily detect and recover from breakdowns in communication. Automatic systems are less successful at this, however we can use features of recognition, understanding and dialog to predict the likelihood of misunderstanding at a given point in an interaction, and then apply heuristic strategies for guiding the conversation back onto track.\n\nA theory of language design for speech-based interactive systems: Speech-mode communication predisposes the user to make certain word choices and to exhibit certain grammatical preferences. An understanding of the principles that underlie these preferences (and how these can be influenced by the system's language) leads to better language design for interactive systems.\n\nThe role of speech in the computer interface: Speech is an effective means of communication, but it is not always suitable for all types of interaction. Ideally we can analyze an interface in terms of the task(s) it will be used for, the costs of specific interactions and the value perceived by the user. To date we've studied models based on time, system error and task structure. These models turn out to be useful for simple systems and appear to be extensible to more complex systems. Many of these issues are being explored in the context of working systems, for example a language interface for a team of humans and robots working together (Treasure Hunt) or a information access for conferences (ConQuest) or for scheduling court time (Let’s Play).\n\nPersonal Website http://www.cs.cmu.edu/~air/\n\n"}
LLAMA-7B PREDICTED ANSWER=====
  Alexander Rudnicky's research focuses on speech processing and spoken interfaces for computer interaction.
PROMPT=====
{'question': 'What is a current interest of Alexander Rudnicky in speech technology?', 'context': "Alexander Rudnicky\nResearch Professor Emeritus, Language Technologies Institute\nContact\n6511 —Gates & Hillman Centers\nEmail alex.rudnicky@cs.cmu.edu\n412-268-2622\nResearch Area\nMultimodal Computing and Interaction, Speech Processing, Spoken Interfaces and Dialogue Processing\n\nResearch\nMy research centers on interactive systems that use speech. I am currently interested in the following problems:\n\nImplicit Learning : Human-computer interaction generates information that the system could use to modify its behavior. For example, a speech recognition error that is repaired leaves information about a misclassification that could be used to improve subsequent accuracy. Exploiting such situations (and in fact contriving to create them) can provide a rich set of experiences that drive self-improving systems\n\nAutomatic detection and recovery from error: Humans easily detect and recover from breakdowns in communication. Automatic systems are less successful at this, however we can use features of recognition, understanding and dialog to predict the likelihood of misunderstanding at a given point in an interaction, and then apply heuristic strategies for guiding the conversation back onto track.\n\nA theory of language design for speech-based interactive systems: Speech-mode communication predisposes the user to make certain word choices and to exhibit certain grammatical preferences. An understanding of the principles that underlie these preferences (and how these can be influenced by the system's language) leads to better language design for interactive systems.\n\nThe role of speech in the computer interface: Speech is an effective means of communication, but it is not always suitable for all types of interaction. Ideally we can analyze an interface in terms of the task(s) it will be used for, the costs of specific interactions and the value perceived by the user. To date we've studied models based on time, system error and task structure. These models turn out to be useful for simple systems and appear to be extensible to more complex systems. Many of these issues are being explored in the context of working systems, for example a language interface for a team of humans and robots working together (Treasure Hunt) or a information access for conferences (ConQuest) or for scheduling court time (Let’s Play).\n\nPersonal Website http://www.cs.cmu.edu/~air/\n\n"}
LLAMA-7B PREDICTED ANSWER=====
  Professor Rudnicky's current interest in speech technology is automatic detection and recovery from error in human-computer interaction, as well as designing language for speech-based interactive systems.
PROMPT=====
{'question': 'How to contact Alexander Rudnicky via email?', 'context': "Alexander Rudnicky\nResearch Professor Emeritus, Language Technologies Institute\nContact\n6511 —Gates & Hillman Centers\nEmail alex.rudnicky@cs.cmu.edu\n412-268-2622\nResearch Area\nMultimodal Computing and Interaction, Speech Processing, Spoken Interfaces and Dialogue Processing\n\nResearch\nMy research centers on interactive systems that use speech. I am currently interested in the following problems:\n\nImplicit Learning : Human-computer interaction generates information that the system could use to modify its behavior. For example, a speech recognition error that is repaired leaves information about a misclassification that could be used to improve subsequent accuracy. Exploiting such situations (and in fact contriving to create them) can provide a rich set of experiences that drive self-improving systems\n\nAutomatic detection and recovery from error: Humans easily detect and recover from breakdowns in communication. Automatic systems are less successful at this, however we can use features of recognition, understanding and dialog to predict the likelihood of misunderstanding at a given point in an interaction, and then apply heuristic strategies for guiding the conversation back onto track.\n\nA theory of language design for speech-based interactive systems: Speech-mode communication predisposes the user to make certain word choices and to exhibit certain grammatical preferences. An understanding of the principles that underlie these preferences (and how these can be influenced by the system's language) leads to better language design for interactive systems.\n\nThe role of speech in the computer interface: Speech is an effective means of communication, but it is not always suitable for all types of interaction. Ideally we can analyze an interface in terms of the task(s) it will be used for, the costs of specific interactions and the value perceived by the user. To date we've studied models based on time, system error and task structure. These models turn out to be useful for simple systems and appear to be extensible to more complex systems. Many of these issues are being explored in the context of working systems, for example a language interface for a team of humans and robots working together (Treasure Hunt) or a information access for conferences (ConQuest) or for scheduling court time (Let’s Play).\n\nPersonal Website http://www.cs.cmu.edu/~air/\n\n"}
LLAMA-7B PREDICTED ANSWER=====
  Email address: alex.rudnicky@cs.cmu.edu
PROMPT=====
{'question': "What are Carolyn Rosé's main research areas?", 'context': "Carolyn Rosé\nProfessor, Language Technologies Institute\nHuman-Computer Interaction Institute\nContact\n5415 —Gates & Hillman Centers\nEmail\n412-268-7130\nResearch Area\nComputer-Supported Collaborative Learning/MOOCs, Information Retrieval, Text Mining and Analytics, Language Technologies for Education, Natural Language Processing and Computational Linguistics\n\nEducation\nPh.D. in Language and Information Technology\n1997\nEmployer Upon Graduation: \nFaculty, LTI CMU\nResearch\nMy research focuses on better understanding the social and pragmatic nature of conversation, and using this understanding to build computational systems that improve the efficacy of conversation both between people, and between people and computers. In order to pursue these goals, I invoke approaches from computational discourse analysis and text mining, conversational agents, and computer-supported collaborative learning. I ground my research in the fields of language technologies and human-computer interaction, and am fortunate to work closely with students and post-docs from the LTI and the Human-Computer Interaction Institute, as well as to direct my own lab, TELEDIA. My group’s highly interdisciplinary work, published in 160 peer-reviewed publications, is represented in the top venues in five fields: language technologies, learning sciences, cognitive science, educational technology and human-computer interaction.\n\nAn exciting direction of my group's work is spearheading a satellite working group to support social interaction for learning in MOOCs with EdX called DANCE. My research toward this end has birthed and substantially contributed to the growth of two thriving interrelated research areas: automated analysis of collaborative learning processes and dynamic support for collaborative learning. Both areas use intelligent conversational agents to support collaborative learning in a context-sensitive way.\n\nAll of my work draws insight from rich theoretical models from sociolinguistics and discourse analysis, and pares them down to precise operationalizations that capture the most important essence for achieving impact. I always start by investigating how conversation works and formalizing this understanding in models that are precise enough to be reproducible and that demonstrate explanatory power in connection with outcomes with real-world value. The next step is to adapt, extend and apply machine learning and text mining technologies that leverage this deep understanding to build computational models capable of automatically applying these constructs to naturally occurring language interactions. Finally, with the technology to automatically monitor naturalistic language communication in place, we can build interventions with real-world benefits.\n\nThis approach leads to three aspects included in each project:\n\nBasic research on discourse analysis to identify conversational constructs that predict important group outcomes such as learning, knowledge transfer or motivation.\nBasic research on text classification technology for automated analysis of conversational constructs identified under research on discourse analysis, as well as tools to enable other researchers to do the same.\nBasic research on conversational agent technology and summarization that eases development of interventions triggered by automatic analyses from basic research on text classification that either enables human facilitators to offer support, directly provide feedback to groups or influence group participation in positive ways.\nHuman-Computer Interaction Institute https://hcii.cmu.edu/\nPersonal Website http://www.cs.cmu.edu/~cprose/\n"}
LLAMA-7B PREDICTED ANSWER=====
  Carolyn Prose's research areas include:
Computer-Supported Collaborative Learning/MOOCs
Information Retrieval
Text Mining and Analytics
Language Technologies for Education
Natural Language Processing and Computational Linguistics
PROMPT=====
{'question': "What is Carolyn Rosé's research goal?", 'context': "Carolyn Rosé\nProfessor, Language Technologies Institute\nHuman-Computer Interaction Institute\nContact\n5415 —Gates & Hillman Centers\nEmail\n412-268-7130\nResearch Area\nComputer-Supported Collaborative Learning/MOOCs, Information Retrieval, Text Mining and Analytics, Language Technologies for Education, Natural Language Processing and Computational Linguistics\n\nEducation\nPh.D. in Language and Information Technology\n1997\nEmployer Upon Graduation: \nFaculty, LTI CMU\nResearch\nMy research focuses on better understanding the social and pragmatic nature of conversation, and using this understanding to build computational systems that improve the efficacy of conversation both between people, and between people and computers. In order to pursue these goals, I invoke approaches from computational discourse analysis and text mining, conversational agents, and computer-supported collaborative learning. I ground my research in the fields of language technologies and human-computer interaction, and am fortunate to work closely with students and post-docs from the LTI and the Human-Computer Interaction Institute, as well as to direct my own lab, TELEDIA. My group’s highly interdisciplinary work, published in 160 peer-reviewed publications, is represented in the top venues in five fields: language technologies, learning sciences, cognitive science, educational technology and human-computer interaction.\n\nAn exciting direction of my group's work is spearheading a satellite working group to support social interaction for learning in MOOCs with EdX called DANCE. My research toward this end has birthed and substantially contributed to the growth of two thriving interrelated research areas: automated analysis of collaborative learning processes and dynamic support for collaborative learning. Both areas use intelligent conversational agents to support collaborative learning in a context-sensitive way.\n\nAll of my work draws insight from rich theoretical models from sociolinguistics and discourse analysis, and pares them down to precise operationalizations that capture the most important essence for achieving impact. I always start by investigating how conversation works and formalizing this understanding in models that are precise enough to be reproducible and that demonstrate explanatory power in connection with outcomes with real-world value. The next step is to adapt, extend and apply machine learning and text mining technologies that leverage this deep understanding to build computational models capable of automatically applying these constructs to naturally occurring language interactions. Finally, with the technology to automatically monitor naturalistic language communication in place, we can build interventions with real-world benefits.\n\nThis approach leads to three aspects included in each project:\n\nBasic research on discourse analysis to identify conversational constructs that predict important group outcomes such as learning, knowledge transfer or motivation.\nBasic research on text classification technology for automated analysis of conversational constructs identified under research on discourse analysis, as well as tools to enable other researchers to do the same.\nBasic research on conversational agent technology and summarization that eases development of interventions triggered by automatic analyses from basic research on text classification that either enables human facilitators to offer support, directly provide feedback to groups or influence group participation in positive ways.\nHuman-Computer Interaction Institute https://hcii.cmu.edu/\nPersonal Website http://www.cs.cmu.edu/~cprose/\n"}
LLAMA-7B PREDICTED ANSWER=====
  Carolyn Prose's research goal is to improve conversation efficiency between people and computers through interdisciplinary approaches combining computational discourse analysis, text mining, conversational agents, and computer-supported collaborative learning.
PROMPT=====
{'question': 'How does Carolyn Rosé support learning in MOOCs?', 'context': "Carolyn Rosé\nProfessor, Language Technologies Institute\nHuman-Computer Interaction Institute\nContact\n5415 —Gates & Hillman Centers\nEmail\n412-268-7130\nResearch Area\nComputer-Supported Collaborative Learning/MOOCs, Information Retrieval, Text Mining and Analytics, Language Technologies for Education, Natural Language Processing and Computational Linguistics\n\nEducation\nPh.D. in Language and Information Technology\n1997\nEmployer Upon Graduation: \nFaculty, LTI CMU\nResearch\nMy research focuses on better understanding the social and pragmatic nature of conversation, and using this understanding to build computational systems that improve the efficacy of conversation both between people, and between people and computers. In order to pursue these goals, I invoke approaches from computational discourse analysis and text mining, conversational agents, and computer-supported collaborative learning. I ground my research in the fields of language technologies and human-computer interaction, and am fortunate to work closely with students and post-docs from the LTI and the Human-Computer Interaction Institute, as well as to direct my own lab, TELEDIA. My group’s highly interdisciplinary work, published in 160 peer-reviewed publications, is represented in the top venues in five fields: language technologies, learning sciences, cognitive science, educational technology and human-computer interaction.\n\nAn exciting direction of my group's work is spearheading a satellite working group to support social interaction for learning in MOOCs with EdX called DANCE. My research toward this end has birthed and substantially contributed to the growth of two thriving interrelated research areas: automated analysis of collaborative learning processes and dynamic support for collaborative learning. Both areas use intelligent conversational agents to support collaborative learning in a context-sensitive way.\n\nAll of my work draws insight from rich theoretical models from sociolinguistics and discourse analysis, and pares them down to precise operationalizations that capture the most important essence for achieving impact. I always start by investigating how conversation works and formalizing this understanding in models that are precise enough to be reproducible and that demonstrate explanatory power in connection with outcomes with real-world value. The next step is to adapt, extend and apply machine learning and text mining technologies that leverage this deep understanding to build computational models capable of automatically applying these constructs to naturally occurring language interactions. Finally, with the technology to automatically monitor naturalistic language communication in place, we can build interventions with real-world benefits.\n\nThis approach leads to three aspects included in each project:\n\nBasic research on discourse analysis to identify conversational constructs that predict important group outcomes such as learning, knowledge transfer or motivation.\nBasic research on text classification technology for automated analysis of conversational constructs identified under research on discourse analysis, as well as tools to enable other researchers to do the same.\nBasic research on conversational agent technology and summarization that eases development of interventions triggered by automatic analyses from basic research on text classification that either enables human facilitators to offer support, directly provide feedback to groups or influence group participation in positive ways.\nHuman-Computer Interaction Institute https://hcii.cmu.edu/\nPersonal Website http://www.cs.cmu.edu/~cprose/\n"}
LLAMA-7B PREDICTED ANSWER=====
  Carolyn Prose supports learning in MOOCs by developing intelligent conversational agents to facilitate collaborative learning and providing dynamic support for learners.
PROMPT=====
{'question': "What are Bhiksha Raj's main research areas?", 'context': 'Bhiksha Raj\nProfessor, Language Technologies Institute\nContact\n6705 —Gates & Hillman Centers\nEmail bhiksha@cs.cmu.edu\n412-268-9826\nResearch Area\nMachine Learning, Multimodal Computing and Interaction, Privacy and Security, Speech Processing, Spoken Interfaces and Dialogue Processing\n\nhttp://mlsp.cs.cmu.edu/people/bhiksha/index.php\n'}
LLAMA-7B PREDICTED ANSWER=====
  Machine Learning, Multimodal Computing, Privacy, Security, Speech Processing, Spoken Interfaces, and Dialogue Processing.
PROMPT=====
{'question': 'Where does Kemal Oflazer teach?', 'context': 'Kemal Oflazer\nTeaching Professor, Language Technologies Institute\nComputer Science Department\nContact\n1009 —Carnegie Mellon - Qatar Campus\nEmail\nComputer Science - Qatar https://www.qatar.cmu.edu/academics-research/academics/computer-science/#/?feed=news&category=49&limit=3&featuredCategory=49&page=1\nPersonal Website https://www.andrew.cmu.edu/user/ko/\n'}
LLAMA-7B PREDICTED ANSWER=====
  Kemal Oflazer teaches at Carnegie Mellon University - Qatar Campus.
PROMPT=====
{'question': "What are Eric Nyberg's research areas?", 'context': 'Eric Nyberg\nProfessor, Language Technologies Institute\nResearch Area\nInformation Extraction, Summarization and Question Answering, Information Retrieval, Text Mining and Analytics, Language Technologies for Education\n\nhttps://www.cs.cmu.edu/~ehn/\n6715 —Gates & Hillman Centers\nEmail ehn@cs.cmu.edu\n412-268-7281\n'}
LLAMA-7B PREDICTED ANSWER=====
  Information Extraction, Summarization and Question Answering
PROMPT=====
{'question': "What are Graham Neubig's research areas?", 'context': 'Graham Neubig\nAssociate Professor, Language Technologies Institute\nResearch Area\nMachine Learning, Machine Translation, Natural Language Processing and Computational Linguistics, Spoken Interfaces and Dialogue Processing\n\nEducation\nMaster of Science in Intelligent Information Systems\nResearch\nMy research is concerned with language and its role in human communication. In particular, my long-term research goal is to break down barriers in human-human or human-machine communication through the development of natural language processing (NLP) technologies. This includes the development of technology for machine translation, which helps break down barriers in communication for people who speak different languages, and natural language understanding, which helps computers understand and respond to human language. Within this overall goal of breaking down barriers to human communication, I have focused on several aspects of language that both make it interesting as a scientific subject, and hold potential for the construction of practical systems.\n\nAdvances in core NLP technology: Human language is complex and nuanced, and handling this complexity in a computational way requires sophisticated algorithms or learning techniques, the development of which is far from a solved problem. The first major area of my work focuses on advances in core NLP technology, which improve the accuracy with which we can analyze, translate, generate, or reply to textual inputs. \n\nModels of language associated with other modalities: Human language does not exist in a vacuum, and is often associated with context from the world around it. The second thread of my research focuses on models of natural language associated with other modalities, tackling the problems, and exploiting the fascinating possibilities presented by having text associated with other types of information. Specifically, I have worked extensively with speech, and am also interested in associations between natural and formal languages such as source code.\n\nLearning from naturally occurring data: Language data exists in abundance, particularly due to the advent of the internet, and it is possible to acquire extremely large amounts of this data for scientific or engineering purposes. A third thread of my research focuses on learning NLP models from naturally occurring data through the use of unsupervised, semi-supervised, or active learning, which allows us to exploit this data to improve models while reducing the necessity for costly manual annotation.\n\nhttp://www.phontron.com/\n5409 —Gates & Hillman Centers\ngneubig@cs.cmu.edu\n'}
LLAMA-7B PREDICTED ANSWER=====
  Machine learning, machine translation, natural language processing, and computational linguistics.
PROMPT=====
{'question': "What is Graham Neubig's research goal?", 'context': 'Graham Neubig\nAssociate Professor, Language Technologies Institute\nResearch Area\nMachine Learning, Machine Translation, Natural Language Processing and Computational Linguistics, Spoken Interfaces and Dialogue Processing\n\nEducation\nMaster of Science in Intelligent Information Systems\nResearch\nMy research is concerned with language and its role in human communication. In particular, my long-term research goal is to break down barriers in human-human or human-machine communication through the development of natural language processing (NLP) technologies. This includes the development of technology for machine translation, which helps break down barriers in communication for people who speak different languages, and natural language understanding, which helps computers understand and respond to human language. Within this overall goal of breaking down barriers to human communication, I have focused on several aspects of language that both make it interesting as a scientific subject, and hold potential for the construction of practical systems.\n\nAdvances in core NLP technology: Human language is complex and nuanced, and handling this complexity in a computational way requires sophisticated algorithms or learning techniques, the development of which is far from a solved problem. The first major area of my work focuses on advances in core NLP technology, which improve the accuracy with which we can analyze, translate, generate, or reply to textual inputs. \n\nModels of language associated with other modalities: Human language does not exist in a vacuum, and is often associated with context from the world around it. The second thread of my research focuses on models of natural language associated with other modalities, tackling the problems, and exploiting the fascinating possibilities presented by having text associated with other types of information. Specifically, I have worked extensively with speech, and am also interested in associations between natural and formal languages such as source code.\n\nLearning from naturally occurring data: Language data exists in abundance, particularly due to the advent of the internet, and it is possible to acquire extremely large amounts of this data for scientific or engineering purposes. A third thread of my research focuses on learning NLP models from naturally occurring data through the use of unsupervised, semi-supervised, or active learning, which allows us to exploit this data to improve models while reducing the necessity for costly manual annotation.\n\nhttp://www.phontron.com/\n5409 —Gates & Hillman Centers\ngneubig@cs.cmu.edu\n'}
LLAMA-7B PREDICTED ANSWER=====
  Graham Neubig's research goal is to break down barriers in human-human or human-machine communication through the development of natural language processing (NLP) technologies.
PROMPT=====
{'question': 'Where does Graham Neubig work?', 'context': 'Graham Neubig\nAssociate Professor, Language Technologies Institute\nResearch Area\nMachine Learning, Machine Translation, Natural Language Processing and Computational Linguistics, Spoken Interfaces and Dialogue Processing\n\nEducation\nMaster of Science in Intelligent Information Systems\nResearch\nMy research is concerned with language and its role in human communication. In particular, my long-term research goal is to break down barriers in human-human or human-machine communication through the development of natural language processing (NLP) technologies. This includes the development of technology for machine translation, which helps break down barriers in communication for people who speak different languages, and natural language understanding, which helps computers understand and respond to human language. Within this overall goal of breaking down barriers to human communication, I have focused on several aspects of language that both make it interesting as a scientific subject, and hold potential for the construction of practical systems.\n\nAdvances in core NLP technology: Human language is complex and nuanced, and handling this complexity in a computational way requires sophisticated algorithms or learning techniques, the development of which is far from a solved problem. The first major area of my work focuses on advances in core NLP technology, which improve the accuracy with which we can analyze, translate, generate, or reply to textual inputs. \n\nModels of language associated with other modalities: Human language does not exist in a vacuum, and is often associated with context from the world around it. The second thread of my research focuses on models of natural language associated with other modalities, tackling the problems, and exploiting the fascinating possibilities presented by having text associated with other types of information. Specifically, I have worked extensively with speech, and am also interested in associations between natural and formal languages such as source code.\n\nLearning from naturally occurring data: Language data exists in abundance, particularly due to the advent of the internet, and it is possible to acquire extremely large amounts of this data for scientific or engineering purposes. A third thread of my research focuses on learning NLP models from naturally occurring data through the use of unsupervised, semi-supervised, or active learning, which allows us to exploit this data to improve models while reducing the necessity for costly manual annotation.\n\nhttp://www.phontron.com/\n5409 —Gates & Hillman Centers\ngneubig@cs.cmu.edu\n'}
LLAMA-7B PREDICTED ANSWER=====
  Graham Neubig works at Carnegie Mellon University.
PROMPT=====
{'question': 'What degree does David Mortensen have?', 'context': 'David Mortensen\nAssistant Research Professor, Language Technologies Institute\nResearch Area\nCorpus Annotation and Resources, Natural Language Processing and Computational Linguistics\nEducation\nMaster of Science in Intelligent Information Systems\nhttps://www.cs.cmu.edu/~dmortens/\n5707 —Gates & Hillman Centers\ndmortens@cs.cmu.edu\ntel:412-268-2894\n'}
LLAMA-7B PREDICTED ANSWER=====
  Master of Science in Intelligent Information Systems
PROMPT=====
{'question': "What is Morency's research intersection?", 'context': 'Louis-Philippe Morency\nLeonardo Associate Professor of Computer Science (On Leave), Language Technologies Institute\nResearch Area\nMachine Learning, Multimodal Computing and Interaction, Spoken Interfaces and Dialogue Processing\n\nResearch\nMy research interest lies at the intersection of machine learning, computer vision, computational linguistics and signal processing — building the computational foundations to enable computers with the abilities to analyze, recognize and predict subtle human communicative behaviors during social interactions. Human face-to-face communication is a little like a dance: participants continuously adjust their behaviors based on their interlocutor’s speech, gestures and facial expressions during social interaction. The actual sophistication of human communication comes to the fore when we try to create computers that can understand and participate, however crudely, in this type of social interaction.\n\nHuman Communication Dynamics\nI formalize this new research endeavor with a human communication dynamics framework, addressing four key computational challenges: behavioral dynamics to model the appearance and temporal variations of individual communicative behaviors and their effects on perceived meanings; multimodal dynamics to model the interdependence between different communicative channels including visual gestures and expressions, language, and acoustic signals; interpersonal dynamics to model the social and conversational influence between participants during dyadic or small-group interactions (i.e., micro-level); and societal dynamics to model the cultural and behavioral changes in a larger groups (i.e., meso-level) or in different societies (i.e, macro-level).\n\nMultimodal Machine Learning\nCentral to this research effort is the introduction of new probabilistic models that can learn temporal and fine-grained dependencies across behaviors, modalities and interlocutors. These energy-based probabilistic models must address core computational issues with human communication dynamics, including hierarchical and nonlinear feature representation, multiview learning and potential over fitting on smaller training sets. For example, I created a family of latent probabilistic models (HCRF, LDCRF, CCNF, etc.) designed to automatically learn the hidden dynamics present in human verbal and nonverbal communication.\n\nHealth Behavior Informatics\nThis research has many applications in education (learning analytics), business (negotiation, interpersonal skills training) and social multimedia (opinion mining, social influence). One area I am particularly excited about is the development of new decision support tools for healthcare applications. For example, how can we quantify, analyze and summarize patient verbal and nonverbal behaviors during psychotherapy? This information could not only help clinicians between therapy sessions but also facilitate collaboration with other medical team members by providing objective behavior measures for the patient’s medical record.\n\nPersonal Website http://www.cs.cmu.edu/~morency/\nContact 5411 —Gates & Hillman Centers\nmorency@cs.cmu.edu\ntel:412-268-5508\n\n'}
LLAMA-7B PREDICTED ANSWER=====
  Machine learning, multimodal computing, and interaction.
PROMPT=====
{'question': 'What models did Morency create?', 'context': 'Louis-Philippe Morency\nLeonardo Associate Professor of Computer Science (On Leave), Language Technologies Institute\nResearch Area\nMachine Learning, Multimodal Computing and Interaction, Spoken Interfaces and Dialogue Processing\n\nResearch\nMy research interest lies at the intersection of machine learning, computer vision, computational linguistics and signal processing — building the computational foundations to enable computers with the abilities to analyze, recognize and predict subtle human communicative behaviors during social interactions. Human face-to-face communication is a little like a dance: participants continuously adjust their behaviors based on their interlocutor’s speech, gestures and facial expressions during social interaction. The actual sophistication of human communication comes to the fore when we try to create computers that can understand and participate, however crudely, in this type of social interaction.\n\nHuman Communication Dynamics\nI formalize this new research endeavor with a human communication dynamics framework, addressing four key computational challenges: behavioral dynamics to model the appearance and temporal variations of individual communicative behaviors and their effects on perceived meanings; multimodal dynamics to model the interdependence between different communicative channels including visual gestures and expressions, language, and acoustic signals; interpersonal dynamics to model the social and conversational influence between participants during dyadic or small-group interactions (i.e., micro-level); and societal dynamics to model the cultural and behavioral changes in a larger groups (i.e., meso-level) or in different societies (i.e, macro-level).\n\nMultimodal Machine Learning\nCentral to this research effort is the introduction of new probabilistic models that can learn temporal and fine-grained dependencies across behaviors, modalities and interlocutors. These energy-based probabilistic models must address core computational issues with human communication dynamics, including hierarchical and nonlinear feature representation, multiview learning and potential over fitting on smaller training sets. For example, I created a family of latent probabilistic models (HCRF, LDCRF, CCNF, etc.) designed to automatically learn the hidden dynamics present in human verbal and nonverbal communication.\n\nHealth Behavior Informatics\nThis research has many applications in education (learning analytics), business (negotiation, interpersonal skills training) and social multimedia (opinion mining, social influence). One area I am particularly excited about is the development of new decision support tools for healthcare applications. For example, how can we quantify, analyze and summarize patient verbal and nonverbal behaviors during psychotherapy? This information could not only help clinicians between therapy sessions but also facilitate collaboration with other medical team members by providing objective behavior measures for the patient’s medical record.\n\nPersonal Website http://www.cs.cmu.edu/~morency/\nContact 5411 —Gates & Hillman Centers\nmorency@cs.cmu.edu\ntel:412-268-5508\n\n'}
LLAMA-7B PREDICTED ANSWER=====
  Louis-Philippe Morency created various probabilistic models for machine learning, including HCRF, LDCRF, and CCNF, to learn temporal and fine-grained dependencies across behaviors, modalities, and interlocutors.
PROMPT=====
{'question': "What is Morency's application focus?", 'context': 'Louis-Philippe Morency\nLeonardo Associate Professor of Computer Science (On Leave), Language Technologies Institute\nResearch Area\nMachine Learning, Multimodal Computing and Interaction, Spoken Interfaces and Dialogue Processing\n\nResearch\nMy research interest lies at the intersection of machine learning, computer vision, computational linguistics and signal processing — building the computational foundations to enable computers with the abilities to analyze, recognize and predict subtle human communicative behaviors during social interactions. Human face-to-face communication is a little like a dance: participants continuously adjust their behaviors based on their interlocutor’s speech, gestures and facial expressions during social interaction. The actual sophistication of human communication comes to the fore when we try to create computers that can understand and participate, however crudely, in this type of social interaction.\n\nHuman Communication Dynamics\nI formalize this new research endeavor with a human communication dynamics framework, addressing four key computational challenges: behavioral dynamics to model the appearance and temporal variations of individual communicative behaviors and their effects on perceived meanings; multimodal dynamics to model the interdependence between different communicative channels including visual gestures and expressions, language, and acoustic signals; interpersonal dynamics to model the social and conversational influence between participants during dyadic or small-group interactions (i.e., micro-level); and societal dynamics to model the cultural and behavioral changes in a larger groups (i.e., meso-level) or in different societies (i.e, macro-level).\n\nMultimodal Machine Learning\nCentral to this research effort is the introduction of new probabilistic models that can learn temporal and fine-grained dependencies across behaviors, modalities and interlocutors. These energy-based probabilistic models must address core computational issues with human communication dynamics, including hierarchical and nonlinear feature representation, multiview learning and potential over fitting on smaller training sets. For example, I created a family of latent probabilistic models (HCRF, LDCRF, CCNF, etc.) designed to automatically learn the hidden dynamics present in human verbal and nonverbal communication.\n\nHealth Behavior Informatics\nThis research has many applications in education (learning analytics), business (negotiation, interpersonal skills training) and social multimedia (opinion mining, social influence). One area I am particularly excited about is the development of new decision support tools for healthcare applications. For example, how can we quantify, analyze and summarize patient verbal and nonverbal behaviors during psychotherapy? This information could not only help clinicians between therapy sessions but also facilitate collaboration with other medical team members by providing objective behavior measures for the patient’s medical record.\n\nPersonal Website http://www.cs.cmu.edu/~morency/\nContact 5411 —Gates & Hillman Centers\nmorency@cs.cmu.edu\ntel:412-268-5508\n\n'}
LLAMA-7B PREDICTED ANSWER=====
  Morency's research focuses on developing machine learning models to analyze and predict human communicative behaviors, with applications in healthcare, education, and business.
PROMPT=====
{'question': 'Who focuses on Speech Processing in their research?', 'context': 'Shinji Watanabe\nAssociate Professor, Language Technologies Institute\nContact\n6405 —Gates & Hillman Centers\nEmail swatanab@andrew.cmu.edu\n412-268-3687\nResearch Area\nNatural Language Processing and Computational Linguistics, Speech Processing\n\nPersonal Website https://sites.google.com/view/shinjiwatanabe?pli=1\n\nAlexander Waibel\nProfessor (On Leave), Language Technologies Institute\nContact\n205 —407 South Craig Street\nEmail waibel@cs.cmu.edu\n412-268-7676\nResearch Area\nMachine Learning, Machine Translation, Multimodal Computing and Interaction, Neural Networks, Speech Processing, Spoken Interfaces and Dialogue Processing, Spoken Language Translation\n\nBio\nDr. Alexander Waibel is a Professor of Computer Science at Carnegie Mellon University, Pittsburgh and at the Karlsruhe Institute of Technology, Germany. He is the director of the International Center for Advanced Communication Technologies (interACT). The Center works in a network with eight of the world’s top research institutions. The Center’s mission is to develop advanced machine learning algorithms to improve human-human and human-machine communication technologies.  Prof. Waibel and his team developed many statistical and neural network learning  algorithms that made such communication breakthroughs possible. Most notably, the “Time-Delay Neural Network” (1987) (the first “convolutional” neural network) now is at the heart of many of today’s AI technologies. System breakthroughs at Waibel’s lab included early multimodal interfaces, speech and language interfaces, the first speech translation system in Europe & USA (1990/1991), the first simultaneous lecture translation system (2005), and Jibbigo, the first commercial speech translator on a phone (2009).\n\nDr. Waibel founded and served as chairmen of C-STAR, the Consortium for Speech Translation Advanced Research in 1991. He directed many research programs in speech, translation, multimodal interfaces and machine learning in the US, Europe and Asia. He served as director of EU-Bridge (2012-2015) and CHIL (2004-2007), two large European multi-site Integrated Project initiatives on intelligent assistants and speech translation services. He also was co-director of IMMI, a joint venture between KIT, CNRS & RWTH.\n\nDr. Waibel is an IEEE Fellow and received many awards for his work on multilingual and multimodal communication  and translation. He published extensively (>750 publications, >25,000 citations, h-index 80) in the field and received/filed numerous patents. Waibel was elected to the National Academy of Sciences of Germany in 2017, and was named Honorary Senator of the Hochschulrektorenkonferenz (Representation of German Universities).\n\nDuring his career, Dr. Waibel founded and built ten successful companies. Following the acquisition of Jibbigo by Facebook, Waibel served as founding director of the Language Technology Group at FB. He also deployed speech translation technologies in humanitarian and disaster relief missions. His team recently deployed the first simultaneous interpretation service for lectures at Universities and interpretation tools at the European Parliament. \n\nEducation\nDr. Waibel received his BS, MS and PhD degrees at Massachusetts Institute of Technology and CMU, respectively.\nPersonal Website https://www.cs.cmu.edu/~ahw/\n\n\n'}
LLAMA-7B PREDICTED ANSWER=====
  Alexander Waibel focuses on Speech Processing in his research.
PROMPT=====
{'question': 'Name professors who have contributed to Computational AI?', 'context': 'Maarten Sap\nAssistant Professor, Language Technologies Institute\nContact\n6713 —Gates & Hillman Centers\nEmail msap2@andrew.cmu.edu\nResearch Area\nComputational Social Science, Conversational AI, Discourse and Pragmatics, Fairness and Ethics in Language Technology\n\nPersonal Website http://maartensap.com/\n'}
LLAMA-7B PREDICTED ANSWER=====
  Sure! Here is a list of some professors who have contributed to computational AI:
1. John McCarthy
2. Marvin Minsky
3. Alan Turing
4. Herbert Simon
5. Edward Feigenbaum
6. Roger Schank
7. Douglas Lenat
8. Terry Winograd
9. John Haugeland
10. Rodney Brooks
PROMPT=====
{'question': 'What paper introduces SPAE for multimodal generation with frozen LLMs?', 'context': 'List of 2023 Open Access papers by yonatan bisk are:\nSPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs\nHomeRobot: Open-Vocabulary Mobile Manipulation\nPlan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents\nMOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception\nReasoning about the Unseen for Efficient Outdoor Object Navigation\nThe Framework Tax: Disparities Between Inference Efficiency in Research and Deployment\nWebArena: A Realistic Web Environment for Building Autonomous Agents\nComputational Language Acquisition with Theory of Mind\n'}
LLAMA-7B PREDICTED ANSWER=====
  Sure! The paper that introduces SPAE for multimodal generation with frozen LLMs is "SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs" (2023).
PROMPT=====
{'question': 'Which 2023 paper by Yonatan Bisk focuses on open-vocabulary mobile manipulation?', 'context': 'List of 2023 Open Access papers by yonatan bisk are:\nSPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs\nHomeRobot: Open-Vocabulary Mobile Manipulation\nPlan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents\nMOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception\nReasoning about the Unseen for Efficient Outdoor Object Navigation\nThe Framework Tax: Disparities Between Inference Efficiency in Research and Deployment\nWebArena: A Realistic Web Environment for Building Autonomous Agents\nComputational Language Acquisition with Theory of Mind\n'}
LLAMA-7B PREDICTED ANSWER=====
  HomeRobot
PROMPT=====
{'question': "What is the title of Yonatan Bisk's work on learning multi-sensory object property representations?", 'context': 'List of 2023 Open Access papers by yonatan bisk are:\nSPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs\nHomeRobot: Open-Vocabulary Mobile Manipulation\nPlan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents\nMOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception\nReasoning about the Unseen for Efficient Outdoor Object Navigation\nThe Framework Tax: Disparities Between Inference Efficiency in Research and Deployment\nWebArena: A Realistic Web Environment for Building Autonomous Agents\nComputational Language Acquisition with Theory of Mind\n'}
LLAMA-7B PREDICTED ANSWER=====
  MOSAIC
PROMPT=====
{'question': 'Which paper by Jamie Callan discusses conversational search using random walks?', 'context': 'List of 2023 Open Access papers by jamie callan are:\nConversational Search with Random Walks over Entity Graphs\nKALE: Using a K-Sparse Projector for Lexical Expansion\nCSurF: Sparse Lexical Retrieval through Contextualized Surface Forms\nActive Retrieval Augmented Generation\nMulti-Objective Improvement of Android Applications\n'}
LLAMA-7B PREDICTED ANSWER=====
  Conversational Search with Random Walks over Entity Graphs
PROMPT=====
{'question': "What does KALE stand for in Jamie Callan's 2023 paper?", 'context': 'List of 2023 Open Access papers by jamie callan are:\nConversational Search with Random Walks over Entity Graphs\nKALE: Using a K-Sparse Projector for Lexical Expansion\nCSurF: Sparse Lexical Retrieval through Contextualized Surface Forms\nActive Retrieval Augmented Generation\nMulti-Objective Improvement of Android Applications\n'}
LLAMA-7B PREDICTED ANSWER=====
  KALE stands for "Using a K-Sparse Projector for Lexical Expansion."
PROMPT=====
{'question': 'Name the paper by Jamie Callan that focuses on sparse lexical retrieval.', 'context': 'List of 2023 Open Access papers by jamie callan are:\nConversational Search with Random Walks over Entity Graphs\nKALE: Using a K-Sparse Projector for Lexical Expansion\nCSurF: Sparse Lexical Retrieval through Contextualized Surface Forms\nActive Retrieval Augmented Generation\nMulti-Objective Improvement of Android Applications\n'}
LLAMA-7B PREDICTED ANSWER=====
  Sure! The paper by Jamie Callan that focuses on sparse lexical retrieval is "CSurF: Sparse Lexical Retrieval through Contextualized Surface Forms."
PROMPT=====
{'question': 'Which faculty member released 0 open access papers in 2023?', 'context': 'List of 2023 Open Access papers by ralf brown are: 0\n'}
LLAMA-7B PREDICTED ANSWER=====
  Ralf Brown did not release any open access papers in 2023.
PROMPT=====
{'question': 'What 2023 paper by Graham Neubig discusses few-shot clustering with LLMs?', 'context': "Faculty Name: graham neubig\nPaperid: 8e8a1489bf4d782d2435cdeb93f7d1f165747c63\nTitle: Large Language Models Enable Few-Shot Clustering\nYear: 2023\nAbstract: Unlike traditional unsupervised clustering, semi-supervised clustering allows users to provide meaningful structure to the data, which helps the clustering algorithm to match the user's intent. Existing approaches to semi-supervised clustering require a significant amount of feedback from an expert to improve the clusters. In this paper, we ask whether a large language model can amplify an expert's guidance to enable query-efficient, few-shot semi-supervised text clustering. We show that LLMs are surprisingly effective at improving clustering. We explore three stages where LLMs can be incorporated into clustering: before clustering (improving input features), during clustering (by providing constraints to the clusterer), and after clustering (using LLMs post-correction). We find incorporating LLMs in the first two stages can routinely provide significant improvements in cluster quality, and that LLMs enable a user to make trade-offs between cost and accuracy to produce desired clusters. We release our code and LLM prompts for the public to use.\nAuthors: Vijay Viswanathan, Kiril Gashteovski, Carolin (Haas) Lawrence, Tongshuang Sherry Wu, Graham Neubig\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is found that incorporating LLMs in the first two stages can routinely provide significant improvements in cluster quality, and that LLMs enable a user to make trade-offs between cost and accuracy to produce desired clusters.'}\nUrl: http://arxiv.org/pdf/2307.00524\n"}
LLAMA-7B PREDICTED ANSWER=====
  In their 2023 paper, "Large Language Models Enable Few-Shot Clustering," Graham Neubig and colleagues explore the potential of incorporating large language models (LLMs) into semi-supervised text clustering to improve cluster quality and enable query-efficient, few-shot clustering.
PROMPT=====
{'question': "Who are the co-authors of Eric Nyberg's 2023 paper on multilingual QA?", 'context': "Faculty Name: eric nyberg\nPaperid: 444737639aeea4e1e616509e368afb0bae8f89d6\nTitle: Language-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA\nYear: 2023\nAbstract: The DialDoc 2023 shared task has expanded the document-grounded dialogue task to encompass multiple languages, despite having limited annotated data. This paper assesses the effectiveness of both language-agnostic and language-aware paradigms for multilingual pre-trained transformer models in a bi-encoder-based dense passage retriever (DPR), concluding that the language-agnostic approach is superior. Additionally, the study investigates the impact of query rewriting techniques using large language models, such as ChatGPT, on multilingual, document-grounded question-answering systems. The experiments conducted demonstrate that, for the examples examined, query rewriting does not enhance performance compared to the original queries. This failure is due to topic switching in final dialogue turns and irrelevant topics being considered for query rewriting.\nAuthors: Srinivas Gowriraj, Soham Dinesh Tiwari, Mitali Potnis, Srijan Bansal, T. Mitamura, Eric Nyberg\nVenue: Workshop on Document-grounded Dialogue and Conversational Question Answering\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper assesses the effectiveness of both language-agnostic and language-aware paradigms for multilingual pre-trained transformer models in a bi-encoder-based dense passage retriever (DPR), concluding that the language-gnostic approach is superior.'}\nUrl: https://aclanthology.org/2023.dialdoc-1.11.pdf\n"}
LLAMA-7B PREDICTED ANSWER=====
  Srinivas Gowriraj, Soham Dinesh Tiwari, Mitali Potnis, Srijan Bansal, and Eric Nyberg.
PROMPT=====
{'question': "Where was Eric Nyberg's 2023 paper on language-agnostic transformers presented?", 'context': "Faculty Name: eric nyberg\nPaperid: 444737639aeea4e1e616509e368afb0bae8f89d6\nTitle: Language-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA\nYear: 2023\nAbstract: The DialDoc 2023 shared task has expanded the document-grounded dialogue task to encompass multiple languages, despite having limited annotated data. This paper assesses the effectiveness of both language-agnostic and language-aware paradigms for multilingual pre-trained transformer models in a bi-encoder-based dense passage retriever (DPR), concluding that the language-agnostic approach is superior. Additionally, the study investigates the impact of query rewriting techniques using large language models, such as ChatGPT, on multilingual, document-grounded question-answering systems. The experiments conducted demonstrate that, for the examples examined, query rewriting does not enhance performance compared to the original queries. This failure is due to topic switching in final dialogue turns and irrelevant topics being considered for query rewriting.\nAuthors: Srinivas Gowriraj, Soham Dinesh Tiwari, Mitali Potnis, Srijan Bansal, T. Mitamura, Eric Nyberg\nVenue: Workshop on Document-grounded Dialogue and Conversational Question Answering\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper assesses the effectiveness of both language-agnostic and language-aware paradigms for multilingual pre-trained transformer models in a bi-encoder-based dense passage retriever (DPR), concluding that the language-gnostic approach is superior.'}\nUrl: https://aclanthology.org/2023.dialdoc-1.11.pdf\n"}
LLAMA-7B PREDICTED ANSWER=====
  The paper was presented at the Workshop on Document-grounded Dialogue and Conversational Question Answering in 2023.
PROMPT=====
{'question': "What is the TLDR of Nyberg's 2023 paper on multilingual document-grounded QA?", 'context': "Faculty Name: eric nyberg\nPaperid: 444737639aeea4e1e616509e368afb0bae8f89d6\nTitle: Language-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA\nYear: 2023\nAbstract: The DialDoc 2023 shared task has expanded the document-grounded dialogue task to encompass multiple languages, despite having limited annotated data. This paper assesses the effectiveness of both language-agnostic and language-aware paradigms for multilingual pre-trained transformer models in a bi-encoder-based dense passage retriever (DPR), concluding that the language-agnostic approach is superior. Additionally, the study investigates the impact of query rewriting techniques using large language models, such as ChatGPT, on multilingual, document-grounded question-answering systems. The experiments conducted demonstrate that, for the examples examined, query rewriting does not enhance performance compared to the original queries. This failure is due to topic switching in final dialogue turns and irrelevant topics being considered for query rewriting.\nAuthors: Srinivas Gowriraj, Soham Dinesh Tiwari, Mitali Potnis, Srijan Bansal, T. Mitamura, Eric Nyberg\nVenue: Workshop on Document-grounded Dialogue and Conversational Question Answering\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper assesses the effectiveness of both language-agnostic and language-aware paradigms for multilingual pre-trained transformer models in a bi-encoder-based dense passage retriever (DPR), concluding that the language-gnostic approach is superior.'}\nUrl: https://aclanthology.org/2023.dialdoc-1.11.pdf\n"}
LLAMA-7B PREDICTED ANSWER=====
  The language-agnostic transformer model is superior for multilingual document-grounded QA.
PROMPT=====
{'question': "Which grants supported Fernando Diaz's 2023 study on pneumococcal vaccines?", 'context': "Faculty Name: fernando diaz\nPaperid: a76e7e394112a26116446a2920467a2702de5f56\nTitle: Pre-vaccination CD56 dimCD16 +NK cell abundance and T h1/T h17 ratio predict responsiveness to conjugated pneumococcal vaccine in older adults\nYear: 2023\nAbstract: \n Older adults are at high risk of morbidity and mortality from Streptococcus pneumoniae (pneumococcus) infections. There are two available vaccines for pneumococcus: T-cell-independent capsular polysaccharide Pneumovax and T-cell-dependent conjugated Prevnar. However, how older adults respond to these vaccines at the cellular level and whether there are baseline predictors for responsiveness, is not known. To address this, we recruited older adults (60+ yrs), who are vaccinated with Prevnar (n=19) or Pneumovax (n=20). Vaccine responsiveness was quantified using opsonophagocytic assays, which revealed that both vaccines induce strong responses. Interestingly, sex was associated with Prevnar responses, where women mounted stronger responses than men. Pre-vaccination flow cytometry data showed that Th1 cells positively, Th17 cells negatively correlated with Prevnar responses. Furthermore, bulk RNA-seq data from PBMCs showed that baseline expression levels of cytotoxic genes (NCAM1, GNLY, PRF1) are negatively associated with Prevnar responses. scRNA-seq data from top and bottom responders showed that this cytotoxicity signature stems from CD56 dimCD16 +NK cells, where having more of these cells are detrimental to responses. Interestingly, women had significantly higher Th1, lower Th17 and lower CD16+ NK cells compared to men, which explains their stronger Prevnar responses. This is the first study to uncover older adults’ responses to two pneumococcal vaccines; we uncovered an activated immune phenotype of Th and NK cell subsets that impedes responses to Prevnar. Interestingly, this phenotype only affected adjuvanted vaccine responses, providing an opportunity for precision vaccinology for pneumococcus disease.\n Supported by grants from National Institute of Health (R35 GM124922, R01 AG052608) and JAX cancer center (JAX-CC).\nAuthors: S. Ravichandran, F. E. Díaz, Onur E Karakaslar, R. Marches, Robert J. Rossi, M. Nahm, D. Chaussabel, G. Kuchel, J. Banchereau, D. Ucar\nVenue: Journal of Immunology\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This is the first study to uncover older adults’ responses to two pneumococcal vaccines; an activated immune phenotype of Th and NK cell subsets that impedes responses to Prevnar is uncovered.'}\nUrl: https://journals.aai.org/jimmunol/article-pdf/210/1_Supplement/252.03/1632514/252_03.pdf\n"}
LLAMA-7B PREDICTED ANSWER=====
  The following grants supported Fernando Diaz's 2023 study on pneumococcal vaccines:
• National Institute of Health (R35 GM124922, R01 AG052608)
• JAX cancer center (JAX-CC)
PROMPT=====
{'question': "What significance does Fernando Diaz's 2023 paper hold regarding pneumococcal vaccines?", 'context': "Faculty Name: fernando diaz\nPaperid: a76e7e394112a26116446a2920467a2702de5f56\nTitle: Pre-vaccination CD56 dimCD16 +NK cell abundance and T h1/T h17 ratio predict responsiveness to conjugated pneumococcal vaccine in older adults\nYear: 2023\nAbstract: \n Older adults are at high risk of morbidity and mortality from Streptococcus pneumoniae (pneumococcus) infections. There are two available vaccines for pneumococcus: T-cell-independent capsular polysaccharide Pneumovax and T-cell-dependent conjugated Prevnar. However, how older adults respond to these vaccines at the cellular level and whether there are baseline predictors for responsiveness, is not known. To address this, we recruited older adults (60+ yrs), who are vaccinated with Prevnar (n=19) or Pneumovax (n=20). Vaccine responsiveness was quantified using opsonophagocytic assays, which revealed that both vaccines induce strong responses. Interestingly, sex was associated with Prevnar responses, where women mounted stronger responses than men. Pre-vaccination flow cytometry data showed that Th1 cells positively, Th17 cells negatively correlated with Prevnar responses. Furthermore, bulk RNA-seq data from PBMCs showed that baseline expression levels of cytotoxic genes (NCAM1, GNLY, PRF1) are negatively associated with Prevnar responses. scRNA-seq data from top and bottom responders showed that this cytotoxicity signature stems from CD56 dimCD16 +NK cells, where having more of these cells are detrimental to responses. Interestingly, women had significantly higher Th1, lower Th17 and lower CD16+ NK cells compared to men, which explains their stronger Prevnar responses. This is the first study to uncover older adults’ responses to two pneumococcal vaccines; we uncovered an activated immune phenotype of Th and NK cell subsets that impedes responses to Prevnar. Interestingly, this phenotype only affected adjuvanted vaccine responses, providing an opportunity for precision vaccinology for pneumococcus disease.\n Supported by grants from National Institute of Health (R35 GM124922, R01 AG052608) and JAX cancer center (JAX-CC).\nAuthors: S. Ravichandran, F. E. Díaz, Onur E Karakaslar, R. Marches, Robert J. Rossi, M. Nahm, D. Chaussabel, G. Kuchel, J. Banchereau, D. Ucar\nVenue: Journal of Immunology\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This is the first study to uncover older adults’ responses to two pneumococcal vaccines; an activated immune phenotype of Th and NK cell subsets that impedes responses to Prevnar is uncovered.'}\nUrl: https://journals.aai.org/jimmunol/article-pdf/210/1_Supplement/252.03/1632514/252_03.pdf\n"}
LLAMA-7B PREDICTED ANSWER=====
  The study by Fernando Diaz and colleagues (2023) investigates the cellular immune response to two pneumococcal vaccines (Prevnar and Pneumovax) in older adults. The study found that pre-vaccination CD56 dimCD16+ NK cell abundance and T helper 1 (Th1)/T helper 17 (Th17) ratio predict responsiveness to conjugated pneumococcal vaccine in older adults. The study also found that women mounted stronger responses than men, and that baseline expression levels of cytotoxic genes (NCAM1, GNLY, PRF1) are negatively associated with Prevnar responses. The study provides insights into the cellular immune mechanisms underlying pneumococcal vaccine responsiveness and may inform precision vaccinology strategies for older adults.
PROMPT=====
{'question': "What predicts vaccine responsiveness in older adults according to Fernando Diaz's 2023 study?", 'context': "Faculty Name: fernando diaz\nPaperid: a76e7e394112a26116446a2920467a2702de5f56\nTitle: Pre-vaccination CD56 dimCD16 +NK cell abundance and T h1/T h17 ratio predict responsiveness to conjugated pneumococcal vaccine in older adults\nYear: 2023\nAbstract: \n Older adults are at high risk of morbidity and mortality from Streptococcus pneumoniae (pneumococcus) infections. There are two available vaccines for pneumococcus: T-cell-independent capsular polysaccharide Pneumovax and T-cell-dependent conjugated Prevnar. However, how older adults respond to these vaccines at the cellular level and whether there are baseline predictors for responsiveness, is not known. To address this, we recruited older adults (60+ yrs), who are vaccinated with Prevnar (n=19) or Pneumovax (n=20). Vaccine responsiveness was quantified using opsonophagocytic assays, which revealed that both vaccines induce strong responses. Interestingly, sex was associated with Prevnar responses, where women mounted stronger responses than men. Pre-vaccination flow cytometry data showed that Th1 cells positively, Th17 cells negatively correlated with Prevnar responses. Furthermore, bulk RNA-seq data from PBMCs showed that baseline expression levels of cytotoxic genes (NCAM1, GNLY, PRF1) are negatively associated with Prevnar responses. scRNA-seq data from top and bottom responders showed that this cytotoxicity signature stems from CD56 dimCD16 +NK cells, where having more of these cells are detrimental to responses. Interestingly, women had significantly higher Th1, lower Th17 and lower CD16+ NK cells compared to men, which explains their stronger Prevnar responses. This is the first study to uncover older adults’ responses to two pneumococcal vaccines; we uncovered an activated immune phenotype of Th and NK cell subsets that impedes responses to Prevnar. Interestingly, this phenotype only affected adjuvanted vaccine responses, providing an opportunity for precision vaccinology for pneumococcus disease.\n Supported by grants from National Institute of Health (R35 GM124922, R01 AG052608) and JAX cancer center (JAX-CC).\nAuthors: S. Ravichandran, F. E. Díaz, Onur E Karakaslar, R. Marches, Robert J. Rossi, M. Nahm, D. Chaussabel, G. Kuchel, J. Banchereau, D. Ucar\nVenue: Journal of Immunology\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This is the first study to uncover older adults’ responses to two pneumococcal vaccines; an activated immune phenotype of Th and NK cell subsets that impedes responses to Prevnar is uncovered.'}\nUrl: https://journals.aai.org/jimmunol/article-pdf/210/1_Supplement/252.03/1632514/252_03.pdf\n"}
LLAMA-7B PREDICTED ANSWER=====
  According to Fernando Diaz's 2023 study, pre-vaccination CD56 dimCD16+ NK cell abundance and T helper 1/T helper 17 (Th1/Th17) ratio predict responsiveness to conjugated pneumococcal vaccine in older adults.
