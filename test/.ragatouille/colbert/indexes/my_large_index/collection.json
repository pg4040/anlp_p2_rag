[
  "Faculty Name: alexander hauptmann\nMetadata:\nPaperid: 2107b867cb8f8afa30a9a940288d7c8b657f8aa5\nTitle: Zero-Shot and Few-Shot Stance Detection on Varied Topics via Conditional Generation\nYear: 2023\nAbstract: Zero-shot and few-shot stance detection identify the polarity of text with regard to a certain target when we have only limited or no training resources for the target. Previous work generally formulates the problem into a classification setting, ignoring the potential use of label text. In this paper, we instead utilize a conditional generation framework and formulate the problem as denoising from partially-filled templates, which can better utilize the semantics among input, label, and target texts. We further propose to jointly train an auxiliary task, target prediction, and to incorporate manually constructed incorrect samples with unlikelihood training to improve the representations for both target and label texts. We also verify the effectiveness of target-related Wikipedia knowledge with the generation framework. Experiments show that our proposed method significantly outperforms several strong baselines on VAST, and achieves new state-of-the-art performance.",
  "We also verify the effectiveness of target-related Wikipedia knowledge with the generation framework. Experiments show that our proposed method significantly outperforms several strong baselines on VAST, and achieves new state-of-the-art performance.\nAuthors: Haoyang Wen, A. Hauptmann\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper utilizes a conditional generation framework and formulates the zero-shot and few-shot stance detection problem as denoising from partially-filled templates, which can better utilize the semantics among input, label, and target texts.'}",
  "Faculty Name: alexander hauptmann\nMetadata:\nPaperid: 376f494126d1ea4f571ea0263c43ac2b6331800a\nTitle: SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs\nYear: 2023\nAbstract: In this work, we introduce Semantic Pyramid AutoEncoder (SPAE) for enabling frozen LLMs to perform both understanding and generation tasks involving non-linguistic modalities such as images or videos. SPAE converts between raw pixels and interpretable lexical tokens (or words) extracted from the LLM's vocabulary. The resulting tokens capture both the semantic meaning and the fine-grained details needed for visual reconstruction, effectively translating the visual content into a language comprehensible to the LLM, and empowering it to perform a wide array of multimodal tasks. Our approach is validated through in-context learning experiments with frozen PaLM 2 and GPT 3.5 on a diverse set of image understanding and generation tasks. Our method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%.",
  "Our method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%.\nAuthors: Lijun Yu, Yong Cheng, Zhiruo Wang, Vivek Kumar, Wolfgang Macherey, Yanping Huang, David A. Ross, Irfan Essa, Yonatan Bisk, Ming Yang, K. Murphy, A. Hauptmann, Lu Jiang\nVenue: Neural Information Processing Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%.'}",
  "Faculty Name: alexander hauptmann\nMetadata:\nPaperid: 405e3910e06c9efe7e660b8697bcb4bab4e92f48\nTitle: STMT: A Spatial-Temporal Mesh Transformer for MoCap-Based Action Recognition\nYear: 2023\nAbstract: We study the problem of human action recognition using motion capture (MoCap) sequences. Unlike existing techniques that take multiple manual steps to derive standard-ized skeleton representations as model input, we propose a novel Spatial-Temporal Mesh Transformer (STMT) to directly model the mesh sequences. The model uses a hierarchical transformer with intra-frame off-set attention and inter-frame self-attention. The attention mechanism allows the model to freely attend between any two vertex patches to learn nonlocal relationships in the spatial-temporal domain. Masked vertex modeling and future frame prediction are used as two self-supervised tasks to fully activate the bi-directional and auto-regressive attention in our hierarchical transformer. The proposed method achieves state-of-the-art performance compared to skeleton-based and point-cloud-based models on common MoCap benchmarks. Code is available at https://github.com/zgzxy001/STMT.",
  "The proposed method achieves state-of-the-art performance compared to skeleton-based and point-cloud-based models on common MoCap benchmarks. Code is available at https://github.com/zgzxy001/STMT.\nAuthors: Xiaoyu Zhu, Po-Yao (Bernie) Huang, Junwei Liang, Celso M. de Melo, A. Hauptmann\nVenue: Computer Vision and Pattern Recognition\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A novel Spatial-Temporal Mesh Transformer (STMT) is proposed to directly model the mesh sequences using motion capture sequences to achieve state-of-the-art performance compared to skeleton-based and point-cloud-based models on common MoCap benchmarks.'}",
  "Faculty Name: alexander hauptmann\nMetadata:\nPaperid: 72cce47fd053bf916314d89a8174726c58c05e02\nTitle: Towards Open-Domain Twitter User Profile Inference\nYear: 2023\nAbstract: ,\nAuthors: Haoyang Wen, Zhenxin Xiao, E. Hovy, Alexander Hauptmann\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': None}",
  "Faculty Name: alexander hauptmann\nMetadata:\nPaperid: 8ccda6de0223bcd897d5dc0efc8f33222a899d0d\nTitle: DocumentNet: Bridging the Data Gap in Document Pre-training\nYear: 2023\nAbstract: Document understanding tasks, in particular, Visually-rich Document Entity Retrieval (VDER), have gained significant attention in recent years thanks to their broad applications in enterprise AI. However, publicly available data have been scarce for these tasks due to strict privacy constraints and high annotation costs. To make things worse, the non-overlapping entity spaces from different datasets hinder the knowledge transfer between document types. In this paper, we propose a method to collect massive-scale and weakly labeled data from the web to benefit the training of VDER models. The collected dataset, named DocumentNet, does not depend on specific document types or entity sets, making it universally applicable to all VDER tasks. The current DocumentNet consists of 30M documents spanning nearly 400 document types organized in a four-level ontology.",
  "The collected dataset, named DocumentNet, does not depend on specific document types or entity sets, making it universally applicable to all VDER tasks. The current DocumentNet consists of 30M documents spanning nearly 400 document types organized in a four-level ontology. Experiments on a set of broadly adopted VDER tasks show significant improvements when DocumentNet is incorporated into the pre-training for both classic and few-shot learning settings. With the recent emergence of large language models (LLMs), DocumentNet provides a large data source to extend their multi-modal capabilities for VDER.\nAuthors: Lijun Yu, Jin Miao, Xiaoyu Sun, Jiayi Chen, A. Hauptmann, H. Dai, Wei Wei\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper proposes a method to collect massive-scale and weakly labeled data from the web to benefit the training of VDER models, and provides a large data source to extend their multi-modal capabilities for VDER.'}",
  "Faculty Name: alexander hauptmann\nMetadata:\nPaperid: 985f0c89c5a607742ec43c1fdc2cbfe54541cbad\nTitle: Language Model Beats Diffusion - Tokenizer is Key to Visual Generation\nYear: 2023\nAbstract: While Large Language Models (LLMs) are the dominant models for generative tasks in language, they do not perform as well as diffusion models on image and video generation. To effectively use LLMs for visual generation, one crucial component is the visual tokenizer that maps pixel-space inputs to discrete tokens appropriate for LLM learning. In this paper, we introduce MAGVIT-v2, a video tokenizer designed to generate concise and expressive tokens for both videos and images using a common token vocabulary. Equipped with this new tokenizer, we show that LLMs outperform diffusion models on standard image and video generation benchmarks including ImageNet and Kinetics. In addition, we demonstrate that our tokenizer surpasses the previously top-performing video tokenizer on two more tasks: (1) video compression comparable to the next-generation video codec (VCC) according to human evaluations, and (2) learning effective representations for action recognition tasks.",
  "In addition, we demonstrate that our tokenizer surpasses the previously top-performing video tokenizer on two more tasks: (1) video compression comparable to the next-generation video codec (VCC) according to human evaluations, and (2) learning effective representations for action recognition tasks.\nAuthors: Lijun Yu, Jos'e Lezama, Nitesh B. Gundavarapu, Luca Versari, Kihyuk Sohn, David C. Minnen, Yong Cheng, Agrim Gupta, Xiuye Gu, Alexander G. Hauptmann, Boqing Gong, Ming-Hsuan Yang, Irfan Essa, David A. Ross, Lu Jiang\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': None}",
  "Faculty Name: alexander hauptmann\nMetadata:\nPaperid: e371d10dd65c8bb25375f3c09d1c0cac777cca65\nTitle: Hyperbolic vs Euclidean Embeddings in Few-Shot Learning: Two Sides of the Same Coin\nYear: 2023\nAbstract: Recent research in representation learning has shown that hierarchical data lends itself to low-dimensional and highly informative representations in hyperbolic space. However, even if hyperbolic embeddings have gathered attention in image recognition, their optimization is prone to numerical hurdles. Further, it remains unclear which applications stand to benefit the most from the implicit bias imposed by hyperbolicity, when compared to traditional Euclidean features. In this paper, we focus on prototypical hyperbolic neural networks. In particular, the tendency of hyperbolic embeddings to converge to the boundary of the Poincar\\'e ball in high dimensions and the effect this has on few-shot classification. We show that the best few-shot results are attained for hyperbolic embeddings at a common hyperbolic radius.",
  "In particular, the tendency of hyperbolic embeddings to converge to the boundary of the Poincar\\'e ball in high dimensions and the effect this has on few-shot classification. We show that the best few-shot results are attained for hyperbolic embeddings at a common hyperbolic radius. In contrast to prior benchmark results, we demonstrate that better performance can be achieved by a fixed-radius encoder equipped with the Euclidean metric, regardless of the embedding dimension.\nAuthors: Gabriel Moreira, Manuel Marques, J. Costeira, Alexander Hauptmann\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is demonstrated that better performance can be achieved by a fixed-radius encoder equipped with the Euclidean metric, regardless of the embedding dimension, and that the best few-shot results are attained for hyperbolic embeddings at a commonhyperbolic radius.'}",
  "List of 2023 Open Access papers by alexander hauptmann are:\nTowards Open-Domain Twitter User Profile Inference\nZero-Shot and Few-Shot Stance Detection on Varied Topics via Conditional Generation\nSPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs\nSTMT: A Spatial-Temporal Mesh Transformer for MoCap-Based Action Recognition\nDocumentNet: Bridging the Data Gap in Document Pre-training\nLanguage Model Beats Diffusion - Tokenizer is Key to Visual Generation\nHyperbolic vs Euclidean Embeddings in Few-Shot Learning: Two Sides of the Same Coin",
  "Faculty Name: alexander rudnicky\nMetadata:\nPaperid: 06a8f2e3c4266196b008851f1ec7ef9f340809da\nTitle: Advancing Regular Language Reasoning in Linear Recurrent Neural Networks\nYear: 2023\nAbstract: In recent studies, linear recurrent neural networks (LRNNs) have achieved Transformer-level performance in natural language modeling and long-range modeling while offering rapid parallel training and constant inference costs. With the resurged interest in LRNNs, we study whether they can learn the hidden rules in training sequences, such as the grammatical structures of regular language. We theoretically analyze some existing LRNNs and discover their limitations on regular language. Motivated by the analysis, we propose a new LRNN equipped with a block-diagonal and input-dependent transition matrix. Experiments suggest that the proposed model is the only LRNN that can perform length extrapolation on regular language tasks such as Sum, Even Pair, and Modular Arithmetic.",
  "Motivated by the analysis, we propose a new LRNN equipped with a block-diagonal and input-dependent transition matrix. Experiments suggest that the proposed model is the only LRNN that can perform length extrapolation on regular language tasks such as Sum, Even Pair, and Modular Arithmetic.\nAuthors: Ting-Han Fan, Ta-Chung Chi, Alexander I. Rudnicky\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work theoretically analyze some existing LRNNs and proposes a new LRNN equipped with a block-diagonal and input-dependent transition matrix that is the only LRNN that can perform length extrapolation on regular language tasks such as Sum, Even Pair, and Modular Arithmetic.'}",
  "Faculty Name: alexander rudnicky\nMetadata:\nPaperid: 161bf3f0705ef8e088f53b383363338daac9af44\nTitle: Latent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings\nYear: 2023\nAbstract: The use of positional embeddings in transformer language models is widely accepted. However, recent research has called into question the necessity of such embeddings. We further extend this inquiry by demonstrating that a randomly initialized and frozen transformer language model, devoid of positional embeddings, inherently encodes strong positional information through the shrinkage of self-attention variance. To quantify this variance, we derive the underlying distribution of each step within a transformer layer. Through empirical validation using a fully pretrained model, we show that the variance shrinkage effect still persists after extensive gradient updates. Our findings serve to justify the decision to discard positional embeddings and thus facilitate more efficient pretraining of transformer language models.",
  "Through empirical validation using a fully pretrained model, we show that the variance shrinkage effect still persists after extensive gradient updates. Our findings serve to justify the decision to discard positional embeddings and thus facilitate more efficient pretraining of transformer language models.\nAuthors: Ta-Chung Chi, Ting-Han Fan, Li-Wei Chen, A. Rudnicky, P. Ramadge\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work demonstrates that a randomly initialized and frozen transformer language model, devoid of positional embeddings, inherently encodes strong positional information through the shrinkage of self-attention variance, and derives the underlying distribution of each step within a transformer layer.'}",
  "Faculty Name: alexander rudnicky\nMetadata:\nPaperid: 2670612b5e11297cd9b98f4d7ff796725f77fe35\nTitle: Structured Dialogue Discourse Parsing\nYear: 2023\nAbstract: Dialogue discourse parsing aims to uncover the internal structure of a multi-participant conversation by finding all the discourse links and corresponding relations. Previous work either treats this task as a series of independent multiple-choice problems, in which the link existence and relations are decoded separately, or the encoding is restricted to only local interaction, ignoring the holistic structural information. In contrast, we propose a principled method that improves upon previous work from two perspectives: encoding and decoding. From the encoding side, we perform structured encoding on the adjacency matrix followed by the matrix-tree learning algorithm, where all discourse links and relations in the dialogue are jointly optimized based on latent tree-level distribution. From the decoding side, we perform structured inference using the modified Chiu-Liu-Edmonds algorithm, which explicitly generates the labeled multi-root non-projective spanning tree that best captures the discourse structure.",
  "From the decoding side, we perform structured inference using the modified Chiu-Liu-Edmonds algorithm, which explicitly generates the labeled multi-root non-projective spanning tree that best captures the discourse structure. In addition, unlike in previous work, we do not rely on hand-crafted features; this improves the model\u2019s robustness. Experiments show that our method achieves new state-of-the-art, surpassing the previous model by 2.3 on STAC and 1.5 on Molweni (F1 scores).\nAuthors: Ta-Chung Chi, Alexander I. Rudnicky\nVenue: SIGDIAL Conferences\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes a principled method that improves upon previous work from two perspectives: encoding and decoding and achieves new state-of-the-art results, surpassing the previous model by 2.3 on STAC and 1.5 on Molweni (F1 scores).'}",
  "Faculty Name: alexander rudnicky\nMetadata:\nPaperid: 465ec2212d865e875e64638b3dd1ecaac21c5ddd\nTitle: Transformer Working Memory Enables Regular Language Reasoning and Natural Language Length Extrapolation\nYear: 2023\nAbstract: Unlike recurrent models, conventional wisdom has it that Transformers cannot perfectly model regular languages. Inspired by the notion of working memory, we propose a new Transformer variant named RegularGPT. With its novel combination of Weight-Sharing, Adaptive-Depth, and Sliding-Dilated-Attention, RegularGPT constructs working memory along the depth dimension, thereby enabling efficient and successful modeling of regular languages such as PARITY. We further test RegularGPT on the task of natural language length extrapolation and surprisingly find that it rediscovers the local windowed attention effect deemed necessary in prior work for length extrapolation.",
  "We further test RegularGPT on the task of natural language length extrapolation and surprisingly find that it rediscovers the local windowed attention effect deemed necessary in prior work for length extrapolation.\nAuthors: Ta-Chung Chi, Ting-Han Fan, A. Rudnicky, P. Ramadge\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Inspired by the notion of working memory, a new Transformer variant named RegularGPT is proposed, which constructs working memory along the depth dimension, thereby enabling efficient and successful modeling of regular languages such as PARITY.'}",
  "Faculty Name: alexander rudnicky\nMetadata:\nPaperid: 4b8d3ede673ddeab9dfb5184da6b748d7a526754\nTitle: A Vector Quantized Approach for Text to Speech Synthesis on Real-World Spontaneous Speech\nYear: 2023\nAbstract: Recent Text-to-Speech (TTS) systems trained on reading or acted corpora have achieved near human-level naturalness. The diversity of human speech, however, often goes beyond the coverage of these corpora. We believe the ability to handle such diversity is crucial for AI systems to achieve human-level communication. Our work explores the use of more abundant real-world data for building speech synthesizers. We train TTS systems using real-world speech from YouTube and podcasts. We observe the mismatch between training and inference alignments in mel-spectrogram based autoregressive models, leading to unintelligible synthesis, and demonstrate that learned discrete codes within multiple code groups effectively resolves this issue. We introduce our MQTTS system whose architecture is designed for multiple code generation and monotonic alignment, along with the use of a clean silence prompt to improve synthesis quality.",
  "We introduce our MQTTS system whose architecture is designed for multiple code generation and monotonic alignment, along with the use of a clean silence prompt to improve synthesis quality. We conduct ablation analyses to identify the efficacy of our methods. We show that MQTTS outperforms existing TTS systems in several objective and subjective measures.\nAuthors: Li-Wei Chen, Shinji Watanabe, Alexander I. Rudnicky\nVenue: AAAI Conference on Artificial Intelligence\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work introduces the MQTTS system, a Text-to-Speech system whose architecture is designed for multiple code generation and monotonic alignment, along with the use of a clean silence prompt to improve synthesis quality, and shows that MqTTS outperforms existing TTS systems in several objective and subjective measures.'}",
  "Faculty Name: alexander rudnicky\nMetadata:\nPaperid: 9799c17fd287bb9e8d231fe032c6dbf9c0c9d675\nTitle: Overview of Robust and Multilingual Automatic Evaluation Metrics\n\nfor Open-Domain Dialogue Systems at DSTC 11 Track 4\nYear: 2023\nAbstract: The advent and fast development of neural networks have revolutionized the research on dialogue systems and subsequently have triggered various challenges regarding their automatic evaluation. Automatic evaluation of open-domain dialogue systems as an open challenge has been the center of the attention of many researchers. Despite the consistent efforts to improve automatic metrics\u2019 correlations with human evaluation, there have been very few attempts to assess their robustness over multiple domains and dimensions. Also, their focus is mainly on the English language. All of these challenges prompt the development of automatic evaluation metrics that are reliable in various domains, dimensions, and languages. This track in the 11th Dialogue System Technology Challenge (DSTC11) is part of the ongoing effort to promote robust and multilingual automatic evaluation metrics. This article describes the datasets and baselines provided to participants and discusses the submission and result details of the two proposed subtasks.",
  "This track in the 11th Dialogue System Technology Challenge (DSTC11) is part of the ongoing effort to promote robust and multilingual automatic evaluation metrics. This article describes the datasets and baselines provided to participants and discusses the submission and result details of the two proposed subtasks.\nAuthors: Mario Rodr'iguez-Cantelar, Chen Zhang, Chengguang Tang, Ke Shi, Sarik Ghazarian, Jo\u00e3o Sedoc, L. F. D\u2019Haro, Alexander I. Rudnicky\nVenue: DSTC\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The datasets and baselines provided to participants are described and the submission and result details of the two proposed subtasks are discussed, which promote robust and multilingual automatic evaluation metrics.'}",
  "Faculty Name: alexander rudnicky\nMetadata:\nPaperid: f743324682d5d50db9b114fa60b908f09c10c9a0\nTitle: Learning to Ask Questions for Zero-shot Dialogue State Tracking\nYear: 2023\nAbstract: We present a method for performing zero-shot Dialogue State Tracking (DST) by casting the task as a learning-to-ask-questions framework. The framework learns to pair the best question generation (QG) strategy with in-domain question answering (QA) methods to extract slot values from a dialogue without any human intervention. A novel self-supervised QA pretraining step using in-domain data is essential to learn the structure without requiring any slot-filling annotations. Moreover, we show that QG methods need to be aligned with the same grammatical person used in the dialogue. Empirical evaluation on the MultiWOZ 2.1 dataset demonstrates that our approach, when used alongside robust QA models, outperforms existing zero-shot methods in the challenging task of zero-shot cross domain adaptation-given a comparable amount of domain knowledge during data creation.",
  "Empirical evaluation on the MultiWOZ 2.1 dataset demonstrates that our approach, when used alongside robust QA models, outperforms existing zero-shot methods in the challenging task of zero-shot cross domain adaptation-given a comparable amount of domain knowledge during data creation. Finally, we analyze the impact of the types of questions used, and demonstrate that the algorithmic approach outperforms template-based question generation.\nAuthors: Diogo Tavares, David Semedo, Alexander I. Rudnicky, Jo\u00e3o Magalh\u00e3es\nVenue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work presents a method for performing zero-shot Dialogue State Tracking by casting the task as a learning-to-ask-questions framework that outperforms template-based question generation and shows that QG methods need to be aligned with the same grammatical person used in the dialogue.'}",
  "List of 2023 Open Access papers by alexander rudnicky are:\nAdvancing Regular Language Reasoning in Linear Recurrent Neural Networks\nStructured Dialogue Discourse Parsing\nA Vector Quantized Approach for Text to Speech Synthesis on Real-World Spontaneous Speech\nOverview of Robust and Multilingual Automatic Evaluation Metrics\n\nfor Open-Domain Dialogue Systems at DSTC 11 Track 4\nLearning to Ask Questions for Zero-shot Dialogue State Tracking\nLatent Positional Information is in the Self-Attention Variance of Transformer Language Models Without Positional Embeddings\nTransformer Working Memory Enables Regular Language Reasoning and Natural Language Length Extrapolation",
  "Faculty Name: alexander waibel\nMetadata:\nPaperid: 100eb82862a66e264686d015934c97c54bdadb4f\nTitle: SYNTACC : Synthesizing Multi-Accent Speech By Weight Factorization\nYear: 2023\nAbstract: Conventional multi-speaker text-to-speech synthesis (TTS) is known to be capable of synthesizing speech for multiple voices, yet it cannot generate speech in different accents. This limitation has motivated us to develop SYNTACC (Synthesizing speech with accents) which adapts conventional multi-speaker TTS to produce multi-accent speech. Our method uses the YourTTS model and involves a novel multi-accent training mechanism. The method works by decomposing each weight matrix into a shared component and an accent-dependent component, with the former being initialized by the pretrained multi-speaker TTS model and the latter being factorized into vectors using rank-1 matrices to reduce the number of training parameters per accent. This weight factorization method proves to be effective in fine-tuning the SYNTACC on multi-accent data sets in a low-resource condition.",
  "This weight factorization method proves to be effective in fine-tuning the SYNTACC on multi-accent data sets in a low-resource condition. Our SYNTACC model eventually allows speech synthesis in not only different voices but also in different accents.\nAuthors: Tuan-Nam Nguyen, Ngoc-Quan Pham, A. Waibel\nVenue: IEEE International Conference on Acoustics, Speech, and Signal Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The SYNTACC model eventually allows speech synthesis in not only different voices but also in different accents, and the weight factorization method proves to be effective in fine-tuning the SYNT ACC on multi-accent data sets in a low-resource condition.'}",
  "Faculty Name: alexander waibel\nMetadata:\nPaperid: 610d9958390ab83515d0d81e19f8e5264faf8e9b\nTitle: KIT\u2019s Multilingual Speech Translation System for IWSLT 2023\nYear: 2023\nAbstract: Many existing speech translation benchmarks focus on native-English speech in high-quality recording conditions, which often do not match the conditions in real-life use-cases. In this paper, we describe our speech translation system for the multilingual track of IWSLT 2023, which focuses on the translation of scientific conference talks. The test condition features accented input speech and terminology-dense contents. The tasks requires translation into 10 languages of varying amounts of resources. In absence of training data from the target domain, we use a retrieval-based approach (kNN-MT) for effective adaptation (+0.8 BLEU for speech translation). We also use adapters to easily integrate incremental training data from data augmentation, and show that it matches the performance of re-training. We observe that cascaded systems are more easily adaptable towards specific target domains, due to their separate modules.",
  "We also use adapters to easily integrate incremental training data from data augmentation, and show that it matches the performance of re-training. We observe that cascaded systems are more easily adaptable towards specific target domains, due to their separate modules. Our cascaded speech system outperforms its end-to-end counterpart on scientific talk translation, although their performance remains similar on TED talks.\nAuthors: Danni Liu, T. Nguyen, Sai Koneru, Enes Yavuz Ugan, Ngoc-Quan Pham, Tuan-Nam Nguyen, Tu Anh Dinh, Carlos Mullov, A. Waibel, J. Niehues\nVenue: International Workshop on Spoken Language Translation\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper describes the speech translation system for the multilingual track of IWSLT 2023, which focuses on the translation of scientific conference talks, and observes that cascaded systems are more easily adaptable towards specific target domains, due to their separate modules.'}",
  "Faculty Name: alexander waibel\nMetadata:\nPaperid: 7e13fcb7b7bae202fb9087e87abaa71a4b19a3e3\nTitle: Convoifilter: A case study of doing cocktail party speech recognition\nYear: 2023\nAbstract: This paper presents an end-to-end model designed to improve automatic speech recognition (ASR) for a particular speaker in a crowded, noisy environment. The model utilizes a single-channel speech enhancement module that isolates the speaker's voice from background noise (ConVoiFilter) and an ASR module. The model can decrease ASR's word error rate (WER) from 80% to 26.4% through this approach. Typically, these two components are adjusted independently due to variations in data requirements. However, speech enhancement can create anomalies that decrease ASR efficiency. By implementing a joint fine-tuning strategy, the model can reduce the WER from 26.4% in separate tuning to 14.5% in joint tuning. We openly share our pre-trained model to foster further research hf.co/nguyenvulebinh/voice-filter.",
  "By implementing a joint fine-tuning strategy, the model can reduce the WER from 26.4% in separate tuning to 14.5% in joint tuning. We openly share our pre-trained model to foster further research hf.co/nguyenvulebinh/voice-filter.\nAuthors: T. Nguyen, A. Waibel\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': \"An end-to-end model designed to improve automatic speech recognition for a particular speaker in a crowded, noisy environment that utilizes a single-channel speech enhancement module that isolates the speaker's voice from background noise and an ASR module.\"}",
  "Faculty Name: alexander waibel\nMetadata:\nPaperid: 807abb9c185ce233e2c8a2fcee49be851a1c968f\nTitle: Incremental Learning of Humanoid Robot Behavior from Natural Interaction and Large Language Models\nYear: 2023\nAbstract: Natural-language dialog is key for intuitive human-robot interaction. It can be used not only to express humans' intents, but also to communicate instructions for improvement if a robot does not understand a command correctly. Of great importance is to endow robots with the ability to learn from such interaction experience in an incremental way to allow them to improve their behaviors or avoid mistakes in the future. In this paper, we propose a system to achieve incremental learning of complex behavior from natural interaction, and demonstrate its implementation on a humanoid robot. Building on recent advances, we present a system that deploys Large Language Models (LLMs) for high-level orchestration of the robot's behavior, based on the idea of enabling the LLM to generate Python statements in an interactive console to invoke both robot perception and action.",
  "Building on recent advances, we present a system that deploys Large Language Models (LLMs) for high-level orchestration of the robot's behavior, based on the idea of enabling the LLM to generate Python statements in an interactive console to invoke both robot perception and action. The interaction loop is closed by feeding back human instructions, environment observations, and execution results to the LLM, thus informing the generation of the next statement. Specifically, we introduce incremental prompt learning, which enables the system to interactively learn from its mistakes. For that purpose, the LLM can call another LLM responsible for code-level improvements of the current interaction based on human feedback. The improved interaction is then saved in the robot's memory, and thus retrieved on similar requests. We integrate the system in the robot cognitive architecture of the humanoid robot ARMAR-6 and evaluate our methods both quantitatively (in simulation) and qualitatively (in simulation and real-world) by demonstrating generalized incrementally-learned knowledge.",
  "We integrate the system in the robot cognitive architecture of the humanoid robot ARMAR-6 and evaluate our methods both quantitatively (in simulation) and qualitatively (in simulation and real-world) by demonstrating generalized incrementally-learned knowledge.\nAuthors: Leonard B\u00e4rmann, Rainer Kartmann, Fabian Peller-Konrad, Alexander H. Waibel, T. Asfour\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': \"A system that deploys Large Language Models for high-level orchestration of the robot's behavior based on the idea of enabling the LLM to generate Python statements in an interactive console to invoke both robot perception and action is presented.\"}",
  "Faculty Name: alexander waibel\nMetadata:\nPaperid: 954ca9ab894df43e2cac18bc3813e9f9bc1bd488\nTitle: Continually learning new languages\nYear: 2023\nAbstract: Multilingual speech recognition with neural networks is often implemented with batch-learning, when all of the languages are available before training. An ability to add new languages after the prior training sessions can be economically bene-\ufb01cial, but the main challenge is catastrophic forgetting. In this work, we combine the qualities of weight factorization, transfer learning and Elastic Weight Consolidation in order to counter catastrophic forgetting and facilitate learning new languages quickly. Such combination allowed us to eliminate catastrophic forgetting while still achieving performance for the new languages comparable with having all languages at once, in experiments of learning from an initial 10 languages to achieve 27 languages.",
  "Such combination allowed us to eliminate catastrophic forgetting while still achieving performance for the new languages comparable with having all languages at once, in experiments of learning from an initial 10 languages to achieve 27 languages.\nAuthors: Ngoc-Quan Pham, J. Niehues, A. Waibel\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work combines the qualities of weight factorization, transfer learning and Elastic Weight Consolidation in order to counter catastrophic forgetting and facilitate learning new languages quickly.'}",
  "Faculty Name: alexander waibel\nMetadata:\nPaperid: aab2ed83bc3739a20e90ae1d97dcf45f3bc8e508\nTitle: AdapITN: A Fast, Reliable, and Dynamic Adaptive Inverse Text Normalization\nYear: 2023\nAbstract: Inverse text normalization (ITN) is the task that transforms text in spoken-form into written-form. While automatic speech recognition (ASR) produces text in spoken-form, human and natural language understanding systems prefer to consume text in written-form. ITN generally deals with semiotic phrases (e.g., numbers, date, time). However, lack of studies to deal with phonetization phrases, which is ASR\u2019s output when it handles unseen data (e.g., foreign-named entities, domain names), although these exist in the same form in the spoken-form text. The reason is that phonetization phrases are infinite patterns and language-dependent. In this study, we introduce a novel end2end model that can handle both semiotic phrases (SEP) and phonetization phrases (PHP), named AdapITN.",
  "The reason is that phonetization phrases are infinite patterns and language-dependent. In this study, we introduce a novel end2end model that can handle both semiotic phrases (SEP) and phonetization phrases (PHP), named AdapITN. We call it \"Adap\" because it allows for handling unseen PHP. The model performs only when necessary by providing a mechanism to narrow normalized regions and external query knowledge, reducing the runtime significantly.\nAuthors: T. Nguyen, Le Duc Minh Nhat, Quang Minh Nguyen, Quoc Truong Do, C. Luong, A. Waibel\nVenue: IEEE International Conference on Acoustics, Speech, and Signal Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A novel end2end model that can handle both semiotic phrases (SEP) and phonetization phrases (PHP), named AdapITN is introduced, named \"Adap\" because it allows for handling unseen PHP.'}",
  "Faculty Name: alexander waibel\nMetadata:\nPaperid: d24d60719e90e69749a75c160cb760d1d9fca44a\nTitle: Incremental Blockwise Beam Search for Simultaneous Speech Translation with Controllable Quality-Latency Tradeoff\nYear: 2023\nAbstract: Blockwise self-attentional encoder models have recently emerged as one promising end-to-end approach to simultaneous speech translation. These models employ a blockwise beam search with hypothesis reliability scoring to determine when to wait for more input speech before translating further. However, this method maintains multiple hypotheses until the entire speech input is consumed -- this scheme cannot directly show a single \\textit{incremental} translation to users. Further, this method lacks mechanisms for \\textit{controlling} the quality vs. latency tradeoff. We propose a modified incremental blockwise beam search incorporating local agreement or hold-$n$ policies for quality-latency control. We apply our framework to models trained for online or offline translation and demonstrate that both types can be effectively used in online mode.",
  "latency tradeoff. We propose a modified incremental blockwise beam search incorporating local agreement or hold-$n$ policies for quality-latency control. We apply our framework to models trained for online or offline translation and demonstrate that both types can be effectively used in online mode. Experimental results on MuST-C show 0.6-3.6 BLEU improvement without changing latency or 0.8-1.4 s latency improvement without changing quality.\nAuthors: Peter Pol\u00e1k, Brian Yan, Shinji Watanabe, A. Waibel, Ondrej Bojar\nVenue: Interspeech\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A modified incremental blockwise beam search incorporating local agreement or hold-$n$ policies for quality-latency control is proposed and applied to models trained for online or offline translation and it is demonstrated that both types can be effectively used in online mode.'}",
  "Faculty Name: alexander waibel\nMetadata:\nPaperid: f3e237e794bc4cd8df7f3e31d0caa2f7ee8cd06b\nTitle: Train Global, Tailor Local: Minimalist Multilingual Translation into Endangered Languages\nYear: 2023\nAbstract: In many humanitarian scenarios, translation into severely low resource languages often does not require a universal translation engine, but a dedicated text-specific translation engine. For example, healthcare records, hygienic procedures, government communication, emergency procedures and religious texts are all limited texts. While generic translation engines for all languages do not exist, translation of multilingually known limited texts into new, endangered languages may be possible and reduce human translation effort. We attempt to leverage translation resources from rich resource languages to efficiently produce best possible translation quality for well known texts, which is available in multiple languages, in a new, severely low resource language. We examine two approaches: 1.) best selection of seed sentences to jump start translations in a new language in view of best generalization to the remainder of a larger targeted text(s), and 2.)",
  "We examine two approaches: 1.) best selection of seed sentences to jump start translations in a new language in view of best generalization to the remainder of a larger targeted text(s), and 2.) we adapt large general multilingual translation engines from many other languages to focus on a specific text in a new, unknown language. We find that adapting large pretrained multilingual models to the domain/text first and then to the severely low resource language works best. If we also select a best set of seed sentences, we can improve average chrF performance on new test languages from a baseline of 21.9 to 50.7, while reducing the number of seed sentences to only \u223c1,000 in the new, unknown language.",
  "If we also select a best set of seed sentences, we can improve average chrF performance on new test languages from a baseline of 21.9 to 50.7, while reducing the number of seed sentences to only \u223c1,000 in the new, unknown language.\nAuthors: Zhong Zhou, J. Niehues, A. Waibel\nVenue: LORESMT\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work examines two approaches to best selection of seed sentences to jump start translations in a new language in view of best generalization to the remainder of a larger targeted text(s), and it finds that adapting large pretrained multilingual models to the domain/text first and then to the severely low resource language works best.'}",
  "Faculty Name: alexander waibel\nMetadata:\nPaperid: f524f119afc13cc07ca15998c10b9509e9e9b0b5\nTitle: End-to-End Evaluation for Low-Latency Simultaneous Speech Translation\nYear: 2023\nAbstract: The challenge of low-latency speech translation has recently draw significant interest in the research community as shown by several publications and shared tasks. Therefore, it is essential to evaluate these different approaches in realistic scenarios. However, currently only specific aspects of the systems are evaluated and often it is not possible to compare different approaches. In this work, we propose the first framework to perform and evaluate the various aspects of low-latency speech translation under realistic conditions. The evaluation is carried out in an end-to-end fashion. This includes the segmentation of the audio as well as the run-time of the different components. Secondly, we compare different approaches to low-latency speech translation using this framework. We evaluate models with the option to revise the output as well as methods with fixed output. Furthermore, we directly compare state-of-the-art cascaded as well as end-to-end systems.",
  "Secondly, we compare different approaches to low-latency speech translation using this framework. We evaluate models with the option to revise the output as well as methods with fixed output. Furthermore, we directly compare state-of-the-art cascaded as well as end-to-end systems. Finally, the framework allows to automatically evaluate the translation quality as well as latency and also provides a web interface to show the low-latency model outputs to the user.\nAuthors: Christian Huber, Tu Anh Dinh, Carlos Mullov, Ngoc-Quan Pham, T. Nguyen, Fabian Retkowski, Stefan Constantin, Enes Yavuz Ugan, Danni Liu, Zhaolin Li, Sai Koneru, J. Niehues, A. Waibel\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes the first framework to perform and evaluate the various aspects of low-latency speech translation under realistic conditions and directly compares state-of-the-art cascaded as well as end-to-end systems.'}",
  "Faculty Name: alexander waibel\nMetadata:\nPaperid: f547c7ec86cbc0989e87f0e23f7e0b2cfc5259c3\nTitle: Towards Efficient Simultaneous Speech Translation: CUNI-KIT System for Simultaneous Track at IWSLT 2023\nYear: 2023\nAbstract: In this paper, we describe our submission to the Simultaneous Track at IWSLT 2023. This year, we continue with the successful setup from the last year, however, we adopt the latest methods that further improve the translation quality. Additionally, we propose a novel online policy for attentional encoder-decoder models. The policy prevents the model to generate translation beyond the current speech input by using an auxiliary CTC output layer. We show that the proposed simultaneous policy can be applied to both streaming blockwise models and offline encoder-decoder models. We observe significant improvements in quality (up to 1.1 BLEU) and the computational footprint (up to 45% relative RTF).",
  "We show that the proposed simultaneous policy can be applied to both streaming blockwise models and offline encoder-decoder models. We observe significant improvements in quality (up to 1.1 BLEU) and the computational footprint (up to 45% relative RTF).\nAuthors: Peter Pol\u00e1k, Danni Liu, Ngoc-Quan Pham, J. Niehues, A. Waibel, Ondrej Bojar\nVenue: International Workshop on Spoken Language Translation\nTldr: {'model': 'tldr@v2.0.0', 'text': \"This year's submission to the Simultaneous Track at IWSLT 2023 is described, and a novel online policy for attentional encoder-decoder models is proposed that prevents the model to generate translation beyond the current speech input by using an auxiliary CTC output layer.\"}",
  "Faculty Name: alexander waibel\nMetadata:\nPaperid: f7e995c3cae465963ecaa8c9b4ce8b9b4323a71b\nTitle: FINDINGS OF THE IWSLT 2023 EVALUATION CAMPAIGN\nYear: 2023\nAbstract: This paper reports on the shared tasks organized by the 20th IWSLT Conference. The shared tasks address 9 scientific challenges in spoken language translation: simultaneous and offline translation, automatic subtitling and dubbing, speech-to-speech translation, multilingual, dialect and low-resource speech translation, and formality control. The shared tasks attracted a total of 38 submissions by 31 teams. The growing interest towards spoken language translation is also witnessed by the constantly increasing number of shared task organizers and contributors to the overview paper, almost evenly distributed across industry and academia.",
  "The shared tasks attracted a total of 38 submissions by 31 teams. The growing interest towards spoken language translation is also witnessed by the constantly increasing number of shared task organizers and contributors to the overview paper, almost evenly distributed across industry and academia.\nAuthors: Sweta Agrawal, Antonios Anastasopoulos, L. Bentivogli, Ondrej Bojar, Claudia Borg, Marine Carpuat, R. Cattoni, Mauro Cettolo, Mingda Chen, William Chen, K. Choukri, Alexandra Chronopoulou, Anna Currey, T. Declerck, Qianqian Dong, Kevin Duh, Y. Est\u00e8ve, Marcello Federico, Souhir Gahbiche, B. Haddow, B. Hsu, Phu Mon Htut, H. Inaguma, D\u00e1vid Javorsk\u00fd, J. Judge, Yasumasa Kano, Tom Ko, Rishu Kumar, Peng Li, Xutai Ma, Prashant Mathur, E. Matusov, Paul McNamee, John P. McCrae, Kenton Murray, Maria Nadejde, Satoshi Nakamura, Matteo Negri, H. Nguyen, J. Niehues, Xing Niu, Atul Kr.",
  "Ojha, John E. Ortega, Proyag Pal, J. Pino, Lonneke van der Plas, Peter Pol\u00e1k, Elijah Matthew Rippeth, Elizabeth Salesky, Jiatong Shi, Matthias Sperber, Sebastian St\u00fcker, Katsuhito Sudoh, Yun Tang, Brian Thompson, Ke M. Tran, Marco Turchi, A. Waibel, Mingxuan Wang, Shinji Watanabe, Rodolfo Zevallos\nVenue: International Workshop on Spoken Language Translation\nTldr: {'model': 'tldr@v2.0.0', 'text': None}",
  "List of 2023 Open Access papers by alexander waibel are:\nAdapITN: A Fast, Reliable, and Dynamic Adaptive Inverse Text Normalization\nTrain Global, Tailor Local: Minimalist Multilingual Translation into Endangered Languages\nTowards Efficient Simultaneous Speech Translation: CUNI-KIT System for Simultaneous Track at IWSLT 2023\nSYNTACC : Synthesizing Multi-Accent Speech By Weight Factorization\nKIT\u2019s Multilingual Speech Translation System for IWSLT 2023\nConvoifilter: A case study of doing cocktail party speech recognition\nContinually learning new languages\nIncremental Blockwise Beam Search for Simultaneous Speech Translation with Controllable Quality-Latency Tradeoff\nEnd-to-End Evaluation for Low-Latency Simultaneous Speech Translation\nFINDINGS OF THE IWSLT 2023 EVALUATION CAMPAIGN\nIncremental Learning of Humanoid Robot Behavior from Natural Interaction and Large Language Models",
  "Title: Malihe Alikhani -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Malihe Alikhani, Adjunct Faculty at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Adjunct Faculty\" name=\"categories-1\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Malihe Alikhani - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Malihe Alikhani, Adjunct Faculty at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Malihe\"/>\n<meta content=\"Lastname\" property=\"profile:Alikhani\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/alikhani-malihe.",
  "cmu.edu//people/faculty/alikhani-malihe.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nMalihe \n                        Alikhani\nAssistant Professor, Northeastern University\nContact\nmalihe(through)pitt.edu\nPersonal Website\n\nLinks:\nhttps://www.malihealikhani.com/",
  "Faculty Name: alon lavie\nMetadata:\nPaperid: 10127fa44054eb985ede206113b96aac3a96fd80\nTitle: The Inside Story: Towards Better Understanding of Machine Translation Neural Evaluation Metrics\nYear: 2023\nAbstract: Neural metrics for machine translation evaluation, such as COMET, exhibit significant improvements in their correlation with human judgments, as compared to traditional metrics based on lexical overlap, such as BLEU. Yet, neural metrics are, to a great extent, \u201cblack boxes\u201d returning a single sentence-level score without transparency about the decision-making process. In this work, we develop and compare several neural explainability methods and demonstrate their effectiveness for interpreting state-of-the-art fine-tuned neural metrics. Our study reveals that these metrics leverage token-level information that can be directly attributed to translation errors, as assessed through comparison of token-level neural saliency maps with Multidimensional Quality Metrics (MQM) annotations and with synthetically-generated critical translation errors.",
  "Our study reveals that these metrics leverage token-level information that can be directly attributed to translation errors, as assessed through comparison of token-level neural saliency maps with Multidimensional Quality Metrics (MQM) annotations and with synthetically-generated critical translation errors. To ease future research, we release our code at: https://github.com/Unbabel/COMET/tree/explainable-metrics\nAuthors: Ricardo Rei, Nuno M. Guerreiro, Marcos Vin\u00edcius Treviso, Lu\u00edsa Coheur, A. Lavie, Andr\u00e9 Martins\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This study reveals that neural explainability metrics leverage token-level information that can be directly attributed to translation errors, as assessed through comparison of token- level neural saliency maps with Multidimensional Quality Metrics annotations and with synthetically-generated critical translation errors.'}",
  "Faculty Name: alon lavie\nMetadata:\nPaperid: 176108285e0c0cacc7734a4038afb700d665f3db\nTitle: Assessing and comparing alternative certification programs: The teacher-classroom-community model\nYear: 2023\nAbstract: Alternative certification programs (ACPs) differ from traditional teacher certification programs in their target populations, duration, tools they employ, their pedagogy, and subject matter curricula. Given the acute shortage of excellent teachers, especially in STEM, significant efforts and resources are invested in ACPs so they prepare highly qualified teachers. Yet, novice teachers face difficulties during their initial integration into the school system. To better understand the state of affairs, we investigated and compared the integration into the school system of graduates of five major Israeli ACPs that are tailored for diverse student-teacher target audiences.",
  "Yet, novice teachers face difficulties during their initial integration into the school system. To better understand the state of affairs, we investigated and compared the integration into the school system of graduates of five major Israeli ACPs that are tailored for diverse student-teacher target audiences. The study goals were to (1) investigate and compare the integration of graduates of the five ACPs into the teaching profession with respect to five teacher-related aspects: (a) self-efficacy, (b) commitment to the teaching profession, (c) challenges encountered, (d) leadership roles, and (e) teamwork; (2) identify ACP characteristics that support the graduates\u2019 integration into the teaching profession. The teacher-classroom-community model we propose, holistically connects three aspects: affective \u2013 the teacher, the teaching profession \u2013 the classroom, and peer interaction and leadership \u2013 the school community. The model provides a common language for comparing how the different ACPs prepared their graduates toward the teaching profession. The model is instrumental for identifying ACP characteristics that support graduates\u2019 integration into teaching and facilitating ACP evaluation by connecting several aspects of teachers\u2019 professional lives.",
  "The model provides a common language for comparing how the different ACPs prepared their graduates toward the teaching profession. The model is instrumental for identifying ACP characteristics that support graduates\u2019 integration into teaching and facilitating ACP evaluation by connecting several aspects of teachers\u2019 professional lives. The study employed a mixed-methodology in which 506 graduates responded to a closed- and open-ended questionnaire and 71 interviews were conducted with graduates (novice teachers), ACP directors, school principals and mentor teachers. The findings depict a complex picture that reflects the different ACPs\u2019 characteristics targeted at diverse audiences. For example, graduates of STEM-oriented programs perceive the different kinds of knowledge, including content knowledge, pedagogical knowledge, and pedagogical content knowledge, as most important to their roles in schools. They undertake fewer roles, and the ones they do assume are discipline-related. Graduates of the more social-leadership-oriented programs identify developing leadership skills as most beneficial and they undertake more leadership-related roles. The research highlights key aspects that teacher education leaders should consider and use for self-evaluation of their ACPs.",
  "Graduates of the more social-leadership-oriented programs identify developing leadership skills as most beneficial and they undertake more leadership-related roles. The research highlights key aspects that teacher education leaders should consider and use for self-evaluation of their ACPs. The strength of this study stems from proposing and applying the teacher-classroom-community model for evaluating teacher certification programs in several contexts and for diverse groups along with their integration into schools.\nAuthors: Y. Dori, Daphne Goldman, Gabriella Shwartz, Nirit Lavie-Alon, Ariel Sarid, T. Tal\nVenue: Frontiers in Education\nTldr: None",
  "Faculty Name: alon lavie\nMetadata:\nPaperid: 1a74a5be47b042896a3c4b479e2acca72390ad62\nTitle: Using citizen science to protect threatened amphibian populations in urban spaces: ecology, life history, and conservation of green toads and fire salamanders in Jerusalem and Haifa\nYear: 2023\nAbstract: The rapid urbanization processes occurring worldwide are amongst the main factors driving the current biodiversity crisis. In particular, a third of known amphibian species are directly threatened by urbanization. The negation of this threat will require conservation efforts aimed at sustaining viable amphibian populations within the urban landscape, which must be informed by a deep understanding of the way amphibian populations are affected by the unique risk factors of the urban environment. To address this need for four populations of amphibians in Israel, we performed a capture-recapture analysis on two datasets. The larger of the two datasets is the result of a multi-year citizen science program focused on two Salamandra infraimmaculata populations within the city of Haifa, Israel.",
  "To address this need for four populations of amphibians in Israel, we performed a capture-recapture analysis on two datasets. The larger of the two datasets is the result of a multi-year citizen science program focused on two Salamandra infraimmaculata populations within the city of Haifa, Israel. The second dataset is the result of one year of survey following a similar protocol that we performed on two Bufotes variabilis populations within the city of Jerusalem and at a nature reserve near it. Individuals of both species have unique and recognizable dorsal spot patterns, which allowed for noninvasive recapture identification. The results of our analysis provide insights that can guide future conservation of the specific studied population, but our conclusions have wider implications, regarding both the ecology of the studied species and applied conservation science: using the salamander dataset, we developed a method of length-based age estimations for this species and found that the studied salamanders have a prolonged period of increased vulnerability throughout their first years of life, even after reaching sexual maturity. Additionally, the shared conclusions from the two case studies indicate that the creation of fish-containing artificial water bodies in Mediterranean habitats can have detrimental impacts on the resident amphibian populations.",
  "Additionally, the shared conclusions from the two case studies indicate that the creation of fish-containing artificial water bodies in Mediterranean habitats can have detrimental impacts on the resident amphibian populations. Synthesis and implications: The significance and extent of our results demonstrate the effectiveness of citizen science as a tool for research and conservation in the urban environment. Our findings call for the implementation of management practices that prioritize the protection of urban amphibians and their habitats. By identifying the vulnerability of amphibians during critical life stages and highlighting the negative impacts of fish-containing water bodies, our study contributes to the development of informed conservation policies with implications for urban planning, habitat management, and biodiversity conservation strategies.\nAuthors: Omer Darel, Olga Rybak, Asaf Ben Levy, Gabi Kolodny, Tamar Kis- Papo, Nirit Lavie Alon, Rotem Vidan, O. Kolodny\nVenue: bioRxiv\nTldr: {'model': 'tldr@v2.0.0', 'text': None}",
  "Faculty Name: alon lavie\nMetadata:\nPaperid: 5579d38636b898c6a67ad67a16a80dd83be0f8d4\nTitle: Towards Multilingual Automatic Dialogue Evaluation\nYear: 2023\nAbstract: None\nAuthors: John Mendon\u00e7a, A. Lavie, Isabel Trancoso\nVenue: arXiv.org\nTldr: None",
  "Faculty Name: alon lavie\nMetadata:\nPaperid: 5c920b2326282d93ad2ac3d1cb8f746bd7ab6f50\nTitle: Results of WMT23 Metrics Shared Task: Metrics Might Be Guilty but References Are Not Innocent\nYear: 2023\nAbstract: This paper presents the results of the WMT23 Metrics Shared Task. Participants submitting automatic MT evaluation metrics were asked to score the outputs of the translation systems competing in the WMT23 News Translation Task. All metrics were evaluated on how well they correlate with human ratings at the system and segment level. Similar to last year, we acquired our own human ratings based on expert-based human evaluation via Multidimensional Quality Metrics (MQM). Following last year\u2019s success, we also included a challenge set subtask, where participants had to create contrastive test suites for evaluating metrics\u2019 ability to capture and penalise specific types of translation errors. Furthermore, we improved our meta-evaluation procedure by considering fewer tasks and calculating a global score by weighted averaging across the various tasks.",
  "Furthermore, we improved our meta-evaluation procedure by considering fewer tasks and calculating a global score by weighted averaging across the various tasks. We present an extensive analysis on how well metrics perform on three language pairs: Chinese-English, Hebrew-English on the sentence-level and English-German on the paragraph-level. The results strongly confirm the results reported last year, that neural-based metrics are significantly better than non-neural metrics in their levels of correlation with human judgments. Further, we investigate the impact of bad reference translations on the correlations of metrics with human judgment. We present a novel approach for generating synthetic reference translations based on the collection of MT system outputs and their corresponding MQM ratings, which has the potential to mitigate bad reference issues we observed this year for some language pairs. Finally, we also study the connections between the magnitude of metric differences and their expected significance in human evaluation, which should help the community to better understand and adopt new metrics.",
  "Finally, we also study the connections between the magnitude of metric differences and their expected significance in human evaluation, which should help the community to better understand and adopt new metrics.\nAuthors: Markus Freitag, Nitika Mathur, Chi-kiu Lo, Eleftherios Avramidis, Ricardo Rei, Brian Thompson, Tom Kocmi, Frederic Blain, Daniel Deutsch, Craig Stewart, Chrysoula Zerva, Sheila Castilho, A. Lavie, George F. Foster\nVenue: Conference on Machine Translation\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A novel approach for generating synthetic reference translations based on the collection of MT system outputs and their corresponding MQM ratings, which has the potential to mitigate bad reference issues the authors observed this year for some language pairs are presented.'}",
  "Faculty Name: alon lavie\nMetadata:\nPaperid: 9364720b2ab9ac67bc08e2b0b49aadded3d4e2e5\nTitle: Appropriateness is all you need!\nYear: 2023\nAbstract: The strive to make AI applications\"safe\"has led to the development of safety-measures as the main or even sole normative requirement of their permissible use. Similar can be attested to the latest version of chatbots, such as chatGPT. In this view, if they are\"safe\", they are supposed to be permissible to deploy. This approach, which we call\"safety-normativity\", is rather limited in solving the emerging issues that chatGPT and other chatbots have caused thus far. In answering this limitation, in this paper we argue for limiting chatbots in the range of topics they can chat about according to the normative concept of appropriateness. We argue that rather than looking for\"safety\"in a chatbot's utterances to determine what they may and may not say, we ought to assess those utterances according to three forms of appropriateness: technical-discursive, social, and moral.",
  "We argue that rather than looking for\"safety\"in a chatbot's utterances to determine what they may and may not say, we ought to assess those utterances according to three forms of appropriateness: technical-discursive, social, and moral. We then spell out what requirements for chatbots follow from these forms of appropriateness to avoid the limits of previous accounts: positionality, acceptability, and value alignment (PAVA). With these in mind, we may be able to determine what a chatbot may and may not say. Lastly, one initial suggestion is to use challenge sets, specifically designed for appropriateness, as a validation method.\nAuthors: Hendrik Kempt, A. Lavie, S. Nagel\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper argues for limiting chatbots in the range of topics they can chat about according to the normative concept of appropriateness, and spells out what requirements for chatbots follow from these forms of Appropriateness to avoid the limits of previous accounts.'}",
  "Faculty Name: alon lavie\nMetadata:\nPaperid: 9e8f125ef479af7e95ee5b8949b24e750c7df367\nTitle: Towards Multilingual Automatic Open-Domain Dialogue Evaluation\nYear: 2023\nAbstract: The main limiting factor in the development of robust multilingual open-domain dialogue evaluation metrics is the lack of multilingual data and the limited availability of open-sourced multilingual dialogue systems. In this work, we propose a workaround for this lack of data by leveraging a strong multilingual pretrained encoder-based Language Model and augmenting existing English dialogue data using Machine Translation. We empirically show that the naive approach of finetuning a pretrained multilingual encoder model with translated data is insufficient to outperform the strong baseline of finetuning a multilingual model with only source data. Instead, the best approach consists in the careful curation of translated data using MT Quality Estimation metrics, excluding low quality translations that hinder its performance.",
  "Instead, the best approach consists in the careful curation of translated data using MT Quality Estimation metrics, excluding low quality translations that hinder its performance.\nAuthors: John Mendon\u00e7a, A. Lavie, I. Trancoso\nVenue: SIGDIAL Conferences\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is empirically show that the naive approach of finetuning a pretrained multilingual encoder model with translated data is insufficient to outperform the strong baseline of finETuning a multilingual model with only source data.'}",
  "Faculty Name: alon lavie\nMetadata:\nPaperid: bcefc74b20649fd41ea05d87a3fa512d2559fc8d\nTitle: Simple LLM Prompting is State-of-the-Art for Robust and Multilingual Dialogue Evaluation\nYear: 2023\nAbstract: Despite significant research effort in the development of automatic dialogue evaluation metrics, little thought is given to evaluating dialogues other than in English. At the same time, ensuring metrics are invariant to semantically similar responses is also an overlooked topic. In order to achieve the desired properties of robustness and multilinguality for dialogue evaluation metrics, we propose a novel framework that takes advantage of the strengths of current evaluation models with the newly-established paradigm of prompting Large Language Models (LLMs). Empirical results show our framework achieves state of the art results in terms of mean Spearman correlation scores across several benchmarks and ranks first place on both the Robust and Multilingual tasks of the DSTC11 Track 4 \u201cAutomatic Evaluation Metrics for Open-Domain Dialogue Systems\u201d, proving the evaluation capabilities of prompted LLMs.",
  "Authors: J. Mendoncca, Patr\u00edcia Pereira, Joao Paulo Carvalho, A. Lavie, I. Trancoso\nVenue: DSTC\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A novel framework that takes advantage of the strengths of current evaluation models with the newly-established paradigm of prompting Large Language Models (LLMs) to achieve the desired properties of robustness and multilinguality for dialogue evaluation metrics.'}",
  "List of 2023 Open Access papers by alon lavie are:\nThe Inside Story: Towards Better Understanding of Machine Translation Neural Evaluation Metrics\nTowards Multilingual Automatic Dialogue Evaluation\nResults of WMT23 Metrics Shared Task: Metrics Might Be Guilty but References Are Not Innocent\nAppropriateness is all you need!\nTowards Multilingual Automatic Open-Domain Dialogue Evaluation\nSimple LLM Prompting is State-of-the-Art for Robust and Multilingual Dialogue Evaluation\nAssessing and comparing alternative certification programs: The teacher-classroom-community model\nUsing citizen science to protect threatened amphibian populations in urban spaces: ecology, life history, and conservation of green toads and fire salamanders in Jerusalem and Haifa",
  "Faculty Name: berg kirkpatrick taylor\nMetadata:\nPaperid: 1527d3b661154ff7310fa2759b6dd0ddfd559492\nTitle: Smaller Language Models are Better Black-box Machine-Generated Text Detectors\nYear: 2023\nAbstract: With the advent of fluent generative language models that can produce convincing utterances very similar to those written by humans, distinguishing whether a piece of text is machine-generated or human-written becomes more challenging and more important, as such models could be used to spread misinformation, fake news, fake reviews and to mimic certain authors and figures. To this end, there have been a slew of methods proposed to detect machine-generated text. Most of these methods need access to the logits of the target model or need the ability to sample from the target. One such black-box detection method relies on the observation that generated text is locally optimal under the likelihood function of the generator, while human-written text is not. We find that overall, smaller and partially-trained models are better universal text detectors: they can more precisely detect text generated from both small and larger models.",
  "One such black-box detection method relies on the observation that generated text is locally optimal under the likelihood function of the generator, while human-written text is not. We find that overall, smaller and partially-trained models are better universal text detectors: they can more precisely detect text generated from both small and larger models. Interestingly, we find that whether the detector and generator were trained on the same data is not critically important to the detection success. For instance the OPT-125M model has an AUC of 0.81 in detecting ChatGPT generations, whereas a larger model from the GPT family, GPTJ-6B, has AUC of 0.45.\nAuthors: Fatemehsadat Mireshghallah, Justus Mattern, Sicun Gao, R. Shokri, Taylor Berg-Kirkpatrick\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Overall, smaller and partially-trained models are better universal text detectors: they can more precisely detect text generated from both small and larger models.'}",
  "Faculty Name: berg kirkpatrick taylor\nMetadata:\nPaperid: 15b08595533bfc640f4dd470ca7a2273badec20a\nTitle: Towards Improving Harmonic Sensitivity and Prediction Stability for Singing Melody Extraction\nYear: 2023\nAbstract: In deep learning research, many melody extraction models rely on redesigning neural network architectures to improve performance. In this paper, we propose an input feature modification and a training objective modification based on two assumptions. First, harmonics in the spectrograms of audio data decay rapidly along the frequency axis. To enhance the model's sensitivity on the trailing harmonics, we modify the Combined Frequency and Periodicity (CFP) representation using discrete z-transform. Second, the vocal and non-vocal segments with extremely short duration are uncommon. To ensure a more stable melody contour, we design a differentiable loss function that prevents the model from predicting such segments. We apply these modifications to several models, including MSNet, FTANet, and a newly introduced model, PianoNet, modified from a piano transcription network. Our experimental results demonstrate that the proposed modifications are empirically effective for singing melody extraction.",
  "We apply these modifications to several models, including MSNet, FTANet, and a newly introduced model, PianoNet, modified from a piano transcription network. Our experimental results demonstrate that the proposed modifications are empirically effective for singing melody extraction.\nAuthors: Keren Shao, K. Chen, Taylor Berg-Kirkpatrick, S. Dubnov\nVenue: International Society for Music Information Retrieval Conference\nTldr: {'model': 'tldr@v2.0.0', 'text': \"This paper proposes an input feature modification and a training objective modification based on two assumptions of harmonics in the spectrograms of audio data decay rapidly along the frequency axis to enhance the model's sensitivity on the trailing harmonics.\"}",
  "Faculty Name: berg kirkpatrick taylor\nMetadata:\nPaperid: 1d7a19085d0e1c3f8593e1d9feb059a27f71a4b4\nTitle: Text Conditional Alt-Text Generation for Twitter Images\nYear: 2023\nAbstract: In this work we present an approach for generating alternative text (or alt-text) descriptions for images shared on social media, specifically Twitter. This task is more than just a special case of image captioning, as alt-text is both more literally descriptive and context-specific. Also critically, images posted to Twitter are often accompanied by user-written text that despite not necessarily describing the image may provide useful context that if properly lever-aged can be informative \u2013 e.g. the tweet may name an uncommon object in the image that the model has not previously seen. We address this with a CLIP prefix model that extracts an embedding of the image and passes it to a mapping network that outputs a short sequence in word embedding space, or a \u201cprefix\u201d, to which we also concatenate the text from the tweet itself. This lets the model condition on both visual and textual information from the post.",
  "This lets the model condition on both visual and textual information from the post. The combined multimodal prefix is then fed as a prompt to a pretrained language model which autore-gressively completes the sequence to generate the alt-text. While prior work has used similar methods for captioning, ours is the first to our knowledge that incorporates textual information from the associated social media post into the prefix as well, and we further demonstrate through ablations that utility of these two information sources stacks. We put forward a new dataset scraped from Twitter and evaluate on it across a variety of automated metrics as well as human evaluation, and show that our approach of conditioning on both tweet text and visual information significantly outperforms prior work.\nAuthors: Nikita Srivatsan, Sof\u00eda Samaniego, Omar Florez, Taylor Berg-Kirkpatrick\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work presents an approach for generating alternative text (or alt-text) descriptions for images shared on social media, specifically Twitter, and is the first to their knowledge that incorporates textual information from the associated social media post into the prefix as well.'}",
  "Faculty Name: berg kirkpatrick taylor\nMetadata:\nPaperid: 1f1a09e59dbd178aa0988ea8f96e780e36923c8a\nTitle: Jointly modeling products and resource pages for task-oriented recommendation\nYear: 2023\nAbstract: Modeling high-level user intent in recommender systems can improve performance, although it is often difficult to obtain a ground truth measure of this intent. In this paper, we investigate a novel way to obtain such an intent signal by leveraging resource pages associated with a particular task. We jointly model product interactions and resource page interactions to create a system which can recommend both products and resource pages to users. Our experiments consider the domain of home improvement product recommendation, where resource pages are DIY (do-it-yourself) project pages from Lowes.com. Each DIY page provides a list of tools, materials, and step-by-step instructions to complete a DIY project, such as building a deck, installing cabinets, and fixing a leaking pipe. We use this data as an indicator of the intended project, which is a natural high-level intent signal for home improvement shoppers.",
  "Each DIY page provides a list of tools, materials, and step-by-step instructions to complete a DIY project, such as building a deck, installing cabinets, and fixing a leaking pipe. We use this data as an indicator of the intended project, which is a natural high-level intent signal for home improvement shoppers. We then extend a state-of-the-art system to incorporate this new intent data, and show a significant improvement in the ability of the system to recommend products. We further demonstrate that our system can be used to successfully recommend DIY project pages to users. We have taken initial steps towards deploying our method for project recommendation in production on the Lowe\u2019s website and for recommendations through marketing emails.\nAuthors: B. Duncan, Surya Kallumadi, Taylor Berg-Kirkpatrick, Julian McAuley\nVenue: The Web Conference\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper jointly model product interactions and resource page interactions to create a system which can recommend both products and resource pages to users, and extends a state-of-the-art system to incorporate this new intent data, and shows a significant improvement in the ability of the system to recommend products.'}",
  "Faculty Name: berg kirkpatrick taylor\nMetadata:\nPaperid: 300d5f610872b84bf8c85c2b51c421f2c7160f3d\nTitle: CuneiML: A Cuneiform Dataset for Machine Learning\nYear: 2023\nAbstract: None\nAuthors: Danlu Chen, Aditi Agarwal, Taylor Berg-Kirkpatrick, Jacobo Myerston\nVenue: Journal of Open Humanities Data\nTldr: None",
  "Faculty Name: berg kirkpatrick taylor\nMetadata:\nPaperid: 3a899fbda8071af3fce011ae2c1f6c00264c070f\nTitle: Exploring the Relationship Between Model Architecture and In-Context Learning Ability\nYear: 2023\nAbstract: What is the relationship between model architecture and the ability to perform in-context learning? In this empirical study, we take the first steps toward answering this question. We evaluate twelve model architectures capable of causal language modeling across a suite of synthetic in-context learning tasks. These selected architectures represent a broad range of paradigms, including recurrent and convolution-based neural networks, transformers, state-space model inspired, and other emerging attention alternatives. We discover that all the considered architectures can perform in-context learning under a wider range of conditions than previously documented. Additionally, we observe stark differences in statistical efficiency and consistency by varying context length and task difficulty. We also measure each architecture's predisposition towards in-context learning when presented with alternative routes for task resolution. Finally, and somewhat surprisingly, we find that several attention alternatives are more robust in-context learners than transformers.",
  "Additionally, we observe stark differences in statistical efficiency and consistency by varying context length and task difficulty. We also measure each architecture's predisposition towards in-context learning when presented with alternative routes for task resolution. Finally, and somewhat surprisingly, we find that several attention alternatives are more robust in-context learners than transformers. Given that such approaches have constant-sized memory footprints at inference time, this result opens the possibility of scaling up in-context learning to accommodate vastly larger numbers of in-context examples.\nAuthors: Ivan Lee, Nan Jiang, Taylor Berg-Kirkpatrick\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This empirical study evaluates twelve model architectures capable of causal language modeling across a suite of synthetic in- context learning tasks and finds that several attention alternatives are more robust in-context learners than transformers.'}",
  "Faculty Name: berg kirkpatrick taylor\nMetadata:\nPaperid: 464edfd902f652d3ab6a25dbb6d9fa47cc3246a9\nTitle: MusicLDM: Enhancing Novelty in Text-to-Music Generation Using Beat-Synchronous Mixup Strategies\nYear: 2023\nAbstract: Diffusion models have shown promising results in cross-modal generation tasks, including text-to-image and text-to-audio generation. However, generating music, as a special type of audio, presents unique challenges due to limited availability of music data and sensitive issues related to copyright and plagiarism. In this paper, to tackle these challenges, we first construct a state-of-the-art text-to-music model, MusicLDM, that adapts Stable Diffusion and AudioLDM architectures to the music domain. We achieve this by retraining the contrastive language-audio pretraining model (CLAP) and the Hifi-GAN vocoder, as components of MusicLDM, on a collection of music data samples.",
  "We achieve this by retraining the contrastive language-audio pretraining model (CLAP) and the Hifi-GAN vocoder, as components of MusicLDM, on a collection of music data samples. Then, to address the limitations of training data and to avoid plagiarism, we leverage a beat tracking model and propose two different mixup strategies for data augmentation: beat-synchronous audio mixup and beat-synchronous latent mixup, which recombine training audio directly or via a latent embeddings space, respectively. Such mixup strategies encourage the model to interpolate between musical training samples and generate new music within the convex hull of the training data, making the generated music more diverse while still staying faithful to the corresponding style. In addition to popular evaluation metrics, we design several new evaluation metrics based on CLAP score to demonstrate that our proposed MusicLDM and beat-synchronous mixup strategies improve both the quality and novelty of generated music, as well as the correspondence between input text and generated music.",
  "In addition to popular evaluation metrics, we design several new evaluation metrics based on CLAP score to demonstrate that our proposed MusicLDM and beat-synchronous mixup strategies improve both the quality and novelty of generated music, as well as the correspondence between input text and generated music.\nAuthors: K. Chen, Yusong Wu, Haohe Liu, Marianna Nezhurina, Taylor Berg-Kirkpatrick, S. Dubnov\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A state-of-the-art text-to-music model that adapts Stable Diffusion and AudioLDM architectures to the music domain is constructed and two different mixup strategies for data augmentation are proposed: beat-synchronous audio mixup and beat- Synchronous latent mixup, which recombine training audio directly or via a latent embeddings space, respectively.'}",
  "Faculty Name: berg kirkpatrick taylor\nMetadata:\nPaperid: 55324ec5662bbea2e226ce3d8e6258a62836e940\nTitle: Universal Source Separation with Weakly Labelled Data\nYear: 2023\nAbstract: Universal source separation (USS) is a fundamental research task for computational auditory scene analysis, which aims to separate mono recordings into individual source tracks. There are three potential challenges awaiting the solution to the audio source separation task. First, previous audio source separation systems mainly focus on separating one or a limited number of specific sources. There is a lack of research on building a unified system that can separate arbitrary sources via a single model. Second, most previous systems require clean source data to train a separator, while clean source data are scarce. Third, there is a lack of USS system that can automatically detect and separate active sound classes in a hierarchical level.",
  "Second, most previous systems require clean source data to train a separator, while clean source data are scarce. Third, there is a lack of USS system that can automatically detect and separate active sound classes in a hierarchical level. To use large-scale weakly labeled/unlabeled audio data for audio source separation, we propose a universal audio source separation framework containing: 1) an audio tagging model trained on weakly labeled data as a query net; and 2) a conditional source separation model that takes query net outputs as conditions to separate arbitrary sound sources. We investigate various query nets, source separation models, and training strategies and propose a hierarchical USS strategy to automatically detect and separate sound classes from the AudioSet ontology. By solely leveraging the weakly labelled AudioSet, our USS system is successful in separating a wide variety of sound classes, including sound event separation, music source separation, and speech enhancement.",
  "By solely leveraging the weakly labelled AudioSet, our USS system is successful in separating a wide variety of sound classes, including sound event separation, music source separation, and speech enhancement. The USS system achieves an average signal-to-distortion ratio improvement (SDRi) of 5.57 dB over 527 sound classes of AudioSet; 10.57 dB on the DCASE 2018 Task 2 dataset; 8.12 dB on the MUSDB18 dataset; an SDRi of 7.28 dB on the Slakh2100 dataset; and an SSNR of 9.00 dB on the voicebank-demand dataset.",
  "We release the source code at https://github.com/bytedance/uss\nAuthors: Qiuqiang Kong, K. Chen, Haohe Liu, Xingjian Du, Taylor Berg-Kirkpatrick, S. Dubnov, M. Plumbley\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A hierarchical USS strategy to automatically detect and separate sound classes from the AudioSet ontology is proposed, which is successful in separating a wide variety of sound classes, including sound event separation, music source separation, and speech enhancement.'}",
  "Faculty Name: berg kirkpatrick taylor\nMetadata:\nPaperid: ac5b4df0e398ca48388330ac5c795b6fe708793c\nTitle: Misusing Tools in Large Language Models With Visual Adversarial Examples\nYear: 2023\nAbstract: Large Language Models (LLMs) are being enhanced with the ability to use tools and to process multiple modalities. These new capabilities bring new benefits and also new security risks. In this work, we show that an attacker can use visual adversarial examples to cause attacker-desired tool usage. For example, the attacker could cause a victim LLM to delete calendar events, leak private conversations and book hotels. Different from prior work, our attacks can affect the confidentiality and integrity of user resources connected to the LLM while being stealthy and generalizable to multiple input prompts. We construct these attacks using gradient-based adversarial training and characterize performance along multiple dimensions. We find that our adversarial images can manipulate the LLM to invoke tools following real-world syntax almost always (~98%) while maintaining high similarity to clean images (~0.9 SSIM).",
  "We construct these attacks using gradient-based adversarial training and characterize performance along multiple dimensions. We find that our adversarial images can manipulate the LLM to invoke tools following real-world syntax almost always (~98%) while maintaining high similarity to clean images (~0.9 SSIM). Furthermore, using human scoring and automated metrics, we find that the attacks do not noticeably affect the conversation (and its semantics) between the user and the LLM.\nAuthors: Xiaohan Fu, Zihan Wang, Shuheng Li, Rajesh K. Gupta, Niloofar Mireshghallah, Taylor Berg-Kirkpatrick, Earlence Fernandes\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work shows that an attacker can use visual adversarial examples to cause attacker-desired tool usage to cause a victim LLM to delete calendar events, leak private conversations and book hotels.'}",
  "Faculty Name: berg kirkpatrick taylor\nMetadata:\nPaperid: c70c11d6de5eec2677eaa87fd3112068db6fedfe\nTitle: CLIPSonic: Text-to-Audio Synthesis with Unlabeled Videos and Pretrained Language-Vision Models\nYear: 2023\nAbstract: Recent work has studied text-to-audio synthesis using large amounts of paired text-audio data. However, audio recordings with high-quality text annotations can be difficult to acquire. In this work, we approach text-to-audio synthesis using unlabeled videos and pre-trained language-vision models. We propose to learn the desired text-audio correspondence by leveraging the visual modality as a bridge. We train a conditional diffusion model to generate the audio track of a video, given a video frame encoded by a pretrained contrastive language-image pretraining (CLIP) model. At test time, we first explore performing a zero-shot modality transfer and condition the diffusion model with a CLIP-encoded text query. However, we observe a noticeable performance drop with respect to image queries.",
  "At test time, we first explore performing a zero-shot modality transfer and condition the diffusion model with a CLIP-encoded text query. However, we observe a noticeable performance drop with respect to image queries. To close this gap, we further adopt a pretrained diffusion prior model to generate a CLIP image embedding given a CLIP text embedding. Our results show the effectiveness of the proposed method, and that the pretrained diffusion prior can reduce the modality transfer gap. While we focus on text-to-audio synthesis, the proposed model can also generate audio from image queries, and it shows competitive performance against a state-of-the-art image-to-audio synthesis model in a subjective listening test. This study offers a new direction of approaching text-to-audio synthesis that leverages the naturally-occurring audio-visual correspondence in videos and the power of pretrained language-vision models.",
  "This study offers a new direction of approaching text-to-audio synthesis that leverages the naturally-occurring audio-visual correspondence in videos and the power of pretrained language-vision models.\nAuthors: Hao-Wen Dong, Xiaoyu Liu, Jordi Pons, Gautam Bhattacharya, Santiago Pascual, J. Serr\u00e0, Taylor Berg-Kirkpatrick, Julian McAuley\nVenue: IEEE Workshop on Applications of Signal Processing to Audio and Acoustics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes to learn the desired text-audio correspondence by leveraging the visual modality as a bridge in videos and pretrained language-vision models, and shows competitive performance against a state-of-the-art image-to-audio synthesis model in a subjective listening test.'}",
  "Faculty Name: berg kirkpatrick taylor\nMetadata:\nPaperid: c817d9901f788e40279c76068ea2622365cd9a1d\nTitle: Simple Temporal Adaptation to Changing Label Sets: Hashtag Prediction via Dense KNN\nYear: 2023\nAbstract: User-generated social media data is constantly changing as new trends influence online discussion and personal information is deleted due to privacy concerns. However, traditional NLP models rely on fixed training datasets, which means they are unable to adapt to temporal change\u2014both test distribution shift and deleted training data\u2014without frequent, costly re-training. In this paper, we study temporal adaptation through the task of longitudinal hashtag prediction and propose a non-parametric dense retrieval technique, which does not require re-training, as a simple but effective solution. In experiments on a newly collected, publicly available, year-long Twitter dataset exhibiting temporal distribution shift, our method improves by 64% over the best static parametric baseline while avoiding costly gradient-based re-training. Our approach is also particularly well-suited to dynamically deleted user data in line with data privacy laws, with negligible computational cost/performance loss.",
  "Our approach is also particularly well-suited to dynamically deleted user data in line with data privacy laws, with negligible computational cost/performance loss.\nAuthors: Niloofar Mireshghallah, Nikolai Vogler, Junxian He, Omar Florez, Ahmed El-Kishky, Taylor Berg-Kirkpatrick\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper studies temporal adaptation through the task of longitudinal hashtag prediction and proposes a non-parametric dense retrieval technique, which does not require re-training, as a simple but effective solution to temporal change.'}",
  "Faculty Name: berg kirkpatrick taylor\nMetadata:\nPaperid: cb754310302086dfbbcd098263200e2a03f65874\nTitle: Membership Inference Attacks against Language Models via Neighbourhood Comparison\nYear: 2023\nAbstract: Membership Inference attacks (MIAs) aim to predict whether a data sample was present in the training data of a machine learning model or not, and are widely used for assessing the privacy risks of language models. Most existing attacks rely on the observation that models tend to assign higher probabilities to their training samples than non-training points. However, simple thresholding of the model score in isolation tends to lead to high false-positive rates as it does not account for the intrinsic complexity of a sample. Recent work has demonstrated that reference-based attacks which compare model scores to those obtained from a reference model trained on similar data can substantially improve the performance of MIAs. However, in order to train reference models, attacks of this kind make the strong and arguably unrealistic assumption that an adversary has access to samples closely resembling the original training data. Therefore, we investigate their performance in more realistic scenarios and find that they are highly fragile in relation to the data distribution used to train reference models.",
  "Therefore, we investigate their performance in more realistic scenarios and find that they are highly fragile in relation to the data distribution used to train reference models. To investigate whether this fragility provides a layer of safety, we propose and evaluate neighbourhood attacks, which compare model scores for a given sample to scores of synthetically generated neighbour texts and therefore eliminate the need for access to the training data distribution. We show that, in addition to being competitive with reference-based attacks that have perfect knowledge about the training data distribution, our attack clearly outperforms existing reference-free attacks as well as reference-based attacks with imperfect knowledge, which demonstrates the need for a reevaluation of the threat model of adversarial attacks.",
  "We show that, in addition to being competitive with reference-based attacks that have perfect knowledge about the training data distribution, our attack clearly outperforms existing reference-free attacks as well as reference-based attacks with imperfect knowledge, which demonstrates the need for a reevaluation of the threat model of adversarial attacks.\nAuthors: Justus Mattern, Fatemehsadat Mireshghallah, Zhijing Jin, B. Sch\u00f6lkopf, Mrinmaya Sachan, Taylor Berg-Kirkpatrick\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Neighbourhood attacks are proposed and evaluated, which compare model scores for a given sample to scores of synthetically generated neighbour texts and therefore eliminate the need for access to the training data distribution and clearly outperforms existing reference-free attacks as well as reference-based attacks with imperfect knowledge.'}",
  "Faculty Name: berg kirkpatrick taylor\nMetadata:\nPaperid: d8785264bbce47ca1ea7f97e7f3bc4ca6cbe824c\nTitle: A Block Metropolis-Hastings Sampler for Controllable Energy-based Text Generation\nYear: 2023\nAbstract: Recent work has shown that energy-based language modeling is an effective framework for controllable text generation because it enables flexible integration of arbitrary discriminators. However, because energy-based LMs are globally normalized, approximate techniques like Metropolis-Hastings (MH) are required for inference. Past work has largely explored simple proposal distributions that modify a single token at a time, like in Gibbs sampling. In this paper, we develop a novel MH sampler that, in contrast, proposes re-writes of the entire sequence in each step via iterative prompting of a large language model. Our new sampler (a) allows for more efficient and accurate sampling from a target distribution and (b) allows generation length to be determined through the sampling procedure rather than fixed in advance, as past work has required. We perform experiments on two controlled generation tasks, showing both downstream performance gains and more accurate target distribution sampling in comparison with single-token proposal techniques.",
  "We perform experiments on two controlled generation tasks, showing both downstream performance gains and more accurate target distribution sampling in comparison with single-token proposal techniques.\nAuthors: Jarad Forristal, Fatemehsadat Mireshghallah, Greg Durrett, Taylor Berg-Kirkpatrick\nVenue: Conference on Computational Natural Language Learning\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A novel MH sampler is developed that proposes re-writes of the entire sequence in each step via iterative prompting of a large language model and allows generation length to be determined through the sampling procedure rather than fixed in advance, as past work has required.'}",
  "Faculty Name: berg kirkpatrick taylor\nMetadata:\nPaperid: d9dc309f719233be9f2a6b6910072e537f96eec8\nTitle: Contrastive Attention Networks for Attribution of Early Modern Print\nYear: 2023\nAbstract: In this paper, we develop machine learning techniques to identify unknown printers in early modern (c.~1500--1800) English printed books.\nSpecifically, we focus on matching uniquely damaged character type-imprints in anonymously printed books to works with known printers in order to provide evidence of their origins.\nUntil now, this work has been limited to manual investigations by analytical bibliographers.\nWe present a Contrastive Attention-based Metric Learning approach to identify similar damage across character image pairs, which is sensitive to very subtle differences in glyph shapes, yet robust to various confounding sources of noise associated with digitized historical books. \nTo overcome the scarce amount of supervised data, we design a random data synthesis procedure that aims to simulate bends, fractures, and inking variations induced by the early printing process.\nOur method successfully improves downstream damaged type-imprint matching among printed works from this period, as validated by in-domain human experts.",
  "To overcome the scarce amount of supervised data, we design a random data synthesis procedure that aims to simulate bends, fractures, and inking variations induced by the early printing process.\nOur method successfully improves downstream damaged type-imprint matching among printed works from this period, as validated by in-domain human experts. The results of our approach on two important philosophical works from the Early Modern period demonstrate potential to extend the extant historical research about the origins and content of these books.\nAuthors: Nikolai Vogler, Kartik Goyal, Kishore PV Reddy, Elizaveta Pertseva, Sam Lemley, Christopher N. Warren, M. G'Sell, Taylor Berg-Kirkpatrick\nVenue: AAAI Conference on Artificial Intelligence\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The method successfully improves downstream damaged type-imprint matching among printed works from this period, as validated by in-domain human experts and demonstrates potential to extend the extant historical research about the origins and content of these books.'}",
  "List of 2023 Open Access papers by berg kirkpatrick taylor are:\nSmaller Language Models are Better Black-box Machine-Generated Text Detectors\nTowards Improving Harmonic Sensitivity and Prediction Stability for Singing Melody Extraction\nJointly modeling products and resource pages for task-oriented recommendation\nMusicLDM: Enhancing Novelty in Text-to-Music Generation Using Beat-Synchronous Mixup Strategies\nUniversal Source Separation with Weakly Labelled Data\nCLIPSonic: Text-to-Audio Synthesis with Unlabeled Videos and Pretrained Language-Vision Models\nMembership Inference Attacks against Language Models via Neighbourhood Comparison\nContrastive Attention Networks for Attribution of Early Modern Print\nText Conditional Alt-Text Generation for Twitter Images\nExploring the Relationship Between Model Architecture and In-Context Learning Ability\nA Block Metropolis-Hastings Sampler for Controllable Energy-based Text Generation\nMisusing Tools in Large Language Models With Visual Adversarial Examples\nSimple Temporal Adaptation to Changing Label Sets: Hashtag Prediction via Dense KNN\nCuneiML: A Cuneiform Dataset for Machine Learning",
  "Title: Taylor Berg-Kirkpatrick -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Taylor Berg-Kirkpatrick, Adjunct Faculty at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Adjunct Faculty\" name=\"categories-1\"/>\n<meta content=\"Machine Learning;Natural Language Processing and Computational Linguistics\" name=\"categories-2\"/>\n<meta content=\"Yes\" name=\"show-categories-2\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Taylor Berg-Kirkpatrick - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Taylor Berg-Kirkpatrick,",
  "Adjunct Faculty at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Taylor\"/>\n<meta content=\"Lastname\" property=\"profile:Berg-Kirkpatrick\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/berg-kirkpatrick-taylor.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nTaylor \n                        Berg-Kirkpatrick\nAssistant Professor, University of California, San Diego\nContact\n6403 \u2014Gates & Hillman Centers\ntberg(through)cs.cmu.edu\nResearch Area\nMachine Learning, Natural Language Processing and Computational Linguistics\nResearch\nUnsupervised Learning\nDeveloping models and methods that can learn to understand aspects of human language\u00a0without relying on hand-labeled data\nStructured Prediction\nBuilding inference procedures that can efficiently and accurately produce complex outputs,",
  "cmu.edu\nResearch Area\nMachine Learning, Natural Language Processing and Computational Linguistics\nResearch\nUnsupervised Learning\nDeveloping models and methods that can learn to understand aspects of human language\u00a0without relying on hand-labeled data\nStructured Prediction\nBuilding inference procedures that can efficiently and accurately produce complex outputs,\u00a0including both structured linguistic annotations (like parse trees) and natural language utterances\u00a0(like summaries)\nAnalysis of Human Artifacts\nUsing automated methods to analyze and decipher structured human artifacts, including text\u00a0but also sources like piano music, images of early modern books (e.g. First Folio of Shakespeare),\u00a0and cuneiform tablets\nPersonal Website\n\nLinks:\nhttps://cseweb.ucsd.edu/~tberg/",
  "Faculty Name: bhiksha raj\nMetadata:\nPaperid: 078f86c6a691806cc71bbef1e734f75690db0ffc\nTitle: FREDOM: Fairness Domain Adaptation Approach to Semantic Scene Understanding\nYear: 2023\nAbstract: Although Domain Adaptation in Semantic Scene Segmentation has shown impressive improvement in recent years, the fairness concerns in the domain adaptation have yet to be well defined and addressed. In addition, fairness is one of the most critical aspects when deploying the segmentation models into human-related real-world applications, e.g., autonomous driving, as any unfair predictions could influence human safety. In this paper, we propose a novel Fairness Domain Adaptation (FREDOM) approach to semantic scene segmentation. In particular, from the proposed formulated fairness objective, a new adaptation framework will be introduced based on the fair treatment of class distributions. Moreover, to generally model the context of structural dependency, a new conditional structural constraint is introduced to impose the consistency of predicted segmentation. Thanks to the proposed Conditional Structure Network, the self-attention mechanism has sufficiently modeled the structural information of segmentation.",
  "Moreover, to generally model the context of structural dependency, a new conditional structural constraint is introduced to impose the consistency of predicted segmentation. Thanks to the proposed Conditional Structure Network, the self-attention mechanism has sufficiently modeled the structural information of segmentation. Through the ablation studies, the proposed method has shown the performance improvement of the segmentation models and promoted fairness in the model predictions. The experimental results on the two standard benchmarks, i.e., SYNTHIA $\\rightarrow$ Cityscapes and GTA5 $\\rightarrow$ Cityscapes, have shown that our method achieved State-of-the-Art (SOTA) performance11The implementation of FREDOM is available at https://github.com/uark-cviu/FREDOM\nAuthors: Thanh-Dat Truong, Ngan T. H. Le, B. Raj, J. Cothren, Khoa Luu\nVenue: Computer Vision and Pattern Recognition\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper proposes a novel Fairness Domain Adaptation (FREDOM) approach to semantic scene segmentation, where a new adaptation framework will be introduced based on the fair treatment of class distributions to generally model the context of structural dependency.'}",
  "Faculty Name: bhiksha raj\nMetadata:\nPaperid: 0a8d38686b18f28aae1222529e6b9e8a60cab1c2\nTitle: UTOPIA: Unconstrained Tracking Objects without Preliminary Examination via Cross-Domain Adaptation\nYear: 2023\nAbstract: Multiple Object Tracking (MOT) aims to find bounding boxes and identities of targeted objects in consecutive video frames. While fully-supervised MOT methods have achieved high accuracy on existing datasets, they cannot generalize well on a newly obtained dataset or a new unseen domain. In this work, we first address the MOT problem from the cross-domain point of view, imitating the process of new data acquisition in practice. Then, a new cross-domain MOT adaptation from existing datasets is proposed without any pre-defined human knowledge in understanding and modeling objects. It can also learn and update itself from the target data feedback. The intensive experiments are designed on four challenging settings, including MOTSynth to MOT17, MOT17 to MOT20, MOT17 to VisDrone, and MOT17 to DanceTrack. We then prove the adaptability of the proposed self-supervised learning strategy.",
  "The intensive experiments are designed on four challenging settings, including MOTSynth to MOT17, MOT17 to MOT20, MOT17 to VisDrone, and MOT17 to DanceTrack. We then prove the adaptability of the proposed self-supervised learning strategy. The experiments also show superior performance on tracking metrics MOTA and IDF1, compared to fully supervised, unsupervised, and self-supervised state-of-the-art methods.\nAuthors: Pha Nguyen, Kha Gia Quach, J. Gauch, S. Khan, B. Raj, Khoa Luu\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A new cross-domain MOT adaptation from existing datasets is proposed without any pre-defined human knowledge in understanding and modeling objects, and it can also learn and update itself from the target data feedback.'}",
  "Faculty Name: bhiksha raj\nMetadata:\nPaperid: 100da279ee981960884a12dfc5a0697c24ed315a\nTitle: SoftMatch: Addressing the Quantity-Quality Trade-off in Semi-supervised Learning\nYear: 2023\nAbstract: The critical challenge of Semi-Supervised Learning (SSL) is how to effectively leverage the limited labeled data and massive unlabeled data to improve the model's generalization performance. In this paper, we first revisit the popular pseudo-labeling methods via a unified sample weighting formulation and demonstrate the inherent quantity-quality trade-off problem of pseudo-labeling with thresholding, which may prohibit learning. To this end, we propose SoftMatch to overcome the trade-off by maintaining both high quantity and high quality of pseudo-labels during training, effectively exploiting the unlabeled data. We derive a truncated Gaussian function to weight samples based on their confidence, which can be viewed as a soft version of the confidence threshold. We further enhance the utilization of weakly-learned classes by proposing a uniform alignment approach. In experiments, SoftMatch shows substantial improvements across a wide variety of benchmarks, including image, text, and imbalanced classification.",
  "We further enhance the utilization of weakly-learned classes by proposing a uniform alignment approach. In experiments, SoftMatch shows substantial improvements across a wide variety of benchmarks, including image, text, and imbalanced classification.\nAuthors: Hao Chen, R. Tao, Yue Fan, Yidong Wang, Jindong Wang, B. Schiele, Xingxu Xie, B. Raj, M. Savvides\nVenue: International Conference on Learning Representations\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper revisits the popular pseudo-labeling methods via a unified sample weighting formulation and demonstrates the inherent quantity-quality trade-off problem of pseudo-labels with thresholding, which may prohibit learning.'}",
  "Faculty Name: bhiksha raj\nMetadata:\nPaperid: 11c50900f50036fb3247be7c83849a8774a4ba60\nTitle: Fixed Inter-Neuron Covariability Induces Adversarial Robustness\nYear: 2023\nAbstract: The vulnerability to adversarial perturbations is a major flaw of Deep Neural Networks (DNNs) that raises question about their reliability when in real-world scenarios. On the other hand, human perception, which DNNs are supposed to emulate, is highly robust to such perturbations, indicating that there may be certain features of the human perception that make it robust but are not represented in the current class of DNNs. One such feature is that the activity of biological neurons is correlated and the structure of this correlation tends to be rather rigid over long spans of times, even if it hampers performance and learning.",
  "One such feature is that the activity of biological neurons is correlated and the structure of this correlation tends to be rather rigid over long spans of times, even if it hampers performance and learning. We hypothesize that integrating such constraints on the activations of a DNN would improve its adversarial robustness, and, to test this hypothesis, we have developed the Self-Consistent Activation (SCA) layer, which comprises of neurons whose activations are consistent with each other, as they conform to a fixed, but learned, covariability pattern.",
  "When evaluated on image and sound recognition tasks, the models with a SCA layer achieved high accuracy, and exhibited significantly greater robustness than multi-layer perceptron models to state-of-the-art Auto-PGD adversarial attacks \\textit{without being trained on adversarially perturbed data\nAuthors: Muhammad A Shah, B. Raj\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The SCA layer is developed, which comprises of neurons whose activations are consistent with each other, as they conform to a fixed, but learned, covariability pattern, and exhibited significantly greater robustness than multi-layer perceptron models to state-of-the-art Auto-PGD adversarial attacks.'}",
  "Faculty Name: bhiksha raj\nMetadata:\nPaperid: 1de2dcb5de694920f50f000a3795eb0ca54d57ab\nTitle: LoFT: Local Proxy Fine-tuning For Improving Transferability Of Adversarial Attacks Against Large Language Model\nYear: 2023\nAbstract: It has been shown that Large Language Model (LLM) alignments can be circumvented by appending specially crafted attack suffixes with harmful queries to elicit harmful responses. To conduct attacks against private target models whose characterization is unknown, public models can be used as proxies to fashion the attack, with successful attacks being transferred from public proxies to private target models. The success rate of attack depends on how closely the proxy model approximates the private model. We hypothesize that for attacks to be transferrable, it is sufficient if the proxy can approximate the target model in the neighborhood of the harmful query. Therefore, in this paper, we propose \\emph{Local Fine-Tuning (LoFT)}, \\textit{i.e.}, fine-tuning proxy models on similar queries that lie in the lexico-semantic neighborhood of harmful queries to decrease the divergence between the proxy and target models.",
  "Therefore, in this paper, we propose \\emph{Local Fine-Tuning (LoFT)}, \\textit{i.e.}, fine-tuning proxy models on similar queries that lie in the lexico-semantic neighborhood of harmful queries to decrease the divergence between the proxy and target models. First, we demonstrate three approaches to prompt private target models to obtain similar queries given harmful queries. Next, we obtain data for local fine-tuning by eliciting responses from target models for the generated similar queries. Then, we optimize attack suffixes to generate attack prompts and evaluate the impact of our local fine-tuning on the attack's success rate. Experiments show that local fine-tuning of proxy models improves attack transferability and increases attack success rate by $39\\%$, $7\\%$, and $0.5\\%$ (absolute) on target models ChatGPT, GPT-4, and Claude respectively.",
  "Experiments show that local fine-tuning of proxy models improves attack transferability and increases attack success rate by $39\\%$, $7\\%$, and $0.5\\%$ (absolute) on target models ChatGPT, GPT-4, and Claude respectively.\nAuthors: Muhammad Ahmed Shah, Roshan Sharma, Hira Dhamyal, R. Olivier, Ankit Shah, Dareen Alharthi, Hazim T Bukhari, Massa Baali, Soham Deshmukh, Michael Kuhlmann, Bhiksha Raj, Rita Singh\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Local fine-tuning of proxy models improves attack transferability and increases attack success rate by $39, $7, and $0.5$ (absolute) on target models ChatGPT, GPT-4, and Claude respectively.'}",
  "Faculty Name: bhiksha raj\nMetadata:\nPaperid: 22c9eb4868c5cabb26d132e0a160b9a093579f08\nTitle: Understanding political polarization using language models: A dataset and method\nYear: 2023\nAbstract: Our paper aims to analyze political polarization in US political system using language models, and thereby help candidates make an informed decision. The availability of this information will help voters understand their candidates' views on the economy, healthcare, education, and other social issues. Our main contributions are a dataset extracted from Wikipedia that spans the past 120 years and a language model\u2010based method that helps analyze how polarized a candidate is. Our data are divided into two parts, background information and political information about a candidate, since our hypothesis is that the political views of a candidate should be based on reason and be independent of factors such as birthplace, alma mater, and so forth. We further split this data into four phases chronologically, to help understand if and how the polarization amongst candidates changes. This data has been cleaned to remove biases.",
  "We further split this data into four phases chronologically, to help understand if and how the polarization amongst candidates changes. This data has been cleaned to remove biases. To understand the polarization, we begin by showing results from some classical language models in Word2Vec and Doc2Vec. And then use more powerful techniques like the Longformer, a transformer\u2010based encoder, to assimilate more information and find the nearest neighbors of each candidate based on their political view and their background. The code and data for the project will be available here: \u201chttps://github.com/samirangode/Understanding_Polarization\u201d\nAuthors: Samiran Gode, Supreeth Bare, B. Raj, H. Yoo\nVenue: The AI Magazine\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The main contributions are a dataset extracted from Wikipedia that spans the past 120 years and a language model\u2010based method that helps analyze how polarized a candidate is.'}",
  "Faculty Name: bhiksha raj\nMetadata:\nPaperid: 255bad49d29202e2d255926ab0983c125dcce835\nTitle: Evaluating Speech Synthesis by Training Recognizers on Synthetic Speech\nYear: 2023\nAbstract: Modern speech synthesis systems have improved significantly, with synthetic speech being indistinguishable from real speech. However, efficient and holistic evaluation of synthetic speech still remains a significant challenge. Human evaluation using Mean Opinion Score (MOS) is ideal, but inefficient due to high costs. Therefore, researchers have developed auxiliary automatic metrics like Word Error Rate (WER) to measure intelligibility. Prior works focus on evaluating synthetic speech based on pre-trained speech recognition models, however, this can be limiting since this approach primarily measures speech intelligibility. In this paper, we propose an evaluation technique involving the training of an ASR model on synthetic speech and assessing its performance on real speech. Our main assumption is that by training the ASR model on the synthetic speech, the WER on real speech reflects the similarity between distributions, a broader assessment of synthetic speech quality beyond intelligibility.",
  "Our main assumption is that by training the ASR model on the synthetic speech, the WER on real speech reflects the similarity between distributions, a broader assessment of synthetic speech quality beyond intelligibility. Our proposed metric demonstrates a strong correlation with both MOS naturalness and MOS intelligibility when compared to SpeechLMScore and MOSNet on three recent Text-to-Speech (TTS) systems: MQTTS, StyleTTS, and YourTTS.\nAuthors: Dareen Alharthi, Roshan Sharma, Hira Dhamyal, Soumi Maiti, Bhiksha Raj, Rita Singh\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper proposes an evaluation technique involving the training of an ASR model on synthetic speech and assessing its performance on real speech, and demonstrates a strong correlation with both MOS naturalness and MOS intelligibility when compared to SpeechLMScore and MosNet on three recent Text-to-Speech systems.'}",
  "Faculty Name: bhiksha raj\nMetadata:\nPaperid: 2a8f592c31d8de9906183b081095b9842025f792\nTitle: Rethinking Audiovisual Segmentation with Semantic Quantization and Decomposition\nYear: 2023\nAbstract: Audiovisual segmentation (AVS) is a challenging task that aims to segment visual objects in videos based on their associated acoustic cues. With multiple sound sources involved, establishing robust correspondences between audio and visual contents poses unique challenges due to its (1) intricate entanglement across sound sources and (2) frequent shift among sound events. Assuming sound events occur independently, the multi-source semantic space (which encompasses all possible semantic categories) can be represented as the Cartesian product of single-source sub-spaces. This motivates us to decompose the multi-source audio semantics into single-source semantics, enabling more effective interaction with visual content. Specifically, we propose a semantic decomposition method based on product quantization, where the multi-source semantics can be decomposed and represented by several quantized single-source semantics.",
  "This motivates us to decompose the multi-source audio semantics into single-source semantics, enabling more effective interaction with visual content. Specifically, we propose a semantic decomposition method based on product quantization, where the multi-source semantics can be decomposed and represented by several quantized single-source semantics. Furthermore, we introduce a global-to-local quantization mechanism, which distills knowledge from stable global (clip-level) features into local (frame-level) ones, to handle the constant shift of audio semantics. Extensive experiments demonstrate that semantically quantized and decomposed audio representation significantly improves AVS performance, e.g., +21.2% mIoU on the most challenging AVS-Semantic benchmark.\nAuthors: Xiang Li, Jinglu Wang, Xiaohao Xu, Xiulian Peng, Rita Singh, Yan Lu, Bhiksha Raj\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes a semantic decomposition method based on product quantization, where the multi-source semantics can be decomposed and represented by several quantized single-source semantics, enabling more effective interaction with visual content.'}",
  "Faculty Name: bhiksha raj\nMetadata:\nPaperid: 35a8802facb4441787017ac5c630a8fa0f2413bd\nTitle: Prolonged school closure during the pandemic time in successive waves of COVID-19- vulnerability of children to sexual abuses \u2013 A case study in Tamil Nadu, India\nYear: 2023\nAbstract: None\nAuthors: Kandaswamy Paramasivan, B. Raj, Nandan Sudarasanam, R. Subburaj\nVenue: Heliyon\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Considering that the median delay in filing CSA complaints was above 30 days in the mild and post-intervention periods, the upsurge of cases in the more relaxed phases indicates increased occurrences of CSA during strict lockdowns.'}",
  "Faculty Name: bhiksha raj\nMetadata:\nPaperid: 37e8e07d3ecfa43a1e64d48202c73f597e6f9fee\nTitle: Towards Noise-Tolerant Speech-Referring Video Object Segmentation: Bridging Speech and Text\nYear: 2023\nAbstract: None\nAuthors: Xiang Li, Jinglu Wang, Xiaohao Xu, Muqiao Yang, Fan Yang, Yizhou Zhao, Rita Singh, Bhiksha Raj\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: None",
  "Faculty Name: bhiksha raj\nMetadata:\nPaperid: 3bd320ddb25886417ae90011b00f13f5d558097b\nTitle: BASS: Block-wise Adaptation for Speech Summarization\nYear: 2023\nAbstract: End-to-end speech summarization has been shown to improve performance over cascade baselines. However, such models are difficult to train on very large inputs (dozens of minutes or hours) owing to compute restrictions and are hence trained with truncated model inputs. Truncation leads to poorer models, and a solution to this problem rests in block-wise modeling, i.e., processing a portion of the input frames at a time. In this paper, we develop a method that allows one to train summarization models on very long sequences in an incremental manner. Speech summarization is realized as a streaming process, where hypothesis summaries are updated every block based on new acoustic information. We devise and test strategies to pass semantic context across the blocks. Experiments on the How2 dataset demonstrate that the proposed block-wise training method improves by 3 points absolute on ROUGE-L over a truncated input baseline.",
  "We devise and test strategies to pass semantic context across the blocks. Experiments on the How2 dataset demonstrate that the proposed block-wise training method improves by 3 points absolute on ROUGE-L over a truncated input baseline.\nAuthors: Roshan Sharma, Kenneth Zheng, Siddhant Arora, Shinji Watanabe, Rita Singh, B. Raj\nVenue: Interspeech\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper develops a method that allows one to train summarization models on very long sequences in an incremental manner and devise and test strategies to pass semantic context across the blocks.'}",
  "Faculty Name: bhiksha raj\nMetadata:\nPaperid: 4628f0c28a8ed231168d1a27a93ddb938da4102d\nTitle: Psychoacoustic Challenges Of Speech Enhancement On VoIP Platforms\nYear: 2023\nAbstract: Within the ambit of VoIP (Voice over Internet Protocol) telecommunications, the complexities introduced by acoustic transformations merit rigorous analysis. This research, rooted in the exploration of proprietary sender-side denoising effects, meticulously evaluates platforms such as Google Meets and Zoom. The study draws upon the Deep Noise Suppression (DNS) 2020 dataset, ensuring a structured examination tailored to various denoising settings and receiver interfaces. A methodological novelty is introduced via the Oaxaca decomposition, traditionally an econometric tool, repurposed herein to analyze acoustic-phonetic perturbations within VoIP systems. To further ground the implications of these transformations, psychoacoustic metrics, specifically PESQ and STOI, were harnessed to furnish a comprehensive understanding of speech alterations. Cumulatively, the insights garnered underscore the intricate landscape of VoIP-influenced acoustic dynamics.",
  "To further ground the implications of these transformations, psychoacoustic metrics, specifically PESQ and STOI, were harnessed to furnish a comprehensive understanding of speech alterations. Cumulatively, the insights garnered underscore the intricate landscape of VoIP-influenced acoustic dynamics. In addition to the primary findings, a multitude of metrics are reported, extending the research purview. Moreover, out-of-domain benchmarking for both time and time-frequency domain speech enhancement models is included, thereby enhancing the depth and applicability of this inquiry. Repository: github.com/deepology/VoIP-DNS-Challenge\nAuthors: Joseph Konan, Ojas Bhargave, Shikhar Agnihotri, Shuo Han, YUNYANG ZENG, Ankit Shah, Bhiksha Raj\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This research, rooted in the exploration of proprietary sender-side denoising effects, meticulously evaluates platforms such as Google Meets and Zoom, and draws upon the Deep Noise Suppression (DNS) 2020 dataset, ensuring a structured examination tailored to various denoised settings and receiver interfaces.'}",
  "Faculty Name: bhiksha raj\nMetadata:\nPaperid: 4e6a004e4f9a3b489004a2efb5b25b0bcd0f48b5\nTitle: Understanding Political Polarisation using Language Models: A dataset and method\nYear: 2023\nAbstract: Our paper aims to analyze political polarization in US political system using Language Models, and thereby help candidates make an informed decision. The availability of this information will help voters understand their candidates views on the economy, healthcare, education and other social issues. Our main contributions are a dataset extracted from Wikipedia that spans the past 120 years and a Language model based method that helps analyze how polarized a candidate is. Our data is divided into 2 parts, background information and political information about a candidate, since our hypothesis is that the political views of a candidate should be based on reason and be independent of factors such as birthplace, alma mater, etc. We further split this data into 4 phases chronologically, to help understand if and how the polarization amongst candidates changes. This data has been cleaned to remove biases.",
  "We further split this data into 4 phases chronologically, to help understand if and how the polarization amongst candidates changes. This data has been cleaned to remove biases. To understand the polarization we begin by showing results from some classical language models in Word2Vec and Doc2Vec. And then use more powerful techniques like the Longformer, a transformer based encoder, to assimilate more information and find the nearest neighbors of each candidate based on their political view and their background.\nAuthors: Samiran Gode, Supreeth Bare, B. Raj, H. Yoo\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A dataset extracted from Wikipedia that spans the past 120 years and a Language model based method that helps analyze how polarized a candidate is are used to understand the polarization.'}",
  "Faculty Name: bhiksha raj\nMetadata:\nPaperid: 593a603354c09d151440ae044de1d80324a2ab01\nTitle: An Approach to Ontological Learning from Weak Labels\nYear: 2023\nAbstract: Ontologies encompass a formal representation of knowledge through the definition of concepts or properties of a domain, and the relationships between those concepts. In this work, we seek to investigate whether using this ontological information will improve learning from weakly labeled data, which are easier to collect since it requires only the presence or absence of an event to be known. We use the AudioSet ontology and dataset, which contains audio clips weakly labeled with the ontology concepts and the ontology providing the \"Is A\" relations between the concepts. We first re-implemented the model proposed by [1] with modifications to fit the multi-label scenario and then expand on that idea by using a Graph Convolutional Network (GCN) to model the ontology information to learn the concepts.",
  "We first re-implemented the model proposed by [1] with modifications to fit the multi-label scenario and then expand on that idea by using a Graph Convolutional Network (GCN) to model the ontology information to learn the concepts. We find that the baseline Twin Neural Network (TNN) does not perform better by incorporating ontology information in the weak and multi-label scenario, but that the GCN does capture the ontology knowledge better for weak, multi-labeled data. We also investigate how different modules can tolerate noises introduced from weak labels and better incorporate ontology information. Our best TNN-GCN model achieves mAP=0.45 and AUC=0.87 for lower-level concepts and mAP=0.72 and AUC=0.86 for higher-level concepts, which is an improvement over the baseline TNN but about the same as our models that do not use ontology information.",
  "Authors: Ankit Shah, Larry Tang, Po Hao Chou, Yilun Zheng, Ziqian Ge, B. Raj\nVenue: IEEE International Conference on Acoustics, Speech, and Signal Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work re-implements the model proposed by [1] with modifications to fit the multi-label scenario and expands on that idea by using a Graph Convolutional Network (GCN) to model the ontology information to learn the concepts.'}",
  "Faculty Name: bhiksha raj\nMetadata:\nPaperid: 5a3307b2e64bbcaff1202e261b8a83f7d03418a8\nTitle: Rethinking Voice-Face Correlation: A Geometry View\nYear: 2023\nAbstract: Previous works on voice-face matching and voice-guided face synthesis demonstrate strong correlations between voice and face, but mainly rely on coarse semantic cues such as gender, age, and emotion. In this paper, we aim to investigate the capability of reconstructing the 3D facial shape from voice from a geometry perspective without any semantic information. We propose a voice-anthropometric measurement (AM)-face paradigm, which identifies predictable facial AMs from the voice and uses them to guide 3D face reconstruction. By leveraging AMs as a proxy to link the voice and face geometry, we can eliminate the influence of unpredictable AMs and make the face geometry tractable. Our approach is evaluated on our proposed dataset with ground-truth 3D face scans and corresponding voice recordings, and we find significant correlations between voice and specific parts of the face geometry, such as the nasal cavity and cranium.",
  "Our approach is evaluated on our proposed dataset with ground-truth 3D face scans and corresponding voice recordings, and we find significant correlations between voice and specific parts of the face geometry, such as the nasal cavity and cranium. Our work offers a new perspective on voice-face correlation and can serve as a good empirical study for anthropometry science.\nAuthors: Xiang Li, Yandong Wen, Muqiao Yang, Jinglu Wang, Rita Singh, B. Raj\nVenue: ACM Multimedia\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes a voice-anthropometric measurement (AM)-face paradigm, which identifies predictable facial AMs from the voice and uses them to guide 3D face reconstruction and finds significant correlations between voice and specific parts of the face geometry, such as the nasal cavity and cranium.'}",
  "Faculty Name: bhiksha raj\nMetadata:\nPaperid: 611f9ee6eef0936462cd78f371798d0699951c59\nTitle: Paaploss: A Phonetic-Aligned Acoustic Parameter Loss for Speech Enhancement\nYear: 2023\nAbstract: Despite rapid advancement in recent years, current speech enhancement models often produce speech that differs in perceptual quality from real clean speech. We propose a learning objective that formalizes differences in perceptual quality, by using domain knowledge of acoustic-phonetics. We identify temporal acoustic parameters \u2013 such as spectral tilt, spectral flux, shimmer, etc. \u2013 that are non-differentiable, and we develop a neural network estimator that can accurately predict their time-series values across an utterance. We also model phoneme-specific weights for each feature, as the acoustic parameters are known to show different behavior in different phonemes. We can add this criterion as an auxiliary loss to any model that produces speech, to optimize speech outputs to match the values of clean speech in these features. Experimentally we show that it improves speech enhancement workflows in both time-domain and time-frequency domain, as measured by standard evaluation metrics.",
  "We can add this criterion as an auxiliary loss to any model that produces speech, to optimize speech outputs to match the values of clean speech in these features. Experimentally we show that it improves speech enhancement workflows in both time-domain and time-frequency domain, as measured by standard evaluation metrics. We also provide an analysis of phoneme-dependent improvement on acoustic parameters, demonstrating the additional interpretability that our method provides. This analysis can suggest which features are currently the bottleneck for improvement.\nAuthors: Muqiao Yang, Joseph Konan, David Bick, YUNYANG ZENG, Shuo Han, Anurag Kumar, Shinji Watanabe, B. Raj\nVenue: IEEE International Conference on Acoustics, Speech, and Signal Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A learning objective is proposed that formalizes differences in perceptual quality, by using domain knowledge of acoustic-phonetics, and a neural network estimator is developed that can accurately predict their time-series values across an utterance.'}",
  "Faculty Name: bhiksha raj\nMetadata:\nPaperid: 6ca2caa4edecc5f08949756266db241ef5e51fc1\nTitle: uSee: Unified Speech Enhancement and Editing with Conditional Diffusion Models\nYear: 2023\nAbstract: Speech enhancement aims to improve the quality of speech signals in terms of quality and intelligibility, and speech editing refers to the process of editing the speech according to specific user needs. In this paper, we propose a Unified Speech Enhancement and Editing (uSee) model with conditional diffusion models to handle various tasks at the same time in a generative manner. Specifically, by providing multiple types of conditions including self-supervised learning embeddings and proper text prompts to the score-based diffusion model, we can enable controllable generation of the unified speech enhancement and editing model to perform corresponding actions on the source speech. Our experiments show that our proposed uSee model can achieve superior performance in both speech denoising and dereverberation compared to other related generative speech enhancement models, and can perform speech editing given desired environmental sound text description, signal-to-noise ratios (SNR), and room impulse responses (RIR).",
  "Our experiments show that our proposed uSee model can achieve superior performance in both speech denoising and dereverberation compared to other related generative speech enhancement models, and can perform speech editing given desired environmental sound text description, signal-to-noise ratios (SNR), and room impulse responses (RIR). Demos of the generated speech are available at https://muqiaoy.github.io/usee.\nAuthors: Muqiao Yang, Chunlei Zhang, Yong Xu, Zhongweiyang Xu, Heming Wang, Bhiksha Raj, Dong Yu\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The proposed uSee model can achieve superior performance in both speech denoising and dereverberation compared to other related generative speech enhancement models, and can perform speech editing given desired environmental sound text description, signal-to-noise ratios (SNR), and room impulse responses (RIR).'}",
  "Faculty Name: bhiksha raj\nMetadata:\nPaperid: 7333be530df311b3148e9857ce9f481975cf0a9b\nTitle: Improving Perceptual Quality, Intelligibility, and Acoustics on VoIP Platforms\nYear: 2023\nAbstract: In this paper, we present a method for fine-tuning models trained on the Deep Noise Suppression (DNS) 2020 Challenge to improve their performance on Voice over Internet Protocol (VoIP) applications. Our approach involves adapting the DNS 2020 models to the specific acoustic characteristics of VoIP communications, which includes distortion and artifacts caused by compression, transmission, and platform-specific processing. To this end, we propose a multi-task learning framework for VoIP-DNS that jointly optimizes noise suppression and VoIP-specific acoustics for speech enhancement. We evaluate our approach on a diverse VoIP scenarios and show that it outperforms both industry performance and state-of-the-art methods for speech enhancement on VoIP applications.",
  "We evaluate our approach on a diverse VoIP scenarios and show that it outperforms both industry performance and state-of-the-art methods for speech enhancement on VoIP applications. Our results demonstrate the potential of models trained on DNS-2020 to be improved and tailored to different VoIP platforms using VoIP-DNS, whose findings have important applications in areas such as speech recognition, voice assistants, and telecommunication.\nAuthors: Joseph Konan, Ojas Bhargave, Shikhar Agnihotri, Hojeong Lee, Ankit Shah, Shuo Han, YUNYANG ZENG, Amanda Shu, Haohui Liu, Xuankai Chang, Hamza Khalid, Minseon Gwak, Kawon Lee, Minjeong Kim, B. Raj\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A multi-task learning framework forVoIP-DNS that jointly optimizes noise suppression and VoIP-specific acoustics for speech enhancement and outperforms both industry performance and state-of-the-art methods for speech Enhancement on VoIP applications is proposed.'}",
  "Faculty Name: bhiksha raj\nMetadata:\nPaperid: 740488982dee323d559f2dae70b1f4b3aa5f7171\nTitle: Approach to Learning Generalized Audio Representation Through Batch Embedding Covariance Regularization and Constant-Q Transforms\nYear: 2023\nAbstract: General-purpose embedding is highly desirable for few-shot even zero-shot learning in many application scenarios, including audio tasks. In order to understand representations better, we conducted a thorough error analysis and visualization of HEAR 2021 submission results. Inspired by the analysis, this work experiments with different front-end audio preprocessing methods, including Constant-Q Transform (CQT) and Short-time Fourier transform (STFT), and proposes a Batch Embedding Covariance Regularization (BECR) term to uncover a more holistic simulation of the frequency information received by the human auditory system. We tested the models on the suite of HEAR 2021 tasks, which encompass a broad category of tasks.",
  "We tested the models on the suite of HEAR 2021 tasks, which encompass a broad category of tasks. Preliminary results show (1) the proposed BECR can incur a more dispersed embedding on the test set, (2) BECR improves the PaSST model without extra computation complexity, and (3) STFT preprocessing outperforms CQT in all tasks we tested. Github:https://github.com/ankitshah009/general_audio_embedding_hear_2021\nAuthors: Ankit Shah, Shuyi Chen, Kejun Zhou, Yue Chen, B. Raj\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Experiments with different front-end audio preprocessing methods are experiments, and a Batch Embedding Covariance Regularization (BECR) term is proposed to uncover a more holistic simulation of the frequency information received by the human auditory system.'}",
  "Faculty Name: bhiksha raj\nMetadata:\nPaperid: 74664618ad3b44eb191ba96fdff5b93f27a29ced\nTitle: Training on Foveated Images Improves Robustness to Adversarial Attacks\nYear: 2023\nAbstract: Deep neural networks (DNNs) have been shown to be vulnerable to adversarial attacks -- subtle, perceptually indistinguishable perturbations of inputs that change the response of the model. In the context of vision, we hypothesize that an important contributor to the robustness of human visual perception is constant exposure to low-fidelity visual stimuli in our peripheral vision. To investigate this hypothesis, we develop \\RBlur, an image transform that simulates the loss in fidelity of peripheral vision by blurring the image and reducing its color saturation based on the distance from a given fixation point. We show that compared to DNNs trained on the original images, DNNs trained on images transformed by \\RBlur are substantially more robust to adversarial attacks, as well as other, non-adversarial, corruptions, achieving up to 25\\% higher accuracy on perturbed data.",
  "We show that compared to DNNs trained on the original images, DNNs trained on images transformed by \\RBlur are substantially more robust to adversarial attacks, as well as other, non-adversarial, corruptions, achieving up to 25\\% higher accuracy on perturbed data.\nAuthors: Muhammad A Shah, B. Raj\nVenue: Neural Information Processing Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'DNNs trained on images transformed by \\\\RBlur are substantially more robust to adversarial attacks, as well as other, non-adversarial, corruptions, achieving up to 25\\\\% higher accuracy on perturbed data.'}",
  "Faculty Name: bhiksha raj\nMetadata:\nPaperid: 7a25aa397ae2a7f82df87a936ce6ff7f03b7ac4c\nTitle: Token Prediction as Implicit Classification to Identify LLM-Generated Text\nYear: 2023\nAbstract: This paper introduces a novel approach for identifying the possible large language models (LLMs) involved in text generation. Instead of adding an additional classification layer to a base LM, we reframe the classification task as a next-token prediction task and directly fine-tune the base LM to perform it. We utilize the Text-to-Text Transfer Transformer (T5) model as the backbone for our experiments. We compared our approach to the more direct approach of utilizing hidden states for classification. Evaluation shows the exceptional performance of our method in the text classification task, highlighting its simplicity and efficiency. Furthermore, interpretability studies on the features extracted by our model reveal its ability to differentiate distinctive writing styles among various LLMs even in the absence of an explicit classifier.",
  "Evaluation shows the exceptional performance of our method in the text classification task, highlighting its simplicity and efficiency. Furthermore, interpretability studies on the features extracted by our model reveal its ability to differentiate distinctive writing styles among various LLMs even in the absence of an explicit classifier. We also collected a dataset named OpenLLMText, containing approximately 340k text samples from human and LLMs, including GPT3.5, PaLM, LLaMA, and GPT2.\nAuthors: Yutian Chen, Hao Kang, Vivian Zhai, Liangze Li, Rita Singh, Bhiksha Raj\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Evaluation shows the exceptional performance of the method in the text classification task, highlighting its simplicity and efficiency, and interpretability studies on the features extracted by the model reveal its ability to differentiate distinctive writing styles among various LLMs even in the absence of an explicit classifier.'}",
  "Faculty Name: bhiksha raj\nMetadata:\nPaperid: 8665c864d71df1e918d2010778fc06712f4e5550\nTitle: Imprecise Label Learning: A Unified Framework for Learning with Various Imprecise Label Configurations\nYear: 2023\nAbstract: Learning with reduced labeling standards, such as noisy label, partial label, and multiple label candidates, which we generically refer to as \\textit{imprecise} labels, is a commonplace challenge in machine learning tasks. Previous methods tend to propose specific designs for every emerging imprecise label configuration, which is usually unsustainable when multiple configurations of imprecision coexist. In this paper, we introduce imprecise label learning (ILL), a framework for the unification of learning with various imprecise label configurations. ILL leverages expectation-maximization (EM) for modeling the imprecise label information, treating the precise labels as latent variables.Instead of approximating the correct labels for training, it considers the entire distribution of all possible labeling entailed by the imprecise information.",
  "ILL leverages expectation-maximization (EM) for modeling the imprecise label information, treating the precise labels as latent variables.Instead of approximating the correct labels for training, it considers the entire distribution of all possible labeling entailed by the imprecise information. We demonstrate that ILL can seamlessly adapt to partial label learning, semi-supervised learning, noisy label learning, and, more importantly, a mixture of these settings. Notably, ILL surpasses the existing specified techniques for handling imprecise labels, marking the first unified framework with robust and effective performance across various challenging settings. We hope our work will inspire further research on this topic, unleashing the full potential of ILL in wider scenarios where precise labels are expensive and complicated to obtain.",
  "We hope our work will inspire further research on this topic, unleashing the full potential of ILL in wider scenarios where precise labels are expensive and complicated to obtain.\nAuthors: Hao Chen, Ankit Shah, Jindong Wang, R. Tao, Yidong Wang, Xingxu Xie, Masashi Sugiyama, Rita Singh, B. Raj\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Imprecise label learning (ILL) is introduced, a framework for the unification of learning with various imprecise label configurations, marking the first unified framework with robust and effective performance across various challenging settings.'}",
  "Faculty Name: bhiksha raj\nMetadata:\nPaperid: 9f9cdced51568c623ec447bf0ea9709b383b5a0f\nTitle: Understanding and Mitigating the Label Noise in Pre-training on Downstream Tasks\nYear: 2023\nAbstract: Pre-training on large-scale datasets and then fine-tuning on downstream tasks have become a standard practice in deep learning. However, pre-training data often contain label noise that may adversely affect the generalization of the model. This paper aims to understand the nature of noise in pre-training datasets and to mitigate its impact on downstream tasks. More specifically, through extensive experiments of supervised pre-training models on synthetic noisy ImageNet-1K and YFCC15M datasets, we demonstrate that while slight noise in pre-training can benefit in-domain (ID) transfer performance, where the training and testing data share the same distribution, it always deteriorates out-of-domain (OOD) performance, where training and testing data distribution are different. We empirically verify that the reason behind is noise in pre-training shapes the feature space differently.",
  "We empirically verify that the reason behind is noise in pre-training shapes the feature space differently. We then propose a lightweight black-box tuning method (NMTune) to affine the feature space to mitigate the malignant effect of noise and improve generalization on both ID and OOD tasks, considering one may not be able to fully fine-tune or even access the pre-trained models. We conduct practical experiments on popular vision and language models that are pre-trained on noisy data for evaluation of our approach. Our analysis and results show the importance of this interesting and novel research direction, which we term Noisy Model Learning.\nAuthors: Hao Chen, Jindong Wang, Ankit Shah, Ran Tao, Hongxin Wei, Xingxu Xie, Masashi Sugiyama, Bhiksha Raj\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A lightweight black-box tuning method (NMTune) is proposed to affine the feature space to mitigate the malignant effect of noise and improve generalization on both ID and OOD tasks, considering one may not be able to fully fine-tune or even access the pre-trained models.'}",
  "Faculty Name: bhiksha raj\nMetadata:\nPaperid: a6e3a10a6286967413e3406374bbeea533640030\nTitle: The Hidden Dance of Phonemes and Visage: Unveiling the Enigmatic Link between Phonemes and Facial Features\nYear: 2023\nAbstract: This work unveils the enigmatic link between phonemes and facial features. Traditional studies on voice-face correlations typically involve using a long period of voice input, including generating face images from voices and reconstructing 3D face meshes from voices. However, in situations like voice-based crimes, the available voice evidence may be short and limited. Additionally, from a physiological perspective, each segment of speech -- phoneme -- corresponds to different types of airflow and movements in the face. Therefore, it is advantageous to discover the hidden link between phonemes and face attributes. In this paper, we propose an analysis pipeline to help us explore the voice-face relationship in a fine-grained manner, i.e., phonemes v.s. facial anthropometric measurements (AM). We build an estimator for each phoneme-AM pair and evaluate the correlation through hypothesis testing.",
  "In this paper, we propose an analysis pipeline to help us explore the voice-face relationship in a fine-grained manner, i.e., phonemes v.s. facial anthropometric measurements (AM). We build an estimator for each phoneme-AM pair and evaluate the correlation through hypothesis testing. Our results indicate that AMs are more predictable from vowels compared to consonants, particularly with plosives. Additionally, we observe that if a specific AM exhibits more movement during phoneme pronunciation, it is more predictable. Our findings support those in physiology regarding correlation and lay the groundwork for future research on speech-face multimodal learning.\nAuthors: Liao Qu, X. Zou, Xiang Li, Yandong Wen, Rita Singh, B. Raj\nVenue: Interspeech\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes an analysis pipeline to help explore the voice-face relationship in a fine-grained manner, i.s. phonemes v. facial anthropometric measurements (AM), and indicates that AMs are more predictable from vowels compared to consonants, particularly with plosives.'}",
  "Faculty Name: bhiksha raj\nMetadata:\nPaperid: ac856b6b7b3f32fb34320b7170526d3ab15ba5f3\nTitle: Fairness Continual Learning Approach to Semantic Scene Understanding in Open-World Environments\nYear: 2023\nAbstract: Continual semantic segmentation aims to learn new classes while maintaining the information from the previous classes. Although prior studies have shown impressive progress in recent years, the fairness concern in the continual semantic segmentation needs to be better addressed. Meanwhile, fairness is one of the most vital factors in deploying the deep learning model, especially in human-related or safety applications. In this paper, we present a novel Fairness Continual Learning approach to the semantic segmentation problem. In particular, under the fairness objective, a new fairness continual learning framework is proposed based on class distributions. Then, a novel Prototypical Contrastive Clustering loss is proposed to address the significant challenges in continual learning, i.e., catastrophic forgetting and background shift. Our proposed loss has also been proven as a novel, generalized learning paradigm of knowledge distillation commonly used in continual learning.",
  "Then, a novel Prototypical Contrastive Clustering loss is proposed to address the significant challenges in continual learning, i.e., catastrophic forgetting and background shift. Our proposed loss has also been proven as a novel, generalized learning paradigm of knowledge distillation commonly used in continual learning. Moreover, the proposed Conditional Structural Consistency loss further regularized the structural constraint of the predicted segmentation. Our proposed approach has achieved State-of-the-Art performance on three standard scene understanding benchmarks, i.e., ADE20K, Cityscapes, and Pascal VOC, and promoted the fairness of the segmentation model.\nAuthors: Thanh-Dat Truong, Hoang-Quan Nguyen, B. Raj, Khoa Luu\nVenue: Neural Information Processing Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A novel Fairness Continual Learning approach to the semantic segmentation problem is presented, in particular, a new fairness continual learning framework is proposed based on class distributions and a novel Prototypical Contrastive Clustering loss is proposed to address the significant challenges in continual learning.'}",
  "Faculty Name: bhiksha raj\nMetadata:\nPaperid: b7e2074934985b6112b6bce8c3680b14e621fdfe\nTitle: Importance of negative sampling in weak label learning\nYear: 2023\nAbstract: Weak-label learning is a challenging task that requires learning from data\"bags\"containing positive and negative instances, but only the bag labels are known. The pool of negative instances is usually larger than positive instances, thus making selecting the most informative negative instance critical for performance. Such a selection strategy for negative instances from each bag is an open problem that has not been well studied for weak-label learning. In this paper, we study several sampling strategies that can measure the usefulness of negative instances for weak-label learning and select them accordingly. We test our method on CIFAR-10 and AudioSet datasets and show that it improves the weak-label classification performance and reduces the computational cost compared to random sampling methods. Our work reveals that negative instances are not all equally irrelevant, and selecting them wisely can benefit weak-label learning.",
  "We test our method on CIFAR-10 and AudioSet datasets and show that it improves the weak-label classification performance and reduces the computational cost compared to random sampling methods. Our work reveals that negative instances are not all equally irrelevant, and selecting them wisely can benefit weak-label learning.\nAuthors: Ankit Shah, Fuyu Tang, Zelin Ye, Rita Singh, Bhiksha Raj\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work reveals that negative instances are not all equally irrelevant, and selecting them wisely can benefit weak-label learning, and reduces the computational cost compared to random sampling methods.'}",
  "Faculty Name: bhiksha raj\nMetadata:\nPaperid: d7911ff6f80bd9f053ef8d304f15791f510f5cda\nTitle: Completing Visual Objects via Bridging Generation and Segmentation\nYear: 2023\nAbstract: This paper presents a novel approach to object completion, with the primary goal of reconstructing a complete object from its partially visible components. Our method, named MaskComp, delineates the completion process through iterative stages of generation and segmentation. In each iteration, the object mask is provided as an additional condition to boost image generation, and, in return, the generated images can lead to a more accurate mask by fusing the segmentation of images. We demonstrate that the combination of one generation and one segmentation stage effectively functions as a mask denoiser. Through alternation between the generation and segmentation stages, the partial object mask is progressively refined, providing precise shape guidance and yielding superior object completion results. Our experiments demonstrate the superiority of MaskComp over existing approaches, e.g., ControlNet and Stable Diffusion, establishing it as an effective solution for object completion.",
  "Through alternation between the generation and segmentation stages, the partial object mask is progressively refined, providing precise shape guidance and yielding superior object completion results. Our experiments demonstrate the superiority of MaskComp over existing approaches, e.g., ControlNet and Stable Diffusion, establishing it as an effective solution for object completion.\nAuthors: Xiang Li, Yinpeng Chen, Chung-Ching Lin, Rita Singh, Bhiksha Raj, Zicheng Liu\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The method, named MaskComp, delineates the completion process through iterative stages of generation and segmentation, and demonstrates that the combination of one generation and one segmentation stage effectively functions as a mask denoiser.'}",
  "Faculty Name: bhiksha raj\nMetadata:\nPaperid: dc157eba8bdb4cfe6ee65566d8295939ac5b4b37\nTitle: PaintSeg: Training-free Segmentation via Painting\nYear: 2023\nAbstract: The paper introduces PaintSeg, a new unsupervised method for segmenting objects without any training. We propose an adversarial masked contrastive painting (AMCP) process, which creates a contrast between the original image and a painted image in which a masked area is painted using off-the-shelf generative models. During the painting process, inpainting and outpainting are alternated, with the former masking the foreground and filling in the background, and the latter masking the background while recovering the missing part of the foreground object. Inpainting and outpainting, also referred to as I-step and O-step, allow our method to gradually advance the target segmentation mask toward the ground truth without supervision or training. PaintSeg can be configured to work with a variety of prompts, e.g. coarse masks, boxes, scribbles, and points.",
  "PaintSeg can be configured to work with a variety of prompts, e.g. coarse masks, boxes, scribbles, and points. Our experimental results demonstrate that PaintSeg outperforms existing approaches in coarse mask-prompt, box-prompt, and point-prompt segmentation tasks, providing a training-free solution suitable for unsupervised segmentation.\nAuthors: Xiang Li, Chung-Ching Lin, Yinpeng Chen, Zicheng Liu, Jinglu Wang, B. Raj\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'An adversarial masked contrastive painting process, which creates a contrast between the original image and a painted image in which a masked area is painted using off-the-shelf generative models, providing a training-free solution suitable for unsupervised segmentation.'}",
  "Faculty Name: bhiksha raj\nMetadata:\nPaperid: e146e5221c124d93f69516c5ae7e1b7b1822848e\nTitle: TAPLoss: A Temporal Acoustic Parameter Loss for Speech Enhancement\nYear: 2023\nAbstract: Speech enhancement models have greatly progressed in recent years, but still show limits in perceptual quality of their speech outputs. We propose an objective for perceptual quality based on temporal acoustic parameters. These are fundamental speech features that play an essential role in various applications, including speaker recognition and paralinguistic analysis. We provide a differentiable estimator for four categories of low-level acoustic descriptors involving: frequency-related parameters, energy or amplitude-related parameters, spectral balance parameters, and temporal features. Un-like prior work that looks at aggregated acoustic parameters or a few categories of acoustic parameters, our temporal acoustic parameter (TAP) loss enables auxiliary optimization and improvement of many fine-grained speech characteristics in enhancement workflows. We show that adding TAPLoss as an auxiliary objective in speech enhancement produces speech with improved perceptual quality and intelligibility.",
  "We show that adding TAPLoss as an auxiliary objective in speech enhancement produces speech with improved perceptual quality and intelligibility. We use data from the Deep Noise Suppression 2020 Challenge to demonstrate that both time-domain models and time-frequency domain models can benefit from our method.\nAuthors: YUNYANG ZENG, Joseph Konan, Shuo Han, David Bick, Muqiao Yang, Anurag Kumar, Shinji Watanabe, B. Raj\nVenue: IEEE International Conference on Acoustics, Speech, and Signal Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work shows that adding TAPLoss as an auxiliary objective in speech enhancement produces speech with improved perceptual quality and intelligibility and uses data from the Deep Noise Suppression 2020 Challenge to demonstrate that both time-domain models and time-frequency domain models can benefit from the method.'}",
  "Faculty Name: bhiksha raj\nMetadata:\nPaperid: e2572e0adacfb116b19b25691e7f6b3749490a88\nTitle: Training Audio Captioning Models without Audio\nYear: 2023\nAbstract: Automated Audio Captioning (AAC) is the task of generating natural language descriptions given an audio stream. A typical AAC system requires manually curated training data of audio segments and corresponding text caption annotations. The creation of these audio-caption pairs is costly, resulting in general data scarcity for the task. In this work, we address this major limitation and propose an approach to train AAC systems using only text. Our approach leverages the multimodal space of contrastively trained audio-text models, such as CLAP. During training, a decoder generates captions conditioned on the pretrained CLAP text encoder. During inference, the text encoder is replaced with the pretrained CLAP audio encoder. To bridge the modality gap between text and audio embeddings, we propose the use of noise injection or a learnable adapter, during training.",
  "During training, a decoder generates captions conditioned on the pretrained CLAP text encoder. During inference, the text encoder is replaced with the pretrained CLAP audio encoder. To bridge the modality gap between text and audio embeddings, we propose the use of noise injection or a learnable adapter, during training. We find that the proposed text-only framework performs competitively with state-of-the-art models trained with paired audio, showing that efficient text-to-audio transfer is possible. Finally, we showcase both stylized audio captioning and caption enrichment while training without audio or human-created text captions.\nAuthors: Soham Deshmukh, Benjamin Elizalde, Dimitra Emmanouilidou, Bhiksha Raj, Rita Singh, Huaming Wang\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes an approach to train AAC systems using only text, and finds that the proposed text-only framework performs competitively with state-of-the-art models trained with paired audio, showing that efficient text-to-audio transfer is possible.'}",
  "Faculty Name: bhiksha raj\nMetadata:\nPaperid: f5a7a4fda49c657742072a2758f43b1cbcde3886\nTitle: Continual Contrastive Spoken Language Understanding\nYear: 2023\nAbstract: Recently, neural networks have shown impressive progress across diverse fields, with speech processing being no exception. However, recent breakthroughs in this area require extensive offline training using large datasets and tremendous computing resources. Unfortunately, these models struggle to retain their previously acquired knowledge when learning new tasks continually, and retraining from scratch is almost always impractical. In this paper, we investigate the problem of learning sequence-to-sequence models for spoken language understanding in a class-incremental learning (CIL) setting and we propose COCONUT, a CIL method that relies on the combination of experience replay and contrastive learning. Through a modified version of the standard supervised contrastive loss applied only to the rehearsal samples, COCONUT preserves the learned representations by pulling closer samples from the same class and pushing away the others. Moreover, we leverage a multimodal contrastive loss that helps the model learn more discriminative representations of the new data by aligning audio and text features.",
  "Moreover, we leverage a multimodal contrastive loss that helps the model learn more discriminative representations of the new data by aligning audio and text features. We also investigate different contrastive designs to combine the strengths of the contrastive loss with teacher-student architectures used for distillation. Experiments on two established SLU datasets reveal the effectiveness of our proposed approach and significant improvements over the baselines. We also show that COCONUT can be combined with methods that operate on the decoder side of the model, resulting in further metrics improvements.\nAuthors: Umberto Cappellazzo, Enrico Fini, Muqiao Yang, Daniele Falavigna, A. Brutti, Bhiksha Raj\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper investigates the problem of learning sequence-to-sequence models for spoken language understanding in a class-incremental learning (CIL) setting and proposes COCONUT, a CIL method that relies on the combination of experience replay and contrastive learning.'}",
  "Faculty Name: bhiksha raj\nMetadata:\nPaperid: f5b88ca9d74e8ddc679adcd07a292bd8481062fa\nTitle: Prompting Audios Using Acoustic Properties For Emotion Representation\nYear: 2023\nAbstract: Emotions lie on a continuum, but current models treat emotions as a finite valued discrete variable. This representation does not capture the diversity in the expression of emotion. To better represent emotions we propose the use of natural language descriptions (or prompts). In this work, we address the challenge of automatically generating these prompts and training a model to better learn emotion representations from audio and prompt pairs. We use acoustic properties that are correlated to emotion like pitch, intensity, speech rate, and articulation rate to automatically generate prompts i.e. 'acoustic prompts'. We use a contrastive learning objective to map speech to their respective acoustic prompts. We evaluate our model on Emotion Audio Retrieval and Speech Emotion Recognition. Our results show that the acoustic prompts significantly improve the model's performance in EAR, in various Precision@K metrics. In SER, we observe a 3.8% relative accuracy improvement on the Ravdess dataset.",
  "We evaluate our model on Emotion Audio Retrieval and Speech Emotion Recognition. Our results show that the acoustic prompts significantly improve the model's performance in EAR, in various Precision@K metrics. In SER, we observe a 3.8% relative accuracy improvement on the Ravdess dataset.\nAuthors: Hira Dhamyal, Benjamin Elizalde, Soham Deshmukh, Huaming Wang, Bhiksha Raj, Rita Singh\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work addresses the challenge of automatically generating prompts and training a model to better learn emotion representations from audio and prompt pairs by using acoustic properties that are correlated to emotion like pitch, intensity, speech rate, and articulation rate to automatically generate prompts.'}",
  "Faculty Name: bhiksha raj\nMetadata:\nPaperid: f969f059b01be02f9995396b6cc397959b574635\nTitle: Pairwise Similarity Learning is SimPLE\nYear: 2023\nAbstract: In this paper, we focus on a general yet important learning problem, pairwise similarity learning (PSL). PSL subsumes a wide range of important applications, such as open-set face recognition, speaker verification, image retrieval and person re-identification. The goal of PSL is to learn a pairwise similarity function assigning a higher similarity score to positive pairs (i.e., a pair of samples with the same label) than to negative pairs (i.e., a pair of samples with different label). We start by identifying a key desideratum for PSL, and then discuss how existing methods can achieve this desideratum. We then propose a surprisingly simple proxy-free method, called SimPLE, which requires neither feature/proxy normalization nor angular margin and yet is able to generalize well in open-set recognition. We apply the proposed method to three challenging PSL tasks: open-set face recognition, image retrieval and speaker verification.",
  "We then propose a surprisingly simple proxy-free method, called SimPLE, which requires neither feature/proxy normalization nor angular margin and yet is able to generalize well in open-set recognition. We apply the proposed method to three challenging PSL tasks: open-set face recognition, image retrieval and speaker verification. Comprehensive experimental results on large-scale benchmarks show that our method performs significantly better than current state-of-the-art methods. Our project page is available at simple.is.tue.mpg.de.\nAuthors: Yandong Wen, Weiyang Liu, Yao Feng, Bhiksha Raj, Rita Singh, Adrian Weller, Michael J. Black, Bernhard Sch\u00f6lkopf\nVenue: IEEE International Conference on Computer Vision\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work identifies a key desideratum for PSL, and proposes a surprisingly simple proxy-free method, called SimPLE, which requires neither feature/proxy normalization nor angular margin and yet is able to generalize well in open-set recognition.'}",
  "Faculty Name: bhiksha raj\nMetadata:\nPaperid: feecd2cfb7871a818ba514e8b4b3f9da482f17bc\nTitle: Synergy between human and machine approaches to sound/scene recognition and processing: An overview of ICASSP special session\nYear: 2023\nAbstract: Machine Listening, as usually formalized, attempts to perform a task that is, from our perspective, fundamentally human-performable, and performed by humans. Current automated models of Machine Listening vary from purely data-driven approaches to approaches imitating human systems. In recent years, the most promising approaches have been hybrid in that they have used data-driven approaches informed by models of the perceptual, cognitive, and semantic processes of the human system. Not only does the guidance provided by models of human perception and domain knowledge enable better, and more generalizable Machine Listening, in the converse, the lessons learned from these models may be used to verify or improve our models of human perception themselves. This paper summarizes advances in the development of such hybrid approaches, ranging from Machine Listening models that are informed by models of peripheral (human) auditory processes, to those that employ or derive semantic information encoded in relations between sounds.",
  "This paper summarizes advances in the development of such hybrid approaches, ranging from Machine Listening models that are informed by models of peripheral (human) auditory processes, to those that employ or derive semantic information encoded in relations between sounds. The research described herein was presented in a special session on\"Synergy between human and machine approaches to sound/scene recognition and processing\"at the 2023 ICASSP meeting.\nAuthors: L. Heller, Benjamin Elizalde, B. Raj, Soham Deshmukh\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Advances in the development of hybrid approaches to Machine Listening models that are informed by models of peripheral (human) auditory processes, to those that employ or derive semantic information encoded in relations between sounds are summarized.'}",
  "List of 2023 Open Access papers by bhiksha raj are:\nFREDOM: Fairness Domain Adaptation Approach to Semantic Scene Understanding\nUTOPIA: Unconstrained Tracking Objects without Preliminary Examination via Cross-Domain Adaptation\nSoftMatch: Addressing the Quantity-Quality Trade-off in Semi-supervised Learning\nFixed Inter-Neuron Covariability Induces Adversarial Robustness\nUnderstanding political polarization using language models: A dataset and method\nProlonged school closure during the pandemic time in successive waves of COVID-19- vulnerability of children to sexual abuses \u2013 A case study in Tamil Nadu, India\nBASS: Block-wise Adaptation for Speech Summarization\nUnderstanding Political Polarisation using Language Models: A dataset and method\nAn Approach to Ontological Learning from Weak Labels\nRethinking Voice-Face Correlation: A Geometry View\nPaaploss: A Phonetic-Aligned Acoustic Parameter Loss for Speech Enhancement\nImproving Perceptual Quality, Intelligibility, and Acoustics on VoIP Platforms\nApproach to Learning Generalized Audio Representation Through Batch Embedding Covariance Regularization and Constant-Q Transforms\nTraining on Foveated Images Improves Robustness to Adversarial",
  "Intelligibility, and Acoustics on VoIP Platforms\nApproach to Learning Generalized Audio Representation Through Batch Embedding Covariance Regularization and Constant-Q Transforms\nTraining on Foveated Images Improves Robustness to Adversarial Attacks\nImprecise Label Learning: A Unified Framework for Learning with Various Imprecise Label Configurations\nThe Hidden Dance of Phonemes and Visage: Unveiling the Enigmatic Link between Phonemes and Facial Features\nFairness Continual Learning Approach to Semantic Scene Understanding in Open-World Environments\nPaintSeg: Training-free Segmentation via Painting\nTAPLoss: A Temporal Acoustic Parameter Loss for Speech Enhancement\nSynergy between human and machine approaches to sound/scene recognition and processing: An overview of ICASSP special session\nLoFT: Local Proxy Fine-tuning For Improving Transferability Of Adversarial Attacks Against Large Language Model\nEvaluating Speech Synthesis by Training Recognizers on Synthetic Speech\nRethinking Audiovisual Segmentation with Semantic Quantization and Decomposition\nTowards Noise-Tolerant Speech-Referring Video Object Segmentation: Bridging Speech and Text\nPsychoacoustic Challenges Of Speech Enhancement On VoIP Platforms\nuSee: Unified Speech Enhancement and Editing with",
  "Training Recognizers on Synthetic Speech\nRethinking Audiovisual Segmentation with Semantic Quantization and Decomposition\nTowards Noise-Tolerant Speech-Referring Video Object Segmentation: Bridging Speech and Text\nPsychoacoustic Challenges Of Speech Enhancement On VoIP Platforms\nuSee: Unified Speech Enhancement and Editing with Conditional Diffusion Models\nToken Prediction as Implicit Classification to Identify LLM-Generated Text\nUnderstanding and Mitigating the Label Noise in Pre-training on Downstream Tasks\nImportance of negative sampling in weak label learning\nCompleting Visual Objects via Bridging Generation and Segmentation\nTraining Audio Captioning Models without Audio\nContinual Contrastive Spoken Language Understanding\nPrompting Audios Using Acoustic Properties For Emotion Representation\nPairwise Similarity Learning is SimPLE",
  "Title: Jeffrey Bigham -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Jeffrey Bigham, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Affiliated Faculty\" name=\"categories-1\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Jeffrey Bigham - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Jeffrey Bigham, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Jeffrey\"/>\n<meta content=\"Lastname\" property=\"profile:Bigham\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/bigham-jeffrey.",
  "cmu.edu//people/faculty/bigham-jeffrey.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nJeffrey \n                        Bigham\nAssociate Professor, Language Technologies Institute\nHuman-Computer Interaction Institute\nContact\n3525 \u2014Newell-Simon Hall\njbigham(through)andrew.cmu.edu\n412-945-0708\nResearch\nI work at the intersection of human-computer interaction, human computation, crowdsourcing, artificial intelligence and natural language processing.\nThe future my research envisions is one in which the intelligent systems that we have dreamed about for decades \u2014 that have inspired generations of computer scientists from its beginning \u2014 are brought about for the benefit of people in their everyday lives.\nMy work is achieving this vision by leveraging on-demand human labor to fill in for components that we cannot currently automate, and by building frameworks that allow groups to do together what even expert individuals cannot do alone.",
  "My work is achieving this vision by leveraging on-demand human labor to fill in for components that we cannot currently automate, and by building frameworks that allow groups to do together what even expert individuals cannot do alone. A crowd-powered world seems counter to the goals of computer science, but by creating and deploying the systems of our dreams, we will learn to create the machines that will someday realize them.\nHuman-Computer Interaction Institute\nPersonal Website\n\nLinks:\nhttps://hcii.cmu.edu/\nhttp://www.cs.cmu.edu/~jbigham/",
  "Title: Lei Li -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio page for LTI faculty member Lei Li\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Core Faculty\" name=\"categories-1\"/>\n<meta content=\"AI;Machine Learning;Machine Translation\" name=\"categories-2\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Lei Li - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio page for LTI faculty member Lei Li\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Lei\"/>\n<meta content=\"Lastname\" property=\"profile:Li\"/>\n<meta content=\"http://cms-staging.andrew.cmu.edu/lti/people/faculty/bio.",
  "andrew.cmu.edu/lti/people/faculty/bio.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nLei \n                        Li\nAssistant Professor, Language Technologies Institute\nContact\n6403 Gates & Hillman Centers\nleili(through)andrew.cmu.edu\n412-268-6355\nAddress\n5000 Forbes Avenue\nPittsburgh, PA 15213\nPersonal Website\n\nLinks:\nhttps://www.cs.cmu.edu/~leili/",
  "Faculty Name: bio\nMetadata:\nPaperid: 0312627ed2ce0f5327d8588c2f9d65afd61e53d3\nTitle: Characterisation and Dynamics of an Emerging Seagrass Meadow\nYear: 2023\nAbstract: Seagrasses are habitat-forming species that support biodiversity and a wide range of associated ecosystem services, from blue carbon capture to providing nursery areas for a variety of organisms. Their decline has been documented worldwide and is attributed to human impacts ranging from habitat loss and eutrophication to the effects of climate change. However, recent recovery trends have also been documented due to reductions in stressors, passive and active restoration, and even changes in environmental conditions owing to local management. In this study, we document for the first time the occurrence of Zostera noltei in the downstream area of the River Minho Estuary. This occurrence was unexpected given the hydrological conditions of the estuary, characterised by dredging and siltation. We reconstructed the occurrence and historical distribution of seagrass beds, and showed that they have existed in the region for more than a decade.",
  "This occurrence was unexpected given the hydrological conditions of the estuary, characterised by dredging and siltation. We reconstructed the occurrence and historical distribution of seagrass beds, and showed that they have existed in the region for more than a decade. The current distribution area was mapped using high-resolution multispectral remote sensing techniques, and in situ photoquadrats to complement the remote sensing information with an evaluation of the seagrass cover. A current seagrass area of 0.81 ha was found with an average cover of 70%. However, the Minho Estuary continues to be strongly affected by sediment deposition, which may affect the seagrass population in the long term. Continued surveys are recommended to confirm the long-term trend of colonisation of this important habitat, which ultimately provides so many benefits to coastal ecosystems and humankind.",
  "However, the Minho Estuary continues to be strongly affected by sediment deposition, which may affect the seagrass population in the long term. Continued surveys are recommended to confirm the long-term trend of colonisation of this important habitat, which ultimately provides so many benefits to coastal ecosystems and humankind.\nAuthors: M. Dolbeth, D. Costa, Manuel de Figueiredo Meyer, J. Gon\u00e7alves, A. Bio\nVenue: Remote Sensing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This study document for the first time the occurrence of Zostera noltei in the downstream area of the River Minho Estuary, and reconstructed the occurrence and historical distribution of seagrass beds, and showed that they have existed in the region for more than a decade.'}",
  "Faculty Name: bio\nMetadata:\nPaperid: 0b2db5968605bbce549f75928c1b5468782bc2ed\nTitle: 491. Risk Factors for Severe Pediatric COVID-19: A Systematic Review\nYear: 2023\nAbstract: Abstract Background Optimal management of COVID-19 in children requires risk stratification based on comorbidities and demographic factors that can predispose to severe disease. The Pediatric Infectious Diseases Society (PIDS) Pediatric COVID-19 Therapies Task Force, comprised of pediatric infectious diseases physicians, intensivists, and pharmacists from 29 US hospitals, develops clinical guidance for pediatric COVID-19 management. In support of these efforts, a systematic review of peer-reviewed literature was conducted to synthesize the evidence for risk factors for severe pediatric COVID-19. Methods Medline, EMBASE, and CDC databases were searched to identify all relevant publications before July 1, 2022. Titles and abstracts were reviewed to identify studies that assessed for potential predictors of severe COVID-19 disease in children < 21 years.",
  "Methods Medline, EMBASE, and CDC databases were searched to identify all relevant publications before July 1, 2022. Titles and abstracts were reviewed to identify studies that assessed for potential predictors of severe COVID-19 disease in children < 21 years. Severe disease was defined by intensive care unit admission, invasive mechanical ventilation, multiorgan dysfunction, or death. A team of reviewers appraised eligible studies, extracted relevant data, and assessed the quality of evidence. Comorbidities and demographic factors were classified as definite, probable, or unlikely risk factors based on the certainty of association with severe COVID-19. Results Sixteen potential risk factors were evaluated based on evidence from 50 studies: 13 reviews/meta-analyses, 23 multi-center, and 14 single-center studies (Figure 1). Severe immunocompromise, obesity, diabetes, prematurity, and neurologic, cardiovascular, and chronic lung disease were classified as definite risk factors. Evidence was less consistent in support of sickle cell disease, mild/moderate immunocompromise, neurodevelopmental, and chronic liver disorders as risk factors.",
  "Severe immunocompromise, obesity, diabetes, prematurity, and neurologic, cardiovascular, and chronic lung disease were classified as definite risk factors. Evidence was less consistent in support of sickle cell disease, mild/moderate immunocompromise, neurodevelopmental, and chronic liver disorders as risk factors. Most studies found asthma, sex, mental health, chronic kidney disease, and inflammatory bowel disease to be unlikely risk factors. Many studies demonstrated that the magnitude of risk for comorbidities was modified by prior immunization, age, and medical complexity (i.e., multiple or poorly controlled comorbidities) (Figure 2).Figure 1. Evidence Review: Comorbidities and Severe COVID-19 in Children Obesity - BMI \u226595th percentile for age and sex per CDC growth curves.",
  "Evidence Review: Comorbidities and Severe COVID-19 in Children Obesity - BMI \u226595th percentile for age and sex per CDC growth curves. Severe immunocompromise - Any of the following: Receipt in the 3 months before COVID-19 diagnosis of chemotherapy for a solid tumor or hematologic malignancy, high-dose corticosteroids (e.g., prednisone >20mg/day for \u226514 days), or other systemic B- or T-cell-depleting immunosuppressive agents; hematopoietic stem cell transplant, CAR T cell therapy, or solid organ transplant within 100 days of COVID-19 diagnosis; human immunodeficiency virus infection and CD4 count <200; combined primary immunodeficiency disorders. Moderate immunocompromise - Routine receipt of non-lymphocyte-depleting immunosuppressive or immunomodulatory medications or prednisone <20 mg/day for inflammatory/immune-mediated disease.Figure 2. Risk Factors and Risk Modifiers for Severe Pediatric COVID-19 *Children who are less likely to gain protection from previous infections or vaccines.",
  "Risk Factors and Risk Modifiers for Severe Pediatric COVID-19 *Children who are less likely to gain protection from previous infections or vaccines. Definite risk factor - Evidence for increased risk for severe COVID-19, supported by large multicenter studies, meta-analyses, or systematic reviews. Probable risk factor - Evidence for increased risk, supported by small or single-center studies; this category also includes factors inconsistently associated with severe COVID-19, suggesting substantial uncertainty. Unlikely risk factor - Evidence against increased risk for severe COVID-19, supported by large multicenter studies, meta-analyses, or systematic reviews. Conclusion This study highlights key comorbidities and effect modifiers associated with severe COVID-19 in children. These findings can be used to facilitate risk stratification and inform management decisions.",
  "Conclusion This study highlights key comorbidities and effect modifiers associated with severe COVID-19 in children. These findings can be used to facilitate risk stratification and inform management decisions. Disclosures Zachary I. Willis, MD, MPH, Merck Sharp & Dohme Corp: Grant/Research Support|Pfizer Inc: Grant/Research Support Gabriela Maron, MD, Astellas Inc: Grant/Research Support|SymBio Pharma: Grant/Research Support Paul K. Sue, MDCM, Allovir, Inc: Participant in Industry Sponsored Trial|Gilead Sciences, Inc: Participant in Industry Sponsored Trial|Merck & Co.: Participant in Industry Sponsored Trial Scott H. James, MD, Bayer: Advisor/Consultant|Evrys: Grant/Research Support|Gilead: Grant/Research Support Mari M. Nakamura, MD, MPH, Gilead Sciences, Inc.: Grant/Research Support Joshua Wolf, MBBS, PhD, Karius Inc.: Grant/Research Support|Merck Inc.",
  ": Grant/Research Support Joshua Wolf, MBBS, PhD, Karius Inc.: Grant/Research Support|Merck Inc.: Participation in industry-sponsored research\nAuthors: C. R. Oliveira, Zachary I Willis, Gabriela M. Maron, Paul K Sue, Brenda I Anosike, L. Bio, Prachi Singh, Scott H James, Christine M Miller, Mari M Nakamura, Joshua Wolf\nVenue: Open Forum Infectious Diseases\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A systematic review of peer-reviewed literature was conducted to synthesize the evidence for risk factors for severe pediatric COVID-19 and found asthma, sex, mental health, chronic kidney disease, and inflammatory bowel disease to be unlikely risk factors.'}",
  "Faculty Name: bio\nMetadata:\nPaperid: 0d983ae9fe2dd2bd354f9e1b5b1a99eef3c626db\nTitle: New Methodology for Intertidal Seaweed Biomass Estimation Using Multispectral Data Obtained with Unoccupied Aerial Vehicles\nYear: 2023\nAbstract: Seaweed assemblages include a variety of structuring species providing habitats, food and shelter for organisms from different trophic levels. Monitoring intertidal seaweed traditionally involves targeting small areas to collect data on species\u2019 biological traits, which is often labour intensive and covers only a small area of the rocky reef under study. Given the various applications for seaweeds and their compounds, there has been an increase in demand for biomass triggered by the development of new markets. Such biomass demand generates new challenges for biomass quantification and the definition of future in-take harvesting commercial quotas by regulating agencies. The use of Unoccupied Aerial Vehicles (UAVs) as a low-cost yet efficient monitoring solution, combined with new sensors such as multispectral cameras, has been proposed for mapping intertidal reefs and seaweed in particular.",
  "The use of Unoccupied Aerial Vehicles (UAVs) as a low-cost yet efficient monitoring solution, combined with new sensors such as multispectral cameras, has been proposed for mapping intertidal reefs and seaweed in particular. In this study, a new methodology was developed and validated to quantify intertidal seaweed biomass based on multispectral UAV imagery, which was made available through an easy-to-use QGIS plugin (named SWUAV_BIO) that automates such biomass estimation. This tool was applied to a case study where the standing stock of Fucus spp. beds located at Viana do Castelo rocky shore (northern Portugal) was assessed using UAV multispectral imagery, providing a reference for future UAV-based ecological studies. Although comparison with the in situ assessments showed that biomass was underestimated by 36%, the SWUAV_BIO plugin is a valuable tool, as it provides an expedited (albeit conservative) seaweed standing stock assessment that can be used to monitor seaweed populations, their changes, and assess the effect of harvesting. These data can be used for an informed and sustainable management of seaweed resources by the competent authorities.",
  "These data can be used for an informed and sustainable management of seaweed resources by the competent authorities.\nAuthors: D\u00e9bora Borges, L. Duarte, I. Costa, A. Bio, Joelen Silva, I. Sousa-Pinto, J. Gon\u00e7alves\nVenue: Remote Sensing\nTldr: None",
  "Faculty Name: bio\nMetadata:\nPaperid: 199205d8d1353999b80a05f6de3c6fa7706885eb\nTitle: Multimodal Imaging Findings of Cerebral Amyloid Angiopathy Related Inflammation With Unusual Clinical Manifestation: A Case Report\nYear: 2023\nAbstract: None\nAuthors: J. Koo, Mina Park, H. S. Yoo, B. Joo, S. Ahn, Jae-Hoon Lee, Young Hoon Ryu, Sang Hyun Suh\nVenue: Investigative Magnetic Resonance Imaging\nTldr: None",
  "Faculty Name: bio\nMetadata:\nPaperid: 218c8d3a5f8c7e1939b453e3360ad28c42eeff7e\nTitle: Application of a Multispectral UAS to Assess the Cover and Biomass of the Invasive Dune Species Carpobrotus edulis\nYear: 2023\nAbstract: Remote sensing can support dune ecosystem conservation. Unoccupied Aircraft Systems (UAS) equipped with multispectral cameras can provide information for identifying different vegetation species, including Carpobrotus edulis\u2014one of the most prominent alien species in Portuguese dune ecosystems. This work investigates the use of multispectral UAS for C. edulis identification and biomass estimation. A UAS with a five-band multispectral camera was used to capture images from the sand dunes of the C\u00e1vado River spit. Simultaneously, field samples of C. edulis were collected for laboratorial quantification of biomass through Dry Weight (DW).",
  "A UAS with a five-band multispectral camera was used to capture images from the sand dunes of the C\u00e1vado River spit. Simultaneously, field samples of C. edulis were collected for laboratorial quantification of biomass through Dry Weight (DW). Five supervised classification algorithms were tested to estimate the total area of C. edulis, with the Random Forest algorithm achieving the best results (C. edulis Producer Accuracy (PA) = 0.91, C. edulis User Accuracy (UA) = 0.80, kappa = 0.87, Overall Accuracy (OA) = 0.89). Sixteen vegetation indices (VIs) were assessed to estimate the Above-Ground Biomass (AGB) of C. edulis, using three regression models to correlate the sample areas VI and DW. An exponential regression model of the Renormalized Difference Vegetation Index (RDVI) presented the best fit for C. edulis DW (R2 = 0.86; p-value < 0.05; normalised root mean square error (NRMSE) = 0.09).",
  "An exponential regression model of the Renormalized Difference Vegetation Index (RDVI) presented the best fit for C. edulis DW (R2 = 0.86; p-value < 0.05; normalised root mean square error (NRMSE) = 0.09). This result was later used to estimate the total AGB in the area, which can be used for monitoring and management plans\u2014namely, removal campaigns.\nAuthors: Manuel de Figueiredo Meyer, J. Gon\u00e7alves, Jacinto Cunha, S. Ramos, A. Bio\nVenue: Remote Sensing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work investigates the use of multispectral UAS for C. edulis identification and biomass estimation, and estimates the total AGB in the area, which can be used for monitoring and management plans\u2014namely, removal campaigns.'}",
  "Faculty Name: bio\nMetadata:\nPaperid: 241bf86642809dc59562aa1448fea36c075b6b8e\nTitle: Clinicoradiologic Characteristics of Intradural Extramedullary Conventional Spinal Ependymoma\nYear: 2023\nAbstract: Purpose Distinguishing intradural extramedullary (IDEM) spinal ependymoma from myxopapillary ependymoma is challenging due to the location of IDEM spinal ependymoma. This study aimed to investigate the utility of clinical and MR imaging features for differentiating between IDEM spinal and myxopapillary ependymomas. Materials and Methods We compared tumor size, longitudinal/axial location, enhancement degree/pattern, tumor margin, signal intensity (SI) of the tumor on T2-weighted images and T1-weighted image (T1WI), increased cerebrospinal fluid (CSF) SI caudal to the tumor on T1WI, and CSF dissemination of pathologically confirmed 12 IDEM spinal and 10 myxopapillary ependymomas.",
  "Furthermore, classification and regression tree (CART) was performed to identify the clinical and MR features for differentiating between IDEM spinal and myxopapillary ependymomas. Results Patients with IDEM spinal ependymomas were older than those with myxopapillary ependymomas (48 years vs. 29.5 years, p < 0.05). A high SI of the tumor on T1W1 was more frequently observed in IDEM spinal ependymomas than in myxopapillary ependymomas (p = 0.02). Conversely, myxopapillary ependymomas show CSF dissemination. Increased CSF SI caudal to the tumor on T1WI was observed more frequently in myxopapillary ependymomas than in IDEM spinal ependymomas (p < 0.05). Dissemination to the CSF space and increased CSF SI caudal to the tumor on T1WI were the most important variables in CART analysis. Conclusion Clinical and radiological variables may help differentiate between IDEM spinal and myxopapillary ependymomas.",
  "Dissemination to the CSF space and increased CSF SI caudal to the tumor on T1WI were the most important variables in CART analysis. Conclusion Clinical and radiological variables may help differentiate between IDEM spinal and myxopapillary ependymomas.\nAuthors: Seung Hyun Lee, Y. Cha, Y. Cho, Mina Park, B. Joo, Sang Hyun Suh, S. Ahn\nVenue: Journal of the Korean Society of Radiology\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Investigation of the utility of clinical and MR imaging features for differentiating between IDEM spinal and myxopapillary ependymomas found dissemination to the CSF space and increased CSF SI caudal to the tumor on T1WI were the most important variables in CART analysis.'}",
  "Faculty Name: bio\nMetadata:\nPaperid: 3cdce526e8bce7c785c624e5a2afe842ccd73e85\nTitle: Magnetic Resonance Elastography for Clinicians and Researchers Unfamiliar With the Field\nYear: 2023\nAbstract: None\nAuthors: Seungtae Lee, B. Joo, Mina Park, S. Ahn, Sang Hyun Suh\nVenue: Investigative Magnetic Resonance Imaging\nTldr: None",
  "Faculty Name: bio\nMetadata:\nPaperid: 4aba9db4337078d1ca3585dbf7d9d42935044c17\nTitle: Epidemiological description of measles outbreaks following a mass vaccination Campaign in Bayelsa State, Nigeria\nYear: 2023\nAbstract: None\nAuthors: S. Abaya, D. Ogoina, B. Abaye, Tella Adedamola\nVenue: AfricArXiv\nTldr: None",
  "Faculty Name: bio\nMetadata:\nPaperid: 5761f39859863520a09eb2854f319dfc9720abef\nTitle: A Radiomics-Based Model for Potentially More Accurate Identification of Subtypes of Breast Cancer Brain Metastases\nYear: 2023\nAbstract: Purpose Breast cancer brain metastases (BCBM) may involve subtypes that differ from the primary breast cancer lesion. This study aimed to develop a radiomics-based model that utilizes preoperative brain MRI for multiclass classification of BCBM subtypes and to investigate whether the model offers better prediction accuracy than the assumption that primary lesions and their BCBMs would be of the same subtype (non-conversion model) in an external validation set. Materials and Methods The training and external validation sets each comprised 51 cases (102 cases total). Four machine learning classifiers combined with three feature selection methods were trained on radiomic features and primary lesion subtypes for prediction of the following four subtypes: 1) hormone receptor (HR)+/human epidermal growth factor receptor 2 (HER2)-, 2) HR+/HER2+, 3) HR-/HER2+, and 4) triple-negative.",
  "After training, the performance of the radiomics-based model was compared to that of the non-conversion model in an external validation set using accuracy and F1-macro scores. Results The rate of discrepant subtypes between primary lesions and their respective BCBMs were 25.5% (n=13 of 51) in the training set and 23.5% (n=12 of 51) in the external validation set. In the external validation set, the accuracy and F1-macro score of the radiomics-based model were significantly higher than those of the non-conversion model (0.902 vs. 0.765, p=0.004; 0.861 vs. 0.699, p=0.002). Conclusion Our radiomics-based model represents an incremental advance in the classification of BCBM subtypes, thereby facilitating a more appropriate personalized therapy.",
  "0.765, p=0.004; 0.861 vs. 0.699, p=0.002). Conclusion Our radiomics-based model represents an incremental advance in the classification of BCBM subtypes, thereby facilitating a more appropriate personalized therapy.\nAuthors: Seonghyeon Cho, B. Joo, Mina Park, S. Ahn, Sang Hyun Suh, Y. Park, S. Ahn, Seung-Koo Lee\nVenue: Yonsei medical journal\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The radiomics-based model represents an incremental advance in the classification of BCBM subtypes, thereby facilitating a more appropriate personalized therapy.'}",
  "Faculty Name: bio\nMetadata:\nPaperid: 632b9672336c52c0842a67b551883de9f487f3b9\nTitle: Pengaruh Konsumsi Informasi terhadap Perilaku Pencegahan COVID-19: Studi Quasi Eksperimental Time Series\nYear: 2023\nAbstract: The COVID-19 pandemic in Indonesia is still ongoing despite a decrease in the number of cases compared to last year. Based on BPS data, it is assumed that some people believe the COVID-19 pandemic is still ongoing and some believe this pandemic is over. The results of previous research show that the level of prevention behavior for COVID-19 is influenced by the level of media consumption, which is mediated by personal responsibility and the moderating role of one's health orientation. This experimental research aims to analyze the relationship between consumption of information about COVID-19 which influences prevention behavior. The method used is Quasi Experimental: The Time Series Experiment, by comparing prevention behavior after giving treatment in the form of COVID-19 information for 2 weeks in each group.",
  "This experimental research aims to analyze the relationship between consumption of information about COVID-19 which influences prevention behavior. The method used is Quasi Experimental: The Time Series Experiment, by comparing prevention behavior after giving treatment in the form of COVID-19 information for 2 weeks in each group. The results of this study indicate that health orientation does not affect a person's personal responsibility, then differences in prevention behavior and also the duration of change in a person's preventive behavior against COVID-19 are influenced by their health orientation.\nAuthors: D. Ariani, Bio Bhirawan, Pustika Chandra Kasih\nVenue: Perspektif\nTldr: None",
  "Faculty Name: bio\nMetadata:\nPaperid: 6aeb44539d461b1ed9e9b23cb875d1b12eb44a3b\nTitle: Antifungal stewardship in practice: Insights from a prospective audit and feedback program\nYear: 2023\nAbstract: Abstract Objective: To identify characteristics of antifungal prospective audit and feedback (PAF) and to compare rates of PAF recommendation and acceptance between antifungal and antibiotic agents. Design: Retrospective cohort study of antifungal and antibiotic audits by a children\u2019s hospital antimicrobial stewardship program (ASP) from November 1, 2020, to October 31, 2022. Methods: Antimicrobial audit data were retrieved from the ASP data warehouse. We characterized antifungal PAF using descriptive statistics. We then compared the overall rates of PAF recommendation and recommendation acceptance between antifungals and antibiotics. We also compared the differences in antifungal and antibiotic PAF recommendation and acceptance rates across various factors, including infectious problem, medical service, and recommendation type.",
  "We then compared the overall rates of PAF recommendation and recommendation acceptance between antifungals and antibiotics. We also compared the differences in antifungal and antibiotic PAF recommendation and acceptance rates across various factors, including infectious problem, medical service, and recommendation type. Results: Of 10,402 antimicrobial audits identified during the study period, 8,599 (83%) were for antibiotics and 1,803 (17%) were for antifungals. The highest antifungal recommendation rates were for liposomal amphotericin B, antifungals used for sepsis or respiratory tract infection, and antifungals prescribed in the cardiovascular intensive care unit. The rate of PAF recommendation was higher for antibiotics than for antifungals (29% vs 21%; P < .001); however, the rates of recommendation acceptance were similar. Recommendations to discontinue or for medication monitoring were more common for antifungals. Conclusions: Our analysis of antifungal PAF identified key opportunities to improve antifungal use, including the optimized use of specific agents and targeted use by certain medical services.",
  "Recommendations to discontinue or for medication monitoring were more common for antifungals. Conclusions: Our analysis of antifungal PAF identified key opportunities to improve antifungal use, including the optimized use of specific agents and targeted use by certain medical services. Moreover, antifungal PAF, despite identifying fewer recommendations compared to antibiotic PAF, were associated with similarly high rates of acceptance, highlighting a promising opportunity for antifungal stewardship.\nAuthors: L. Bio, Yingjie Weng, Hayden T. Schwenk\nVenue: Infection control and hospital epidemiology\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Antifungal PAF, despite identifying fewer recommendations compared to antibiotic PAF, were associated with similarly high rates of acceptance, highlighting a promising opportunity for antifungal stewardship.'}",
  "Faculty Name: bio\nMetadata:\nPaperid: 6d90cab3017e2940d15b701b5c85d08cd857a482\nTitle: Associated Factors of Spontaneous Hemorrhage in Brain Metastases in Patients with Lung Adenocarcinoma\nYear: 2023\nAbstract: Simple Summary Risk factors of hemorrhage in brain metastases from lung adenocarcinoma has been unknown and how hemorrhage in brain metastases affects patients\u2019 prognosis has not been clarified. We performed a retrospective analysis on 159 BMs and found that hemorrhage in BMs from lung adenocarcinomas may be associated with BM tumor size and a combination of TKI and intracranial radiotherapy. However, BM hemorrhage did not affect OSBM. Abstract Background: Hemorrhage in brain metastases (BMs) from lung cancer is common and associated with a poor prognosis. Research on associated factors of spontaneous hemorrhage in patients with BMs is limited. This study aimed to investigate the predictive risk factors for BM hemorrhage and assess whether hemorrhage affects patient survival.",
  "Research on associated factors of spontaneous hemorrhage in patients with BMs is limited. This study aimed to investigate the predictive risk factors for BM hemorrhage and assess whether hemorrhage affects patient survival. Methods: We retrospectively evaluated 159 BMs from 80 patients with lung adenocarcinoma from January 2017 to May 2022. Patients were classified into hemorrhagic and non-hemorrhagic groups. Patient demographics, lung cancer molecular subtype, treatment type, and tumor\u2013node\u2013metastasis stage were compared between the groups. Multivariate generalized estimating equation (GEE) analysis and gradient boosting were performed. To determine whether BM hemorrhage can stratify overall survival after BM (OSBM), univariate survival analysis was performed. Results: In the univariate analysis, hemorrhagic BMs were significantly larger and had a history of receiving combination therapy with tyrosine kinase inhibitor (TKI) and intracranial radiation (p < 0.05). Multivariate GEE showed that tumor size and combination therapy were independent risk factors for BM hemorrhage (p < 0.05).",
  "Multivariate GEE showed that tumor size and combination therapy were independent risk factors for BM hemorrhage (p < 0.05). Gradient boosting demonstrated that the strongest predictor of BM hemorrhage was tumor size (variable importance: 49.83), followed by age (16.65) and TKI combined with intracranial radiation (13.81). There was no significant difference in OSBM between the two groups (p = 0.33). Conclusions: Hemorrhage in BMs from lung adenocarcinomas may be associated with BM tumor size and a combination of TKI and intracranial radiotherapy. BM hemorrhage did not affect OSBM.\nAuthors: Song Soo Kim, Seoyoung Lee, Mina Park, B. Joo, S. Suh, S. Ahn\nVenue: Cancers\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A retrospective analysis on 159 BMs found that hemorrhage in BMs from lung adenocarcinomas may be associated with BM tumor size and a combination of TKI and intracranial radiotherapy, but BM hemorrhage did not affect OSBM.'}",
  "Faculty Name: bio\nMetadata:\nPaperid: 743934021cb702b658cad466bdc86a1f555df409\nTitle: VSC-HVDC transmission line fault location based on transient characteristics\nYear: 2023\nAbstract: Accurate and reliable fault location is necessary for ensuring the safe and reliable operation of the VSC-HVDC transmission system. This paper proposed a single-terminal fault location method based on the fault transient characteristics of the two-terminal VSCHVDC transmission system. The pole-to-pole transient fault process was divided into three stages, the time-domain expression of the DC current during the diode freewheel stage was used to locate the fault point, and a criterion for judging whether the fault evolves to the diode freewheel stage was proposed. Taking into account the enhancing effect of the opposite system to the fault current, theDC side pole-to-ground fault networkwas equated to a fourth-order circuit model, the relationship of fault distance with the characteristic roots of fault current differential equationwas derived, and the Prony algorithmwas utilized for datafitting to extract characteristic roots to realize fault location.",
  "A two-terminal VSC-HVDC transmission system was modelled in PSCAD/EMTDC. The simulation result verifies that the proposed principle can accurately locate the fault point on the VSC-HVDC transmission lines.\nAuthors: Yanxia Zhang, Anlu BIo, Jian Wang, Fu-chun Zhang, L. Jingyi, Yanxia Zhang\nVenue: Archives of Electrical Engineering\nTldr: None",
  "Faculty Name: bio\nMetadata:\nPaperid: 811f15fd63b63a39db75d326fde993c8afc2ab91\nTitle: Prominent cerebral veins on susceptibility\u2010weighted angiography in acute meningoencephalitis\nYear: 2023\nAbstract: We have commonly observed prominent cerebral veins on susceptibility\u2010weighted angiography (SWAN) in acute meningoencephalitis. This study aimed to investigate the clinical significance of these findings.\nAuthors: Y. Jung, Mina Park, B. Joo, Sang Hyun Suh, Kyung-Yul Lee, S. Ahn\nVenue: Brain and Behavior\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This study aimed to investigate the clinical significance of findings from commonly observed prominent cerebral veins on susceptibility\u2010weighted angiography (SWAN) in acute meningoencephalitis.'}",
  "Faculty Name: bio\nMetadata:\nPaperid: 871163fcf6ec6b9e7aaf8bf70f48e3ed3897122c\nTitle: 2945. Audit and Feedback Informed ASP Interventions Lead to Sustained Reductions in Suboptimal Antibiotic Prescribing at Hospital Discharge\nYear: 2023\nAbstract: Abstract Background Antimicrobial stewardship programs (ASPs) have traditionally focused on the inpatient setting; however, a significant proportion of antibiotics initiated during hospital stays are continued at the time of discharge. Previous studies have found that rates of suboptimal antibiotic prescribing at the time of hospital discharge may be as high as 30%. Our study aimed to implement ASP interventions targeted at reducing suboptimal prescribing at the time of hospital discharge and to assess the effectiveness and durability of these interventions over time. Methods Beginning 11/2020, our ASP began audit and feedback of both enteral and parenteral hospital discharge antibiotic prescriptions. A prescription was determined to be suboptimal if the dose, frequency, duration, selection, or formulation were inconsistent with institutional and/or national guidelines or based on the clinical judgment of the ASP pharmacist.",
  "A prescription was determined to be suboptimal if the dose, frequency, duration, selection, or formulation were inconsistent with institutional and/or national guidelines or based on the clinical judgment of the ASP pharmacist. Findings from this process were used to develop interventions, including targeted provider and medical service education, institutional guideline development, and electronic health record modifications. The rate of suboptimal discharge antibiotic prescribing from 12/2020-4/2023 was plotted on a statistical process p-chart, including a historical baseline (9/2020-10/2020). Results A total of 4347 prescription audits were performed over a 28-month period and included 4211 enteral and 136 parenteral antibiotics. Reasons prescriptions were identified as suboptimal are included in Figure 1. A p-chart (Figure 2) identified a decline in suboptimal prescribing from a baseline rate of 29% to 15% after implementation of audit and feedback, modification of medication order entry panels, and targeted interventions to surgical services. After implementation of all interventions (Table 1), a centerline shift was detected, with a decrease in suboptimal prescribing from 15% to 8%. Figure 1.",
  "After implementation of all interventions (Table 1), a centerline shift was detected, with a decrease in suboptimal prescribing from 15% to 8%. Figure 1. Reasons discharge prescriptions were identified as suboptimal (N=568). A prescription may have more than one reason for being considered suboptimal. Figure 2. Suboptimal Antibiotic Prescriptions at Hospital Discharge, 2020 \u2013 2023: P-chart for suboptimal prescription rate. The yellow line indicates mean suboptimal prescription percentage for the study period (15% and 8%, respectively). The purple dashed line indicates literature reported rate of suboptimal prescribing (30%). Interventions annotated 1-7 within figure are found in Table 1. LCL, lower control limit; UCL, upper control limit. Conclusion Suboptimal antibiotic prescribing rates decreased by 72% over a 2.5-year period through a mix of audit with feedback and targeted interventions. These new processes may demonstrate a potentially effective sustained reduction in suboptimal prescribing. ASPs should consider implementation of hospital discharge prescription review as part of ambulatory stewardship efforts.",
  "These new processes may demonstrate a potentially effective sustained reduction in suboptimal prescribing. ASPs should consider implementation of hospital discharge prescription review as part of ambulatory stewardship efforts. Disclosures All Authors: No reported disclosures\nAuthors: Lauren Puckett, L. Bio, Sean T. Cornell, Hayden T. Schwenk\nVenue: Open Forum Infectious Diseases\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Suboptimal antibiotic prescribing rates decreased by 72% over a 2.5-year period through a mix of audit with feedback and targeted interventions, which may demonstrate a potentially effective sustained reduction in suboptimal prescribing.'}",
  "Faculty Name: bio\nMetadata:\nPaperid: 8dc1a1a2ca79440911bbf35f77e1d9e6ee5db257\nTitle: Assessment of Meningeal Lymphatics in the Parasagittal Dural Space: A Prospective Feasibility Study Using Dynamic Contrast-Enhanced Magnetic Resonance Imaging\nYear: 2023\nAbstract: Objective Meningeal lymphatic vessels are predominantly located in the parasagittal dural space (PSD); these vessels drain interstitial fluids out of the brain and contribute to the glymphatic system. We aimed to investigate the ability of dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) in assessing the dynamic changes in the meningeal lymphatic vessels in PSD. Materials and Methods Eighteen participants (26\u201371 years; male:female, 10:8), without neurological or psychiatric diseases, were prospectively enrolled and underwent DCE-MRI. Three regions of interests (ROIs) were placed on the PSD, superior sagittal sinus (SSS), and cortical vein. Early and delayed enhancement patterns and six kinetic curve-derived parameters were obtained and compared between the three ROIs.",
  "Three regions of interests (ROIs) were placed on the PSD, superior sagittal sinus (SSS), and cortical vein. Early and delayed enhancement patterns and six kinetic curve-derived parameters were obtained and compared between the three ROIs. Moreover, the participants were grouped into the young (< 65 years; n = 9) or older (\u2265 65 years; n = 9) groups. Enhancement patterns and kinetic curve-derived parameters in the PSD were compared between the two groups. Results The PSD showed different enhancement patterns than the SSS and cortical veins (P < 0.001 and P < 0.001, respectively) in the early and delayed phases. The PSD showed slow early enhancement and a delayed wash-out pattern. The six kinetic curve-derived parameters of PSD was significantly different than that of the SSS and cortical vein. The PSD wash-out rate of older participants was significantly lower (median, 0.09; interquartile range [IQR], 0.01\u20130.15) than that of younger participants (median, 0.32; IQR, 0.07\u20130.45) (P = 0.040).",
  "Conclusion This study shows that the dynamic changes of meningeal lymphatic vessels in PSD can be assessed with DCE-MRI, and the results are different from those of the venous structures. Our finding that delayed wash-out was more pronounced in the PSD of older participants suggests that aging may disturb the meningeal lymphatic drainage.\nAuthors: B. Joo, Mina Park, S. Ahn, Sang Hyun Suh\nVenue: Korean Journal of Radiology\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This study shows that the dynamic changes of meningeal lymphatic vessels in PSD can be assessed with DCE-MRI, and the results are different from those of the venous structures.'}",
  "Faculty Name: bio\nMetadata:\nPaperid: 9855079261ea160e5de463282b87d32181f5f4ec\nTitle: Dispensing of Antibiotics Without Prescription in Southern Benin, West Africa, 2018\nYear: 2023\nAbstract: The over-the-counter sale of antibiotics is recognized as a basis for antibiotic abuse and thus represents a global threat. This study aimed to determine the frequency of dispensing of certain antibiotics without prescription in the city of Cotonou. This was a cross-sectional study with descriptive and analytical aims. Data were collected in randomly selected pharmacies in Cotonou. A pseudo client visited some pharmacies to request the delivery of certain antibiotics and clinical scenarios were simulated to assess the attitudes and practices of professionals. Investigative staff visited 55 pharmacies and requested either amoxicillin/clavulanic acid, ciprofloxacin, gentamycin or ceftriaxone without providing a prescription or any other justification for the request.",
  "Investigative staff visited 55 pharmacies and requested either amoxicillin/clavulanic acid, ciprofloxacin, gentamycin or ceftriaxone without providing a prescription or any other justification for the request. The frequencies of antibiotics dispensed without prescription during the visit of the pseudo-client were Amoxicillin-clavulanic acid cp (100%), Gentamycin 80 mg inj (60%), Ciprofloxacin 500 mg cp (72, 73%), and Ceftriaxone 1 g inj (58,18%). In the diarrhea scenario, only 4% of the pharmacies visited offered oral rehydration. For the bronchopulmonary clinical case, the most proposed antibiotics were: Amoxicillin-clavulanic acid (50%), Amoxicillin (28.57%) and Azithromycin (21.43%). The dispensing of antibiotics without prescription in pharmacies is high. There is an urgent need for regulatory measures and public awareness to limit this practice. This research work has been published in EC Pharmacology And Toxicology (2022).",
  "The dispensing of antibiotics without prescription in pharmacies is high. There is an urgent need for regulatory measures and public awareness to limit this practice. This research work has been published in EC Pharmacology And Toxicology (2022).\nAuthors: A. Allabi, Areine Gracidie Agbo, Assad Bio-Sya, G\u00e9raud Padonou, Bawa Boya\nVenue: The Global Health Network Conference Proceedings 2022\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The frequency of dispensing of certain antibiotics without prescription in pharmacies in the city of Cotonou is high and there is an urgent need for regulatory measures and public awareness to limit this practice.'}",
  "Faculty Name: bio\nMetadata:\nPaperid: c00bfad720f4748530d93526afff5f8b28ab8480\nTitle: Sea Level Rise Effects on the Sedimentary Dynamics of the Douro Estuary Sandspit (Portugal)\nYear: 2023\nAbstract: Sandspits are important natural defences against the effects of storm events in estuarine regions, and their temporal and spatial dynamics are related to river flow, wave energy, and wind action. Understanding the impact of extreme wave events on the morphodynamics of these structures for current conditions and future projections is of paramount importance to promote coastal and navigation safety. In this work, a numerical analysis of the impact of a storm on the sandspit of the Douro estuary (NW Portugal) was carried out considering several mean sea level conditions induced by climate change. The selected numerical models were SWAN, for hydrodynamics, and XBeach, for hydrodynamic and morphodynamic assessments. The extreme event selected for this study was based on the meteo-oceanic conditions recorded during Hurricane Christina (January 2014), which caused significant damage on the western Portuguese coast.",
  "The extreme event selected for this study was based on the meteo-oceanic conditions recorded during Hurricane Christina (January 2014), which caused significant damage on the western Portuguese coast. The analysis focused on the short-term (two days) impact of the storm on the morphodynamics of the sandspit in terms of its erosion and accretion patterns. The obtained results demonstrate that the mean sea level rise will induce some increase in the erosion/accretion volumes on the seaward side of the sandspit. Overtopping of the detached breakwater and the possibility of wave overtopping of the sandspit crest were observed for the highest simulated mean sea levels.\nAuthors: Francisca Caeiro-Gon\u00e7alves, A. Bio, I. Iglesias, P. Avilez-Valente\nVenue: Water\nTldr: None",
  "Faculty Name: bio\nMetadata:\nPaperid: d2e5517a946ebba40250be6f6d880ffd046bb5b0\nTitle: Clinicopathological Characteristics of NRG1 Fusion-Positive Solid Tumors in Korean Patients.\nYear: 2023\nAbstract: Purpose\nNRG1 gene fusion is a potentially actionable oncogenic driver. The oncoprotein binds to ERBB3-ERBB2 heterodimers and activates downstream signaling, supporting a therapeutic approach for inhibiting ERBB3/ERBB2. However, the frequency and clinicopathological features of solid tumors harboring NRG1 fusions in Korean patients remain largely unknown.\n\n\nMaterials and Methods\nWe reviewed archival data from next-generation sequencing panel tests conducted at a single institution, specifically selecting patients with in-frame fusions that preserved the functional domain. The clinicopathological characteristics of patients harboring NRG1 fusions were retrospectively reviewed.",
  "Materials and Methods\nWe reviewed archival data from next-generation sequencing panel tests conducted at a single institution, specifically selecting patients with in-frame fusions that preserved the functional domain. The clinicopathological characteristics of patients harboring NRG1 fusions were retrospectively reviewed.\n\n\nResults\nOut of 8,148 patients, NRG1 fusions were identified in 22 patients (0.27%). The average age of the patients was 59 years (range, 32-78 years), and the male-to-female ratio was 1:1.2. The lung was the most frequently observed primary site (n=13), followed by the pancreaticobiliary tract (n=3), gastrointestinal tract (n=2, stomach and rectum each), ovary (n=2), breast (n=1), and soft tissue (n=1). Histologically, all tumors demonstrated adenocarcinoma histology, with the exception of one case of sarcoma. CD74 (n=8) and SLC3A2 (n=4) were the most frequently identified fusion partners. Dominant features included the presence of fewer than three co-occurring genetic alterations, a low tumor mutation burden, and low programmed death-ligand 1 expression. Various clinical responses were observed in patients with NRG1 fusions.",
  "Conclusion\nDespite the rarity of NRG1 fusions in Korean patients with solid tumors, identification through next-generation sequencing enables the possibility of new targeted therapies.\nAuthors: Y. Cha, Chung Lee, B. Joo, Kyung A Kim, Choong-kun Lee, H. Shim\nVenue: Cancer research and treatment : official journal of Korean Cancer Association\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Despite the rarity of NRG1 fusions in Korean patients with solid tumors, identification through next-generation sequencing enables the possibility of new targeted therapies.'}",
  "Faculty Name: bio\nMetadata:\nPaperid: d66b4e9a8e7dc75c819065e7ce7aaced7a9b8dea\nTitle: Viscoelastic Property of the Brain Assessed With Magnetic Resonance Elastography and Its Association With Glymphatic System in Neurologically Normal Individuals\nYear: 2023\nAbstract: Objective To investigate the feasibility of assessing the viscoelastic properties of the brain using magnetic resonance elastography (MRE) and a novel MRE transducer to determine the relationship between the viscoelastic properties and glymphatic function in neurologically normal individuals. Materials and Methods This prospective study included 47 neurologically normal individuals aged 23\u201374 years (male-to-female ratio, 21:26). The MRE was acquired using a gravitational transducer based on a rotational eccentric mass as the driving system. The magnitude of the complex shear modulus |G*| and the phase angle \u03c6 were measured in the centrum semiovale area. To evaluate glymphatic function, the Diffusion Tensor Image Analysis Along the Perivascular Space (DTI-ALPS) method was utilized and the ALPS index was calculated.",
  "To evaluate glymphatic function, the Diffusion Tensor Image Analysis Along the Perivascular Space (DTI-ALPS) method was utilized and the ALPS index was calculated. Univariable and multivariable (variables with P < 0.2 from the univariable analysis) linear regression analyses were performed for |G*| and \u03c6 and included sex, age, normalized white matter hyperintensity (WMH) volume, brain parenchymal volume, and ALPS index as covariates. Results In the univariable analysis for |G*|, age (P = 0.005), brain parenchymal volume (P = 0.152), normalized WMH volume (P = 0.011), and ALPS index (P = 0.005) were identified as candidates with P < 0.2. In the multivariable analysis, only the ALPS index was independently associated with |G*|, showing a positive relationship (\u03b2 = 0.300, P = 0.029).",
  "In the multivariable analysis, only the ALPS index was independently associated with |G*|, showing a positive relationship (\u03b2 = 0.300, P = 0.029). For \u03c6, normalized WMH volume (P = 0.128) and ALPS index (P = 0.015) were identified as candidates for multivariable analysis, and only the ALPS index was independently associated with \u03c6 (\u03b2 = 0.057, P = 0.039). Conclusion Brain MRE using a gravitational transducer is feasible in neurologically normal individuals over a wide age range. The significant correlation between the viscoelastic properties of the brain and glymphatic function suggests that a more organized or preserved microenvironment of the brain parenchyma is associated with a more unimpeded glymphatic fluid flow.",
  "The significant correlation between the viscoelastic properties of the brain and glymphatic function suggests that a more organized or preserved microenvironment of the brain parenchyma is associated with a more unimpeded glymphatic fluid flow.\nAuthors: B. Joo, S. Won, R. Sinkus, Seung-Koo Lee\nVenue: Korean Journal of Radiology\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The significant correlation between the viscoelastic properties of the brain and glymphatic function suggests that a more organized or preserved microenvironment of theBrain MRE using a gravitational transducer is feasible in neurologically normal individuals over a wide age range.'}",
  "Faculty Name: bio\nMetadata:\nPaperid: e93a0de0b7ddc69cc13168b00302622f1dbfa8ba\nTitle: Nonmedical Use of Prescription Psychotropic Drugs among Secondary School Students in Parakou, northern Benin\nYear: 2023\nAbstract: None\nAuthors: Assad Bio-Sya, Philippe J Onzo, E. Klikpo, A. Allabi\nVenue: Research Journal of Drug Abuse\nTldr: None",
  "Faculty Name: bio\nMetadata:\nPaperid: fb1b32c8073b31a7e4ec0cd1ed4a0370820dc249\nTitle: La for\u00eat et la faune de C\u00f4te d\u2019Ivoire dans une situation alarmante \u2013 Synth\u00e8se des r\u00e9sultats de l\u2019Inventaire forestier et faunique national\nYear: 2023\nAbstract: La C\u00f4te d\u2019Ivoire a engag\u00e9 d\u00e9but 2019 un inventaire national de ses for\u00eats et de sa faune, accompagn\u00e9 par des enqu\u00eates socio-\u00e9conomiques aupr\u00e8s des agriculteurs. Cet inventaire, d\u00e9ploy\u00e9 sur l\u2019ensemble du territoire, fournit une grande quantit\u00e9 d\u2019informations. Il montre que l\u2019\u00e9tat des for\u00eats et de la faune est fortement d\u00e9grad\u00e9 et que les cultures industrielles (cacaoyer, h\u00e9v\u00e9a, palmier \u00e0 huile dans le sud, anacardier et coton dans le centre et le nord) sont devenues dominantes.",
  "La superficie de la for\u00eat en C\u00f4te d\u2019Ivoire est estim\u00e9e en 2020 \u00e0 2,97\u00a0millions\u00a0d\u2019hectares, soit 9,2\u00a0% de la surface totale du territoire, dont\u00a02,88\u00a0millions\u00a0d\u2019hectares de for\u00eat (dite) naturelle et un peu plus de 92\u00a0000\u00a0ha de reboisement. Le taux de d\u00e9forestation moyen annuel depuis 1986 est de 2,8\u00a0% (superficie de la for\u00eat en 1986 de 7,85\u00a0millions\u00a0d\u2019hectares). La superficie de la for\u00eat dans les for\u00eats \u00e9tatiques, dites for\u00eats class\u00e9es, n\u2019est plus que de 13,3\u00a0% alors que la cr\u00e9ation des for\u00eats class\u00e9es dans les ann\u00e9es 1970 avait pour objectif la pr\u00e9servation et la gestion durable des for\u00eats. La rar\u00e9faction, voire la disparition, des essences commerciales ne permet plus de mettre en \u0153uvre une exploitation foresti\u00e8re respectant les crit\u00e8res de gestion durable.",
  "La rar\u00e9faction, voire la disparition, des essences commerciales ne permet plus de mettre en \u0153uvre une exploitation foresti\u00e8re respectant les crit\u00e8res de gestion durable. Les aires prot\u00e9g\u00e9es (parcs nationaux, r\u00e9serves) ne contiennent plus que 32,2\u00a0% de for\u00eat. En outre, des transects d\u2019observation de la faune d\u00e9ploy\u00e9s sur tout le territoire ont permis de montrer que la faune commune (aulacode, guib harnach\u00e9, li\u00e8vre, etc.) est encore bien pr\u00e9sente. En revanche, les grands mammif\u00e8res (antilopes, \u00e9l\u00e9phants, singes) sont cantonn\u00e9s dans quelques aires prot\u00e9g\u00e9es et for\u00eats class\u00e9es avec des tailles de population souvent critiques.",
  "est encore bien pr\u00e9sente. En revanche, les grands mammif\u00e8res (antilopes, \u00e9l\u00e9phants, singes) sont cantonn\u00e9s dans quelques aires prot\u00e9g\u00e9es et for\u00eats class\u00e9es avec des tailles de population souvent critiques. Enfin, l\u2019analyse socio-\u00e9conomique montre que les for\u00eats class\u00e9es sont occup\u00e9es par une population humaine compos\u00e9e \u00e0 50\u00a0% d\u2019allog\u00e8nes, \u00e0 28\u00a0% d\u2019autochtones et \u00e0 22\u00a0% d\u2019allochtones\u00a0: le cacao occupe la plus grande partie des cultures install\u00e9es majoritairement par les allog\u00e8nes. Dans le domaine rural, ce sont surtout les autochtones (76\u00a0%) qui s\u2019investissent dans l\u2019agriculture (principalement l\u2019anacarde), suivis des allog\u00e8nes (13\u00a0%) et des allochtones (11\u00a0%). L\u2019\u00e9tat des \u00e9cosyst\u00e8mes forestiers et de leur faune est alarmant, mais des mesures fortes prises rapidement pourraient permettre d\u2019am\u00e9liorer cette situation au moins dans les secteurs les mieux pr\u00e9serv\u00e9s.",
  "L\u2019\u00e9tat des \u00e9cosyst\u00e8mes forestiers et de leur faune est alarmant, mais des mesures fortes prises rapidement pourraient permettre d\u2019am\u00e9liorer cette situation au moins dans les secteurs les mieux pr\u00e9serv\u00e9s. La poursuite de campagnes d\u2019inventaire r\u00e9guli\u00e8res sera un outil essentiel pour mesurer l\u2019impact de ces d\u00e9cisions.\nAuthors: P. Cuny, F. Plancheron, Abraham Bio, E. Kouakou, F. Morneau\nVenue: BOIS &amp; FORETS DES TROPIQUES\nTldr: None",
  "List of 2023 Open Access papers by bio are:\n491. Risk Factors for Severe Pediatric COVID-19: A Systematic Review\nAntifungal stewardship in practice: Insights from a prospective audit and feedback program\n2945. Audit and Feedback Informed ASP Interventions Lead to Sustained Reductions in Suboptimal Antibiotic Prescribing at Hospital Discharge\nCharacterisation and Dynamics of an Emerging Seagrass Meadow\nNew Methodology for Intertidal Seaweed Biomass Estimation Using Multispectral Data Obtained with Unoccupied Aerial Vehicles\nApplication of a Multispectral UAS to Assess the Cover and Biomass of the Invasive Dune Species Carpobrotus edulis\nSea Level Rise Effects on the Sedimentary Dynamics of the Douro Estuary Sandspit (Portugal)\nDispensing of Antibiotics Without Prescription in Southern Benin, West Africa, 2018\nNonmedical Use of Prescription Psychotropic Drugs among Secondary School Students in Parakou,",
  "West Africa, 2018\nNonmedical Use of Prescription Psychotropic Drugs among Secondary School Students in Parakou, northern Benin\nLa for\u00eat et la faune de C\u00f4te d\u2019Ivoire dans une situation alarmante \u2013 Synth\u00e8se des r\u00e9sultats de l\u2019Inventaire forestier et faunique national\nPengaruh Konsumsi Informasi terhadap Perilaku Pencegahan COVID-19: Studi Quasi Eksperimental Time Series\nVSC-HVDC transmission line fault location based on transient characteristics\nEpidemiological description of measles outbreaks following a mass vaccination Campaign in Bayelsa State,",
  "Nigeria\nMultimodal Imaging Findings of Cerebral Amyloid Angiopathy Related Inflammation With Unusual Clinical Manifestation: A Case Report\nClinicoradiologic Characteristics of Intradural Extramedullary Conventional Spinal Ependymoma\nMagnetic Resonance Elastography for Clinicians and Researchers Unfamiliar With the Field\nA Radiomics-Based Model for Potentially More Accurate Identification of Subtypes of Breast Cancer Brain Metastases\nAssociated Factors of Spontaneous Hemorrhage in Brain Metastases in Patients with Lung Adenocarcinoma\nProminent cerebral veins on susceptibility\u2010weighted angiography in acute meningoencephalitis\nAssessment of Meningeal Lymphatics in the Parasagittal Dural Space: A Prospective Feasibility Study Using Dynamic Contrast-Enhanced Magnetic Resonance Imaging\nClinicopathological Characteristics of NRG1 Fusion-Positive Solid Tumors in Korean Patients.\nViscoelastic Property of the Brain Assessed With Magnetic Resonance Elastography and Its Association With Glymphatic System in Neurologically Normal Individuals",
  "Title: Yonatan Bisk -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Yonatan Bisk, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Core Faculty\" name=\"categories-1\"/>\n<meta content=\"Embodiment;Grounding;RoboNLP;Unsupervised Learning;Vision and Language\" name=\"categories-2\"/>\n<meta content=\"Yes\" name=\"show-categories-2\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Yonatan Bisk - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Yonatan Bisk,",
  "Faculty Member at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Yonatan\"/>\n<meta content=\"Lastname\" property=\"profile:Bisk\"/>\n<meta content=\"http://cms-staging.andrew.cmu.edu/lti/people/faculty/bisk-yonatan.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nYonatan \n                        Bisk\nAssistant Professor, Language Technologies Institute\nContact\n6703 Gates & Hillman Centers\nybisk(through)cs.cmu.edu\nResearch Area\nEmbodiment, Grounding, RoboNLP, Unsupervised Learning, Vision and Language\nResearch\nMy work broadly falls into: 1. Uncovering the latent structures of natural language, 2. Modeling the semantics of the physical world, and 3. Connecting language to perception and control.",
  "Grounding, RoboNLP, Unsupervised Learning, Vision and Language\nResearch\nMy work broadly falls into: 1. Uncovering the latent structures of natural language, 2. Modeling the semantics of the physical world, and 3. Connecting language to perception and control.\nPersonal Website\n\nLinks:\nhttps://yonatanbisk.com/",
  "Faculty Name: brian macwhinney\nMetadata:\nPaperid: 02a626bd8538ecb675bd2bcd8f5985274e965d00\nTitle: Assessment and Therapy Goal Planning Using Free Computerized Language Analysis Software.\nYear: 2023\nAbstract: Background\nWe discuss a free software system (Computerized Language Analysis [CLAN]) that can enable fast, thorough, and informative language sample analysis (LSA).\n\n\nMethod\nWe describe methods for eliciting, transcribing, analyzing, and interpreting language samples. Using a hypothetical child speaker, we illustrate use KidEval to generate a diagnostic report.\n\n\nResults\nGiven LSA results suggestive of expressive language delay, we analyze further using CLAN's Developmental Sentence Score and Index of Productive Syntax routines, and outline the child's use of Brown's morphemes.",
  "Results\nGiven LSA results suggestive of expressive language delay, we analyze further using CLAN's Developmental Sentence Score and Index of Productive Syntax routines, and outline the child's use of Brown's morphemes.\n\n\nDiscussion\nThis tutorial provides an introduction to the use of free CLAN software. We discuss how LSA results can be used to structure therapy goals that address specific aspects of grammatical structure that the child may not yet demonstrate in their spoken language. Finally, we provide answers to common questions, including user support.\nAuthors: N. Ratner, B. MacWhinney\nVenue: Perspectives of the ASHA Special Interest Groups\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This tutorial provides an introduction to the use of free CLAN software and discusses how LSA results can be used to structure therapy goals that address specific aspects of grammatical structure that the child may not yet demonstrate in their spoken language.'}",
  "Faculty Name: brian macwhinney\nMetadata:\nPaperid: 0773228ecc4c1f2d729c0ae5764c77c1c9bb9573\nTitle: Automation of Language Sample Analysis\nYear: 2023\nAbstract: Purpose: A major barrier to the wider use of language sample analysis (LSA) is the fact that transcription is very time intensive. Methods that can reduce the required time and effort could help in promoting the use of LSA for clinical practice and research. Method: This article describes an automated pipeline, called Batchalign, that takes raw audio and creates full transcripts in Codes for the Human Analysis of Talk (CHAT) transcription format, complete with utterance- and word-level time alignments and morphosyntactic analysis. The pipeline only requires major human intervention for final checking. It combines a series of existing tools with additional novel reformatting processes. The steps in the pipeline are (a) automatic speech recognition, (b) utterance tokenization, (c) automatic corrections, (d) speaker ID assignment, (e) forced alignment, (f) user adjustments, and (g) automatic morphosyntactic and profiling analyses.",
  "The steps in the pipeline are (a) automatic speech recognition, (b) utterance tokenization, (c) automatic corrections, (d) speaker ID assignment, (e) forced alignment, (f) user adjustments, and (g) automatic morphosyntactic and profiling analyses. Results: For work with recordings from adults with language disorders, six major results were obtained: (a) The word error rate was between 2.4% for controls and 3.4% for patients, (b) utterance tokenization accuracy was at the level reported for speakers without language disorders, (c) word-level diarization accuracy was at 93% for control participants and 83% for participants with language disorders, (d) utterance-level diarization accuracy based on word-level diarization was high, (e) adherence to CHAT format was fully accurate, and (f) human transcriber time was reduced by up to 75%. Conclusion: The pipeline dramatically shortens the time gap between data collection and data analysis and provides an output superior to that typically generated by human transcribers.",
  "Conclusion: The pipeline dramatically shortens the time gap between data collection and data analysis and provides an output superior to that typically generated by human transcribers.\nAuthors: Houjun Liu, B. MacWhinney, Davida Fromm, Alyssa M. Lanzi\nVenue: Journal of Speech, Language and Hearing Research\nTldr: {'model': 'tldr@v2.0.0', 'text': 'An automated pipeline that takes raw audio and creates full transcripts in Codes for the Human Analysis of Talk (CHAT) transcription format, complete with utterance- and word-level time alignments and morphosyntactic analysis, provides an output superior to that typically generated by human transcribers.'}",
  "Faculty Name: brian macwhinney\nMetadata:\nPaperid: 283dbaa4da4beafa5e5719095bcc88e63d17815e\nTitle: The role of novelty stimuli in second language acquisition: evidence from the optimized training by the Pinyin Tutor at TalkBank\nYear: 2023\nAbstract: None\nAuthors: Yanhui Zhang, B. MacWhinney\nVenue: Smart Learning Environments\nTldr: None",
  "Faculty Name: brian macwhinney\nMetadata:\nPaperid: 3859f18277f0c5876a53411b07f80d65254c52e5\nTitle: Using diagnostic feedback to enhance the development of phonetic knowledge of an L2: a CALL design based on the unified competition model and the implementation with the Pinyin Tutor\nYear: 2023\nAbstract: None\nAuthors: Yanhui Zhang, B. MacWhinney\nVenue: Language Testing in Asia\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The findings demonstrated that the repeated feedback-embedded training with the Pinyin Tutor significantly boosted the learners\u2019 proficiency in all aspects of PinyIn knowledge for second language (L2) learners of Chinese whose first language backgrounds were varied and whose initial proficiencies in Chinese were elementary.'}",
  "Faculty Name: brian macwhinney\nMetadata:\nPaperid: 4d35540aaf993c8fa7e1fa5fc6a990f1eb830263\nTitle: A New Benchmark of Aphasia Speech Recognition and Detection Based on E-Branchformer and Multi-task Learning\nYear: 2023\nAbstract: Aphasia is a language disorder that affects the speaking ability of millions of patients. This paper presents a new benchmark for Aphasia speech recognition and detection tasks using state-of-the-art speech recognition techniques with the AphsiaBank dataset. Specifically, we introduce two multi-task learning methods based on the CTC/Attention architecture to perform both tasks simultaneously. Our system achieves state-of-the-art speaker-level detection accuracy (97.3%), and a relative WER reduction of 11% for moderate Aphasia patients. In addition, we demonstrate the generalizability of our approach by applying it to another disordered speech database, the DementiaBank Pitt corpus. We will make our all-in-one recipes and pre-trained model publicly available to facilitate reproducibility. Our standardized data preprocessing pipeline and open-source recipes enable researchers to compare results directly, promoting progress in disordered speech processing.",
  "We will make our all-in-one recipes and pre-trained model publicly available to facilitate reproducibility. Our standardized data preprocessing pipeline and open-source recipes enable researchers to compare results directly, promoting progress in disordered speech processing.\nAuthors: Jiyang Tang, William Chen, Xuankai Chang, Shinji Watanabe, B. MacWhinney\nVenue: Interspeech\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A new benchmark for Aphasia speech recognition and detection tasks using state-of-the-art speech recognition techniques with the AphsiaBank dataset is presented and two multi-task learning methods based on the CTC/Attention architecture are introduced to perform both tasks simultaneously.'}",
  "Faculty Name: brian macwhinney\nMetadata:\nPaperid: 52b48ab5d7d87642395818bea1ff804ff6dd0bd3\nTitle: Collaborative Commentary for Understanding Communication Disorders.\nYear: 2023\nAbstract: PURPOSE\nThe goal of the Collaborative Commentary (CC) system is to make the TalkBank adult clinical databases-including AphasiaBank, DementiaBank, RHDBank, and TBIBank-open to commentary and analysis from the full community of researchers, instructors, students, and clinicians.\n\n\nMETHOD\nCC allows a group leader to establish a commentary group and invite colleagues or students to join as members of the group. Members can then browse through the transcript database using the TalkBank Browser. When they wish to insert a comment, they click on the utterance line number or drag the cursor across a range of utterances and a window opens to receive the comment. The comment can include open text along with codes selected from a predefined set of codes created by that commentary group.",
  "RESULTS\nCC was released for public use in August 2022. It is being used currently in five research projects and eight classes. An important feature of CC is its ability to evaluate the reliability of coding systems and to sharpen analytic categories. By familiarizing instructors and researchers with the capabilities of CC, we expect to see an increasing usage of CC for a variety of clinical and research applications.\n\n\nCONCLUSIONS\nCC can contribute to a better understanding of connected speech features in aphasia, dementia, right hemisphere disorder, and traumatic brain injury. CC represents an extreme innovation not only for the study of adult neurogenic communication disorders but also for the study of spoken language generally.\nAuthors: B. MacWhinney, Davida Fromm\nVenue: American Journal of Speech-Language Pathology\nTldr: {'model': 'tldr@v2.0.0', 'text': 'CC can contribute to a better understanding of connected speech features in aphasia, dementia, right hemisphere disorder, and traumatic brain injury and is being used currently in five research projects and eight classes.'}",
  "Faculty Name: brian macwhinney\nMetadata:\nPaperid: cf152ac1b3c9daea5b48f858acc13193a83df185\nTitle: Establishing the DementiaBank Delaware Corpus: An Online Multimedia Database for the Study of Language and Cognition in Dementia\nYear: 2023\nAbstract: To better understand the progressive decline of language abilities in aging and dementia, we expanded the quality and quantity of resources in DementiaBank \u2014 an open\u2010access database of multimedia spoken language interactions for the study of speech and language abilities across the progression of dementia. This work builds from the success of the TalkBank Project with regard to data sharing, transcription, analysis, and web delivery. Specifically, this work collected connected speech and language data to develop the new \u201cDelaware corpus\u201d and to share resources for future analyses.",
  "This work builds from the success of the TalkBank Project with regard to data sharing, transcription, analysis, and web delivery. Specifically, this work collected connected speech and language data to develop the new \u201cDelaware corpus\u201d and to share resources for future analyses.\nAuthors: Alyssa M. Lanzi, Anna K Saylor, Davida Fromm, B. MacWhinney, Matthew L Cohen\nVenue: Alzheimer's &amp; Dementia\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work collected connected speech and language data to develop the new \u201cDelaware corpus\u201d and to share resources for future analyses to better understand the progressive decline of language abilities in aging and dementia.'}",
  "Faculty Name: brian macwhinney\nMetadata:\nPaperid: d898963243ad4b177b799f197a7732395e165cf6\nTitle: Evaluating Picture Description Speech for Dementia Detection using Image-text Alignment\nYear: 2023\nAbstract: Using picture description speech for dementia detection has been studied for 30 years. Despite the long history, previous models focus on identifying the differences in speech patterns between healthy subjects and patients with dementia but do not utilize the picture information directly. In this paper, we propose the first dementia detection models that take both the picture and the description texts as inputs and incorporate knowledge from large pre-trained image-text alignment models. We observe the difference between dementia and healthy samples in terms of the text's relevance to the picture and the focused area of the picture. We thus consider such a difference could be used to enhance dementia detection accuracy. Specifically, we use the text's relevance to the picture to rank and filter the sentences of the samples. We also identified focused areas of the picture as topics and categorized the sentences according to the focused areas.",
  "We thus consider such a difference could be used to enhance dementia detection accuracy. Specifically, we use the text's relevance to the picture to rank and filter the sentences of the samples. We also identified focused areas of the picture as topics and categorized the sentences according to the focused areas. We propose three advanced models that pre-processed the samples based on their relevance to the picture, sub-image, and focused areas. The evaluation results show that our advanced models, with knowledge of the picture and large image-text alignment models, achieve state-of-the-art performance with the best detection accuracy at 83.44%, which is higher than the text-only baseline model at 79.91%. Lastly, we visualize the sample and picture results to explain the advantages of our models.",
  "Lastly, we visualize the sample and picture results to explain the advantages of our models.\nAuthors: Youxiang Zhu, Nan Lin, Xiaohui Liang, J. Batsis, R. Roth, B. MacWhinney\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The first dementia detection models that take both the picture and the description texts as inputs and incorporate knowledge from large pre-trained image-text alignment models are proposed and achieve state-of-the-art performance.'}",
  "Faculty Name: brian macwhinney\nMetadata:\nPaperid: f1ebdd8c99aa33284e3604c28b72efa9dc46047c\nTitle: Multilingual Alzheimer\u2019s Dementia Recognition through Spontaneous Speech: A Signal Processing Grand Challenge\nYear: 2023\nAbstract: This Signal Processing Grand Challenge (SPGC) targets a difficult automatic prediction problem of societal and medical relevance, namely, the detection of Alzheimer\u2019s Dementia (AD). Participants were invited to employ signal processing and machine learning methods to create predictive models based on spontaneous speech data. The Challenge has been designed to assess the extent to which predictive models built based on speech in one language (English) generalise to another language (Greek). To the best of our knowledge no work has investigated acoustic features of the speech signal in multilingual AD detection. Our baseline system used conventional machine learning algorithms with Active Data Representation of acoustic features, achieving accuracy of 73.91% on AD detection, and 4.95 root mean squared error on cognitive score prediction.",
  "Our baseline system used conventional machine learning algorithms with Active Data Representation of acoustic features, achieving accuracy of 73.91% on AD detection, and 4.95 root mean squared error on cognitive score prediction.\nAuthors: S. Luz, F. Haider, Davida Fromm, Ioulietta Lazarou, Y. Kompatsiaris, B. MacWhinney\nVenue: IEEE International Conference on Acoustics, Speech, and Signal Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This Signal Processing Grand Challenge (SPGC) targets a difficult automatic prediction problem of societal and medical relevance, namely, the detection of Alzheimer\u2019s Dementia, and aims to assess the extent to which predictive models built based on speech in one language generalise to another language.'}",
  "Faculty Name: brian macwhinney\nMetadata:\nPaperid: f7254ae607056ba5522c10dbcf21b394967b6d42\nTitle: DementiaBank: Theoretical Rationale, Protocol, and Illustrative Analyses\nYear: 2023\nAbstract: Purpose: Dementia from Alzheimer's disease (AD) is characterized primarily by a significant decline in memory abilities; however, language abilities are also commonly affected and may precede the decline of other cognitive abilities. To study the progression of language, there is a need for open-access databases that can be used to build algorithms to produce translational models sensitive enough to detect early declines in language abilities. DementiaBank is an open-access repository of transcribed video/audio data from communicative interactions from people with dementia, mild cognitive impairment (MCI), and controls. The aims of this tutorial are to (a) describe the newly established standardized DementiaBank discourse protocol, (b) describe the Delaware corpus data, and (c) provide examples of automated linguistic analyses that can be conducted with the Delaware corpus data and describe additional DementiaBank resources.",
  "The aims of this tutorial are to (a) describe the newly established standardized DementiaBank discourse protocol, (b) describe the Delaware corpus data, and (c) provide examples of automated linguistic analyses that can be conducted with the Delaware corpus data and describe additional DementiaBank resources. Method: The DementiaBank discourse protocol elicits four types of discourse: picture description, story narrative, procedural, and personal narrative. The Delaware corpus currently includes data from 20 neurotypical adults and 33 adults with MCI from possible AD who completed the DementiaBank discourse protocol and a cognitive\u2013linguistic battery. Language samples were video- and audio-recorded, transcribed, coded, and uploaded to DementiaBank. The protocol materials and transcription programs can be accessed for free via the DementiaBank website. Results: Illustrative analyses show the potential of the Delaware corpus data to help understand discourse metrics at the individual and group levels. In addition, they highlight analyses that could be used across TalkBank's other clinical banks (e.g., AphasiaBank). Information is also included on manual and automatic speech recognition transcription methods.",
  "In addition, they highlight analyses that could be used across TalkBank's other clinical banks (e.g., AphasiaBank). Information is also included on manual and automatic speech recognition transcription methods. Conclusions: DementiaBank is a shared online database that can facilitate research efforts to address the gaps in knowledge about language changes associated with MCI and dementia from AD. Identifying early language markers could lead to improved assessment and treatment approaches for adults at risk for dementia.\nAuthors: Alyssa M. Lanzi, Anna K Saylor, Davida Fromm, Houjun Liu, B. MacWhinney, Matthew L. Cohen\nVenue: American Journal of Speech-Language Pathology\nTldr: {'model': 'tldr@v2.0.0', 'text': 'DementiaBank is a shared online database that can facilitate research efforts to address the gaps in knowledge about language changes associated with MCI and dementia from AD and is shown to have potential to help understand discourse metrics at the individual and group levels.'}",
  "List of 2023 Open Access papers by brian macwhinney are:\nAssessment and Therapy Goal Planning Using Free Computerized Language Analysis Software.\nAutomation of Language Sample Analysis\nThe role of novelty stimuli in second language acquisition: evidence from the optimized training by the Pinyin Tutor at TalkBank\nUsing diagnostic feedback to enhance the development of phonetic knowledge of an L2: a CALL design based on the unified competition model and the implementation with the Pinyin Tutor\nA New Benchmark of Aphasia Speech Recognition and Detection Based on E-Branchformer and Multi-task Learning\nCollaborative Commentary for Understanding Communication Disorders.\nEstablishing the DementiaBank Delaware Corpus: An Online Multimedia Database for the Study of Language and Cognition in Dementia\nEvaluating Picture Description Speech for Dementia Detection using Image-text Alignment\nMultilingual Alzheimer\u2019s Dementia Recognition through Spontaneous Speech: A Signal Processing Grand Challenge\nDementiaBank: Theoretical Rationale, Protocol, and Illustrative Analyses",
  "Title: Ralf Brown -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Ralf Brown, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Core Faculty\" name=\"categories-1\"/>\n<meta content=\"Information Extraction, Summarization and Question Answering;Information Retrieval, Text Mining and Analytics;Machine Translation;Natural Language Processing and Computational Linguistics\" name=\"categories-2\"/>\n<meta content=\"Yes\" name=\"show-categories-2\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Ralf Brown - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Ralf Brown,",
  "Faculty Member at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Ralf\"/>\n<meta content=\"Lastname\" property=\"profile:Brown\"/>\n<meta content=\"http://cms-staging.andrew.cmu.edu/lti/people/faculty/brown-ralf.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nRalf \n                        Brown\nSenior Systems Scientist/Chair of Admissions, Language Technologies Institute\nContact\n5711 Gates & Hillman Centers\nralf(through)andrew.cmu.edu\n412-268-8298\nResearch Area\nInformation Extraction, Summarization and Question Answering, Information Retrieval, Text Mining and Analytics, Machine Translation, Natural Language Processing and Computational Linguistics\nResearch\nMy research interests primarily revolve around multilingual processing,",
  "cmu.edu\n412-268-8298\nResearch Area\nInformation Extraction, Summarization and Question Answering, Information Retrieval, Text Mining and Analytics, Machine Translation, Natural Language Processing and Computational Linguistics\nResearch\nMy research interests primarily revolve around multilingual processing, with sidelines in text categorization and information extraction:\nMachine Translation\nI have worked primarily on example-based machine translation (EBMT), a data-driven translation approach that originated a few years before statistical machine translation characterized by the use of individual examples from the training corpus during translation. I have also applied my EBMT system to cross-language information retrieval and speech-to-speech translation.\nDigital Forensics\nI have worked on reconstructing corrupted ZIP archives and on extracting text in arbitrary encodings from files and raw disk images. As part of this work, I developed language identification for more than 1,300 languages, and am continuing to improve the accuracy with which languages can be identified.\nInformation Extraction\nMy current work focuses on extracting actions and affected components from aircraft maintenance records.\nPersonal Website\n\nLinks:\nhttps://lti.cs.cmu.edu/research-areas/natural-language-processing-and-computational-linguistics\nhttp://www.cs.cmu.edu/~ralf/",
  "Title: Jamie Callan -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Jamie Callan, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Core Faculty\" name=\"categories-1\"/>\n<meta content=\"Information Retrieval, Text Mining and Analytics\" name=\"categories-2\"/>\n<meta content=\"Yes\" name=\"show-categories-2\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Jamie Callan - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Jamie Callan, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Jamie \"/>\n<meta content=\"Lastname\" property=\"profile:Callan\"/>\n<meta content=\"http://lti.cmu.",
  "Faculty Member at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Jamie \"/>\n<meta content=\"Lastname\" property=\"profile:Callan\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/callan-jamie.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nJamie  \n                        Callan\nProfessor, Language Technologies Institute\nContact\n5419 \u2014Gates & Hillman Centers\ncallan(through)cs.cmu.edu\n412-268-4525\nResearch Area\nInformation Retrieval, Text Mining and Analytics\nResearch\nMy research and teaching focus on information retrieval and analysis. I have worked on a wide range of topics over the years, but am particularly interested in search engine architectures, information filtering and text mining. A sample of current projects is shown below. See my\npersonal webpage\nfor more information.",
  "I have worked on a wide range of topics over the years, but am particularly interested in search engine architectures, information filtering and text mining. A sample of current projects is shown below. See my\npersonal webpage\nfor more information.\nProjects\nLemur: The Lemur Project develops open-source search engines, toolbars, text analysis tools, search services and datasets that support international research and development. The project is best known for its Indri and Galago search engines, and large-scale ClueWeb datasets. Our software and datasets are widely used in scientific and research applications, and some commercial applications. Lemur's software development philosophy emphasizes state-of-the-art accuracy, flexibility and efficiency.\nSearch Engines With Knowledge Resources: This project develops new methods for using knowledge graphs and ontologies to improve search engine accuracy, especially for vague, ambiguous or poorly specified queries. Knowledge graphs and ontologies are less structured than typical relational databases and semantic web resources, but more structured than text stored in full-text search engines. The weak semantics in these semi-structured information resources can support interesting applications, but can also accommodate contradictions, inconsistencies and mistakes \u2014 making them easier to scale for large amounts of information.",
  "The weak semantics in these semi-structured information resources can support interesting applications, but can also accommodate contradictions, inconsistencies and mistakes \u2014 making them easier to scale for large amounts of information. A search engine can use these resources to identify the probable meanings of query terms, and use this knowledge to identify documents that match those meanings.\nRetrieval of Scientific Data: Numerical data continues to expand as the results of scholarly research in data-rich sciences (e.g., non-textual data) continue to grow. This project extends search engine architectures to support large, centralized, universal repositories of affordable and easily used scientific data. Our goal is to access tabular, numeric and other non-textual information as easily and readily as documents without laborious additional work.\nSelective and Federated Search: I have a long-term interest in environments that contain numerous search engines. Much of my prior research focused on integrating many independent search engines \u2014 perhaps operated by different organizations with different interests\u2014 into a single integrated federated search system. My recent work investigates a related problem: decomposing a massive text collection into hundreds or thousands of small search engines designed to have skewed utility distributions that enable most index partitions to be ignored for most queries.",
  "My recent work investigates a related problem: decomposing a massive text collection into hundreds or thousands of small search engines designed to have skewed utility distributions that enable most index partitions to be ignored for most queries. This\nselective search\narchitecture is as effective as conventional search engine architectures, but has far lower computational costs and reveals new challenges and opportunities in large-scale search. The decomposition process creates text collections, thus inviting research on the characteristics desired or to be avoided in a text collection to enable accurate search. We've developed new resource selection algorithms to address efficiency problems in existing algorithms and dynamically adjust search costs based on query difficulty. Our goal is an easily customizable and extensible off-the-shelf method that provides an order of magnitude reduction in search costs over the current state-of-the-art, especially on corpora of more than a billion documents.\nPersonal Website\n\nLinks:\nhttp://www.cs.cmu.edu/~callan/\nhttp://www.cs.cmu.edu/~callan/",
  "Faculty Name: carolyn ros\u00e9\nMetadata:\nPaperid: 06dc7b3d8cbc40fb4e39b42de1bc664deaacca74\nTitle: High school students\u2019 data modeling practices and processes: from modeling unstructured data to evaluating automated decisions\nYear: 2023\nAbstract: ABSTRACT It\u2019s critical to foster artificial intelligence (AI) literacy for high school students, the first generation to grow up surrounded by AI, to understand working mechanism of data-driven AI technologies and critically evaluate automated decisions from predictive models. While efforts have been made to engage youth in understanding AI through developing machine learning models, few provided in-depth insights into the nuanced learning processes. In this study, we examined high school students\u2019 data modeling practices and processes. Twenty-eight students developed machine learning models with text data for classifying negative and positive reviews of ice cream stores. We identified nine data modeling practices that describe students\u2019 processes of model exploration, development, and testing and two themes about evaluating automated decisions from data technologies. The results provide implications for designing accessible data modeling experiences for students to understand data justice as well as the role and responsibility of data modelers in creating AI technologies.",
  "We identified nine data modeling practices that describe students\u2019 processes of model exploration, development, and testing and two themes about evaluating automated decisions from data technologies. The results provide implications for designing accessible data modeling experiences for students to understand data justice as well as the role and responsibility of data modelers in creating AI technologies.\nAuthors: Shiyan Jiang, Hengtao Tang, Can Tatar, C. Ros\u00e9, J. Chao\nVenue: Journal of Educational Media\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It\u2019s critical to foster artificial intelligence literacy for high school students to understand working mechanism of data-driven AI technologies and critically evaluate automated decisions from predictive models.'}",
  "Faculty Name: carolyn ros\u00e9\nMetadata:\nPaperid: 0c0d8ea1c1745e7b56bc3b1513a715ae3df30c44\nTitle: Linguistic representations for fewer-shot relation extraction across domains\nYear: 2023\nAbstract: Recent work has demonstrated the positive impact of incorporating linguistic representations as additional context and scaffolds on the in-domain performance of several NLP tasks. We extend this work by exploring the impact of linguistic representations on cross-domain performance in a few-shot transfer setting. An important question is whether linguistic representations enhance generalizability by providing features that function as cross-domain pivots. We focus on the task of relation extraction on three datasets of procedural text in two domains, cooking and materials science. Our approach augments a popular transformer-based architecture by alternately incorporating syntactic and semantic graphs constructed by freely available off-the-shelf tools. We examine their utility for enhancing generalization, and investigate whether earlier findings, e.g. that semantic representations can be more helpful than syntactic ones, extend to relation extraction in multiple domains.",
  "We examine their utility for enhancing generalization, and investigate whether earlier findings, e.g. that semantic representations can be more helpful than syntactic ones, extend to relation extraction in multiple domains. We find that while the inclusion of these graphs results in significantly higher performance in few-shot transfer, both types of graph exhibit roughly equivalent utility.\nAuthors: Sireesh Gururaja, Ritam Dutt, Ting-gen Liao, C. Ros\u00e9\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work explores the impact of linguistic representations on cross-domain performance in a few-shot transfer setting, and investigates whether earlier findings, e.g. that semantic representations can be more helpful than syntactic ones, extend to relation extraction in multiple domains.'}",
  "Faculty Name: carolyn ros\u00e9\nMetadata:\nPaperid: 117e1323677cb5d78ece0fd07b5cfa81618f4866\nTitle: Using counterfactual contrast to improve compositional generalization for multi-step quantitative reasoning\nYear: 2023\nAbstract: In quantitative question answering, compositional generalization is one of the main challenges of state of the art models, especially when longer sequences of reasoning steps are required. In this paper we propose CounterComp, a method that uses counterfactual scenarios to generate samples with compositional contrast. Instead of a data augmentation approach, CounterComp is based on metric learning, which allows for direct sampling from the training set and circumvents the need for additional human labels. Our proposed auxiliary metric learning loss improves the performance of three state of the art models on four recently released datasets. We also show how the approach can improve OOD performance on unseen domains, as well as unseen compositions. Lastly, we demonstrate how the method can lead to better compositional attention patterns during training.",
  "Our proposed auxiliary metric learning loss improves the performance of three state of the art models on four recently released datasets. We also show how the approach can improve OOD performance on unseen domains, as well as unseen compositions. Lastly, we demonstrate how the method can lead to better compositional attention patterns during training.\nAuthors: Armineh Nourbakhsh, Sameena Shah, C. Ros\u00e9\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper proposes CounterComp, a method that uses counterfactual scenarios to generate samples with compositional contrast based on metric learning, which allows for direct sampling from the training set and circumvents the need for additional human labels.'}",
  "Faculty Name: carolyn ros\u00e9\nMetadata:\nPaperid: 15d85036b15388bcb0199c83c01ba833e6095a31\nTitle: Towards Extracting and Understanding the Implicit Rubrics of Transformer Based Automatic Essay Scoring Models\nYear: 2023\nAbstract: By aligning the functional components derived from the activations of transformer models trained for AES with external knowledge such as human-understandable feature groups, the proposed method improves the interpretability of a Longformer Automatic Essay Scoring (AES) system and provides tools for performing such analyses on further neural AES systems. The analysis focuses on models trained to score essays based on organization, main idea, support, and language. The findings provide insights into the models\u2019 decision-making processes, biases, and limitations, contributing to the development of more transparent and reliable AES systems.",
  "The analysis focuses on models trained to score essays based on organization, main idea, support, and language. The findings provide insights into the models\u2019 decision-making processes, biases, and limitations, contributing to the development of more transparent and reliable AES systems.\nAuthors: James Fiacco, David Adamson, C. Ros\u00e9\nVenue: Workshop on Innovative Use of NLP for Building Educational Applications\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The proposed method improves the interpretability of a Longformer Automatic Essay Scoring (AES) system and provides tools for performing such analyses on further neural AES systems.'}",
  "Faculty Name: carolyn ros\u00e9\nMetadata:\nPaperid: 27ca2d927421035e10b48c96a96db32224f1f8e6\nTitle: Exploring Artificial Intelligence in English Language Arts with StoryQ\nYear: 2023\nAbstract: Exploring Artificial Intelligence (AI) in English Language Arts (ELA) with StoryQ is a 10-hour curriculum module designed for high school ELA classes. The module introduces students to fundamental AI concepts and essential machine learning workflow using StoryQ, a web-based GUI environment for Grades 6-12 learners. In this module, students work with unstructured text data and learn to train, test, and improve text classification models such as intent recognition, clickbait filter, and sentiment analysis. As they interact with machine-learning language models deeply, students also gain a nuanced understanding of language and how to wield it, not just as a data structure, but as a tool in our human-human encounters as well. The current version contains eight lessons, all delivered through a full-featured online learning and teaching platform. Computers and Internet access are required to implement the module.",
  "The current version contains eight lessons, all delivered through a full-featured online learning and teaching platform. Computers and Internet access are required to implement the module. The module was piloted in an ELA class in the Spring of 2022, and the student learning outcomes were positive. The module is currently undergoing revision and will be further tested and improved in Fall 2022.\nAuthors: J. Chao, Rebecca Ellis, Shiyan Jiang, C. Ros\u00e9, W. Finzer, Can Tatar, James Fiacco, Kenia Wiedemann\nVenue: AAAI Conference on Artificial Intelligence\nTldr: {'model': 'tldr@v2.0.0', 'text': None}",
  "Faculty Name: carolyn ros\u00e9\nMetadata:\nPaperid: 2f760d84babe36f98d2fdc5b6dcb60c0169a3466\nTitle: Studying Interdisciplinary Collaboration as a Core Skill\nYear: 2023\nAbstract: None\nAuthors: Rosanna Vitiello, Joey Huang, Samantha Speer, N. Yankova, Kylie A Peppler, Melisa Orta-Martinez, Carolyn P. Ros\u00e9\nVenue: Proceedings of the International Conference on Computer-supported for Collaborative Learning\nTldr: None",
  "Faculty Name: carolyn ros\u00e9\nMetadata:\nPaperid: 7ec990ab7362e8eac0c074830d44a58a1d89b4a6\nTitle: Enhancing student learning and achievement through orchestration of group processes and group composition\nYear: 2023\nAbstract: None\nAuthors: Carolyn P. Ros\u00e9, Sanna J\u00e4rvel\u00e4\nVenue: International Journal of Computer-Supported Collaborative Learning\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This September issue of the International Journal of Computer-Supported Collaborative Learning reflects on the importance of productive collaborative processes, with an emphasis on feedback processes, and the scaffolding that upholds and promotes productive learning processes, whether it is explicit or implicit.'}",
  "Faculty Name: carolyn ros\u00e9\nMetadata:\nPaperid: 9fdc5ca71d1600bee600a4398315af5c29b3955e\nTitle: SPEERLoom: An Open-Source Loom Kit for Interdisciplinary Engagement in Math, Engineering, and Textiles\nYear: 2023\nAbstract: Weaving is a fabrication process that is grounded in mathematics and engineering: from the binary, matrix-like nature of the pattern drafts weavers have used for centuries, to the punch card programming of the first Jacquard looms. This intersection of disciplines provides an opportunity to ground abstract mathematical concepts in a concrete and embodied art, viewing this textile art through the lens of engineering. Currently, available looms are not optimized to take advantage of this opportunity to increase mathematics learning by providing hands-on interdisciplinary learning in collegiate classrooms. In this work, we present SPEERLoom: an open-source, robotic Jacquard loom kit designed to be a tool for interweaving cloth fabrication, mathematics, and engineering to support interdisciplinary learning in the classroom. We discuss the design requirements and subsequent design of SPEERLoom.",
  "In this work, we present SPEERLoom: an open-source, robotic Jacquard loom kit designed to be a tool for interweaving cloth fabrication, mathematics, and engineering to support interdisciplinary learning in the classroom. We discuss the design requirements and subsequent design of SPEERLoom. We also present the results of a pilot study in a post-secondary class finding that SPEERLoom supports hands-on, interdisciplinary learning of math, engineering, and textiles.\nAuthors: Samantha Speer, Ana P Garcia-Alonzo, Joey Huang, N. Yankova, Carolyn Ros\u00e9, Kylie A Peppler, James Mccann, Melisa Orta Martinez\nVenue: ACM Symposium on User Interface Software and Technology\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The design requirements and subsequent design of SPEERLoom, an open-source, robotic Jacquard loom kit designed to be a tool for interweaving cloth fabrication, mathematics, and engineering to support interdisciplinary learning in the classroom are discussed.'}",
  "Faculty Name: carolyn ros\u00e9\nMetadata:\nPaperid: bc936884d358d73d6b514f7e5899e67ad09690d8\nTitle: Editorial: Nine elements for robust collaborative learning analytics: A constructive collaborative critique\nYear: 2023\nAbstract: None\nAuthors: A. Wise, Carolyn P. Ros\u00e9, Sanna J\u00e4rvel\u00e4\nVenue: International Journal of Computer-Supported Collaborative Learning\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The four full articles of this March issue offer a view of the kind of work that the CSCL community is engaging in to capture meaningful traces of learning, map them onto valued learning constructs, and discover useful ways to present them back to teachers, students and other educational stakeholders.'}",
  "List of 2023 Open Access papers by carolyn ros\u00e9 are:\nEnhancing student learning and achievement through orchestration of group processes and group composition\nEditorial: Nine elements for robust collaborative learning analytics: A constructive collaborative critique\nHigh school students\u2019 data modeling practices and processes: from modeling unstructured data to evaluating automated decisions\nLinguistic representations for fewer-shot relation extraction across domains\nUsing counterfactual contrast to improve compositional generalization for multi-step quantitative reasoning\nTowards Extracting and Understanding the Implicit Rubrics of Transformer Based Automatic Essay Scoring Models\nExploring Artificial Intelligence in English Language Arts with StoryQ\nSPEERLoom: An Open-Source Loom Kit for Interdisciplinary Engagement in Math, Engineering, and Textiles\nStudying Interdisciplinary Collaboration as a Core Skill",
  "Title: Justine Cassell -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Justine Cassell, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Core Faculty\" name=\"categories-1\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Justine Cassell - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Justine Cassell, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Justine\"/>\n<meta content=\"Lastname\" property=\"profile:Cassell\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/cassell-justine.",
  "cmu.edu//people/faculty/cassell-justine.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nJustine \n                        Cassell\nProfessor (On Leave), Language Technologies Institute\nContact\n5107 \u2014Gates & Hillman Centers\njcassell(through)andrew.cmu.edu\n412-204-6268\nHuman-Computer Interaction Institute\nPersonal Website\n\nLinks:\nhttps://hcii.cmu.edu/\nhttp://www.justinecassell.com/",
  "Faculty Name: chenyan xiong\nMetadata:\nPaperid: 105759bdb5e3bddc1d3244df2eff2d5c997a1d84\nTitle: Improving Multitask Retrieval by Promoting Task Specialization\nYear: 2023\nAbstract: Abstract In multitask retrieval, a single retriever is trained to retrieve relevant contexts for multiple tasks. Despite its practical appeal, naive multitask retrieval lags behind task-specific retrieval, in which a separate retriever is trained for each task. We show that it is possible to train a multitask retriever that outperforms task-specific retrievers by promoting task specialization. The main ingredients are: (1) a better choice of pretrained model\u2014one that is explicitly optimized for multitasking\u2014along with compatible prompting, and (2) a novel adaptive learning method that encourages each parameter to specialize in a particular task. The resulting multitask retriever is highly performant on the KILT benchmark.",
  "The resulting multitask retriever is highly performant on the KILT benchmark. Upon analysis, we find that the model indeed learns parameters that are more task-specialized compared to naive multitasking without prompting or adaptive learning.1\nAuthors: Wenzheng Zhang, Chenyan Xiong, K. Stratos, Arnold Overwijk\nVenue: Transactions of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is shown that it is possible to train a multitask retriever that outperforms task-specific retrievers by promoting task specialization, and the model indeed learns parameters that are more task-specialized compared to naive multitasking without prompting or adaptive learning.'}",
  "Faculty Name: chenyan xiong\nMetadata:\nPaperid: 159100c8323fc558e4073a3a006f3f243aca3a60\nTitle: Text Matching Improves Sequential Recommendation by Reducing Popularity Biases\nYear: 2023\nAbstract: This paper proposes Text mAtching based SequenTial rEcommenda-tion model (TASTE), which maps items and users in an embedding space and recommends items by matching their text representations. TASTE verbalizes items and user-item interactions using identifiers and attributes of items. To better characterize user behaviors, TASTE additionally proposes an attention sparsity method, which enables TASTE to model longer user-item interactions by reducing the self-attention computations during encoding. Our experiments show that TASTE outperforms the state-of-the-art methods on widely used sequential recommendation datasets. TASTE alleviates the cold start problem by representing long-tail items using full-text modeling and bringing the benefits of pretrained language models to recommendation systems. Our further analyses illustrate that TASTE significantly improves the recommendation accuracy by reducing the popularity bias of previous item id based recommendation models and returning more appropriate and text-relevant items to satisfy users.",
  "Our further analyses illustrate that TASTE significantly improves the recommendation accuracy by reducing the popularity bias of previous item id based recommendation models and returning more appropriate and text-relevant items to satisfy users. All codes are available at https://github.com/OpenMatch/TASTE.\nAuthors: Zhenghao Liu, Senkun Mei, Chenyan Xiong, Xiaohua Li, Shi Yu, Zhiyuan Liu, Yu Gu, Ge Yu\nVenue: International Conference on Information and Knowledge Management\nTldr: {'model': 'tldr@v2.0.0', 'text': None}",
  "Faculty Name: chenyan xiong\nMetadata:\nPaperid: 1fe3a802efdc4f1a3e5c8187547f38a3ec65750b\nTitle: Unsupervised Dense Retrieval Training with Web Anchors\nYear: 2023\nAbstract: In this work, we present an unsupervised retrieval method with contrastive learning on web anchors. The anchor text describes the content that is referenced from the linked page. This shows similarities to search queries that aim to retrieve pertinent information from relevant documents. Based on their commonalities, we train an unsupervised dense retriever, Anchor-DR, with a contrastive learning task that matches the anchor text and the linked document. To filter out uninformative anchors (such as \"homepage\" or other functional anchors), we present a novel filtering technique to only select anchors that contain similar types of information as search queries. Experiments show that Anchor-DR outperforms state-of-the-art methods on unsupervised dense retrieval by a large margin (e.g., by 5.3% NDCG@10 on MSMARCO).",
  "Experiments show that Anchor-DR outperforms state-of-the-art methods on unsupervised dense retrieval by a large margin (e.g., by 5.3% NDCG@10 on MSMARCO). The gain of our method is especially significant for search and question answering tasks. Our analysis further reveals that the pattern of anchor-document pairs is similar to that of search query-document pairs. Code available at https://github.com/Veronicium/AnchorDR.\nAuthors: Yiqing Xie, X. Liu, Chenyan Xiong\nVenue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work trains an unsupervised dense retriever, Anchor-DR, with a contrastive learning task that matches the anchor text and the linked document, and presents a novel filtering technique to only select anchors that contain similar types of information as search queries.'}",
  "Faculty Name: chenyan xiong\nMetadata:\nPaperid: 24811cadf16519910f643b6084107164e6ca4219\nTitle: Augmentation-Adapted Retriever Improves Generalization of Language Models as Generic Plug-In\nYear: 2023\nAbstract: Retrieval augmentation can aid language models (LMs) in knowledge-intensive tasks by supplying them with external information. Prior works on retrieval augmentation usually jointly fine-tune the retriever and the LM, making them closely coupled. In this paper, we explore the scheme of generic retrieval plug-in: the retriever is to assist target LMs that may not be known beforehand or are unable to be fine-tuned together. To retrieve useful documents for unseen target LMs, we propose augmentation-adapted retriever (AAR), which learns LM\u2019s preferences obtained from a known source LM. Experiments on the MMLU and PopQA datasets demonstrate that our AAR trained with a small source LM is able to significantly improve the zero-shot generalization of larger target LMs ranging from 250M Flan-T5 to 175B InstructGPT.",
  "Experiments on the MMLU and PopQA datasets demonstrate that our AAR trained with a small source LM is able to significantly improve the zero-shot generalization of larger target LMs ranging from 250M Flan-T5 to 175B InstructGPT. Further analysis indicates that the preferences of different LMs overlap, enabling AAR trained with a single source LM to serve as a generic plug-in for various target LMs. Our code is open-sourced at https://github.com/OpenMatch/Augmentation-Adapted-Retriever.\nAuthors: Zichun Yu, Chenyan Xiong, S. Yu, Zhiyuan Liu\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper proposes augmentation-adapted retriever (AAR), which learns LM\u2019s preferences obtained from a known source LM to assist target LMs that may not be known beforehand or are unable to be fine-tuned together in a generic retrieval plug-in.'}",
  "Faculty Name: chenyan xiong\nMetadata:\nPaperid: 275da3802142fc42f6fab2ce2104223b2e0ef40d\nTitle: Fusion-in-T5: Unifying Document Ranking Signals for Improved Information Retrieval\nYear: 2023\nAbstract: Common IR pipelines are typically cascade systems that may involve multiple rankers and/or fusion models to integrate different information step-by-step. In this paper, we propose a novel re-ranker named Fusion-in-T5 (FiT5), which integrates document text information, retrieval features, and global document information into a single unified model using templated-based input and global attention. Experiments on passage ranking benchmarks MS MARCO and TREC DL show that FiT5 significantly improves ranking performance over prior pipelines. Analyses find that through global attention, FiT5 is able to jointly utilize the ranking features via gradually attending to related documents, and thus improve the detection of subtle nuances between them. Our code will be open-sourced.",
  "Analyses find that through global attention, FiT5 is able to jointly utilize the ranking features via gradually attending to related documents, and thus improve the detection of subtle nuances between them. Our code will be open-sourced.\nAuthors: S. Yu, Cheng-Chung Fan, Chenyan Xiong, David Jin, Zhiyuan Liu, Zhenghao Liu Tsinghua University, Huazhong University of Science, Technology, Microsoft Research, M. I. O. Technology, N. University\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A novel re-ranker named Fusion-in-T5 (FiT5), which integrates document text information, retrieval features, and global document information into a single unified model using templated-based input and global attention, is proposed.'}",
  "Faculty Name: chenyan xiong\nMetadata:\nPaperid: 38aaf8a29df6deeff0bf64cc835d242a25b10337\nTitle: Model-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers\nYear: 2023\nAbstract: This paper explores the effectiveness of model-generated signals in improving zero-shot generalization of text-to-text Transformers such as T5. We study various designs to pretrain T5 using an auxiliary model to construct more challenging token replacements for the main model to denoise. Key aspects under study include the decoding target, the location of the RTD head, and the masking pattern. Based on these studies, we develop a new model, METRO-T0, which is pretrained using the redesigned ELECTRA-Style pretraining strategies and then prompt-finetuned on a mixture of NLP tasks. METRO-T0 outperforms all similar-sized baselines on prompted NLP benchmarks, such as _T0 Eval_ and MMLU, and rivals the state-of-the-art T0-11B model with only **8%** of its parameters.",
  "METRO-T0 outperforms all similar-sized baselines on prompted NLP benchmarks, such as _T0 Eval_ and MMLU, and rivals the state-of-the-art T0-11B model with only **8%** of its parameters. Our analysis on model\u2019s neural activation and parameter sensitivity reveals that the effectiveness of METRO-T0 stems from more balanced contribution of parameters and better utilization of their capacity. The code and model checkpoints are available at [https://github.com/gonglinyuan/metro_t0](https://github.com/gonglinyuan/metro_t0).",
  "The code and model checkpoints are available at [https://github.com/gonglinyuan/metro_t0](https://github.com/gonglinyuan/metro_t0).\nAuthors: Linyuan Gong, Chenyan Xiong, Xiaodong Liu, Payal Bajaj, Yiqing Xie, Alvin Cheung, Jianfeng Gao, Xia Song\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A new model, METRO-T0 is developed, which is pretrained using the redesigned ELECTRA-Style pretraining strategies and then prompt-finetuned on a mixture of NLP tasks and rivals the state-of-the-art T0-11B model with only **8%** of its parameters.'}",
  "Faculty Name: chenyan xiong\nMetadata:\nPaperid: a57b90cfc2eab46b773e65240d4ff910f05f989e\nTitle: Structure-Aware Language Model Pretraining Improves Dense Retrieval on Structured Data\nYear: 2023\nAbstract: This paper presents Structure Aware Dense Retrieval (SANTA) model, which encodes user queries and structured data in one universal embedding space for retrieving structured data. SANTA proposes two pretraining methods to make language models structure-aware and learn effective representations for structured data: 1) Structured Data Alignment, which utilizes the natural alignment relations between structured data and unstructured data for structure-aware pretraining. It contrastively trains language models to represent multi-modal text data and teaches models to distinguish matched structured data for unstructured texts. 2) Masked Entity Prediction, which designs an entity-oriented mask strategy and asks language models to fill in the masked entities. Our experiments show that SANTA achieves state-of-the-art on code search and product search and conducts convincing results in the zero-shot setting.",
  "2) Masked Entity Prediction, which designs an entity-oriented mask strategy and asks language models to fill in the masked entities. Our experiments show that SANTA achieves state-of-the-art on code search and product search and conducts convincing results in the zero-shot setting. SANTA learns tailored representations for multi-modal text data by aligning structured and unstructured data pairs and capturing structural semantics by masking and predicting entities in the structured data. All codes are available at https://github.com/OpenMatch/OpenMatch.\nAuthors: Xinze Li, Zhenghao Liu, Chenyan Xiong, Shi Yu, Yu Gu, Zhiyuan Liu, Ge Yu\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': None}",
  "Faculty Name: chenyan xiong\nMetadata:\nPaperid: b9e8b62bcc019f47a0a015568f70039b3b7c1196\nTitle: Toolink: Linking Toolkit Creation and Using through Chain-of-Solving on Open-Source Model\nYear: 2023\nAbstract: Large Language Models (LLMs) have demonstrated remarkable progress in utilizing tools, but their closed-source nature and high inference costs pose limitations on their adaptability, necessitating a valid method that leverages smaller, open-sourced models. In this paper, we introduce Toolink, a comprehensive framework that performs task-solving by first creating a toolkit and then integrating the planning and calling of tools through a chain-of-solving (CoS) approach. We first validate the efficacy of Toolink in harnessing the model's creativity and CoS ability on ChatGPT. Subsequently, we curate CoS-GPT, a chain-of-solving dataset designed for tool-using, and finetune the LLaMA-7B model. It results in LLaMA-CoS, a powerful open-source model with advanced tool-planning and tool-calling capabilities.",
  "Subsequently, we curate CoS-GPT, a chain-of-solving dataset designed for tool-using, and finetune the LLaMA-7B model. It results in LLaMA-CoS, a powerful open-source model with advanced tool-planning and tool-calling capabilities. Evaluation on diverse tasks from BIG-bench demonstrates its CoS ability matches that of ChatGPT while its performance surpasses the chain-of-thought approach. Further studies highlight the generalization of LLaMA-CoS to unseen tasks and showcase its capability in using toolkits not explicitly tailored for the target task, affirming its robustness in real-world scenarios. All codes and data are released.",
  "Further studies highlight the generalization of LLaMA-CoS to unseen tasks and showcase its capability in using toolkits not explicitly tailored for the target task, affirming its robustness in real-world scenarios. All codes and data are released.\nAuthors: Cheng Qian, Chenyan Xiong, Zhenghao Liu, Zhiyuan Liu\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper introduces Toolink, a comprehensive framework that performs task-solving by first creating a toolkit and then integrating the planning and calling of tools through a chain-of-s solving (CoS) approach, and results in LLaMA-CoS, a powerful open-source model with advanced tool-planning and tool-calling capabilities.'}",
  "Faculty Name: chenyan xiong\nMetadata:\nPaperid: bfa7f7bec1c4553c6c382ec2dbf4f889d7fa6e4f\nTitle: CompleQA: Benchmarking the Impacts of Knowledge Graph Completion Methods on Question Answering\nYear: 2023\nAbstract: None\nAuthors: Donghan Yu, Yu Gu, Chenyan Xiong, Yiming Yang\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: None",
  "Faculty Name: chenyan xiong\nMetadata:\nPaperid: cdfd0926ad26c3c95a02db2ae891b7d4a457429c\nTitle: OpenMatch-v2: An All-in-one Multi-Modality PLM-based Information Retrieval Toolkit\nYear: 2023\nAbstract: Pre-trained language models (PLMs) have emerged as the foundation of the most advanced Information Retrieval (IR) models. Powered by PLMs, the latest IR research has proposed novel models, new domain adaptation algorithms as well as enlarged datasets. In this paper, we present a Python-based IR toolkit OpenMatch-v2. As a full upgrade of OpenMatch proposed in 2021, OpenMatch-v2 incorporates the most recent advancements of PLM-based IR research, providing support for new, cross-modality models and enhanced domain adaptation techniques with a streamlined, optimized infrastructure. The code of OpenMatch is publicly available at https://github.com/OpenMatch/OpenMatch.",
  "The code of OpenMatch is publicly available at https://github.com/OpenMatch/OpenMatch.\nAuthors: Shi Yu, Zhenghao Liu, Chenyan Xiong, Zhiyuan Liu\nVenue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\nTldr: {'model': 'tldr@v2.0.0', 'text': 'As a full upgrade of OpenMatch proposed in 2021, OpenMatch-v2 incorporates the most recent advancements of PLM-based IR research, providing support for new, cross-modality models and enhanced domain adaptation techniques with a streamlined, optimized infrastructure.'}",
  "Faculty Name: chenyan xiong\nMetadata:\nPaperid: e0401ca2d4fd6d0ed55130a4a24b33ed90111479\nTitle: Augmenting Zero-Shot Dense Retrievers with Plug-in Mixture-of-Memories\nYear: 2023\nAbstract: In this paper we improve the zero-shot generalization ability of language models via Mixture-Of-Memory Augmentation (MoMA), a mechanism that retrieves augmentation documents from multiple information corpora (\"external memories\"), with the option to\"plug in\"new memory at inference time. We develop a joint learning mechanism that trains the augmentation component with latent labels derived from the end retrieval task, paired with hard negatives from the memory mixture. We instantiate the model in a zero-shot dense retrieval setting by augmenting a strong T5-based retriever with MoMA. Our model, MoMA, obtains strong zero-shot retrieval accuracy on the eighteen tasks included in the standard BEIR benchmark. It outperforms systems that seek generalization from increased model parameters and computation steps.",
  "Our model, MoMA, obtains strong zero-shot retrieval accuracy on the eighteen tasks included in the standard BEIR benchmark. It outperforms systems that seek generalization from increased model parameters and computation steps. Our analysis further illustrates the necessity of augmenting with mixture-of-memory for robust generalization, the benefits of augmentation learning, and how MoMA utilizes the plug-in memory at inference time without changing its parameters. We plan to open source our code.\nAuthors: Suyu Ge, Chenyan Xiong, Corby Rosset, Arnold Overwijk, Jiawei Han, Paul N. Bennett\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': None}",
  "List of 2023 Open Access papers by chenyan xiong are:\nText Matching Improves Sequential Recommendation by Reducing Popularity Biases\nFusion-in-T5: Unifying Document Ranking Signals for Improved Information Retrieval\nOpenMatch-v2: An All-in-one Multi-Modality PLM-based Information Retrieval Toolkit\nCompleQA: Benchmarking the Impacts of Knowledge Graph Completion Methods on Question Answering\nImproving Multitask Retrieval by Promoting Task Specialization\nUnsupervised Dense Retrieval Training with Web Anchors\nAugmentation-Adapted Retriever Improves Generalization of Language Models as Generic Plug-In\nModel-Generated Pretraining Signals Improves Zero-Shot Generalization of Text-to-Text Transformers\nStructure-Aware Language Model Pretraining Improves Dense Retrieval on Structured Data\nToolink: Linking Toolkit Creation and Using through Chain-of-Solving on Open-Source Model\nAugmenting Zero-Shot Dense Retrievers with Plug-in Mixture-of-Memories",
  "Faculty Name: christopher dyer\nMetadata:\nPaperid: 0b6941a9af3ccd8fa1109c3110483589ce1c3993\nTitle: Epidemiological Factors Associated with Prescription of Opioids for Chronic Non-Cancer Pain in Adults: A Country-Wide, Registry-Based Study in Denmark Spans 2004\u20132018\nYear: 2023\nAbstract: Purpose Denmark has a high consumption of prescribed opioids, and many citizens with chronic non-cancer pain (CNCP). Therefore, we aimed to characterize and assess epidemiological risk factors associated with long-term non-cancer opioid use among Danish citizens. Patients and Methods We conducted a longitudinal, retrospective, observational, register-based study using nationwide databases containing essential medical, healthcare, and socio-economic information. Statistical analysis, including backward stepwise logistic regression analysis, was used to explain long-term opioid use by individuals filling at least one prescription for an opioid product N02AA01\u2013N02AX06 during 01/01/2004\u201331/12/2017, follow-up until the end of 2018.",
  "Results The analyzed cohort contained N=1,683,713 non-cancer opioid users, of which 979,666 were classified with CNCP diagnosis using ICD-10 codes. Long-term opioid use was predicted by a mean of 1,583.30 and a median of 300 oral morphine equivalent mg (OMEQ) per day during the first year, together with divorced, age group 40\u201353 years, retirement, receiving social welfare or unemployment \u22656 months. In addition, living in Northern Jutland, co-medications such as beta-blockers, anti-diabetics, anti-rheumatics, and minor surgery \u226490 days before inclusion.",
  "In addition, living in Northern Jutland, co-medications such as beta-blockers, anti-diabetics, anti-rheumatics, and minor surgery \u226490 days before inclusion. Protective variables were an education level of secondary school or higher, children living at home, household income of middle or highest tertile, opioid doses in either the 2nd or 3rd quartile OMEQ, male, the oldest age group, living in the Capital Region or Zealand, co-medication lipid-lowering, one comorbidity, heart failure, surgeries \u226490 days before the index: lips/teeth/jaw/mouth/throat, heart/vessels, elbow/forearm, hip/thigh, knee/lower leg/ankle/foot. Conclusion Long-term opioid users differ epidemiologically from those using opioids for a shorter period. The study findings are essential for future recommendations revision in Denmark and comparable countries.",
  "Conclusion Long-term opioid users differ epidemiologically from those using opioids for a shorter period. The study findings are essential for future recommendations revision in Denmark and comparable countries.\nAuthors: C. Hansen, M. Ernst, Christopher D. Smith, B. Abrahamsen\nVenue: Journal of Pain Research\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Long-term opioid users differ epidemiologically from those using opioids for a shorter period, which is essential for future recommendations revision in Denmark and comparable countries.'}",
  "Faculty Name: christopher dyer\nMetadata:\nPaperid: 77563837a811329c901d0639b7b3b630600b844d\nTitle: Towards Improved Identification of Vertebral Fractures in Routine Computed Tomography (CT) Scans: Development and External Validation of a Machine Learning Algorithm\nYear: 2023\nAbstract: Vertebral fractures (VFs) are the hallmark of osteoporosis, being one of the most frequent types of fragility fracture and an early sign of the disease. They are associated with significant morbidity and mortality. VFs are incidentally found in one out of five imaging studies, however, more than half of the VFs are not identified nor reported in patient computed tomography (CT) scans. Our study aimed to develop a machine learning algorithm to identify VFs in abdominal/chest CT scans and evaluate its performance.",
  "VFs are incidentally found in one out of five imaging studies, however, more than half of the VFs are not identified nor reported in patient computed tomography (CT) scans. Our study aimed to develop a machine learning algorithm to identify VFs in abdominal/chest CT scans and evaluate its performance. We acquired two independent data sets of routine abdominal/chest CT scans of patients aged 50\u2009years or older: a training set of 1011 scans from a non\u2010interventional, prospective proof\u2010of\u2010concept study at the Universitair Ziekenhuis (UZ) Brussel and a validation set of 2000 subjects from an observational cohort study at the Hospital of Holb\u00e6k. Both data sets were externally reevaluated to identify reference standard VF readings using the Genant semiquantitative (SQ) grading. Four independent models have been trained in a cross\u2010validation experiment using the training set and an ensemble of four models has been applied to the external validation set.",
  "Both data sets were externally reevaluated to identify reference standard VF readings using the Genant semiquantitative (SQ) grading. Four independent models have been trained in a cross\u2010validation experiment using the training set and an ensemble of four models has been applied to the external validation set. The validation set contained 15.3% scans with one or more VF (SQ2\u20103), whereas 663 of 24,930 evaluable vertebrae (2.7%) were fractured (SQ2\u20103) as per reference standard readings. Comparison of the ensemble model with the reference standard readings in identifying subjects with one or more moderate or severe VF resulted in an area under the receiver operating characteristic curve (AUROC) of 0.88 (95% confidence interval [CI], 0.85\u20130.90), accuracy of 0.92 (95% CI, 0.91\u20130.93), kappa of 0.72 (95% CI, 0.67\u20130.76), sensitivity of 0.81 (95% CI, 0.76\u20130.85), and specificity of 0.95 (95% CI, 0.93\u20130.96).",
  "We demonstrated that a machine learning algorithm trained for VF detection achieved strong performance on an external validation set. It has the potential to support healthcare professionals with the early identification of VFs and prevention of future fragility fractures. \u00a9 2023 UCB S.A. and The Authors. Journal of Bone and Mineral Research published by Wiley Periodicals LLC on behalf of American Society for Bone and Mineral Research (ASBMR).\nAuthors: J. Nicolaes, M. Skj\u00f8dt, S. Raeymaeckers, Christopher D. Smith, B. Abrahamsen, T. Fuerst, Marc Debois, D. Vandermeulen, C. Libanati\nVenue: Journal of Bone and Mineral Research\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is demonstrated that a machine learning algorithm trained for VF detection achieved strong performance on an external validation set and has the potential to support healthcare professionals with the early identification of VFs and prevention of future fragility fractures.'}",
  "Faculty Name: christopher dyer\nMetadata:\nPaperid: 902d6060c930535b1557dfaaea59b17ee711e993\nTitle: Fracture Risk in Men and Women With Vertebral Fractures Identified Opportunistically on Routine Computed Tomography Scans and Not Treated for Osteoporosis: An Observational Cohort Study\nYear: 2023\nAbstract: Vertebral fractures (VFs) have been associated with future fractures, yet few studies have evaluated whether this pertains to VFs available for identification on routine radiological imaging. We sought to evaluate the risk of subsequent fractures in subjects with VF identified opportunistically on computed tomography (CT) scans performed as part of routine clinical practice. From the radiology database of Holb\u00e6k Hospital we identified the first CT scan including the thorax and/or abdomen of 2000 consecutive men and women aged 50\u2009years or older, performed from January 1, 2010 onward. The scans were assessed in a blinded approach to identify chest and lumbar VF, and these data linked to national Danish registers.",
  "The scans were assessed in a blinded approach to identify chest and lumbar VF, and these data linked to national Danish registers. Subjects were excluded if treated with an osteoporosis medication (OM) in the year prior to baseline (date of CT), and the remaining subjects with VF matched on age and sex in 1:2 ratio against subjects with no VF. We found that the risk of major osteoporotic fractures (hip, non\u2010cervical vertebral, humerus, and distal forearm fractures) was higher for subjects with VF than without VF: incidence rates (IRs) were 32.88 and 19.59 fractures per 1000 subject\u2010years, respectively, and the adjusted hazard ratio (HRadj) was 1.72 (95% confidence interval [CI], 1.03\u20132.86). Subsequent hip fracture IRs were 16.75 and 6.60; HRadj 3.02 (95% CI, 1.39\u20136.55).",
  "Subsequent hip fracture IRs were 16.75 and 6.60; HRadj 3.02 (95% CI, 1.39\u20136.55). There were no significant differences in other fracture outcomes (including a pooled estimate of any subsequent fracture, except face, skull, and fingers: IRs 41.52 and 31.38; HRadj 1.31 [95% CI, 0.85\u20132.03]). Our findings suggest that subjects undergoing routine CT scans including the chest and/or abdomen are a high risk population in terms of fracture risk. Even within this group, subjects with VF are at higher risk of future major osteoporotic fracture (MOF), in particular hip fracture. Hence, systematic opportunistic screening for VF and subsequent fracture risk management is important to reduce the risk of new fractures. \u00a9 2023 The Authors. JBMR Plus published by Wiley Periodicals LLC on behalf of American Society for Bone and Mineral Research.",
  "Hence, systematic opportunistic screening for VF and subsequent fracture risk management is important to reduce the risk of new fractures. \u00a9 2023 The Authors. JBMR Plus published by Wiley Periodicals LLC on behalf of American Society for Bone and Mineral Research.\nAuthors: M. Skj\u00f8dt, J. Nicolaes, Christopher D. Smith, K. Olsen, C. Cooper, C. Libanati, B. Abrahamsen\nVenue: JBMR Plus\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is found that subjects undergoing routine CT scans including the chest and/or abdomen are a high risk population in terms of fracture risk and even within this group, subjects with VF are at higher risk of future major osteoporotic fracture (MOF), in particular hip fracture.'}",
  "Faculty Name: christopher dyer\nMetadata:\nPaperid: b8c2d7b6100d61b43aa4721a2803de8b4977948f\nTitle: Murder in a Landscape: The Significance of the Death of Henry Flackett in the Staffordshire Moorlands in 1515\nYear: 2023\nAbstract: ABSTRACT The history of crime offers us insights into private vengeance, community cohesion, social tensions, the defence of honour and property disputes. Henry Flackett of Stanshope in Alstonefield, Staffordshire, was killed by three assailants known to him in 1515, provoked by a contested heap of manure. A combination of sources provides an unusually vivid and detailed picture of the crime, in which gentry honour played a part, provoking an attempt to enforce the law through the conventional channels of inquest, common law, and equity courts. The event is set in the context of the society, economy and landscape of the Staffordshire Moorlands in a period of agrarian change.\nAuthors: C. Dyer\nVenue: Midland History\nTldr: None",
  "Faculty Name: christopher dyer\nMetadata:\nPaperid: c2d8ae82bc5e38226eef873e2fb344f912ff8ad0\nTitle: A simple food with many meanings: bread in late medieval England\nYear: 2023\nAbstract: ABSTRACT Bread was the most important item of diet in medieval England. Cereals were consumed in boiled form, but bread was preferred. Bread was not just convenient, but was also symbolic of well-being. Although breads were made from other cereals and legumes, wheat bread occupied a prime position, and in particular white wheat bread was regarded highly by consumers. Reasons are given for these attitudes, including the practical advantage that white bread was an efficient source of energy and was cost-effective. The political management of the corn trade and bread baking through such regulations as the assize of bread was intended to prevent unrest, but occasionally consumers organised \u2018food riots\u2019.\nAuthors: Christopher Dyer\nVenue: Journal of Medieval History\nTldr: None",
  "List of 2023 Open Access papers by christopher dyer are:\nMurder in a Landscape: The Significance of the Death of Henry Flackett in the Staffordshire Moorlands in 1515\nA simple food with many meanings: bread in late medieval England\nEpidemiological Factors Associated with Prescription of Opioids for Chronic Non-Cancer Pain in Adults: A Country-Wide, Registry-Based Study in Denmark Spans 2004\u20132018\nTowards Improved Identification of Vertebral Fractures in Routine Computed Tomography (CT) Scans: Development and External Validation of a Machine Learning Algorithm\nFracture Risk in Men and Women With Vertebral Fractures Identified Opportunistically on Routine Computed Tomography Scans and Not Treated for Osteoporosis: An Observational Cohort Study",
  "Title: William Cohen -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of William Cohen, Adjunct Faculty at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Adjunct Faculty\" name=\"categories-1\"/>\n<meta content=\"Information Extraction, Summarization and Question Answering;Machine Learning\" name=\"categories-2\"/>\n<meta content=\"Yes\" name=\"show-categories-2\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"William Cohen - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of William Cohen, Adjunct Faculty at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:William\"/>\n<meta content=\"Lastname\" property=\"profile:Cohen\"/>\n<meta content=\"http://lti.cmu.",
  "Adjunct Faculty at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:William\"/>\n<meta content=\"Lastname\" property=\"profile:Cohen\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/cohen-william.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nWilliam \n                        Cohen\nDirector of Research Engineering, Google AI\nConsulting Professor, School of Computer Science\nContact\n8217 \u2014Gates & Hillman Centers\nwcohen(through)cs.cmu.edu\n412-268-7664\nResearch Area\nInformation Extraction, Summarization and Question Answering, Machine Learning\nResearch\nMy research interests include information integration and machine learning, particularly information extraction, text categorization and learning from large datasets. I have a longstanding interest in statistical relational learning and learning models, or learning from data that display non-trivial structure.",
  "Summarization and Question Answering, Machine Learning\nResearch\nMy research interests include information integration and machine learning, particularly information extraction, text categorization and learning from large datasets. I have a longstanding interest in statistical relational learning and learning models, or learning from data that display non-trivial structure.\nProjects I'm currently involved with include NELL, a large-scale information extraction system (which uses SEAL, as well as other techniques); and ProPPR, a locally groundable probabilistic first-order logic.\nPersonal Website\n\nLinks:\nhttp://www.cs.cmu.edu/~wcohen/",
  "Faculty Name: daniel fried\nMetadata:\nPaperid: 0524230fb6da632043c714523b409431dc08edc9\nTitle: Analysis of the transparent surface layer formed at the surfaces of arrested enamel caries lesions with tomographic imaging methods\nYear: 2023\nAbstract: None\nAuthors: Nai-Yuan N. Chang, Morgan Ng, Tina Dillas, Yi-Ching Ho, Yihua Zhu, D. Fried\nVenue: JADA Foundational Science\nTldr: None",
  "Faculty Name: daniel fried\nMetadata:\nPaperid: 19f59c14b3d79e3203c696128a135d33eb35e468\nTitle: Pragmatic Inference with a CLIP Listener for Contrastive Captioning\nYear: 2023\nAbstract: We propose a simple yet effective and robust method for contrastive captioning: generating discriminative captions that distinguish target images from very similar alternative distractor images. Our approach is built on a pragmatic inference procedure that formulates captioning as a reference game between a speaker, which produces possible captions describing the target, and a listener, which selects the target given the caption. Unlike previous methods that derive both speaker and listener distributions from a single captioning model, we leverage an off-the-shelf CLIP model to parameterize the listener. Compared with captioner-only pragmatic models, our method benefits from rich vision language alignment representations from CLIP when reasoning over distractors. Like previous methods for discriminative captioning, our method uses a hyperparameter to control the tradeoff between the informativity (how likely captions are to allow a human listener to discriminate the target image) and the fluency of the captions.",
  "Like previous methods for discriminative captioning, our method uses a hyperparameter to control the tradeoff between the informativity (how likely captions are to allow a human listener to discriminate the target image) and the fluency of the captions. However, we find that our method is substantially more robust to the value of this hyperparameter than past methods, which allows us to automatically optimize the captions for informativity - outperforming past methods for discriminative captioning by 11% to 15% accuracy in human evaluations\nAuthors: Jiefu Ou, Benno Krojer, Daniel Fried\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes a simple yet effective and robust method for contrastive captioning: generating discriminative captions that distinguish target images from very similar alternative distractor images by leveraging an off-the-shelf CLIP model to parameterize the listener.'}",
  "Faculty Name: daniel fried\nMetadata:\nPaperid: 1bf21dabbdfc81fd4f9e92b1201ecce744cabb6a\nTitle: SantaCoder: don't reach for the stars!\nYear: 2023\nAbstract: The BigCode project is an open-scientific collaboration working on the responsible development of large language models for code. This tech report describes the progress of the collaboration until December 2022, outlining the current state of the Personally Identifiable Information (PII) redaction pipeline, the experiments conducted to de-risk the model architecture, and the experiments investigating better preprocessing methods for the training data. We train 1.1B parameter models on the Java, JavaScript, and Python subsets of The Stack and evaluate them on the MultiPL-E text-to-code benchmark. We find that more aggressive filtering of near-duplicates can further boost performance and, surprisingly, that selecting files from repositories with 5+ GitHub stars deteriorates performance significantly.",
  "We find that more aggressive filtering of near-duplicates can further boost performance and, surprisingly, that selecting files from repositories with 5+ GitHub stars deteriorates performance significantly. Our best model outperforms previous open-source multilingual code generation models (InCoder-6.7B and CodeGen-Multi-2.7B) in both left-to-right generation and infilling on the Java, JavaScript, and Python portions of MultiPL-E, despite being a substantially smaller model. All models are released under an OpenRAIL license at https://hf.co/bigcode.\nAuthors: Loubna Ben Allal, Raymond Li, Denis Kocetkov, Chenghao Mou, Christopher Akiki, Carlos Mu\u00f1oz Ferrandis, Niklas Muennighoff, Mayank Mishra, A. Gu, Manan Dey, Logesh Kumar Umapathi, Carolyn Jane Anderson, Yangtian Zi, J. Poirier, Hailey Schoelkopf, S. Troshin, Dmitry Abulkhanov, M. Romero, M. Lappert, F. Toni, Bernardo Garc'ia del R'io, Qian Liu, Shamik Bose, Urvashi Bhattacharyya,",
  "Poirier, Hailey Schoelkopf, S. Troshin, Dmitry Abulkhanov, M. Romero, M. Lappert, F. Toni, Bernardo Garc'ia del R'io, Qian Liu, Shamik Bose, Urvashi Bhattacharyya, Terry Yue Zhuo, I. Yu, Paulo Villegas, Marco Zocca, Sourab Mangrulkar, D. Lansky, Huu Nguyen, Danish Contractor, Luisa Villa, Jia Li, Dzmitry Bahdanau, Yacine Jernite, S. Hughes, Daniel Fried, Arjun Guha, H. D. Vries, Leandro von Werra\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The current state of the Personally Identifiable Information (PII) redaction pipeline is outlined, the experiments conducted to de-risk the model architecture, and the experiments investigating better preprocessing methods for the training data are outlined.'}",
  "Faculty Name: daniel fried\nMetadata:\nPaperid: 2b2d9ee18507aa89a7f1ecba0bf68844c7d9aa75\nTitle: Grounding Language Models to Images for Multimodal Generation\nYear: 2023\nAbstract: We propose an ef\ufb01cient method to ground pre-trained text-only language models to the visual domain, enabling them to process and generate arbitrarily interleaved image-and-text data. Our method leverages the abilities of language models learnt from large scale text-only pretraining, such as in-context learning and free-form text generation. We keep the language model frozen, and \ufb01netune input and output linear layers to enable cross-modality interactions. This allows our model to process arbitrarily interleaved image-and-text inputs, and generate free-form text inter-leaved with retrieved images. We achieve strong zero-shot performance on grounded tasks such as contextual image retrieval and multimodal dialogue, and showcase compelling interactive abilities. Our approach works with any off-the-shelf language model and paves the way towards an effective, general solution for leveraging pretrained language models in visually grounded settings.",
  "We achieve strong zero-shot performance on grounded tasks such as contextual image retrieval and multimodal dialogue, and showcase compelling interactive abilities. Our approach works with any off-the-shelf language model and paves the way towards an effective, general solution for leveraging pretrained language models in visually grounded settings.\nAuthors: Jing Yu Koh, R. Salakhutdinov, Daniel Fried\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': None}",
  "Faculty Name: daniel fried\nMetadata:\nPaperid: 3dc7c209b772baaf3cca527ac3c5deca330f7b2e\nTitle: Exploratory Analysis of Objective Outcome Measures for the Clinical Assessment of Erosive Tooth Wear\nYear: 2023\nAbstract: This study proposed using enamel surface texture and thickness for the objective detection and monitoring of erosive tooth wear (ETW), comparing them to the standard subjective Basic Erosive Wear Evaluation (BEWE). Thirty-two subjects (n = 597 teeth) were enrolled in this longitudinal observational clinical study. Enamel thickness (by cross-polarization optical coherence tomography, CP-OCT) and 3D dental microwear parameters, i.e., area-scale fractal complexity (Asfc), anisotropy (Str), and roughness (Sa) (by white-light scanning confocal profilometry), were obtained from buccal surfaces. Buccal, occlusal, and lingual surfaces were scored for BEWE and the maximum score per tooth (BEWEMax) was determined at baseline and 12 months (M12). Data outcome relationships were evaluated (alpha = 0.05).",
  "Buccal, occlusal, and lingual surfaces were scored for BEWE and the maximum score per tooth (BEWEMax) was determined at baseline and 12 months (M12). Data outcome relationships were evaluated (alpha = 0.05). Enamel thickness decreased (p < 0.001), BEWE scores, Sa, and Str increased (p < 0.001), while Asfc did not change at M12. Baseline BEWEBuccal correlated strongly with BEWEMax (r = 0.86, p < 0.001) and moderately with BEWELingual (r = 0.42, p < 0.001), but not with enamel thickness (r = 0.03, p = 0.43). Change (\u0394) in surface texture outcomes correlated poorly but significantly with \u0394BEWEBuccal (r = \u22120.15\u20130.16, p < 0.001) and did not correlate with \u0394enamel thickness (r = 0.02\u20130.09, p > 0.06). Teeth with BEWE progression revealed a greater increase in \u0394Sa and \u0394Str.",
  "Teeth with BEWE progression revealed a greater increase in \u0394Sa and \u0394Str. These findings suggest that enamel surface roughness can potentially determine ETW severity, and CP-OCT may be relevant for clinically monitoring enamel thickness.\nAuthors: M. J. R. Romero, P. Ungar, D. Fried, F. Lippert, D. Zero, S. Zunt, G. Eckert, A. Gossweiler, D. Elkington-Stauss, Guillermo Tamayo-Cabeza, A. Kelly, Troy Bartels, Camille Kita, Elizabeth Wewers, A. Hara\nVenue: Diagnostics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is suggested that enamel surface roughness can potentially determine ETW severity, and CP-OCT may be relevant for clinically monitoring enamel thickness.'}",
  "Faculty Name: daniel fried\nMetadata:\nPaperid: 3e4085e5869f1b7959707a1e1d7d273b6057eb4e\nTitle: StarCoder: may the source be with you!\nYear: 2023\nAbstract: The BigCode community, an open-scientific collaboration working on the responsible development of Large Language Models for Code (Code LLMs), introduces StarCoder and StarCoderBase: 15.5B parameter models with 8K context length, infilling capabilities and fast large-batch inference enabled by multi-query attention. StarCoderBase is trained on 1 trillion tokens sourced from The Stack, a large collection of permissively licensed GitHub repositories with inspection tools and an opt-out process. We fine-tuned StarCoderBase on 35B Python tokens, resulting in the creation of StarCoder. We perform the most comprehensive evaluation of Code LLMs to date and show that StarCoderBase outperforms every open Code LLM that supports multiple programming languages and matches or outperforms the OpenAI code-cushman-001 model.",
  "We perform the most comprehensive evaluation of Code LLMs to date and show that StarCoderBase outperforms every open Code LLM that supports multiple programming languages and matches or outperforms the OpenAI code-cushman-001 model. Furthermore, StarCoder outperforms every model that is fine-tuned on Python, can be prompted to achieve 40\\% pass@1 on HumanEval, and still retains its performance on other programming languages. We take several important steps towards a safe open-access model release, including an improved PII redaction pipeline and a novel attribution tracing tool, and make the StarCoder models publicly available under a more commercially viable version of the Open Responsible AI Model license.\nAuthors: Raymond Li, Loubna Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov, Chenghao Mou, Marc Marone, Christopher Akiki, Jia Li, Jenny Chim, Qian Liu, Evgenii Zheltonozhskii, Terry Yue Zhuo, Thomas Wang, Olivier Dehaene, Mishig Davaadorj, J. Lamy-Poirier, Jo\u00e3o Monteiro, Oleh Shliazhko, Nicolas Gontier,",
  "Jenny Chim, Qian Liu, Evgenii Zheltonozhskii, Terry Yue Zhuo, Thomas Wang, Olivier Dehaene, Mishig Davaadorj, J. Lamy-Poirier, Jo\u00e3o Monteiro, Oleh Shliazhko, Nicolas Gontier, Nicholas Meade, Armel Zebaze, Ming-Ho Yee, Logesh Kumar Umapathi, Jian Zhu, Benjamin Lipkin, Muhtasham Oblokulov, Zhiruo Wang, Rudra Murthy, J. Stillerman, S. Patel, Dmitry Abulkhanov, Marco Zocca, Manan Dey, Zhihan Zhang, N. Fahmy, Urvashi Bhattacharyya, W. Yu, Swayam Singh, Sasha Luccioni, Paulo Villegas, M. Kunakov, Fedor Zhdanov, Manuel Romero, Tony Lee, Nadav Timor, Jennifer Ding, Claire Schlesinger, Hailey Schoelkopf, Jana Ebert, Tri Dao, Mayank Mishra, A. Gu, Jennifer Robinson, Carolyn Jane Anderson, Brendan Dolan-Gavitt, Danish Contractor, Siva Reddy, Daniel Fried,",
  "Nadav Timor, Jennifer Ding, Claire Schlesinger, Hailey Schoelkopf, Jana Ebert, Tri Dao, Mayank Mishra, A. Gu, Jennifer Robinson, Carolyn Jane Anderson, Brendan Dolan-Gavitt, Danish Contractor, Siva Reddy, Daniel Fried, Dzmitry Bahdanau, Yacine Jernite, Carlos Mu\u00f1oz Ferrandis, Sean M. Hughes, Thomas Wolf, Arjun Guha, Leandro von Werra, H. D. Vries\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work performs the most comprehensive evaluation of Code LLMs to date and shows that StarCoderBase outperforms every open Code LLM that supports multiple programming languages and matches or outperforms the OpenAI code-cushman-001 model.'}",
  "Faculty Name: daniel fried\nMetadata:\nPaperid: 4a48291d52be0ef4e399270eb029fe03ca2ed831\nTitle: Assessment of the activity of secondary caries lesions with short-wavelength infrared, thermal, and optical coherence tomographic imaging\nYear: 2023\nAbstract: Abstract. Significance: Leakage in the interfaces between restorative materials and tooth structure allows for fluid and bacterial acid infiltration, causing restoration failure due to secondary caries. Dentists spend more time replacing composite restorations than placing new ones. Previous in vitro and in vivo studies on enamel and root surfaces using shortwave-infrared (SWIR) and thermal imaging during dehydration with forced air have been promising for assessing lesion activity. Aim: We hypothesized that SWIR reflectance and thermal imaging methods can be used to monitor the activity of secondary caries lesions around composite restorations. The objective of this study was to employ these methods to measure the rate of fluid loss from lesions during dehydration with forced air to assess lesion activity. Approach: Sixty-three extracted human teeth with total of 109 suspected secondary lesions were examined using SWIR and thermal imaging during dehydration.",
  "The objective of this study was to employ these methods to measure the rate of fluid loss from lesions during dehydration with forced air to assess lesion activity. Approach: Sixty-three extracted human teeth with total of 109 suspected secondary lesions were examined using SWIR and thermal imaging during dehydration. The thickness of the highly mineralized transparent surface layer (TSL) at lesion interfaces indicative of lesion activity was measured by optical coherence tomography (OCT). Micro-computed tomography (MicroCT) was used to further confirm lesion severity and structure. OCT and MicroCT measurements of lesion structure, depth, and severity were correlated with fluid loss rates measured with SWIR reflectance and thermal imaging. Results: TSL thickness measured with OCT correlated with both SWIR reflectance and thermal measurements of rates of fluid loss (p\u2009\u2009<\u2009\u20090.05). Increasing TSL thickness led to decreased permeability of lesions, potentially indicating full lesion arrest at TSL\u2009\u2009\u2265\u2009\u200970\u2009\u2009\u03bcm. SWIR performed better than thermal imaging for secondary lesion activity assessment, although both methods performed best on smooth surface lesions.",
  "Increasing TSL thickness led to decreased permeability of lesions, potentially indicating full lesion arrest at TSL\u2009\u2009\u2265\u2009\u200970\u2009\u2009\u03bcm. SWIR performed better than thermal imaging for secondary lesion activity assessment, although both methods performed best on smooth surface lesions. Conclusions: Nondestructive SWIR reflectance and OCT imaging methods are promising for clinically monitoring the activity of secondary caries lesions.\nAuthors: Nai-Yuan N. Chang, Tina Dillas, Yihua Zhu, D. Fried\nVenue: Journal of Biomedical Optics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Nondestructive SWIR reflectance and OCT imaging methods are promising for clinically monitoring the activity of secondary caries lesions.'}",
  "Faculty Name: daniel fried\nMetadata:\nPaperid: 5016766c87982f5c62ef6580e120939ab155d776\nTitle: Amortizing Pragmatic Program Synthesis with Rankings\nYear: 2023\nAbstract: In program synthesis, an intelligent system takes in a set of user-generated examples and returns a program that is logically consistent with these examples. The usage of Rational Speech Acts (RSA) framework has been successful in building \\emph{pragmatic} program synthesizers that return programs which -- in addition to being logically consistent -- account for the fact that a user chooses their examples informatively. However, the computational burden of running the RSA algorithm has restricted the application of pragmatic program synthesis to domains with a small number of possible programs. This work presents a novel method of amortizing the RSA algorithm by leveraging a \\emph{global pragmatic ranking} -- a single, total ordering of all the hypotheses. We prove that for a pragmatic synthesizer that uses a single demonstration, our global ranking method exactly replicates RSA's ranked responses. We further empirically show that global rankings effectively approximate the full pragmatic synthesizer in an online, multi-demonstration setting.",
  "We prove that for a pragmatic synthesizer that uses a single demonstration, our global ranking method exactly replicates RSA's ranked responses. We further empirically show that global rankings effectively approximate the full pragmatic synthesizer in an online, multi-demonstration setting. Experiments on two program synthesis domains using our pragmatic ranking method resulted in orders of magnitudes of speed ups compared to the RSA synthesizer, while outperforming the standard, non-pragmatic synthesizer.\nAuthors: Yewen Pu, Saujas Vaduguru, Priyan Vaithilingam, Elena L. Glassman, Daniel Fried\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': \"This work presents a novel method of amortizing the RSA algorithm by leveraging a single, total ordering of all the hypotheses, and proves that for a pragmatic synthesizer that uses a single demonstration, the global ranking method exactly replicates RSA's ranked responses.\"}",
  "Faculty Name: daniel fried\nMetadata:\nPaperid: 52b9ab94b9a4be203031bbc1fa61251513b1d5f7\nTitle: Monitoring lesion activity on primary teeth with CP\u2010OCT and SWIR reflectance imaging\nYear: 2023\nAbstract: The purpose of this study was to use cross polarization optical coherence tomography (CP\u2010OCT) and short wavelength infrared imaging (SWIR) reflectance imaging to monitor changes in the structure and activity of early occlusal caries on primary teeth over a period of 6 months during intervention with fluoride.\nAuthors: Yihua Zhu, Jungsoo Kim, B. Lin, D. Fried\nVenue: Lasers in Surgery and Medicine\nTldr: {'model': 'tldr@v2.0.0', 'text': None}",
  "Faculty Name: daniel fried\nMetadata:\nPaperid: 6aedce6dc4e6c9a218bbc95fc4ae4d4de8d424ac\nTitle: Active Surveillance of Root Caries in Vivo with CP-OCT\nYear: 2023\nAbstract: The active surveillance of root caries lesions to monitor potential remineralization or decay progression is challenging for the clinician, due to unreliable diagnostic information. The conventional visual and tactile methods for assessing the lesion activity are not reliable, and the clinician is often unable to determine if the lesion is progressing or has been arrested. An important marker of an arrested lesion is a highly mineralized transparent surface zone (TSL) that forms when the mineral is deposited in the outer layer of the lesion. The purpose of this study was to determine if cross-polarization optical coherence tomography (CP-OCT) could be used to detect changes in the lesion severity and activity during active monitoring. In total, 18 subjects with 22 suspected active root caries lesions were evaluated using CP-OCT at the baseline, 3 months, and 6 months. All subjects were instructed to use a high fluoride dentifrice at the baseline.",
  "In total, 18 subjects with 22 suspected active root caries lesions were evaluated using CP-OCT at the baseline, 3 months, and 6 months. All subjects were instructed to use a high fluoride dentifrice at the baseline. The results showed that CP-OCT was able to discriminate the active from the arrested lesions by identifying the presence of a TSL on arrested lesions. The results also indicated that the mean TSL thickness increased significantly (p < 0.05) for the nine lesion areas. In addition, CP-OCT was able to show the progression of demineralization, erosion, and changes in gingival contours in scanned areas. CP-OCT was valuable for monitoring the activity and severity of root caries lesions in vivo. CP-OCT can be used to assess the activity of root caries lesions at a single time point by detecting the presence of a TSL at the lesion surface indicative of the lesion arrest.",
  "CP-OCT was valuable for monitoring the activity and severity of root caries lesions in vivo. CP-OCT can be used to assess the activity of root caries lesions at a single time point by detecting the presence of a TSL at the lesion surface indicative of the lesion arrest.\nAuthors: Yihua Zhu, Minyoung Kim, D. Curtis, Jing Wang, O. Le, D. Fried\nVenue: Diagnostics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'CP-OCT was valuable for monitoring the activity and severity of root caries lesions in vivo and was able to show the progression of demineralization, erosion, and changes in gingival contours in scanned areas.'}",
  "Faculty Name: daniel fried\nMetadata:\nPaperid: 6fb5c0eff3696ef252aca9638e10176ecce7cecb\nTitle: Generating Images with Multimodal Language Models\nYear: 2023\nAbstract: We propose a method to fuse frozen text-only large language models (LLMs) with pre-trained image encoder and decoder models, by mapping between their embedding spaces. Our model demonstrates a wide suite of multimodal capabilities: image retrieval, novel image generation, and multimodal dialogue. Ours is the first approach capable of conditioning on arbitrarily interleaved image and text inputs to generate coherent image (and text) outputs. To achieve strong performance on image generation, we propose an efficient mapping network to ground the LLM to an off-the-shelf text-to-image generation model. This mapping network translates hidden representations of text into the embedding space of the visual models, enabling us to leverage the strong text representations of the LLM for visual outputs. Our approach outperforms baseline generation models on tasks with longer and more complex language. In addition to novel image generation, our model is also capable of image retrieval from a prespecified dataset, and decides whether to retrieve or generate at inference time.",
  "Our approach outperforms baseline generation models on tasks with longer and more complex language. In addition to novel image generation, our model is also capable of image retrieval from a prespecified dataset, and decides whether to retrieve or generate at inference time. This is done with a learnt decision module which conditions on the hidden representations of the LLM. Our model exhibits a wider range of capabilities compared to prior multimodal language models. It can process image-and-text inputs, and produce retrieved images, generated images, and generated text -- outperforming non-LLM based generation models across several text-to-image tasks that measure context dependence.\nAuthors: Jing Yu Koh, Daniel Fried, R. Salakhutdinov\nVenue: Neural Information Processing Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes a method to fuse frozen text-only large language models (LLMs) with pre-trained image encoder and decoder models, by mapping between their embedding spaces, and exhibits a wider range of capabilities compared to prior multimodal language models.'}",
  "Faculty Name: daniel fried\nMetadata:\nPaperid: aa705ba5294ed9d06978fe6a08ab2f2b5dd08e1e\nTitle: Time\u2010resolved SWIR imaging for the assessment of the activity of occlusal caries lesions\nYear: 2023\nAbstract: The aim of this study was to develop a clinical SWIR reflectance handpiece to assess the activity of lesions on the occlusal surfaces. The time\u2010resolved reflectivity of 10 active and 10 arrested occlusal caries lesions on extracted teeth was monitored at 1470\u2009nm using a benchtop system and a modified clinical prototype during forced air drying. The presence of a highly mineralized surface layer measured with microcomputed tomography (microCT) was used to indicate lesion activity. Multiple kinetic parameters were extracted from the acquired SWIR time versus intensity dehydration curves and used to assess lesion activity. Three parameters: delay, %Ifin, and rate calculated from the SWIR dehydration curves were significantly different (p\u2009<\u20090.05) between active and arrested lesions.",
  "Multiple kinetic parameters were extracted from the acquired SWIR time versus intensity dehydration curves and used to assess lesion activity. Three parameters: delay, %Ifin, and rate calculated from the SWIR dehydration curves were significantly different (p\u2009<\u20090.05) between active and arrested lesions. The modified clinical probe was able to completely dehydrate all the active lesion areas in the occlusal pits and fissures in less than 30\u2009s.\nAuthors: Morgan Ng, Spencer Wycoff, Yihua Zhu, Yi-Ching Ho, Hannah Takasuka, D. Fried\nVenue: Journal of Biophotonics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A clinical SWIR reflectance handpiece to assess the activity of lesions on the occlusal surfaces was developed and was able to completely dehydrate all the active lesion areas in the Occlusal pits and fissures in less than 30\\u2009s.'}",
  "Faculty Name: daniel fried\nMetadata:\nPaperid: bebca5d54374c83a7489638d3b45d2b006d559f0\nTitle: Diagnostic Performance of Multispectral SWIR Transillumination and Reflectance Imaging for Caries Detection\nYear: 2023\nAbstract: The aim of this clinical study was to compare the diagnostic performance of dual short wavelength infrared (SWIR) occlusal transillumination and reflectance multispectral imaging with conventional visual assessment and radiography for caries detection on premolars scheduled for extraction for orthodontics reasons. Polarized light microscopy (PLM) and micro-computed tomography (microCT) performed after tooth extraction were used as gold standards. The custom-fabricated imaging probe was 3D-printed and the imaging system employed a SWIR camera and fiber-optic light sources emitting light at 1300 nm for occlusal transillumination and 1600 nm for reflectance measurements. Teeth (n = 135) on 40 test subjects were imaged in vivo using the SWIR imaging prototype in the study and teeth were extracted after imaging.",
  "Teeth (n = 135) on 40 test subjects were imaged in vivo using the SWIR imaging prototype in the study and teeth were extracted after imaging. Our study demonstrates for the first time that near-simultaneous real-time transillumination and reflectance video can be successfully acquired for caries detection. Both SWIR imaging modalities had markedly higher sensitivity for lesions on proximal and occlusal surfaces compared to conventional methods (visual and radiographic). Reflectance imaging at 1600 nm had higher sensitivity and specificity than transillumination at 1300 nm. The combined SWIR methods yielded higher specificity but the combined sensitivity was lower than for each individual method.\nAuthors: Yihua Zhu, C. Ng, O. Le, Yi-Ching Ho, D. Fried\nVenue: Diagnostics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This study demonstrates for the first time that near-simultaneous real-time transillumination and reflectance video can be successfully acquired for caries detection.'}",
  "Faculty Name: daniel fried\nMetadata:\nPaperid: e41482f4ee984f17382f6cdd900df094d928be06\nTitle: WebArena: A Realistic Web Environment for Building Autonomous Agents\nYear: 2023\nAbstract: With advances in generative AI, there is now potential for autonomous agents to manage daily tasks via natural language commands. However, current agents are primarily created and tested in simplified synthetic environments, leading to a disconnect with real-world scenarios. In this paper, we build an environment for language-guided agents that is highly realistic and reproducible. Specifically, we focus on agents that perform tasks on the web, and create an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management. Our environment is enriched with tools (e.g., a map) and external knowledge bases (e.g., user manuals) to encourage human-like task-solving. Building upon our environment, we release a set of benchmark tasks focusing on evaluating the functional correctness of task completions. The tasks in our benchmark are diverse, long-horizon, and designed to emulate tasks that humans routinely perform on the internet.",
  "Building upon our environment, we release a set of benchmark tasks focusing on evaluating the functional correctness of task completions. The tasks in our benchmark are diverse, long-horizon, and designed to emulate tasks that humans routinely perform on the internet. We experiment with several baseline agents, integrating recent techniques such as reasoning before acting. The results demonstrate that solving complex tasks is challenging: our best GPT-4-based agent only achieves an end-to-end task success rate of 14.41%, significantly lower than the human performance of 78.24%. These results highlight the need for further development of robust agents, that current state-of-the-art large language models are far from perfect performance in these real-life tasks, and that WebArena can be used to measure such progress.",
  "These results highlight the need for further development of robust agents, that current state-of-the-art large language models are far from perfect performance in these real-life tasks, and that WebArena can be used to measure such progress.\nAuthors: Shuyan Zhou, Frank F. Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, Yonatan Bisk, Daniel Fried, Uri Alon, Graham Neubig\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper builds an environment for language-guided agents that is highly realistic and reproducible, and creates an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management.'}",
  "Faculty Name: daniel fried\nMetadata:\nPaperid: eafc0e6504514650753207108f15e62e09008950\nTitle: Longitudinal assessment of dental erosion-abrasion by cross-polarization optical coherence tomography in vitro.\nYear: 2023\nAbstract: This study tested a novel in vitro dental erosion-abrasion model and the performance of cross-polarization optical coherence tomography (CP-OCT) in longitudinally monitoring the simulated lesions. Thirty human enamel specimens were prepared and randomized to receive three dental erosion-abrasion (EA) protocols: severe (s-EA, lemon juice/pH:2.5/4.25%w/v citric acid), moderate (m-EA, grapefruit juice/pH:3.5/1.03%w/v citric acid) and no-EA (water, control). EA challenge was performed by exposing the specimens to acidic solutions 4x/day and to brushing 2x/day with 1:3 fluoridated toothpaste slurry, for 14 days.",
  "EA challenge was performed by exposing the specimens to acidic solutions 4x/day and to brushing 2x/day with 1:3 fluoridated toothpaste slurry, for 14 days. Enamel thickness measurements were obtained using CP-OCT at baseline (D0), 7 (D7) and 14 days (D14) and micro-computed tomography (micro-CT) at D14. Enamel surface loss was measured with both CP-OCT and optical profilometry at D0, D7 and D14. Data was analyzed with repeated-measures ANOVA and Pearson's correlation (r) (\u03b1 = 0.05). CP-OCT enamel thickness decreased over time in the s-EA group (D0 >D7 > D14, p < 0.001) and m-EA group (D0 > D14, p = 0.019) but did not change in the no-EA group (p = 0.30). Overall, CP-OCT and micro-CT results at D14 correlated moderately (r = 0.73).",
  "Overall, CP-OCT and micro-CT results at D14 correlated moderately (r = 0.73). CP-OCT surface loss was highest for s-EA (p <0.001) but did not differ between moderate and no-EA (p = 0.25). Enamel surface loss with profilometry increased with severity (no-EA>m-EA>s-EA, p < 0.001). D14 surface loss was higher than D7 for both methods except for the no-EA group with profilometry. CP-OCT and profilometry had moderate overall correlation (r = 0.70). Our results revealed that the currently proposed in vitro dental erosion-abrasion model is valid and could simulate lesions of different severities over time. CP-OCT was a suitable method for monitoring the EA lesions.",
  "CP-OCT and profilometry had moderate overall correlation (r = 0.70). Our results revealed that the currently proposed in vitro dental erosion-abrasion model is valid and could simulate lesions of different severities over time. CP-OCT was a suitable method for monitoring the EA lesions.\nAuthors: M. J. R. Romero, S. J. Bezerra, Daniel Fried, F. Lippert, G. Eckert, A. Hara\nVenue: Brazilian Oral Research\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The results revealed that the currently proposed in vitro dental erosion-abrasion model is valid and could simulate lesions of different severities over time and CP-OCT was a suitable method for monitoring the EA lesions.'}",
  "Faculty Name: daniel fried\nMetadata:\nPaperid: f983cf75e368dcd07dd3a762721c095678514e56\nTitle: AutoReply: Detecting Nonsense in Dialogue with Discriminative Replies\nYear: 2023\nAbstract: None\nAuthors: Weiyan Shi, Emily Dinan, Adi Renduchintala, Daniel Fried, Athul Paul Jacob, Zhou Yu, Mike Lewis\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: None",
  "List of 2023 Open Access papers by daniel fried are:\nAnalysis of the transparent surface layer formed at the surfaces of arrested enamel caries lesions with tomographic imaging methods\nExploratory Analysis of Objective Outcome Measures for the Clinical Assessment of Erosive Tooth Wear\nAssessment of the activity of secondary caries lesions with short-wavelength infrared, thermal, and optical coherence tomographic imaging\nMonitoring lesion activity on primary teeth with CP\u2010OCT and SWIR reflectance imaging\nActive Surveillance of Root Caries in Vivo with CP-OCT\nTime\u2010resolved SWIR imaging for the assessment of the activity of occlusal caries lesions\nDiagnostic Performance of Multispectral SWIR Transillumination and Reflectance Imaging for Caries Detection\nLongitudinal assessment of dental erosion-abrasion by cross-polarization optical coherence tomography in vitro.\nAutoReply: Detecting Nonsense in Dialogue with Discriminative Replies\nPragmatic Inference with a CLIP Listener for Contrastive Captioning\nSantaCoder: don't reach for the stars!\nGrounding Language Models to Images for Multimodal Generation\nStarCoder: may the source be with you!",
  "AutoReply: Detecting Nonsense in Dialogue with Discriminative Replies\nPragmatic Inference with a CLIP Listener for Contrastive Captioning\nSantaCoder: don't reach for the stars!\nGrounding Language Models to Images for Multimodal Generation\nStarCoder: may the source be with you!\nGenerating Images with Multimodal Language Models\nWebArena: A Realistic Web Environment for Building Autonomous Agents\nAmortizing Pragmatic Program Synthesis with Rankings",
  "Faculty Name: daphne ippolito\nMetadata:\nPaperid: 03fb535de5cfcf435705a079334ac60f501226ab\nTitle: Reverse-Engineering Decoding Strategies Given Blackbox Access to a Language Generation System\nYear: 2023\nAbstract: Neural language models are increasingly deployed into APIs and websites that allow a user to pass in a prompt and receive generated text. Many of these systems do not reveal generation parameters. In this paper, we present methods to reverse-engineer the decoding method used to generate text (i.e., top-_k_ or nucleus sampling). Our ability to discover which decoding strategy was used has implications for detecting generated text. Additionally, the process of discovering the decoding strategy can reveal biases caused by selecting decoding settings which severely truncate a model\u2019s predicted distributions. We perform our attack on several families of open-source language models, as well as on production systems (e.g., ChatGPT).",
  "Additionally, the process of discovering the decoding strategy can reveal biases caused by selecting decoding settings which severely truncate a model\u2019s predicted distributions. We perform our attack on several families of open-source language models, as well as on production systems (e.g., ChatGPT).\nAuthors: Daphne Ippolito, Nicholas Carlini, Katherine Lee, Milad Nasr, Yun William Yu\nVenue: International Conference on Natural Language Generation\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Methods to reverse-engineer the decoding method used to generate text (i.e., top-_k_ or nucleus sampling) are presented, which has implications for detecting generated text.'}",
  "Faculty Name: daphne ippolito\nMetadata:\nPaperid: 1567bcac0ab09269c9d0ff33c9a406132417fab9\nTitle: A Pretrainer's Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, & Toxicity\nYear: 2023\nAbstract: Pretraining is the preliminary and fundamental step in developing capable language models (LM). Despite this, pretraining data design is critically under-documented and often guided by empirically unsupported intuitions. To address this, we pretrain 28 1.5B parameter decoder-only models, training on data curated (1) at different times, (2) with varying toxicity and quality filters, and (3) with different domain compositions. First, we quantify the effect of pretraining data age. A temporal shift between evaluation data and pretraining data leads to performance degradation, which is not overcome by finetuning. Second, we explore the effect of quality and toxicity filters, showing a trade-off between performance on standard benchmarks and risk of toxic generations. Our findings indicate there does not exist a one-size-fits-all solution to filtering training data.",
  "Second, we explore the effect of quality and toxicity filters, showing a trade-off between performance on standard benchmarks and risk of toxic generations. Our findings indicate there does not exist a one-size-fits-all solution to filtering training data. We also find that the effects of different types of filtering are not predictable from text domain characteristics. Lastly, we empirically validate that the inclusion of heterogeneous data sources, like books and web, is broadly beneficial and warrants greater prioritization. These findings constitute the largest set of experiments to validate, quantify, and expose many undocumented intuitions about text pretraining, which we hope will help support more informed data-centric decisions in LM development.",
  "These findings constitute the largest set of experiments to validate, quantify, and expose many undocumented intuitions about text pretraining, which we hope will help support more informed data-centric decisions in LM development.\nAuthors: S. Longpre, Gregory Yauney, Emily Reif, Katherine Lee, Adam Roberts, Barret Zoph, Denny Zhou, Jason Wei, Kevin Robinson, David M. Mimno, Daphne Ippolito\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'These findings constitute the largest set of experiments to validate, quantify, and expose many undocumented intuitions about text pretraining, which are hoped to help support more informed data-centric decisions in LM development.'}",
  "Faculty Name: daphne ippolito\nMetadata:\nPaperid: 2e965b5d97c2d6fb4af284307735be39283792ba\nTitle: Extracting Training Data from Diffusion Models\nYear: 2023\nAbstract: Image diffusion models such as DALL-E 2, Imagen, and Stable Diffusion have attracted significant attention due to their ability to generate high-quality synthetic images. In this work, we show that diffusion models memorize individual images from their training data and emit them at generation time. With a generate-and-filter pipeline, we extract over a thousand training examples from state-of-the-art models, ranging from photographs of individual people to trademarked company logos. We also train hundreds of diffusion models in various settings to analyze how different modeling and data decisions affect privacy. Overall, our results show that diffusion models are much less private than prior generative models such as GANs, and that mitigating these vulnerabilities may require new advances in privacy-preserving training.",
  "We also train hundreds of diffusion models in various settings to analyze how different modeling and data decisions affect privacy. Overall, our results show that diffusion models are much less private than prior generative models such as GANs, and that mitigating these vulnerabilities may require new advances in privacy-preserving training.\nAuthors: Nicholas Carlini, Jamie Hayes, Milad Nasr, Matthew Jagielski, Vikash Sehwag, Florian Tram\u00e8r, B. Balle, Daphne Ippolito, Eric Wallace\nVenue: USENIX Security Symposium\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The results show that diffusion models are much less private than prior generative models such as GANs, and that mitigating these vulnerabilities may require new advances in privacy-preserving training.'}",
  "Faculty Name: daphne ippolito\nMetadata:\nPaperid: 8724579d3f126e753a0451d98ff57b165f722e72\nTitle: Are aligned neural networks adversarially aligned?\nYear: 2023\nAbstract: Large language models are now tuned to align with the goals of their creators, namely to be\"helpful and harmless.\"These models should respond helpfully to user questions, but refuse to answer requests that could cause harm. However, adversarial users can construct inputs which circumvent attempts at alignment. In this work, we study to what extent these models remain aligned, even when interacting with an adversarial user who constructs worst-case inputs (adversarial examples). These inputs are designed to cause the model to emit harmful content that would otherwise be prohibited. We show that existing NLP-based optimization attacks are insufficiently powerful to reliably attack aligned text models: even when current NLP-based attacks fail, we can find adversarial inputs with brute force. As a result, the failure of current attacks should not be seen as proof that aligned text models remain aligned under adversarial inputs.",
  "As a result, the failure of current attacks should not be seen as proof that aligned text models remain aligned under adversarial inputs. However the recent trend in large-scale ML models is multimodal models that allow users to provide images that influence the text that is generated. We show these models can be easily attacked, i.e., induced to perform arbitrary un-aligned behavior through adversarial perturbation of the input image. We conjecture that improved NLP attacks may demonstrate this same level of adversarial control over text-only models.\nAuthors: Nicholas Carlini, Milad Nasr, Christopher A. Choquette-Choo, Matthew Jagielski, Irena Gao, Anas Awadalla, Pang Wei Koh, Daphne Ippolito, Katherine Lee, Florian Tram\u00e8r, Ludwig Schmidt\nVenue: Neural Information Processing Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is shown that existing NLP-based optimization attacks are insufficiently powerful to reliably attack aligned text models, and conjecture that improved NLP attacks may demonstrate this same level of adversarial control over text-only models.'}",
  "List of 2023 Open Access papers by daphne ippolito are:\nReverse-Engineering Decoding Strategies Given Blackbox Access to a Language Generation System\nA Pretrainer's Guide to Training Data: Measuring the Effects of Data Age, Domain Coverage, Quality, & Toxicity\nExtracting Training Data from Diffusion Models\nAre aligned neural networks adversarially aligned?",
  "Faculty Name: david mortensen\nMetadata:\nPaperid: 11a571eaab42a6ffb1d938635a093315e392756d\nTitle: ChatGPT MT: Competitive for High- (but Not Low-) Resource Languages\nYear: 2023\nAbstract: Large language models (LLMs) implicitly learn to perform a range of language tasks, including machine translation (MT). Previous studies explore aspects of LLMs\u2019 MT capabilities. However, there exist a wide variety of languages for which recent LLM MT performance has never before been evaluated. Without published experimental evidence on the matter, it is difficult for speakers of the world\u2019s diverse languages to know how and whether they can use LLMs for their languages. We present the first experimental evidence for an expansive set of 204 languages, along with MT cost analysis, using the FLORES-200 benchmark. Trends reveal that GPT models approach or exceed traditional MT model performance for some high-resource languages (HRLs) but consistently lag for low-resource languages (LRLs), under-performing traditional MT for 84.1% of languages we covered.",
  "Trends reveal that GPT models approach or exceed traditional MT model performance for some high-resource languages (HRLs) but consistently lag for low-resource languages (LRLs), under-performing traditional MT for 84.1% of languages we covered. Our analysis reveals that a language\u2019s resource level is the most important feature in determining ChatGPT\u2019s relative ability to translate it, and suggests that ChatGPT is especially disadvantaged for LRLs and African languages.\nAuthors: Nathaniel R. Robinson, Perez Ogayo, David R. Mortensen, Graham Neubig\nVenue: Conference on Machine Translation\nTldr: {'model': 'tldr@v2.0.0', 'text': \"This work presents the first experimental evidence for an expansive set of 204 languages, along with MT cost analysis, using the FLORES-200 benchmark, and reveals that a language\u2019s resource level is the most important feature in determining ChatGPT's relative ability to translate it, and suggests thatChatGPT is especially disadvantaged for LRLs and African languages.\"}",
  "Faculty Name: david mortensen\nMetadata:\nPaperid: 17fbffb05fa14e21d1c506fd5f0f568b955fe983\nTitle: Do All Languages Cost the Same? Tokenization in the Era of Commercial Language Models\nYear: 2023\nAbstract: Language models have graduated from being research prototypes to commercialized products offered as web APIs, and recent works have highlighted the multilingual capabilities of these products. The API vendors charge their users based on usage, more specifically on the number of ``tokens'' processed or generated by the underlying language models. What constitutes a token, however, is training data and model dependent with a large variance in the number of tokens required to convey the same information in different languages. In this work, we analyze the effect of this non-uniformity on the fairness of an API's pricing policy across languages. We conduct a systematic analysis of the cost and utility of OpenAI's language model API on multilingual benchmarks in 22 typologically diverse languages. We show evidence that speakers of a large number of the supported languages are overcharged while obtaining poorer results. These speakers tend to also come from regions where the APIs are less affordable to begin with.",
  "We show evidence that speakers of a large number of the supported languages are overcharged while obtaining poorer results. These speakers tend to also come from regions where the APIs are less affordable to begin with. Through these analyses, we aim to increase transparency around language model APIs' pricing policies and encourage the vendors to make them more equitable.\nAuthors: Orevaoghene Ahia, Sachin Kumar, Hila Gonen, Jungo Kasai, David R. Mortensen, Noah A. Smith, Yulia Tsvetkov\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': \"This work conducts a systematic analysis of the cost and utility of OpenAI's language model API on multilingual benchmarks in 22 typologically diverse languages and shows evidence that speakers of a large number of the supported languages are overcharged while obtaining poorer results.\"}",
  "Faculty Name: david mortensen\nMetadata:\nPaperid: 1d343a435c8b27b986cbeac1708e2b76abf2f9bc\nTitle: Kuki-Chin Phonology: An Overview\nYear: 2023\nAbstract: None\nAuthors: David R Mortensen\nVenue: Himalayan Linguistics\nTldr: None",
  "Faculty Name: david mortensen\nMetadata:\nPaperid: 659be1ff350634f50cc066d258ee6a45e697e552\nTitle: SigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing\nYear: 2023\nAbstract: In our submission to the SIGMORPHON 2023 Shared Task on interlinear glossing (IGT), we explore approaches to data augmentation and modeling across seven low-resource languages. For data augmentation, we explore two approaches: creating artificial data from the provided training data and utilizing existing IGT resources in other languages. On the modeling side, we test an enhanced version of the provided token classification baseline as well as a pretrained multilingual seq2seq model. Additionally, we apply post-correction using a dictionary for Gitksan, the language with the smallest amount of data. We find that our token classification models are the best performing, with the highest word-level accuracy for Arapaho and highest morpheme-level accuracy for Gitksan out of all submissions. We also show that data augmentation is an effective strategy, though applying artificial data pretraining has very different effects across both models tested.",
  "We find that our token classification models are the best performing, with the highest word-level accuracy for Arapaho and highest morpheme-level accuracy for Gitksan out of all submissions. We also show that data augmentation is an effective strategy, though applying artificial data pretraining has very different effects across both models tested.\nAuthors: Taiqi He, Lindia Tjuatja, Nathaniel R. Robinson, Shinji Watanabe, David R. Mortensen, Graham Neubig, L. Levin\nVenue: Special Interest Group on Computational Morphology and Phonology Workshop\nTldr: {'model': 'tldr@v2.0.0', 'text': 'In this submission to the SIGMORPHON 2023 Shared Task on interlinear glossing (IGT), approaches to data augmentation and modeling across seven low-resource languages are explored and token classification models are found to be the best performing.'}",
  "Faculty Name: david mortensen\nMetadata:\nPaperid: 7a08051aac75a809737096e39820bf836908d4e1\nTitle: Construction Grammar Provides Unique Insight into Neural Language Models\nYear: 2023\nAbstract: Construction Grammar (CxG) has recently been used as the basis for probing studies that have investigated the performance of large pretrained language models (PLMs) with respect to the structure and meaning of constructions. In this position paper, we make suggestions for the continuation and augmentation of this line of research. We look at probing methodology that was not designed with CxG in mind, as well as probing methodology that was designed for specific constructions. We analyse selected previous work in detail, and provide our view of the most important challenges and research questions that this promising new field faces.",
  "We look at probing methodology that was not designed with CxG in mind, as well as probing methodology that was designed for specific constructions. We analyse selected previous work in detail, and provide our view of the most important challenges and research questions that this promising new field faces.\nAuthors: Leonie Weissweiler, Taiqi He, Naoki Otani, David R. Mortensen, L. Levin, Hinrich Sch\u00fctze\nVenue: CXGSNLP\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The view of the most important challenges and research questions that this promising new field of research faces is provided, and an analysis of selected previous work in detail is provided.'}",
  "Faculty Name: david mortensen\nMetadata:\nPaperid: bf42c0462d1415cdde877c90d58da11545407b8a\nTitle: Generalized Glossing Guidelines: An Explicit, Human- and Machine-Readable, Item-and-Process Convention for Morphological Annotation\nYear: 2023\nAbstract: Interlinear glossing provides a vital type of morphosyntactic annotation, both for linguists and language revitalists, and numerous conventions exist for representing it formally and computationally. Some of these formats are human readable; others are machine readable. Some are easy to edit with general-purpose tools. Few represent non-concatentative processes like infixation, reduplication, mutation, truncation, and tonal overwriting in a consistent and formally rigorous way (on par with affixation). We propose an annotation convention\u00e2\u20ac\u201dGeneralized Glossing Guidelines (GGG) that combines all of these positive properties using an Item-and-Process (IP) framework. We describe the format, demonstrate its linguistic adequacy, and compare it with two other interlinear glossed text annotation schemes.",
  "We propose an annotation convention\u00e2\u20ac\u201dGeneralized Glossing Guidelines (GGG) that combines all of these positive properties using an Item-and-Process (IP) framework. We describe the format, demonstrate its linguistic adequacy, and compare it with two other interlinear glossed text annotation schemes.\nAuthors: David R. Mortensen, Ela Gulsen, Taiqi He, Nathaniel R. Robinson, Jonathan D. Amith, Lindia Tjuatja, L. Levin\nVenue: Special Interest Group on Computational Morphology and Phonology Workshop\nTldr: {'model': 'tldr@v2.0.0', 'text': 'An annotation convention is proposed that combines all of these positive properties using an Item-and-Process (IP) framework, and its linguistic adequacy is demonstrated, and it is compared with two other interlinear glossed text annotation schemes.'}",
  "Faculty Name: david mortensen\nMetadata:\nPaperid: c5c6d006e399386c99068daba138021a62d6cc17\nTitle: Transformed Protoform Reconstruction\nYear: 2023\nAbstract: Protoform reconstruction is the task of inferring what morphemes or words appeared like in the ancestral languages of a set of daughter languages. Meloni et al (2021) achieved the state-of-the-art on Latin protoform reconstruction with an RNN-based encoder-decoder with attention model. We update their model with the state-of-the-art seq2seq model: the Transformer. Our model outperforms their model on a suite of different metrics on two different datasets: their Romance data of 8,000 cognates spanning 5 languages and a Chinese dataset (Hou 2004) of 800+ cognates spanning 39 varieties. We also probe our model for potential phylogenetic signal contained in the model. Our code is publicly available at https://github.com/cmu-llab/acl-2023.",
  "We also probe our model for potential phylogenetic signal contained in the model. Our code is publicly available at https://github.com/cmu-llab/acl-2023.\nAuthors: Young Min Kim, Kalvin Chang, Chenxuan Cui, David R. Mortensen\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The Meloni et al (2021) model is updated with the state-of-the-art seq2seq model: the Transformer, which outperforms their model on a suite of different metrics on two different datasets: their Romance data of 8,000 cognate spanning 5 languages and a Chinese dataset (Hou 2004) of 800+ cognates spanning 39 varieties.'}",
  "Faculty Name: david mortensen\nMetadata:\nPaperid: db14d05b18ec852f8afcd6d2d10bbd9eeaef8325\nTitle: PWESuite: Phonetic Word Embeddings and Tasks They Facilitate\nYear: 2023\nAbstract: Mapping words into a fixed-dimensional vector space is the backbone of modern NLP. While most word embedding methods successfully encode semantic information, they overlook phonetic information that is crucial for many tasks. We develop three methods that use articulatory features to build phonetically informed word embeddings. To address the inconsistent evaluation of existing phonetic word embedding methods, we also contribute a task suite to fairly evaluate past, current, and future methods. We evaluate both (1) intrinsic aspects of phonetic word embeddings, such as word retrieval and correlation with sound similarity, and (2) extrinsic performance on tasks such as rhyme and cognate detection and sound analogies. We hope our task suite will promote reproducibility and inspire future phonetic embedding research.",
  "We evaluate both (1) intrinsic aspects of phonetic word embeddings, such as word retrieval and correlation with sound similarity, and (2) extrinsic performance on tasks such as rhyme and cognate detection and sound analogies. We hope our task suite will promote reproducibility and inspire future phonetic embedding research.\nAuthors: Vil\u00e9m Zouhar, Kalvin Chang, Chenxuan Cui, Nathaniel Carlson, Nathaniel R. Robinson, Mrinmaya Sachan, David R. Mortensen\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Three methods that use articulatory features to build phonetically informed word embeddings are developed that address the inconsistent evaluation of existing phonetic word embedding methods and contribute a task suite to fairly evaluate past, current, and future methods.'}",
  "List of 2023 Open Access papers by david mortensen are:\nChatGPT MT: Competitive for High- (but Not Low-) Resource Languages\nDo All Languages Cost the Same? Tokenization in the Era of Commercial Language Models\nSigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing\nConstruction Grammar Provides Unique Insight into Neural Language Models\nGeneralized Glossing Guidelines: An Explicit, Human- and Machine-Readable, Item-and-Process Convention for Morphological Annotation\nTransformed Protoform Reconstruction\nPWESuite: Phonetic Word Embeddings and Tasks They Facilitate\nKuki-Chin Phonology: An Overview",
  "Title: Mona Diab -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio page for Language Technologies Institute faculty member and director Mona Diab\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Core Faculty\" name=\"categories-1\"/>\n<meta content=\"Fairness and Ethics in Language Technology\" name=\"categories-2\"/>\n<meta content=\"Yes\" name=\"show-categories-2\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Mona Diab - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio page for Language Technologies Institute faculty member and director Mona Diab\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Mona\"/>\n<meta content=\"Lastname\" property=\"profile:Diab\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/diab-mona.",
  "cmu.edu//people/faculty/diab-mona.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nMona \n                        Diab\nLTI Director and Tenured Professor, Language Technologies Institute\nContact\n5723 Gates & Hillman Centers\nmdiab(through)andrew.cmu.edu\n412-268-3669\nAddress\n5000 Forbes Avenue\nPittsburgh, PA 15213\nResearch Area\nFairness and Ethics in Language Technology\n\nLinks:",
  "Title: Fernando DIaz -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Fernando Diaz, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Core Faculty\" name=\"categories-1\"/>\n<meta content=\"Information Retrieval, Text Mining and Analytics;Natural Language Processing and Computational Linguistics\" name=\"categories-2\"/>\n<meta content=\"Yes\" name=\"show-categories-2\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Fernando DIaz - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Fernando Diaz, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Fernando\"/>\n<meta content=\"Lastname\" property=\"profile:Diaz\"/>\n<meta content=\"http://lti.cmu.",
  "Faculty Member at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Fernando\"/>\n<meta content=\"Lastname\" property=\"profile:Diaz\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/diaz-fernando.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nFernando \n                        Diaz\nAssociate Professor, Language Technologies Institute\nContact\ndiazf(through)cmu.edu\nResearch Area\nInformation Retrieval, Text Mining and Analytics, Natural Language Processing and Computational Linguistics\nResearch\nInformation Retrieval: Recommender Systems, Retrieval and Ranking Models\nNatural Language Processing: Fairness and Ethics in Language Technology, Creativity, Evaluation\nPersonal Website\n\nLinks:\nhttps://841.io/",
  "Title: Christopher Dyer -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Christopher Dyer, Adjunct Faculty at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Adjunct Faculty\" name=\"categories-1\"/>\n<meta content=\"Machine Learning;Machine Translation;Natural Language Processing and Computational Linguistics\" name=\"categories-2\"/>\n<meta content=\"Yes\" name=\"show-categories-2\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Christopher Dyer - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Christopher Dyer, Adjunct Faculty at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Christopher\"/>\n<meta content=\"Lastname\" property=\"profile:Dyer\"/>\n<meta content=\"http://lti.cmu.",
  "Adjunct Faculty at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Christopher\"/>\n<meta content=\"Lastname\" property=\"profile:Dyer\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/dyer-christopher.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nChristopher \n                        Dyer\nSenior Staff Scientist, DeepMind\nContact\ncdyer(through)cs.cmu.edu\nResearch Area\nMachine Learning, Machine Translation, Natural Language Processing and Computational Linguistics\nPersonal Website\n\nLinks:\nhttp://www.cs.cmu.edu/~cdyer/",
  "Faculty Name: emma strubell\nMetadata:\nPaperid: 1433b8d43d446fcc7f3e1370b22f744a4dd7c8e4\nTitle: To Build Our Future, We Must Know Our Past: Contextualizing Paradigm Shifts in Natural Language Processing\nYear: 2023\nAbstract: NLP is in a period of disruptive change that is impacting our methodologies, funding sources, and public perception. In this work, we seek to understand how to shape our future by better understanding our past. We study factors that shape NLP as a field, including culture, incentives, and infrastructure by conducting long-form interviews with 26 NLP researchers of varying seniority, research area, institution, and social identity. Our interviewees identify cyclical patterns in the field, as well as new shifts without historical parallel, including changes in benchmark culture and software infrastructure. We complement this discussion with quantitative analysis of citation, authorship, and language use in the ACL Anthology over time. We conclude by discussing shared visions, concerns, and hopes for the future of NLP.",
  "We complement this discussion with quantitative analysis of citation, authorship, and language use in the ACL Anthology over time. We conclude by discussing shared visions, concerns, and hopes for the future of NLP. We hope that this study of our field's past and present can prompt informed discussion of our community's implicit norms and more deliberate action to consciously shape the future.\nAuthors: Sireesh Gururaja, Amanda Bertsch, Clara Na, D. Widder, Emma Strubell\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work conducts long-form interviews with 26 NLP researchers of varying seniority, research area, institution, and social identity to study factors that shape NLP as a field, including culture, incentives, and infrastructure.'}",
  "Faculty Name: emma strubell\nMetadata:\nPaperid: 45e50baac4d341f0cf1a40af096bfa9c3f555235\nTitle: Understanding the Effect of Model Compression on Social Bias in Large Language Models\nYear: 2023\nAbstract: Large Language Models (LLMs) trained with self-supervision on vast corpora of web text fit to the social biases of that text. Without intervention, these social biases persist in the model's predictions in downstream tasks, leading to representational harm. Many strategies have been proposed to mitigate the effects of inappropriate social biases learned during pretraining. Simultaneously, methods for model compression have become increasingly popular to reduce the computational burden of LLMs. Despite the popularity and need for both approaches, little work has been done to explore the interplay between these two. We perform a carefully controlled study of the impact of model compression via quantization and knowledge distillation on measures of social bias in LLMs. Longer pretraining and larger models led to higher social bias, and quantization showed a regularizer effect with its best trade-off around 20% of the original pretraining time.",
  "Longer pretraining and larger models led to higher social bias, and quantization showed a regularizer effect with its best trade-off around 20% of the original pretraining time.\nAuthors: Gustavo Gon\u00e7alves, Emma Strubell\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A carefully controlled study of the impact of model compression via quantization and knowledge distillation on measures of social bias in LLMs finds that longer pretraining and larger models led to higher social bias, and quantization showed a regularizer effect with its best trade-off around 20% of the original pretraining time.'}",
  "Faculty Name: emma strubell\nMetadata:\nPaperid: 667ba2e8f1933b6c32e9672012526904b4c5dc31\nTitle: Surveying (Dis)Parities and Concerns of Compute Hungry NLP Research\nYear: 2023\nAbstract: Many recent improvements in NLP stem from the development and use of large pre-trained language models (PLMs) with billions of parameters. Large model sizes makes computational cost one of the main limiting factors for training and evaluating such models; and has raised severe concerns about the sustainability, reproducibility, and inclusiveness for researching PLMs. These concerns are often based on personal experiences and observations. However, there had not been any large-scale surveys that investigate them. In this work, we provide a first attempt to quantify these concerns regarding three topics, namely, environmental impact, equity, and impact on peer reviewing. By conducting a survey with 312 participants from the NLP community, we capture existing (dis)parities between different and within groups with respect to seniority, academia, and industry; and their impact on the peer reviewing process.",
  "By conducting a survey with 312 participants from the NLP community, we capture existing (dis)parities between different and within groups with respect to seniority, academia, and industry; and their impact on the peer reviewing process. For each topic, we provide an analysis and devise recommendations to mitigate found disparities, some of which already successfully implemented. Finally, we discuss additional concerns raised by many participants in free-text responses.\nAuthors: Ji-Ung Lee, Haritz Puerto, Betty van Aken, Yuki Arase, J. Forde, Leon Derczynski, Andreas Ruckl'e, Iryna Gurevych, Roy Schwartz, Emma Strubell, Jesse Dodge\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work captures existing (dis)parities between different and within groups with respect to seniority, academia, and industry; and their impact on the peer reviewing process; and provides an analysis and devise recommendations to mitigate found disparities.'}",
  "Faculty Name: emma strubell\nMetadata:\nPaperid: 71debf888acd57bb1baa4c146f31e58c66ea51af\nTitle: On the Interactions of Structural Constraints and Data Resources for Structured Prediction\nYear: 2023\nAbstract: ,\nAuthors: Zhisong Zhang, Emma Strubell, E. Hovy\nVenue: SUSTAINLP\nTldr: {'model': 'tldr@v2.0.0', 'text': None}",
  "Faculty Name: emma strubell\nMetadata:\nPaperid: 84d20ad9f42d80dfd5130a6362d5422be8a6bdc3\nTitle: Efficiency Pentathlon: A Standardized Arena for Efficiency Evaluation\nYear: 2023\nAbstract: Rising computational demands of modern natural language processing (NLP) systems have increased the barrier to entry for cutting-edge research while posing serious environmental concerns. Yet, progress on model efficiency has been impeded by practical challenges in model evaluation and comparison. For example, hardware is challenging to control due to disparate levels of accessibility across different institutions. Moreover, improvements in metrics such as FLOPs often fail to translate to progress in real-world applications. In response, we introduce Pentathlon, a benchmark for holistic and realistic evaluation of model efficiency. Pentathlon focuses on inference, which accounts for a majority of the compute in a model's lifecycle. It offers a strictly-controlled hardware platform, and is designed to mirror real-world applications scenarios. It incorporates a suite of metrics that target different aspects of efficiency, including latency, throughput, memory overhead, and energy consumption.",
  "It offers a strictly-controlled hardware platform, and is designed to mirror real-world applications scenarios. It incorporates a suite of metrics that target different aspects of efficiency, including latency, throughput, memory overhead, and energy consumption. Pentathlon also comes with a software library that can be seamlessly integrated into any codebase and enable evaluation. As a standardized and centralized evaluation platform, Pentathlon can drastically reduce the workload to make fair and reproducible efficiency comparisons. While initially focused on natural language processing (NLP) models, Pentathlon is designed to allow flexible extension to other fields. We envision Pentathlon will stimulate algorithmic innovations in building efficient models, and foster an increased awareness of the social and environmental implications in the development of future-generation NLP models.",
  "While initially focused on natural language processing (NLP) models, Pentathlon is designed to allow flexible extension to other fields. We envision Pentathlon will stimulate algorithmic innovations in building efficient models, and foster an increased awareness of the social and environmental implications in the development of future-generation NLP models.\nAuthors: Hao Peng, Qingqing Cao, Jesse Dodge, Matthew E. Peters, Jared Fernandez, Tom Sherborne, Kyle Lo, Sam Skjonsberg, Emma Strubell, Darrell Plessas, Iz Beltagy, Pete Walsh, Noah A. Smith, Hannaneh Hajishirzi\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': \"Pentathlon is a benchmark for holistic and realistic evaluation of model efficiency, which focuses on inference, which accounts for a majority of the compute in a model's lifecycle, and is designed to mirror real-world applications scenarios.\"}",
  "Faculty Name: emma strubell\nMetadata:\nPaperid: 88549b4f48b9709acdfb8b9e41656b6d133c5390\nTitle: Queer People are People First: Deconstructing Sexual Identity Stereotypes in Large Language Models\nYear: 2023\nAbstract: Large Language Models (LLMs) are trained primarily on minimally processed web text, which exhibits the same wide range of social biases held by the humans who created that content. Consequently, text generated by LLMs can inadvertently perpetuate stereotypes towards marginalized groups, like the LGBTQIA+ community. In this paper, we perform a comparative study of how LLMs generate text describing people with different sexual identities. Analyzing bias in the text generated by an LLM using regard score shows measurable bias against queer people. We then show that a post-hoc method based on chain-of-thought prompting using SHAP analysis can increase the regard of the sentence, representing a promising approach towards debiasing the output of LLMs in this setting.",
  "We then show that a post-hoc method based on chain-of-thought prompting using SHAP analysis can increase the regard of the sentence, representing a promising approach towards debiasing the output of LLMs in this setting.\nAuthors: Harnoor Dhingra, Preetiha Jayashanker, Sayali S. Moghe, Emma Strubell\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is shown that a post-hoc method based on chain-of-thought prompting using SHAP analysis can increase the regard of the sentence, representing a promising approach towards debiasing the output of LLMs in this setting.'}",
  "Faculty Name: emma strubell\nMetadata:\nPaperid: a815c3209e7baff4466dbf6e129129511f842b7e\nTitle: Making Scalable Meta Learning Practical\nYear: 2023\nAbstract: Despite its flexibility to learn diverse inductive biases in machine learning programs, meta learning (i.e., learning to learn) has long been recognized to suffer from poor scalability due to its tremendous compute/memory costs, training instability, and a lack of efficient distributed training support. In this work, we focus on making scalable meta learning practical by introducing SAMA, which combines advances in both implicit differentiation algorithms and systems. Specifically, SAMA is designed to flexibly support a broad range of adaptive optimizers in the base level of meta learning programs, while reducing computational burden by avoiding explicit computation of second-order gradient information, and exploiting efficient distributed training techniques implemented for first-order gradients. Evaluated on multiple large-scale meta learning benchmarks, SAMA showcases up to 1.7/4.8x increase in throughput and 2.0/3.8x decrease in memory consumption respectively on single-/multi-GPU setups compared to other baseline meta learning algorithms.",
  "Evaluated on multiple large-scale meta learning benchmarks, SAMA showcases up to 1.7/4.8x increase in throughput and 2.0/3.8x decrease in memory consumption respectively on single-/multi-GPU setups compared to other baseline meta learning algorithms. Furthermore, we show that SAMA-based data optimization leads to consistent improvements in text classification accuracy with BERT and RoBERTa large language models, and achieves state-of-the-art results in both small- and large-scale data pruning on image classification tasks, demonstrating the practical applicability of scalable meta learning across language and vision domains.\nAuthors: Sang Keun Choe, Sanket Vaibhav Mehta, Hwijeen Ahn, W. Neiswanger, Pengtao Xie, Emma Strubell, Eric P. Xing\nVenue: Neural Information Processing Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'SAMA is designed to flexibly support a broad range of adaptive optimizers in the base level of meta learning programs, while reducing computational burden by avoiding explicit computation of second-order gradient information, and exploiting efficient distributed training techniques implemented for first-order gradients.'}",
  "Faculty Name: emma strubell\nMetadata:\nPaperid: b13da1161d65a8de7a96051b5bc68d5eaa8eb37b\nTitle: Regularizing Self-training for Unsupervised Domain Adaptation via Structural Constraints\nYear: 2023\nAbstract: Self-training based on pseudo-labels has emerged as a dominant approach for addressing conditional distribution shifts in unsupervised domain adaptation (UDA) for semantic segmentation problems. A notable drawback, however, is that this family of approaches is susceptible to erroneous pseudo labels that arise from confirmation biases in the source domain and that manifest as nuisance factors in the target domain. A possible source for this mismatch is the reliance on only photometric cues provided by RGB image inputs, which may ultimately lead to sub-optimal adaptation. To mitigate the effect of mismatched pseudo-labels, we propose to incorporate structural cues from auxiliary modalities, such as depth, to regularise conventional self-training objectives. Specifically, we introduce a contrastive pixel-level objectness constraint that pulls the pixel representations within a region of an object instance closer, while pushing those from different object categories apart.",
  "Specifically, we introduce a contrastive pixel-level objectness constraint that pulls the pixel representations within a region of an object instance closer, while pushing those from different object categories apart. To obtain object regions consistent with the true underlying object, we extract information from both depth maps and RGB-images in the form of multimodal clustering. Crucially, the objectness constraint is agnostic to the ground-truth semantic labels and, hence, appropriate for unsupervised domain adaptation. In this work, we show that our regularizer significantly improves top performing self-training methods (by up to $2$ points) in various UDA benchmarks for semantic segmentation. We include all code in the supplementary.\nAuthors: Rajshekhar Das, Jonathan M Francis, Sanket Vaibhav Mehta, Jean Oh, Emma Strubell, Jose Moura\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The regularizer significantly improves top performing self-training methods in various UDA benchmarks for semantic segmentation and introduces a contrastive pixel-level objectness constraint that pulls the pixel representations within a region of an object instance closer, while pushing those from different object categories apart.'}",
  "Faculty Name: emma strubell\nMetadata:\nPaperid: b777aa86b5a1d49ce8eababc5c2ee56d3562801e\nTitle: The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment\nYear: 2023\nAbstract: Increased focus on the computational efficiency of NLP systems has motivated the design of efficient model architectures and improvements to underlying hardware accelerators. However, the resulting increases in computational throughput and reductions in floating point operations have not directly translated to improvements in wall-clock inference latency. We demonstrate that these discrepancies can be largely attributed to bottlenecks introduced by deep learning frameworks. We denote this phenomenon as the \\textit{framework tax}, and observe that the disparity is growing as hardware speed increases over time. In this work, we examine this phenomenon through a series of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency. Code is available at https://github.com/JaredFern/Framework-Tax.",
  "In this work, we examine this phenomenon through a series of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency. Code is available at https://github.com/JaredFern/Framework-Tax.\nAuthors: Jared Fernandez, Jacob Kahn, Clara Na, Yonatan Bisk, Emma Strubell\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work examines the effects of model design decisions, framework paradigms, and hardware platforms on total model latency through a series of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency.'}",
  "Faculty Name: emma strubell\nMetadata:\nPaperid: ba31ccac5fe5ea151727e8427e78bb300c35f899\nTitle: Data-efficient Active Learning for Structured Prediction with Partial Annotation and Self-Training\nYear: 2023\nAbstract: In this work we propose a pragmatic method that reduces the annotation cost for structured label spaces using active learning. Our approach leverages partial annotation, which reduces labeling costs for structured outputs by selecting only the most informative sub-structures for annotation. We also utilize self-training to incorporate the current model's automatic predictions as pseudo-labels for un-annotated sub-structures. A key challenge in effectively combining partial annotation with self-training to reduce annotation cost is determining which sub-structures to select to label. To address this challenge, we adopt an error estimator to adaptively decide the partial selection ratio according to the current model's capability. In evaluations spanning four structured prediction tasks, we show that our combination of partial annotation and self-training using an adaptive selection ratio reduces annotation cost over strong full annotation baselines under a fair comparison scheme that takes reading time into consideration.",
  "In evaluations spanning four structured prediction tasks, we show that our combination of partial annotation and self-training using an adaptive selection ratio reduces annotation cost over strong full annotation baselines under a fair comparison scheme that takes reading time into consideration.\nAuthors: Zhisong Zhang, Emma Strubell, E. Hovy\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': \"This work proposes a pragmatic method that reduces the annotation cost for structured label spaces using active learning by adopting an error estimator to adaptively decide the partial selection ratio according to the current model's capability.\"}",
  "List of 2023 Open Access papers by emma strubell are:\nTo Build Our Future, We Must Know Our Past: Contextualizing Paradigm Shifts in Natural Language Processing\nUnderstanding the Effect of Model Compression on Social Bias in Large Language Models\nSurveying (Dis)Parities and Concerns of Compute Hungry NLP Research\nOn the Interactions of Structural Constraints and Data Resources for Structured Prediction\nEfficiency Pentathlon: A Standardized Arena for Efficiency Evaluation\nQueer People are People First: Deconstructing Sexual Identity Stereotypes in Large Language Models\nMaking Scalable Meta Learning Practical\nRegularizing Self-training for Unsupervised Domain Adaptation via Structural Constraints\nThe Framework Tax: Disparities Between Inference Efficiency in Research and Deployment\nData-efficient Active Learning for Structured Prediction with Partial Annotation and Self-Training",
  "Faculty Name: eric nyberg\nMetadata:\nPaperid: 0f008e07d601e8f21d1df5db3d36e85484840083\nTitle: GameQA: Gamified Mobile App Platform for Building Multiple-Domain Question-Answering Datasets\nYear: 2023\nAbstract: The methods used to create many of the well-known Question-Answering (QA) datasets are hard to replicate for low-resource languages. A commonality amongst these methods is hiring annotators to source answers from the internet by querying a single answer source, such as Wikipedia. Applying these methods for low-resource languages can be problematic since there is no single large answer source for these languages. Consequently, this can result in a high ratio of unanswered questions, since the amount of information in any single source is limited. To address this problem, we developed a novel crowd-sourcing platform to gather multiple-domain QA data for low-resource languages. Our platform, which consists of a mobile app and a web API, gamifies the data collection process.",
  "To address this problem, we developed a novel crowd-sourcing platform to gather multiple-domain QA data for low-resource languages. Our platform, which consists of a mobile app and a web API, gamifies the data collection process. We successfully released the app for Icelandic (a low-resource language with about 350,000 native speakers) to build a dataset which rivals large QA datasets for high-resource languages both in terms of size and ratio of answered questions. We have made the platform open source with instructions on how to localize and deploy it to gather data for other low-resource languages.",
  "We have made the platform open source with instructions on how to localize and deploy it to gather data for other low-resource languages.\nAuthors: Njall Skarphedinsson, Breki Gudmundsson, Steinar Smari, M. L\u00e1rusd\u00f3ttir, H. Einarsson, Abuzar Khan, Eric Nyberg, H. Loftsson\nVenue: Conference of the European Chapter of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work developed a novel crowd-sourcing platform to gather multiple-domain QA data for low-resource languages and successfully released the app for Icelandic to build a dataset which rivals large QA datasets for high- resource languages both in terms of size and ratio of answered questions.'}",
  "Faculty Name: eric nyberg\nMetadata:\nPaperid: 3a30217c4115777fb30c182c97cc77d34d065556\nTitle: InPars-Light: Cost-Effective Unsupervised Training of Efficient Rankers\nYear: 2023\nAbstract: We carried out a reproducibility study of InPars, which is a method for unsupervised training of neural rankers (Bonifacio et al., 2022). As a by-product, we developed InPars-light, which is a simple-yet-effective modification of InPars. Unlike InPars, InPars-light uses 7x-100x smaller ranking models and only a freely available language model BLOOM, which -- as we found out -- produced more accurate rankers compared to a proprietary GPT-3 model. On all five English retrieval collections (used in the original InPars study) we obtained substantial (7%-30%) and statistically significant improvements over BM25 (in nDCG and MRR) using only a 30M parameter six-layer MiniLM-30M ranker and a single three-shot prompt.",
  "On all five English retrieval collections (used in the original InPars study) we obtained substantial (7%-30%) and statistically significant improvements over BM25 (in nDCG and MRR) using only a 30M parameter six-layer MiniLM-30M ranker and a single three-shot prompt. In contrast, in the InPars study only a 100x larger monoT5-3B model consistently outperformed BM25, whereas their smaller monoT5-220M model (which is still 7x larger than our MiniLM ranker) outperformed BM25 only on MS MARCO and TREC DL 2020. In the same three-shot prompting scenario, our 435M parameter DeBERTA v3 ranker was at par with the 7x larger monoT5-3B (average gain over BM25 of 1.3 vs 1.32): In fact, on three out of five datasets, DeBERTA slightly outperformed monoT5-3B. Finally, these good results were achieved by re-ranking only 100 candidate documents compared to 1000 used by Bonifacio et al. (2022).",
  "Finally, these good results were achieved by re-ranking only 100 candidate documents compared to 1000 used by Bonifacio et al. (2022). We believe that InPars-light is the first truly cost-effective prompt-based unsupervised recipe to train and deploy neural ranking models that outperform BM25. Our code and data is publicly available. https://github.com/searchivarius/inpars_light/\nAuthors: Leonid Boytsov, Preksha Patel, Vivek Sourabh, Riddhi Nisar, Sayan Kundu, R. Ramanathan, Eric Nyberg\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'InPars-light is the first truly cost-effective prompt-based unsupervised recipe to train and deploy neural ranking models that outperform BM25.'}",
  "Faculty Name: eric nyberg\nMetadata:\nPaperid: 444737639aeea4e1e616509e368afb0bae8f89d6\nTitle: Language-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA\nYear: 2023\nAbstract: The DialDoc 2023 shared task has expanded the document-grounded dialogue task to encompass multiple languages, despite having limited annotated data. This paper assesses the effectiveness of both language-agnostic and language-aware paradigms for multilingual pre-trained transformer models in a bi-encoder-based dense passage retriever (DPR), concluding that the language-agnostic approach is superior. Additionally, the study investigates the impact of query rewriting techniques using large language models, such as ChatGPT, on multilingual, document-grounded question-answering systems. The experiments conducted demonstrate that, for the examples examined, query rewriting does not enhance performance compared to the original queries. This failure is due to topic switching in final dialogue turns and irrelevant topics being considered for query rewriting.",
  "The experiments conducted demonstrate that, for the examples examined, query rewriting does not enhance performance compared to the original queries. This failure is due to topic switching in final dialogue turns and irrelevant topics being considered for query rewriting.\nAuthors: Srinivas Gowriraj, Soham Dinesh Tiwari, Mitali Potnis, Srijan Bansal, T. Mitamura, Eric Nyberg\nVenue: Workshop on Document-grounded Dialogue and Conversational Question Answering\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper assesses the effectiveness of both language-agnostic and language-aware paradigms for multilingual pre-trained transformer models in a bi-encoder-based dense passage retriever (DPR), concluding that the language-gnostic approach is superior.'}",
  "Faculty Name: eric nyberg\nMetadata:\nPaperid: 61354e45bca908ad08f24e44bd507b4e1c958e6f\nTitle: Chain-of-Skills: A Configurable Model for Open-Domain Question Answering\nYear: 2023\nAbstract: The retrieval model is an indispensable component for real-world knowledge-intensive tasks, e.g., open-domain question answering (ODQA). As separate retrieval skills are annotated for different datasets, recent work focuses on customized methods, limiting the model transfer- ability and scalability. In this work, we propose a modular retriever where individual modules correspond to key skills that can be reused across datasets. Our approach supports flexible skill configurations based on the target domain to boost performance. To mitigate task interference, we design a novel modularization parameterization inspired by sparse Transformer. We demonstrate that our model can benefit from self-supervised pretraining on Wikipedia and fine-tuning using multiple ODQA datasets, both in a multi-task fashion. Our approach outperforms recent self-supervised retrievers in zero-shot evaluations and achieves state-of-the-art fine-tuned retrieval performance on NQ, HotpotQA and OTT-QA.",
  "Our approach outperforms recent self-supervised retrievers in zero-shot evaluations and achieves state-of-the-art fine-tuned retrieval performance on NQ, HotpotQA and OTT-QA.\nAuthors: Kaixin Ma, Hao Cheng, Yu Zhang, Xiaodong Liu, Eric Nyberg, Jianfeng Gao\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes a modular retriever where individual modules correspond to key skills that can be reused across datasets and achieves state-of-the-art fine-tuned retrieval performance on NQ, HotpotQA and OTT-QA.'}",
  "Faculty Name: eric nyberg\nMetadata:\nPaperid: 8d0c37eee7162f33178979b4183f0211e2dcae0d\nTitle: Difference-Masking: Choosing What to Mask in Continued Pretraining\nYear: 2023\nAbstract: The self-supervised objective of masking-and-predicting has led to promising performance gains on a variety of downstream tasks. However, while most approaches randomly mask tokens, there is strong intuition that deciding what to mask can substantially improve learning outcomes. We investigate this in continued pretraining setting in which pretrained models continue to pretrain on domain-specific data before performing some downstream task. We introduce Difference-Masking, a masking strategy that automatically chooses what to mask during continued pretraining by considering what makes a task domain different from the pretraining domain. Empirically, we find that Difference-Masking outperforms baselines on continued pretraining settings across four diverse language-only and multimodal video tasks.",
  "Empirically, we find that Difference-Masking outperforms baselines on continued pretraining settings across four diverse language-only and multimodal video tasks.\nAuthors: Alex Wilf, Syeda Nahida Akter, Leena Mathur, P. Liang, Sheryl Mathew, Mengrou Shou, Eric Nyberg, Louis-Philippe Morency\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Difference-Masking is introduced, a masking strategy that automatically chooses what to mask during continued pretraining by considering what makes a task domain different from the pretraining domain.'}",
  "Faculty Name: eric nyberg\nMetadata:\nPaperid: c251d929c2e54a61366c02c7052f055d408072a1\nTitle: A super wear-resistant coating for Mg alloys achieved by plasma electrolytic oxidation and discontinuous deposition\nYear: 2023\nAbstract: None\nAuthors: Xixi Dong, Mingxu Xia, Feng Wang, Hailin Yang, G. Ji, E. Nyberg, S. Ji\nVenue: Journal of Magnesium and Alloys\nTldr: None",
  "Faculty Name: eric nyberg\nMetadata:\nPaperid: daf657e9dc60e104827b6f574d3946c489188e69\nTitle: Using Implicit Feedback to Improve Question Generation\nYear: 2023\nAbstract: Question Generation (QG) is a task of Natural Language Processing (NLP) that aims at automatically generating questions from text. Many applications can benefit from automatically generated questions, but often it is necessary to curate those questions, either by selecting or editing them. This task is informative on its own, but it is typically done post-generation, and, thus, the effort is wasted. In addition, most existing systems cannot incorporate this feedback back into them easily. In this work, we present a system, GEN, that learns from such (implicit) feedback. Following a pattern-based approach, it takes as input a small set of sentence/question pairs and creates patterns which are then applied to new unseen sentences. Each generated question, after being corrected by the user, is used as a new seed in the next iteration, so more patterns are created each time. We also take advantage of the corrections made by the user to score the patterns and therefore rank the generated questions.",
  "Each generated question, after being corrected by the user, is used as a new seed in the next iteration, so more patterns are created each time. We also take advantage of the corrections made by the user to score the patterns and therefore rank the generated questions. Results show that GEN is able to improve by learning from both levels of implicit feedback when compared to the version with no learning, considering the top 5, 10, and 20 questions. Improvements go up from 10%, depending on the metric and strategy used.\nAuthors: Hugo Rodrigues, Eric Nyberg, Lu\u00edsa Coheur\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A system that learns from both levels of implicit feedback when compared to the version with no learning, considering the top 5, 10, and 20 questions, and improvements go up from 10%, depending on the metric and strategy used.'}",
  "List of 2023 Open Access papers by eric nyberg are:\nGameQA: Gamified Mobile App Platform for Building Multiple-Domain Question-Answering Datasets\nInPars-Light: Cost-Effective Unsupervised Training of Efficient Rankers\nLanguage-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA\nChain-of-Skills: A Configurable Model for Open-Domain Question Answering\nA super wear-resistant coating for Mg alloys achieved by plasma electrolytic oxidation and discontinuous deposition\nDifference-Masking: Choosing What to Mask in Continued Pretraining\nUsing Implicit Feedback to Improve Question Generation",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 043512db27dbb03eb05eb5f5679b5bd5f59d18ca\nTitle: Research on the Training Path of Live E-commerce Talents Oriented by Industry Development\nYear: 2023\nAbstract: The growth of user scale and application popularization of live streaming e-commerce promote the transformation of live streaming stores to store live streaming, live streaming scene to scene live streaming, and the transformation of web celebrity staff to staff web celebrity. The stock talents of live streaming e-commerce can no longer meet the development of the industry. Long-term training of applied talents in higher vocational colleges can provide human resources to the industry and promote the development of local industries. However, the rapid development of live-streaming e-commerce industry leads to the shortage of industrial development and talent supply, the dislocation of industrial demand and talent training, the disconnect between practical training conditions and training requirements, and the lack of complementarity between higher vocational teachers and industries.",
  "However, the rapid development of live-streaming e-commerce industry leads to the shortage of industrial development and talent supply, the dislocation of industrial demand and talent training, the disconnect between practical training conditions and training requirements, and the lack of complementarity between higher vocational teachers and industries. According to the new in April 2022, the revision of \"vocational education law\" requirements to promote enterprise depth to participate in vocational education, education fusion is live electricity talent training, talent training to adhere to the industry development, post, class, competition, and training process, college teachers and industry mentor complementary development, jointly promote live electricity talent training.\nAuthors: Shouhui Xia, Xili Rao, Xin Wu\nVenue: Academic Journal of Management and Social Sciences\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The rapid development of live-streaming e-commerce industry leads to the shortage of industrial development and talent supply, the dislocation of industrial demand and talent training, the disconnect between practical training conditions and training requirements, and the lack of complementarity between higher vocational teachers and industries.'}",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 05916c0933cb6cc434d4fcc469f928e13ae57689\nTitle: Recent progresses on the gamma-ray observations of DAMPE\nYear: 2023\nAbstract: None\nAuthors: Z. Shen, K. Duan, Zunlei Xu, Wei Jiang, Xiang Li, Xiao Yuan Huang, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, F. de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, J. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang,",
  "F. de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, J. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Y. Huang, M. Ionica, Luyao Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A.",
  "Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, H. Su, Meng Su, H. Sun, Zhiyu Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Yuanzhu Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu, G. Xue,",
  "Yuanzhu Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hong-yun Zhao, Xu Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: None",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 06eb9ad79cf76007e6847c771a4645f1dab6c36d\nTitle: US residents' preferences for sharing of electronic health record and genetic information: a discrete choice experiment.\nYear: 2023\nAbstract: None\nAuthors: A. Wagner, Felicia Zhang, Kerry A Ryan, Eric Xing, Paige Nong, Sharon L. R. Kardia, Jodyn E. Platt\nVenue: Value in Health\nTldr: {'model': 'tldr@v2.0.0', 'text': 'For both genetic and EHR information, patients strongly prefer their data to be de-identified and to have the choice to opt out of sharing information with commercial companies.'}",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 075b751201f549daeba9840f78768f4ceb507e17\nTitle: Identification of Nonlinear Latent Hierarchical Models\nYear: 2023\nAbstract: Identifying latent variables and causal structures from observational data is essential to many real-world applications involving biological data, medical data, and unstructured data such as images and languages. However, this task can be highly challenging, especially when observed variables are generated by causally related latent variables and the relationships are nonlinear. In this work, we investigate the identification problem for nonlinear latent hierarchical causal models in which observed variables are generated by a set of causally related latent variables, and some latent variables may not have observed children. We show that the identifiability of causal structures and latent variables (up to invertible transformations) can be achieved under mild assumptions: on causal structures, we allow for multiple paths between any pair of variables in the graph, which relaxes latent tree assumptions in prior work; on structural functions, we permit general nonlinearity and multi-dimensional continuous variables, alleviating existing work's parametric assumptions.",
  "Specifically, we first develop an identification criterion in the form of novel identifiability guarantees for an elementary latent variable model. Leveraging this criterion, we show that both causal structures and latent variables of the hierarchical model can be identified asymptotically by explicitly constructing an estimation procedure. To the best of our knowledge, our work is the first to establish identifiability guarantees for both causal structures and latent variables in nonlinear latent hierarchical models.\nAuthors: Lingjing Kong, Biwei Huang, Feng Xie, E. Xing, Yuejie Chi, Kun Zhang\nVenue: Neural Information Processing Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work develops an identification criterion in the form of novel identifiability guarantees for an elementary latent variable model and shows that both causal structures and latent variables of the hierarchical model can be identified asymptotically by explicitly constructing an estimation procedure.'}",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 0ba649135b008efa0f7d7db83a7405d3fa580658\nTitle: Effective Multi-Agent Deep Reinforcement Learning Control with Relative Entropy Regularization\nYear: 2023\nAbstract: In this paper, a novel Multi-agent Reinforcement Learning (MARL) approach, Multi-Agent Continuous Dynamic Policy Gradient (MACDPP) was proposed to tackle the issues of limited capability and sample efficiency in various scenarios controlled by multiple agents. It alleviates the inconsistency of multiple agents' policy updates by introducing the relative entropy regularization to the Centralized Training with Decentralized Execution (CTDE) framework with the Actor-Critic (AC) structure. Evaluated by multi-agent cooperation and competition tasks and traditional control tasks including OpenAI benchmarks and robot arm manipulation, MACDPP demonstrates significant superiority in learning capability and sample efficiency compared with both related multi-agent and widely implemented signal-agent baselines and therefore expands the potential of MARL in effectively learning challenging control scenarios.",
  "Evaluated by multi-agent cooperation and competition tasks and traditional control tasks including OpenAI benchmarks and robot arm manipulation, MACDPP demonstrates significant superiority in learning capability and sample efficiency compared with both related multi-agent and widely implemented signal-agent baselines and therefore expands the potential of MARL in effectively learning challenging control scenarios.\nAuthors: Chenyang Miao, Yunduan Cui, Huiyun Li, Xin Wu\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Evaluated by multi-agent cooperation and competition tasks and traditional control tasks including OpenAI benchmarks and robot arm manipulation, MACDPP demonstrates significant superiority in learning capability and sample efficiency compared with both related multi- agent and widely implemented signal-agent baselines and therefore expands the potential of MARL in effectively learning challenging control scenarios.'}",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 1250676d646a9b48cf3bab66f13dc3c628ff68af\nTitle: 3D Open-vocabulary Segmentation with Foundation Models\nYear: 2023\nAbstract: Open-vocabulary segmentation of 3D scenes is a fundamental function of human perception and thus a crucial objective in computer vision research. However, this task is heavily impeded by the lack of large-scale and diverse 3D open-vocabulary segmentation datasets for training robust and generalizable models. Distilling knowledge from pre-trained 2D open-vocabulary segmentation models helps but it compromises the open-vocabulary feature significantly as the 2D models are mostly finetuned with close-vocabulary datasets. We tackle the challenges in 3D open-vocabulary segmentation by exploiting the open-vocabulary multimodal knowledge and object reasoning capability of pre-trained foundation models CLIP and DINO, without necessitating any fine-tuning. Specifically, we distill open-vocabulary visual and textual knowledge from CLIP into a neural radiance field (NeRF) which effectively lifts 2D features into view-consistent 3D segmentation.",
  "Specifically, we distill open-vocabulary visual and textual knowledge from CLIP into a neural radiance field (NeRF) which effectively lifts 2D features into view-consistent 3D segmentation. Furthermore, we introduce the Relevancy-Distribution Alignment loss and Feature-Distribution Alignment loss to respectively mitigate the ambiguities of CLIP features and distill precise object boundaries from DINO features, eliminating the need for segmentation annotations during training. Extensive experiments show that our method even outperforms fully supervised models trained with segmentation annotations, suggesting that 3D open-vocabulary segmentation can be effectively learned from 2D images and text-image pairs.",
  "Extensive experiments show that our method even outperforms fully supervised models trained with segmentation annotations, suggesting that 3D open-vocabulary segmentation can be effectively learned from 2D images and text-image pairs.\nAuthors: Kunhao Liu, Fangneng Zhan, Jiahui Zhang, Muyu Xu, Yingchen Yu, Abdulmotaleb El-Saddik, Christian Theobalt, Eric P. Xing, Shijian Lu\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work distill open-vocabulary visual and textual knowledge from CLIP into a neural radiance field (NeRF) which effectively lifts 2D features into view-consistent 3D segmentation, suggesting that 3D open- Vocabulary segmentation can be effectively learned from 2D images and text-image pairs.'}",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 1262758538525835d918007d15726794e19a07b7\nTitle: Squeeze, Recover and Relabel: Dataset Condensation at ImageNet Scale From A New Perspective\nYear: 2023\nAbstract: We present a new dataset condensation framework termed Squeeze, Recover and Relabel (SRe$^2$L) that decouples the bilevel optimization of model and synthetic data during training, to handle varying scales of datasets, model architectures and image resolutions for efficient dataset condensation. The proposed method demonstrates flexibility across diverse dataset scales and exhibits multiple advantages in terms of arbitrary resolutions of synthesized images, low training cost and memory consumption with high-resolution synthesis, and the ability to scale up to arbitrary evaluation network architectures. Extensive experiments are conducted on Tiny-ImageNet and full ImageNet-1K datasets. Under 50 IPC, our approach achieves the highest 42.5% and 60.8% validation accuracy on Tiny-ImageNet and ImageNet-1K, outperforming all previous state-of-the-art methods by margins of 14.5% and 32.9%, respectively.",
  "Under 50 IPC, our approach achieves the highest 42.5% and 60.8% validation accuracy on Tiny-ImageNet and ImageNet-1K, outperforming all previous state-of-the-art methods by margins of 14.5% and 32.9%, respectively. Our approach also surpasses MTT in terms of speed by approximately 52$\\times$ (ConvNet-4) and 16$\\times$ (ResNet-18) faster with less memory consumption of 11.6$\\times$ and 6.4$\\times$ during data synthesis. Our code and condensed datasets of 50, 200 IPC with 4K recovery budget are available at https://github.com/VILA-Lab/SRe2L.\nAuthors: Zeyuan Yin, Eric P. Xing, Zhiqiang Shen\nVenue: Neural Information Processing Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The proposed dataset condensation framework demonstrates flexibility across diverse dataset scales and exhibits multiple advantages in terms of arbitrary resolutions of synthesized images, low training cost and memory consumption with high-resolution synthesis, and the ability to scale up to arbitrary evaluation network architectures.'}",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 165e6111afcb14cf92b10d70cd1dad1c4aad4ada\nTitle: Convolutional Neural Network Measurement of Non-Fiducial Electrons Cosmic-Rays Using the DAMPE Experiment.\nYear: 2023\nAbstract: None\nAuthors: E. Putti-Garcia, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Zi-Yuan Chen, P. Coppin, M. Cui, T. Cui, Y. Cui, I. De Mitri, F. de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, J. Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang,",
  "de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, J. Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, Lu Jiang, Weizhong Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, Tao Ma, Xiao Ma, G. Marsella, M. N. Mazziotta,",
  "Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, Tao Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, Rui Qiao, J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, H. Su, Meng Su, H. Sun, Zhigang Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu,",
  "Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hong-yun Zhao, Xu Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: None",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 16b42fc85f4c073aa00c410cbdce965d7c6f8d4d\nTitle: One-for-All: Generalized LoRA for Parameter-Efficient Fine-tuning\nYear: 2023\nAbstract: We present Generalized LoRA (GLoRA), an advanced approach for universal parameter-efficient fine-tuning tasks. Enhancing Low-Rank Adaptation (LoRA), GLoRA employs a generalized prompt module to optimize pre-trained model weights and adjust intermediate activations, providing more flexibility and capability across diverse tasks and datasets. Moreover, GLoRA facilitates efficient parameter adaptation by employing a scalable, modular, layer-wise structure search that learns individual adapter of each layer. Originating from a unified mathematical formulation, GLoRA exhibits strong transfer learning, few-shot learning and domain generalization abilities, as it adapts to new tasks through not only weights but also additional dimensions like activations. Comprehensive experiments demonstrate that GLoRA outperforms all previous methods in natural, specialized, and structured vision benchmarks, achieving superior accuracy with fewer parameters and computations.",
  "Comprehensive experiments demonstrate that GLoRA outperforms all previous methods in natural, specialized, and structured vision benchmarks, achieving superior accuracy with fewer parameters and computations. The proposed method on LLaMA-1 and LLaMA-2 also show considerable enhancements compared to the original LoRA in the language domain. Furthermore, our structural re-parameterization design ensures that GLoRA incurs no extra inference cost, rendering it a practical solution for resource-limited applications. Code and models are available at: https://github.com/Arnav0400/ViT-Slim/tree/master/GLoRA.\nAuthors: Arnav Chavan, Zhuang Liu, D. Gupta, Eric P. Xing, Zhiqiang Shen\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Generalized LoRA is presented, an advanced approach for universal parameter-efficient fine-tuning tasks, which outperforms all previous methods in natural, specialized, and structured vision benchmarks, achieving superior accuracy with fewer parameters and computations.'}",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 19ce6aa0fd8a7b7decd836326e2e3fe8222bae22\nTitle: Visible and Infrared Image Fusion of Forest Fire Scenes Based on Generative Adversarial Networks with Multi-Classification and Multi-Level Constraints\nYear: 2023\nAbstract: Aimed at addressing deficiencies in existing image fusion methods, this paper proposed a multi-level and multi-classification generative adversarial network (GAN)-based method (MMGAN) for fusing visible and infrared images of forest fire scenes (the surroundings of firefighters), which solves the problem that GANs tend to ignore visible contrast ratio information and detailed infrared texture information. The study was based on real-time visible and infrared image data acquired by visible and infrared binocular cameras on forest firefighters\u2019 helmets. We improved the GAN by, on the one hand, splitting the input channels of the generator into gradient and contrast ratio paths, increasing the depth of convolutional layers, and improving the extraction capability of shallow networks.",
  "We improved the GAN by, on the one hand, splitting the input channels of the generator into gradient and contrast ratio paths, increasing the depth of convolutional layers, and improving the extraction capability of shallow networks. On the other hand, we designed a discriminator using a multi-classification constraint structure and trained it against the generator in a continuous and adversarial manner to supervise the generator, generating better-quality fused images. Our results indicated that compared to mainstream infrared and visible image fusion methods, including anisotropic diffusion fusion (ADF), guided filtering fusion (GFF), convolutional neural networks (CNN), FusionGAN, and dual-discriminator conditional GAN (DDcGAN), the MMGAN model was overall optimal and had the best visual effect when applied to image fusions of forest fire surroundings. Five of the six objective metrics were optimal, and one ranked second-to-optimal. The image fusion speed was more than five times faster than that of the other methods. The MMGAN model significantly improved the quality of fused images of forest fire scenes, preserved the contrast ratio information of visible images and the detailed texture information of infrared images of forest fire scenes, and could accurately reflect information on forest fire scene surroundings.",
  "The MMGAN model significantly improved the quality of fused images of forest fire scenes, preserved the contrast ratio information of visible images and the detailed texture information of infrared images of forest fire scenes, and could accurately reflect information on forest fire scene surroundings.\nAuthors: Qi Jin, Sanqing Tan, Gui Zhang, Zhi Yang, Yijun Wen, Huashun Xiao, Xin Wu\nVenue: Forests\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A multi-level and multi-classification generative adversarial network (GAN)-based method for fusing visible and infrared images of forest fire scenes (the surroundings of firefighters), which solves the problem that GANs tend to ignore visible contrast ratio information and detailed infrared texture information.'}",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 1d54cbcb331af0f618c4f9537b1164061727007d\nTitle: The split delivery vehicle routing problem with time windows and three-dimensional loading constraints\nYear: 2023\nAbstract: None\nAuthors: Miao Yan, L. Chu, Xin Wu\nVenue: Journal of Industrial and Management Optimization\nTldr: None",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 1db4a8f3c35ae1d2e8f7029abf67f37b0030ea2a\nTitle: Defending Against Malicious Behaviors in Federated Learning with Blockchain\nYear: 2023\nAbstract: In the era of deep learning, federated learning (FL) presents a promising approach that allows multi-institutional data owners, or clients, to collaboratively train machine learning models without compromising data privacy. However, most existing FL approaches rely on a centralized server for global model aggregation, leading to a single point of failure. This makes the system vulnerable to malicious attacks when dealing with dishonest clients. In this work, we address this problem by proposing a secure and reliable FL system based on blockchain and distributed ledger technology. Our system incorporates a peer-to-peer voting mechanism and a reward-and-slash mechanism, which are powered by on-chain smart contracts, to detect and deter malicious behaviors. Both theoretical and empirical analyses are presented to demonstrate the effectiveness of the proposed approach, showing that our framework is robust against malicious client-side behaviors.",
  "Our system incorporates a peer-to-peer voting mechanism and a reward-and-slash mechanism, which are powered by on-chain smart contracts, to detect and deter malicious behaviors. Both theoretical and empirical analyses are presented to demonstrate the effectiveness of the proposed approach, showing that our framework is robust against malicious client-side behaviors.\nAuthors: Nanqing Dong, Zhipeng Wang, Jiahao Sun, Michael C. Kampffmeyer, Yizhe Wen, Shuoying Zhang, W. Knottenbelt, Eric P. Xing\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes a secure and reliable FL system based on blockchain and distributed ledger technology that incorporates a peer-to-peer voting mechanism and a reward-and-slash mechanism, which are powered by on-chain smart contracts, to detect and deter malicious behaviors.'}",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 21aecd6ba669c18397295fd63e312c010c2eeca3\nTitle: A Novel Definition of Fuzzy Difference on Non-increasing Fuzzy Real Numbers\nYear: 2023\nAbstract: In this paper, firstly, a novel definition of a fuzzy difference based on non-increasing fuzzy real numbers is introduced, which is different from the previous definitions by using fuzzy interval-numbers and Zadeh\u2019s extension principle. Then we give some important conclusions of fuzzy difference from the view of two cuts of fuzzy sets. Moreover, a definition of a opposite fuzzy real number is given so that we show the connection between the fuzzy difference and fuzzy addition on fuzzy real numbers. Finally, we provide several examples for the sake of illustrating the fuzzy difference on non-increasing fuzzy real numbers is reasonable generalization of classical difference. In addition, we give the prospect that we want to use this difference to research fuzzy derivatives.\nAuthors: Xin Wu, Yun Zhang, Shuang Lin, Yu Zhong\nVenue: Journal of Physics: Conference Series\nTldr: {'model': 'tldr@v2.0.0', 'text': None}",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 274b363f94a741f38cad95f1ab68edaadf6fc0d9\nTitle: Analysis of Individual Cosmic-Ray Proton and Helium Fluxes towards PeV Energies with DAMPE\nYear: 2023\nAbstract: The DArk Matter Particle Explorer (DAMPE) is a satellite-borne experiment, in operation since 2015, aimed at studying cosmic rays and high-energy gamma rays. Proton and helium are the first-and second-most abundant components in cosmic rays. Given their smaller interaction cross sections with the interstellar medium, compared to heavier nuclei, they can travel larger distances, thereby becoming important probes to cosmic-ray sources as well as acceleration and propagation mechanisms. Recently, in the DAMPE collaboration, machine learning (ML) techniques were developed and deployed to improve particle tracking and identification and correct for the calorimeter readout saturation at high energies. This work presents a direct measurement of the energy spectra of cosmic-ray protons and helium nuclei, using 84 and 81 months of data, respectively, recorded by DAMPE.",
  "This work presents a direct measurement of the energy spectra of cosmic-ray protons and helium nuclei, using 84 and 81 months of data, respectively, recorded by DAMPE. Application of the above-mentioned ML techniques helps in extending the spectra to higher kinetic energies than those previously reported by DAMPE\nAuthors: A. Ruina, P. Coppin, A. Kotenko, Pengxiong Ma, M. Stolpovskiy, A. Tykhonov, C. Yue, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, F. de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R.",
  "Yu-Xin Cui, I. De Mitri, F. de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, Luyang Jiang, Wei Jiang, Y. Jiang, J. Kong, D. Kyratzis, S. Lei, W. Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, T. Ma, Xiao Ma, G. Marsella, M.",
  "Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, Z. Shangguan, E. Xu, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, H. Su, Meng Su, H. Sun, Zhigang Sun, A. Surdo, X. Teng, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu, Zunlei Xu, G.",
  "Ying Wang, Y. Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hongying Zhao, Xu Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: None",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 279aeb0ffdaec08391f6a50695e2b01d6a148b7e\nTitle: The First LHAASO Catalog of Gamma-Ray Sources\nYear: 2023\nAbstract: \n We present the first catalog of very-high-energy and ultra-high-energy gamma-ray sources detected by the Large High Altitude Air Shower Observatory. The catalog was compiled using 508 days of data collected by the Water Cherenkov Detector Array from 2021 March to 2022 September and 933 days of data recorded by the Kilometer Squared Array from 2020 January to 2022 September. This catalog represents the main result from the most sensitive large coverage gamma-ray survey of the sky above 1 TeV, covering decl. from \u221220\u00b0 to 80\u00b0. In total, the catalog contains 90 sources with an extended size smaller than 2\u00b0 and a significance of detection at >5\u03c3. Based on our source association criteria, 32 new TeV sources are proposed in this study.",
  "from \u221220\u00b0 to 80\u00b0. In total, the catalog contains 90 sources with an extended size smaller than 2\u00b0 and a significance of detection at >5\u03c3. Based on our source association criteria, 32 new TeV sources are proposed in this study. Among the 90 sources, 43 sources are detected with ultra-high energy (E > 100 TeV) emission at >4\u03c3 significance level. We provide the position, extension, and spectral characteristics of all the sources in this catalog.\nAuthors: Z. Cao, F. Aharonian, Q. An, Axikegu, Y. Bai, Y. Bao, D. Bastieri, X. Bi, Y. Bi, J. Cai, Q. Cao, W. Cao, Z. Cao, J. Chang, J. Chang, A. Chen, E. Chen, Liang Chen, Lin Chen, Long Chen, M. Chen, M. Chen, Q. Chen, S. Chen, S. Z. Chen, T. Chen, Y. Chen, N. Cheng, Y. Cheng, M. Cui, S. Cui, X. Cui, Y. Cui,",
  "Lin Chen, Long Chen, M. Chen, M. Chen, Q. Chen, S. Chen, S. Z. Chen, T. Chen, Y. Chen, N. Cheng, Y. Cheng, M. Cui, S. Cui, X. Cui, Y. Cui, B. Dai, H. Dai, Z. Dai, Danzengluobu, D. Volpe, X. Dong, K. Duan, J. Fan, Y. Z. Fan, J. Fang, K. Fang, C. Feng, L. Feng, S. Feng, X. Feng, Y. Feng, S. Gabici, B. Gao, C. Gao, L. Gao, Q. Gao, W. Gao, W. Gao, M. Ge, L. Geng, G. Giacinti, G. Gong, Q. Gou, M. Gu, F. Guo, X. Guo, Y. Guo, Y. Guo, Y. Han, H. He, Haoyu He, J. Y. He, X. He, Y. He, M. Heller, Y. Hor, B.",
  "Gou, M. Gu, F. Guo, X. Guo, Y. Guo, Y. Guo, Y. Han, H. He, Haoyu He, J. Y. He, X. He, Y. He, M. Heller, Y. Hor, B. Hou, C. Hou, X. Hou, H. Hu, Q. Hu, S. Hu, D. Huang, T. Q. Huang, W. Huang, X. Huang, X. Y. Huang, Y. Huang, Z. Huang, X. Ji, H. Jia, K. Jia, K. Jiang, X. W. Jiang, Z. Jiang, M. Jin, M. Kang, T. Ke, D. Kuleshov, K. Kurinov, B. Li, Cheng Li, Cong Li, D. Li, F. Li, H. B. Li, H. C. Li, H. Li, J. Li, Jian Li, Jie Li, K. Li, W. Li, X. Li, Xin Li, Y. Li, Zhe Li, Zhuo Li, E. Liang, Y. Liang, S.",
  "B. Li, H. C. Li, H. Li, J. Li, Jian Li, Jie Li, K. Li, W. Li, X. Li, Xin Li, Y. Li, Zhe Li, Zhuo Li, E. Liang, Y. Liang, S. Lin, B. Liu, C. Liu, D. Liu, H. Liu, H. Liu, J. Liu, J. Liu, J. Liu, M. Y. Liu, R. Liu, S. M. Liu, W. Liu, Y. Liu, Y. N. Liu, R. Lu, Q. Luo, H. Lv, B. Ma, L. Ma, X. Ma, J. Mao, Z. Min, W. Mitthumsiri, H. Mu, Y. Nan, A. Neronov, Z. Ou, B. Pang, P. Pattarakijwanich, Z. Pei, M. Qi, Y. Qi, B. Qiao, J. Qin, D. Ruffolo, A. S'aiz, D. Semikoz, C. Shao, L. Shao, O. Shchegolev,",
  "Pattarakijwanich, Z. Pei, M. Qi, Y. Qi, B. Qiao, J. Qin, D. Ruffolo, A. S'aiz, D. Semikoz, C. Shao, L. Shao, O. Shchegolev, X. Sheng, F. Shu, H. Song, Y. Stenkin, V. Stepanov, Y. Su, Q. Sun, X. Sun, Z. Sun, P. Tam, Q. Tang, Z. Tang, W. Tian, C. Wang, C. Wang, G. W. Wang, H. Wang, H. H. Wang, J. C. Wang, K. Wang, L. Wang, L. Y. Wang, P. Wang, R. Wang, W. Wang, X. G. Wang, X. Y. Wang, Y. Wang, Y. Wang, Y. J. Wang, Z. H. Wang, Z. X. Wang, Zhen Wang, Z. Wang, D. Wei, J. Wei, Y. J. Wei, T. Wen, C. Y. Wu, H. Wu, S. Wu,",
  "Wang, Y. Wang, Y. J. Wang, Z. H. Wang, Z. X. Wang, Zhen Wang, Z. Wang, D. Wei, J. Wei, Y. J. Wei, T. Wen, C. Y. Wu, H. Wu, S. Wu, Xin Wu, Y. Wu, S. Xi, J. Xia, J. Xia, G. Xiang, D. Xiao, G. Xiao, G. Xin, Y. Xin, Yangang Xing, Z. Xiong, D. Xu, R. Xu, R. Xu, W. Xu, L. Xue, D. Yan, J. Yan, T. Yan, C. Yang, F. Yang, F. Yang, H. W. Yang, J. Y. Yang, L. L. Yang, M. Yang, R. Yang, S. Yang, Y. Yao, Z. Yao, Y. Ye, L. Yin, N. Yin, X. You, Z. You, Y. Yu, Q. Yuan, H. Yue, H. Zeng, T. Zeng, W. Zeng, M. Zha, B. Zhang, F.",
  "Yao, Z. Yao, Y. Ye, L. Yin, N. Yin, X. You, Z. You, Y. Yu, Q. Yuan, H. Yue, H. Zeng, T. Zeng, W. Zeng, M. Zha, B. Zhang, F. Zhang, H. Zhang, H. Zhang, J. Zhang, L. X. Zhang, Li Zhang, P. Zhang, P. Zhang, R. Zhang, S. B. Zhang, S. Zhang, S. Zhang, X. Zhang, X. Zhang, Y. Zhang, Yi. Zhang, Yong Zhang, B. Zhao, J. Zhao, Liang Zhao, L. Zhao, S. Zhao, F. Zheng, B. Zhou, H. Zhou, J. Zhou, M. Zhou, P. Zhou, R. Zhou, X. Zhou, C. Zhu, F. Zhu, H. Zhu, K. Zhu, X. Zuo\nVenue: Astrophysical Journal Supplement Series\nTldr: None",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 28378edeeca3aafb81b7a07454fcf41146736a3e\nTitle: Machine Learning for Predicting Forest Fire Occurrence in Changsha: An Innovative Investigation into the Introduction of a Forest Fuel Factor\nYear: 2023\nAbstract: Affected by global warming and increased extreme weather, Hunan Province saw a phased and concentrated outbreak of forest fires in 2022, causing significant damage and impact. Predicting the occurrence of forest fires can enhance the ability to make early predictions and strengthen early warning and responses. Currently, fire prevention and extinguishing in China\u2019s forests and grasslands face severe challenges due to the overlapping of natural and social factors. Existing forest fire occurrence prediction models mostly take into account vegetation, topographic, meteorological and human activity factors; however, the occurrence of forest fires is closely related to the forest fuel moisture content.",
  "Existing forest fire occurrence prediction models mostly take into account vegetation, topographic, meteorological and human activity factors; however, the occurrence of forest fires is closely related to the forest fuel moisture content. In this study, the traditional driving factors of forest fire such as satellite hotspots, vegetation, meteorology, topography and human activities from 2004 to 2021 were introduced along with forest fuel factors (vegetation canopy water content and evapotranspiration from the top of the vegetation canopy), and a database of factors for predicting forest fire occurrence was constructed. And a forest fire occurrence prediction model was built using machine learning methods such as the Random Forest model (RF), the Gradient Boosting Decision Tree model (GBDT) and the Adaptive Augmentation Model (AdaBoost). The accuracy of the models was verified using Area Under Curve (AUC) and four other metrics. The RF model with an AUC value of 0.981 was more accurate than all other models in predicting the probability of forest fire occurrence, followed by the GBDT (AUC = 0.978) and AdaBoost (AUC = 0.891) models.",
  "The RF model with an AUC value of 0.981 was more accurate than all other models in predicting the probability of forest fire occurrence, followed by the GBDT (AUC = 0.978) and AdaBoost (AUC = 0.891) models. The RF model, which has the best accuracy, was selected to predict the monthly forest fire probability in Changsha in 2022 and combined with the Inverse Distance Weight Interpolation method to plot the monthly forest fire probability in Changsha. We found that the monthly spatial and temporal distribution of forest fire probability in Changsha varied significantly, with March, April, May, September, October, November and December being the months with higher forest fire probability. The highest probability of forest fires occurred in the central and northern regions. In this study, the core drivers affecting the occurrence of forest fires in Changsha City were found to be vegetation canopy evapotranspiration and vegetation canopy water content. The RF model was identified as a more suitable forest fire occurrence probability prediction model for Changsha City.",
  "In this study, the core drivers affecting the occurrence of forest fires in Changsha City were found to be vegetation canopy evapotranspiration and vegetation canopy water content. The RF model was identified as a more suitable forest fire occurrence probability prediction model for Changsha City. Meanwhile, this study found that vegetation characteristics and combustible factors have more influence on forest fire occurrence in Changsha City than meteorological factors, and surface temperature has less influence on forest fire occurrence in Changsha City.\nAuthors: Xin Wu, Gui Zhang, Zhi Yang, Sanqing Tan, Yongke Yang, Ziheng Pang\nVenue: Remote Sensing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It was found that vegetation characteristics and combustible factors have more influence on forest fire occurrence in Changsha City than meteorological factors, and surface temperature has less influence on tree canopy evapotranspiration and vegetation canopy water content.'}",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 3970960ccc1a73da4257cf5580665eaae1a15edb\nTitle: ViT-Based Terrain Recognition System for wearable soft exosuit\nYear: 2023\nAbstract: None\nAuthors: Fangliang Yang, Chunjie Chen, Zhuo Wang, Hui Chen, Yao Liu, Gang Li, Xin Wu\nVenue: Biomimetic Intelligence and Robotics\nTldr: None",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 39bb5d44735c07b1e1f4341a2d4bc8d5e783f491\nTitle: SlimPajama-DC: Understanding Data Combinations for LLM Training\nYear: 2023\nAbstract: This paper aims to understand the impacts of various data combinations (e.g., web text, wikipedia, github, books) on the training of large language models using SlimPajama. SlimPajama is a rigorously deduplicated, multi-source dataset, which has been refined and further deduplicated to 627B tokens from the extensive 1.2T tokens RedPajama dataset contributed by Together. We've termed our research as SlimPajama-DC, an empirical analysis designed to uncover fundamental characteristics and best practices associated with employing SlimPajama in the training of large language models. During our research with SlimPajama, two pivotal observations emerged: (1) Global deduplication vs. local deduplication.",
  "During our research with SlimPajama, two pivotal observations emerged: (1) Global deduplication vs. local deduplication. We analyze and discuss how global (across different sources of datasets) and local (within the single source of dataset) deduplications affect the performance of trained models. (2) Proportions of high-quality/highly-deduplicated multi-source datasets in the combination. To study this, we construct six configurations of SlimPajama dataset and train individual ones using 1.3B Cerebras-GPT model with Alibi and SwiGLU. Our best configuration outperforms the 1.3B model trained on RedPajama using the same number of training tokens by a significant margin. All our 1.3B models are trained on Cerebras 16$\\times$ CS-2 cluster with a total of 80 PFLOP/s in bf16 mixed precision. We further extend our discoveries (such as increasing data diversity is crucial after global deduplication) on a 7B model with large batch-size training.",
  "We further extend our discoveries (such as increasing data diversity is crucial after global deduplication) on a 7B model with large batch-size training. Our models and the separate SlimPajama-DC datasets are available at: https://huggingface.co/MBZUAI-LLM and https://huggingface.co/datasets/cerebras/SlimPajama-627B.\nAuthors: Zhiqiang Shen, Tianhua Tao, Liqun Ma, W. Neiswanger, Zhengzhong Liu, Hongyi Wang, Bowen Tan, Joel Hestness, Natalia Vassilieva, Daria Soboleva, Eric P. Xing\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper aims to understand the impacts of various data combinations on the training of large language models using SlimPajama, a rigorously deduplicated, multi-source dataset, and analyzes and discusses how global and local dedUplications affect the performance of trained models.'}",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 3dc80cea6704a2bc1d714e3bbd502846f3498743\nTitle: Carbon Flux with DAMPE Using Machine Learning Methods\nYear: 2023\nAbstract: DAMPE space-borne cosmic ray experiment has been collecting data since December 2015. Many high-impact results on the ion, electron and photon fluxes were obtained. This submission presents the carbon flux analysis with DAMPE using machine learning techniques. The readout electronics would saturate at energy deposits above several TeV in a single BGO bar of the DAMPE calorimeter. The total energy loss per event due to saturation can sometimes reach over a hundred TeV. We present a convolutional neural network model which can accurately recover the energy lost due to saturation and thus significantly increase the dynamic range of DAMPE. Another machine learning model combines the resolution of the hodoscopic BGO calorimeter and the high-resolution tracker of DAMPE to provide the best possible prediction of the direction of the incoming particle. This allows measuring charges at energies up to several hundred TeV.",
  "Another machine learning model combines the resolution of the hodoscopic BGO calorimeter and the high-resolution tracker of DAMPE to provide the best possible prediction of the direction of the incoming particle. This allows measuring charges at energies up to several hundred TeV. In this work, we present the application of these methods to carbon flux analysis.\nAuthors: M. Stolpovskiy, Francesco Alemanno, C. Altomare, Qi An, P. Azzarello, F. Barbato, P. Bernardini, Xiaomei Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Yunqiang Cui, I. De Mitri, Francesco de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang,",
  "Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, Piergiorgio Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guangshun Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, Luyang Jiang, Weizhong Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, Tao Ma, Xiao Ma, G. Marsella, M. N.",
  "X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, Tao Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, H. Su, Meng Su, H. Sun, Zhiyu Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Yuanzhu Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu,",
  "X. Wang, Y. Wang, Ying Wang, Yuanzhu Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zizhong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hong-yun Zhao, Xu Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A convolutional neural network model is presented which can accurately recover the energy lost due to saturation and thus significantly increase the dynamic range of DAMPE.'}",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 3ecea2ef252d44745caf04860f4ca2983d427f30\nTitle: Acupuncture Alleviates CUMS-Induced Depression-Like Behaviors by Restoring Prefrontal Cortex Neuroplasticity\nYear: 2023\nAbstract: Purpose To explore the therapeutic efficiency of acupuncture and the related molecular mechanism of neural plasticity in depression. Methods Chronic unpredictable mild stress- (CUMS-) induced rats were established for the depression animal model. There were a total of four rat groups, including the control group, the CUMS group, the CUMS+acupuncture group, and the CUMS+fluoxetine group. The acupuncture group and the fluoxetine group were given a 3-week treatment after the modeling intervention. The researcher performed the open-field, elevated plus maze, and sucrose preference tests to evaluate depressive behaviors. The number of nerve cells, dendrites' length, and the prefrontal cortex's spine density were detected using Golgi staining.",
  "The researcher performed the open-field, elevated plus maze, and sucrose preference tests to evaluate depressive behaviors. The number of nerve cells, dendrites' length, and the prefrontal cortex's spine density were detected using Golgi staining. The prefrontal cortex expression, such as BDNF, PSD95, SYN, and PKMZ protein, was detected using the western blot and RT-PCR. Results Acupuncture could alleviate depressive-like behaviors and promote the recovery of the neural plasticity functions in the prefrontal cortex, showing the increasing cell numbers, prolonging the length of the dendrites, and enhancing the spine density. The neural plasticity-related proteins in the prefrontal cortex, including BDNF, PSD95, SYN, and PKMZ, were all downregulated in the CUMS-induced group; however, these effects could be partly reversed after being treated by acupuncture and fluoxetine (P < 0.05). Conclusion Acupuncture can ameliorate depressive-like behaviors by promoting the recovery of neural plasticity functions and neural plasticity-related protein upregulation in the prefrontal cortex of CUMS-induced depressed rats.",
  "Conclusion Acupuncture can ameliorate depressive-like behaviors by promoting the recovery of neural plasticity functions and neural plasticity-related protein upregulation in the prefrontal cortex of CUMS-induced depressed rats. Our study provides new insights into the antidepressant approach, and further studies are warranted to elucidate the mechanisms of acupuncture involved in depression treatment.\nAuthors: Peng Li, Wenya Huang, Yi-ping Chen, M. Aslam, Wen-jing Cheng, Yang Huang, Wenjie Chen, Yanxun Huang, Xin Wu, Yining Yan, Junliang Shen, Tao Tong, Shuqiong Huang, Xianjun Meng\nVenue: Journal of Neural Transplantation and Plasticity\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This study provides new insights into the antidepressant approach, and further studies are warranted to elucidate the mechanisms of acupuncture involved in depression treatment.'}",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 3ed28c3ee6f1d7645fa46b7353f1475a3122a6c4\nTitle: Influence of sensor array on MS/AE source location accuracy in rock mass\nYear: 2023\nAbstract: None\nAuthors: Lin-qi Huang, Xin Wu, Xi-bing Li, Shao-feng Wang\nVenue: Transactions of Nonferrous Metals Society of China\nTldr: None",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 44772fe1c3fa422a3da7e25092db2544893d6bfb\nTitle: Improved Logical Reasoning of Language Models via Differentiable Symbolic Programming\nYear: 2023\nAbstract: Pre-trained large language models (LMs) struggle to perform logical reasoning reliably despite advances in scale and compositionality. In this work, we tackle this challenge through the lens of symbolic programming. We propose DSR-LM, a Differentiable Symbolic Reasoning framework where pre-trained LMs govern the perception of factual knowledge, and a symbolic module performs deductive reasoning. In contrast to works that rely on hand-crafted logic rules, our differentiable symbolic reasoning framework efficiently learns weighted rules and applies semantic loss to further improve LMs. DSR-LM is scalable, interpretable, and allows easy integration of prior knowledge, thereby supporting extensive symbolic programming to robustly derive a logical conclusion. The results of our experiments suggest that DSR-LM improves the logical reasoning abilities of pre-trained language models, resulting in a significant increase in accuracy of over 20% on deductive reasoning benchmarks.",
  "The results of our experiments suggest that DSR-LM improves the logical reasoning abilities of pre-trained language models, resulting in a significant increase in accuracy of over 20% on deductive reasoning benchmarks. Furthermore, DSR-LM outperforms a variety of competitive baselines when faced with systematic changes in sequence length.\nAuthors: Hanlin Zhang, Jiani Huang, Ziyang Li, M. Naik, Eric P. Xing\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'DSR-LM is proposed, a Differentiable Symbolic Reasoning framework where pre-trained LMs govern the perception of factual knowledge, and a symbolic module performs deductive reasoning, and efficiently learns weighted rules and applies semantic loss to further improve LMs.'}",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 44a8056e5be87941c574b92b0c07193662c0c5c0\nTitle: Gpr35 shapes gut microbial ecology to modulate hepatic steatosis.\nYear: 2023\nAbstract: None\nAuthors: Xin Wu, Shuobing Chen, Qingyuan Yan, Feng Yu, Hua Shao, Xiao Zheng, Xueli Zhang\nVenue: Pharmacological Research\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work identifies G protein-coupled receptor 35 (Gpr35) as a regulator of gut microbial ecology and the susceptibility to obesity and hepatic steatosis in mice and provides mechanistic insights into a genetic-diet-microbe interplay that dictates susceptibility to metabolic disorder.'}",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 484206a2d2fabaf267e3fcf99bd04b124e9bc64d\nTitle: An innovative divertor concept, the fish tail divertor, for reducing the surface temperature on the divertor target plate in EAST tokamak experiments\nYear: 2023\nAbstract: An innovative divertor concept, the fish tail divertor, is proposed in this paper, aimed at reducing the surface temperature on the tokamak divertor plate as well as that due to the edge localized modes. This new concept has been implemented in experiments to demonstrate its capability of strike point sweeping on the plate at a frequency range from 10 to 100 Hz by using an oscillating magnetic field. A strike point movement of 5\u20136 cm is achieved by applying a coil current of several percent of plasma current, leading to a significant reduction of divertor surface temperature. The result indicates a possible application in a fusion reactor.",
  "A strike point movement of 5\u20136 cm is achieved by applying a coil current of several percent of plasma current, leading to a significant reduction of divertor surface temperature. The result indicates a possible application in a fusion reactor.\nAuthors: Yang Zhang, Xiaodong Zhang, Q. Qiu, Jian Zhang, B. Li, Lei Chen, Zheng-ping Luo, J. Qian, Liang Wang, Haiqing Liu, L. Meng, Xianghang Liu, Bin Zhang, B. Shen, Q. Yuan, B. Xiao, X. Gong, G. Xu, Jiansheng Hu, K. Lu, Xin Wu, Yuntao Song\nVenue: Nuclear Fusion\nTldr: None",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 48d3d400d7aced1caf1dcace33f37b8df50735f7\nTitle: Special issue on wearable robots and intelligent device\nYear: 2023\nAbstract: None\nAuthors: Xin Wu, S. Bai, L. O\u2019Sullivan\nVenue: Biomimetic Intelligence and Robotics\nTldr: None",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 53a8712c48ddcd2bf1af30f9235f42b372f66980\nTitle: The response linearity of energy measurement up to TeV in the DAMPE experiment\nYear: 2023\nAbstract: The DArk Matter Particle Explorer (DAMPE) space mission is designed to measure cosmic rays and gamma rays. The key sub-detector of DAMPE is the Bismuth Germanium Oxide (BGO) Electromagnetic CALorimeter (ECAL), which measures the energies of electrons/gamma-rays ranging from 5 GeV - 10 TeV. A laser test carried out to study the response of the BGO ECAL to up to \u223c TeV energy deposition revealed that the BGO \ufb02uorescence response retains linearity at laser energy deposition densities higher than that induced by a \u223c 10 TeV electromagnetic shower. The energy measurements obtained from on-orbit data were also compared with Monte Carlo simulation results. The present study con\ufb01rms that there is no \ufb02uorescence quenching e\ufb00ect in the DAMPE BGO ECAL.",
  "The energy measurements obtained from on-orbit data were also compared with Monte Carlo simulation results. The present study con\ufb01rms that there is no \ufb02uorescence quenching e\ufb00ect in the DAMPE BGO ECAL.\nAuthors: Cong-Ying Zhao, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, Francesco de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, J. Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco,",
  "G. Donvito, D. Droz, J. Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, L. Jiang, Weizhong Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X.",
  "F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, H. Su, Meng Su, H. Sun, Zhigang Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zizhong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang,",
  "Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zizhong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Hongying Zhao, Xu Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: None",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 5c577988ccebfea96de86678d04fd94fad367d2e\nTitle: Jais and Jais-chat: Arabic-Centric Foundation and Instruction-Tuned Open Generative Large Language Models\nYear: 2023\nAbstract: We introduce Jais and Jais-chat, new state-of-the-art Arabic-centric foundation and instruction-tuned open generative large language models (LLMs). The models are based on the GPT-3 decoder-only architecture and are pretrained on a mixture of Arabic and English texts, including source code in various programming languages. With 13 billion parameters, they demonstrate better knowledge and reasoning capabilities in Arabic than any existing open Arabic and multilingual models by a sizable margin, based on extensive evaluation. Moreover, the models are competitive in English compared to English-centric open models of similar size, despite being trained on much less English data. We provide a detailed description of the training, the tuning, the safety alignment, and the evaluation of the models.",
  "Moreover, the models are competitive in English compared to English-centric open models of similar size, despite being trained on much less English data. We provide a detailed description of the training, the tuning, the safety alignment, and the evaluation of the models. We release two open versions of the model -- the foundation Jais model, and an instruction-tuned Jais-chat variant -- with the aim of promoting research on Arabic LLMs.",
  "We provide a detailed description of the training, the tuning, the safety alignment, and the evaluation of the models. We release two open versions of the model -- the foundation Jais model, and an instruction-tuned Jais-chat variant -- with the aim of promoting research on Arabic LLMs. Available at https://huggingface.co/inception-mbzuai/jais-13b-chat\nAuthors: Neha Sengupta, Sunil Kumar Sahu, Bokang Jia, Satheesh Katipomu, Haonan Li, Fajri Koto, Osama Mohammed Afzal, Samta Kamboj, O. Pandit, Rahul Pal, Lalit Pradhan, Zainul Mujahid, Massa Baali, Xudong Han, Alham Fikri Aji, Zhengzhong Liu, Andy Hock, Andrew Feldman, Jonathan Lee, A. Jackson, Preslav Nakov, Timothy Baldwin, Eric P. Xing\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Jais and Jais-chat are introduced, new state-of-the-art Arabic-centric foundation and instruction-tuned open generative large language models (LLMs) based on the GPT-3 decoder-only architecture that demonstrate better knowledge and reasoning capabilities in Arabic than any existing open Arabic and multilingual models by a sizable margin.'}",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 5d17963ceb279be116e7a1207542ea94f1b2a8c8\nTitle: Contextualized Policy Recovery: Modeling and Interpreting Medical Decisions with Adaptive Imitation Learning\nYear: 2023\nAbstract: Interpretable policy learning seeks to estimate intelligible decision policies from observed actions; however, existing models fall short by forcing a tradeoff between accuracy and interpretability. This tradeoff limits data-driven interpretations of human decision-making process. e.g. to audit medical decisions for biases and suboptimal practices, we require models of decision processes which provide concise descriptions of complex behaviors. Fundamentally, existing approaches are burdened by this tradeoff because they represent the underlying decision process as a universal policy, when in fact human decisions are dynamic and can change drastically with contextual information. Thus, we propose Contextualized Policy Recovery (CPR), which re-frames the problem of modeling complex decision processes as a multi-task learning problem in which complex decision policies are comprised of context-specific policies.",
  "Thus, we propose Contextualized Policy Recovery (CPR), which re-frames the problem of modeling complex decision processes as a multi-task learning problem in which complex decision policies are comprised of context-specific policies. CPR models each context-specific policy as a linear observation-to-action mapping, and generates new decision models $\\textit{on-demand}$ as contexts are updated with new observations. CPR is compatible with fully offline and partially observable decision environments, and can be tailored to incorporate any recurrent black-box model or interpretable decision model. We assess CPR through studies on simulated and real data, achieving state-of-the-art performance on the canonical tasks of predicting antibiotic prescription in intensive care units ($+22\\%$ AUROC vs. previous SOTA) and predicting MRI prescription for Alzheimer's patients ($+7.7\\%$ AUROC vs. previous SOTA). With this improvement in predictive performance, CPR closes the accuracy gap between interpretable and black-box methods for policy learning, allowing high-resolution exploration and analysis of context-specific decision models.",
  "previous SOTA). With this improvement in predictive performance, CPR closes the accuracy gap between interpretable and black-box methods for policy learning, allowing high-resolution exploration and analysis of context-specific decision models.\nAuthors: J. Deuschel, Caleb N. Ellington, Benjamin J. Lengerich, Yingtao Luo, Pascal Friederich, Eric P. Xing\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Contextualized Policy Recovery is proposed, which re-frames the problem of modeling complex decision processes as a multi-task learning problem in which complex decision policies are comprised of context-specific policies, and closes the accuracy gap between interpretable and black-box methods for policy learning.'}",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 5db910c3ccf8a8b2cbea22d65cc56268c57a64df\nTitle: Characterization of Asphaltene Deposition Behavior in Diluted Heavy Oil under High-Pressure Conditions\nYear: 2023\nAbstract: Some oil wells in the Tahe oilfield have been reported to produce extremely heavy oil due to asphaltene deposition. To enhance the flow of crude oil through the wellbore, engineers adopted the use of light oil from nearby wells to dissolve the heavy crude in the wells\u2019 sections to maximize recovery from the Tahe oilfield. However, this mixing has led to the problem of accelerated asphaltene deposition, which often blocks the wellbore in the process. In this research, the factors that influence the stability of diluted heavy oil, temperature, and mixing ratio on asphaltene deposition characteristics under high pressure are studied using a high-temperature and high-pressure crude oil flow property experimental device based on the differential pressure method. The results under high pressure show that the initial deposition pressure of asphaltene decreases as the experimental temperature increases.",
  "The results under high pressure show that the initial deposition pressure of asphaltene decreases as the experimental temperature increases. With an increase in the mixing light oil ratio, the initial deposition pressure of diluted heavy oil increases, and the deposition trend of asphaltene strengthens. The asphaltene accumulation and deposition will be aggravated by filling quartz sand and pipe diameter changes. The research here is helpful to understand the deposition characteristics of asphaltene during the production of diluted heavy oil. It offers significant guidance in the prevention and control of asphaltene precipitation in heavy oil wells.\nAuthors: Zuguo Yang, Xin Wu, Jixiang Guo, Jianjun Zhang, R. Xiong, Lei Liu, Wyclif Kiyingi\nVenue: Energies\nTldr: None",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 5e424004958853f4e366e7a86a1c3a56a76cb2a4\nTitle: LightSeq: Sequence Level Parallelism for Distributed Training of Long Context Transformers\nYear: 2023\nAbstract: Increasing the context length of large language models (LLMs) unlocks fundamentally new capabilities, but also significantly increases the memory footprints of training. Previous model-parallel systems such as Megatron-LM partition and compute different attention heads in parallel, resulting in large communication volumes, so they cannot scale beyond the number of attention heads, thereby hindering its adoption. In this paper, we introduce a new approach, LightSeq, for long-context LLMs training. LightSeq has many notable advantages. First, LightSeq partitions over the sequence dimension, hence is agnostic to model architectures and readily applicable for models with varying numbers of attention heads, such as Multi-Head, Multi-Query and Grouped-Query attention. Second, LightSeq not only requires up to 4.7x less communication than Megatron-LM on popular LLMs but also overlaps the communication with computation.",
  "Second, LightSeq not only requires up to 4.7x less communication than Megatron-LM on popular LLMs but also overlaps the communication with computation. To further reduce the training time, LightSeq features a novel gradient checkpointing scheme to bypass an forward computation for memory-efficient attention. We evaluate LightSeq on Llama-7B and its variants with sequence lengths from 32K to 512K. Through comprehensive experiments on single and cross-node training, we show that LightSeq achieves up to 1.24-2.01x end-to-end speedup, and a 2-8x longer sequence length on models with fewer heads, compared to Megatron-LM. Codes will be available at https://github.com/RulinShao/LightSeq.",
  "Codes will be available at https://github.com/RulinShao/LightSeq.\nAuthors: Dacheng Li, Rulin Shao, Anze Xie, Eric P. Xing, Joseph E. Gonzalez, Ion Stoica, Xuezhe Ma, Hao Zhang\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A new approach, LightSeq, is introduced for long-context LLMs training that partitions over the sequence dimension, hence is agnostic to model architectures and readily applicable for models with varying numbers of attention heads, such as Multi-Head, Multi-Query and Grouped-Query attention.'}",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 5eceb4d435f1eb86d9b211ffc1f76c87f79aa2c8\nTitle: Practical Probabilistic Model-based Deep Reinforcement Learning by Integrating Dropout Uncertainty and Trajectory Sampling\nYear: 2023\nAbstract: This paper addresses the prediction stability, prediction accuracy and control capability of the current probabilistic model-based reinforcement learning (MBRL) built on neural networks. A novel approach dropout-based probabilistic ensembles with trajectory sampling (DPETS) is proposed where the system uncertainty is stably predicted by combining the Monte-Carlo dropout and trajectory sampling in one framework. Its loss function is designed to correct the fitting error of neural networks for more accurate prediction of probabilistic models. The state propagation in its policy is extended to filter the aleatoric uncertainty for superior control capability. Evaluated by several Mujoco benchmark control tasks under additional disturbances and one practical robot arm manipulation task, DPETS outperforms related MBRL approaches in both average return and convergence velocity while achieving superior performance than well-known model-free baselines with significant sample efficiency.",
  "Evaluated by several Mujoco benchmark control tasks under additional disturbances and one practical robot arm manipulation task, DPETS outperforms related MBRL approaches in both average return and convergence velocity while achieving superior performance than well-known model-free baselines with significant sample efficiency. The open source code of DPETS is available at https://github.com/mrjun123/DPETS.\nAuthors: Wenjun Huang, Yunduan Cui, Huiyun Li, Xin Wu\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Evaluated by several Mujoco benchmark control tasks under additional disturbances and one practical robot arm manipulation task, DPETS outperforms related MBRL approaches in both average return and convergence velocity while achieving superior performance than well-known model-free baselines with significant sample efficiency.'}",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 5ee7569f3be298494afd613f0d81add43b262e1d\nTitle: Realization of thousand-second improved confinement plasma with Super I-mode in Tokamak EAST\nYear: 2023\nAbstract: Mastering nuclear fusion, which is an abundant, safe, and environmentally competitive energy, is a great challenge for humanity. Tokamak represents one of the most promising paths toward controlled fusion. Obtaining a high-performance, steady-state, and long-pulse plasma regime remains a critical issue. Recently, a big breakthrough in steady-state operation was made on the Experimental Advanced Superconducting Tokamak (EAST). A steady-state plasma with a world-record pulse length of 1056 s was obtained, where the density and the divertor peak heat flux were well controlled, with no core impurity accumulation, and a new high-confinement and self-organizing regime (Super I-mode = I-mode + e-ITB) was discovered and demonstrated. These achievements contribute to the integration of fusion plasma technology and physics, which is essential to operate next-step devices.\nAuthors: Yuntao Song, X.",
  "These achievements contribute to the integration of fusion plasma technology and physics, which is essential to operate next-step devices.\nAuthors: Yuntao Song, X. Zou, X. Gong, A. Becoulet, R. Buttery, P. Bonoli, T. Hoang, R. Maingi, J. Qian, X. Zhong, A. Liu, E. Li, R. Ding, Juan Huang, Q. Zang, Haiqing Liu, Liang Wang, Ling Zhang, Guoqiang Li, Youwen Sun, A. Garofalo, T. Osborne, T. Leonard, S. Baek, G. Wallace, Liqing Xu, Bin Zhang, Shouxin Wang, Y. Chu, Tao Zhang, Y. Duan, Hui Lian, Xuexi Zhang, Yifei Jin, L. Zeng, B. Lyu, Binjia Xiao, Yao Huang, Yong Wang, B. Shen, N. Xiang, Yu Wu, Jiefeng Wu, Xiaojie Wang, B. Ding, Miaohui Li, Xinjun Zhang, C. Qin, Weibin Xi, Jian Zhang, Liansheng Huang, D. Yao,",
  "Yao Huang, Yong Wang, B. Shen, N. Xiang, Yu Wu, Jiefeng Wu, Xiaojie Wang, B. Ding, Miaohui Li, Xinjun Zhang, C. Qin, Weibin Xi, Jian Zhang, Liansheng Huang, D. Yao, Yanlan Hu, G. Zuo, Q. Yuan, Zhiwei Zhou, Mao Wang, Handong Xu, Yahong Xie, Zhengchu Wang, Junling Chen, Guosheng Xu, Jiansheng Hu, K. Lu, Fukun Liu, Xin Wu, B. Wan, Jiangang Li\nVenue: Science Advances\nTldr: None",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 600c75049c0c8b9767f388664bd38ad9b4fa1549\nTitle: A new anti-colon cancer tumor pathway of Phenyllactic acid by reducing adhesion of Fusobacterium nucleatum\nYear: 2023\nAbstract: None\nAuthors: Xin Wu, Jinzhao Xu, Danping Wang, Xiaoying Yang, Xiaoxi Xu\nVenue: Food Science and Technology\nTldr: None",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 640e1bcc472a71d36c6b9261403b60c680d93917\nTitle: GET: a foundation model of transcription across human cell types\nYear: 2023\nAbstract: Transcriptional regulation, involving the complex interplay between regulatory sequences and proteins, directs all biological processes. Computational models of transcriptions lack generalizability to accurately extrapolate in unseen cell types and conditions. Here, we introduce GET, an interpretable foundation model, designed to uncover regulatory grammars across 213 human fetal and adult cell types. Relying exclusively on chromatin accessibility data and sequence information, GET achieves experimental-level accuracy in predicting gene expression even in previously unseen cell types. GET showcases remarkable adaptability across new sequencing platforms and assays, enabling regulatory inference across a broad range of cell types and conditions, and uncovering universal and cell type specific transcription factor interaction networks. We evaluated its performance on prediction of regulatory activity, inference of regulatory elements and regulators, and identification of physical interactions between transcription factors. Specifically, we show GET outperforms current models in predicting lentivirus-based massive parallel reporter assay readout with reduced input data.",
  "We evaluated its performance on prediction of regulatory activity, inference of regulatory elements and regulators, and identification of physical interactions between transcription factors. Specifically, we show GET outperforms current models in predicting lentivirus-based massive parallel reporter assay readout with reduced input data. In Fetal erythroblast, we identify distal (>1Mbp) regulatory regions that were missed by previous models. In B cell, we identified a lymphocyte-specific transcription factor-transcription factor interaction that explains the functional significance of a lymphoma-risk predisposing germline mutation. In sum, we provide a generalizable and accurate model for transcription together with catalogs of gene regulation and transcription factor interactions, all with cell type specificity.",
  "In B cell, we identified a lymphocyte-specific transcription factor-transcription factor interaction that explains the functional significance of a lymphoma-risk predisposing germline mutation. In sum, we provide a generalizable and accurate model for transcription together with catalogs of gene regulation and transcription factor interactions, all with cell type specificity.\nAuthors: Xi Fu, Shentong Mo, Anqi Shao, Anouchka P. Laurent, Alejandro Buendia, Adolfo A. Ferrando, Alberto Ciccia, Yanyan Lan, Teresa Palomero, David M. Owens, Eric P. Xing, Ra\u00fal Rabad\u00e1n\nVenue: bioRxiv\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work introduces GET, an interpretable foundation model, designed to uncover regulatory grammars across 213 human fetal and adult cell types, and provides a generalizable and accurate model for transcription together with catalogs of gene regulation and transcription factor interactions, all with cell type specificity.'}",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 64b802537c34bc000be7c04652753c1c38d60dbc\nTitle: Poverty Alleviation Resettlement and Household Natural Resources Dependence: A Case Study from Ankang Prefecture, China\nYear: 2023\nAbstract: In order to assess the degree to which China\u2019s poverty alleviation resettlement (PAR) has been able to address the development conundrum of natural resources reliance and human welfare, it was necessary to investigate the effects of PAR on rural households with regard to their dependence on natural resources. This article evaluated households\u2019 natural resources dependence in rural China by constructing a natural resources dependence index and empirically analyzing the effect of PAR on households by using household survey data from Ankang Prefecture, located in southern Shaanxi Province. The findings demonstrated that PAR could effectively decrease the dependence of households on local natural resources, thus safeguarding the natural environment. Moreover, there were noteworthy distinctions regarding households\u2019 natural resources dependence.",
  "The findings demonstrated that PAR could effectively decrease the dependence of households on local natural resources, thus safeguarding the natural environment. Moreover, there were noteworthy distinctions regarding households\u2019 natural resources dependence. This research endeavored to complete the fusion of natural resource dependence and PAR at the household level, and then contemplated the policy implications of PAR on rural households\u2019 dependence on resources, furnishing fresh information for future evaluations of nature conservation and development policies.\nAuthors: Wei Liu, Xin Wu\nVenue: Agriculture\nTldr: None",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 66ec74cffac0cc70bdb07a1677cb7915d79fe1f7\nTitle: A study of Forbush Decreases effects with DAMPE experiment\nYear: 2023\nAbstract: Forbush Decrease (FD) is a rapid decrease and slow recover in the observed galactic cosmic ray intensity, caused by active solar events sweeping low energy galactic cosmic rays (GCRs) away from Earth. Differnet properties of FDs have been observed by different scientific experiment but mostly from worldwide ground based Neutron Monitors (NMS), they focus on secondary neutron from the atmosphere. The Dark Matter Particle Explorer (DAMPE) is a satellite-based cosmic-ray experiment that has been stably operated for more than 7 years. Precise measurements of cosmic ray electrons and positrons from DAMPE make it possible to directly study FDs from a new perspective. We analyze the FD properties, such as decrease amplitude and recover time as a function of energy, observed by DAMPE from 2017 to 2021. Finally we simulate the FDs with a numerical model, and successfully reproduce the FDs.",
  "We analyze the FD properties, such as decrease amplitude and recover time as a function of energy, observed by DAMPE from 2017 to 2021. Finally we simulate the FDs with a numerical model, and successfully reproduce the FDs. The preliminary result shows that the head-on events causes energy related recover time, while edge-on events causes energy unrelated recover time of FDs.\nAuthors: WenHsiung Li, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, Xiaomei Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, Francesco de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang,",
  "Francesco de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, Piergiorgio Fusco, M. Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guangshun Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, Lulu Jiang, Wei Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N.",
  "X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, Hong-mei Su, Meng Su, H. Sun, Zhiyu Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Yuanzhu Wang, D. Wei, J. Wei, Yifeng Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu,",
  "J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Yuanzhu Wang, D. Wei, J. Wei, Yifeng Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zizhong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hongying Zhao, Xun Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: None",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 6721244fad7f4790272be86e8b165fccd69578ab\nTitle: KD-DLGAN: Data Limited Image Generation via Knowledge Distillation\nYear: 2023\nAbstract: Generative Adversarial Networks (GANs) rely heavily on large-scale training data for training high-quality image generation models. With limited training data, the GAN discriminator often suffers from severe overfitting which directly leads to degraded generation especially in generation diversity. Inspired by the recent advances in knowledge distillation (KD), we propose KD-DLGAN, a knowledge-distillation based generation framework that introduces pre-trained vision-language models for training effective data-limited generation models. KD-DLGAN consists of two innovative designs. The first is aggregated generative KD that mitigates the discriminator overfitting by challenging the discriminator with harder learning tasks and distilling more generalizable knowledge from the pre-trained models. The second is correlated generative KD that improves the generation diversity by distilling and preserving the diverse image-text correlation within the pre-trained models. Extensive experiments over multiple benchmarks show that KD-DLGAN achieves superior image generation with limited training data.",
  "The second is correlated generative KD that improves the generation diversity by distilling and preserving the diverse image-text correlation within the pre-trained models. Extensive experiments over multiple benchmarks show that KD-DLGAN achieves superior image generation with limited training data. In addition, KD-DLGAN complements the state-of-the-art with consistent and substantial performance gains. Note that codes will be released.\nAuthors: Kaiwen Cui, Yingchen Yu, Fangneng Zhan, Shengcai Liao, Shijian Lu1, Eric P. Xing\nVenue: Computer Vision and Pattern Recognition\nTldr: {'model': 'tldr@v2.0.0', 'text': 'KD-DLGAN is proposed, a knowledge-distillation based generation framework that introduces pre-trained vision-language models for training effective data-limited generation models and achieves superior image generation with limited training data.'}",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 7124f495399759ce089e6637dc48e073e9d168aa\nTitle: 3D Semantic Segmentation in the Wild: Learning Generalized Models for Adverse-Condition Point Clouds\nYear: 2023\nAbstract: Robust point cloud parsing under all-weather conditions is crucial to level-5 autonomy in autonomous driving. However, how to learn a universal 3D semantic segmentation (3DSS) model is largely neglected as most existing benchmarks are dominated by point clouds captured under normal weather. We introduce SemanticSTF, an adverse-weather point cloud dataset that provides dense point-level annotations and allows to study 3DSS under various adverse weather conditions. We study all-weather 3DSS modeling under two setups: 1) domain adaptive 3DSS that adapts from normal-weather data to adverse-weather data; 2) domain generalizable 3DSS that learns all-weather 3DSS models from normal-weather data.",
  "We study all-weather 3DSS modeling under two setups: 1) domain adaptive 3DSS that adapts from normal-weather data to adverse-weather data; 2) domain generalizable 3DSS that learns all-weather 3DSS models from normal-weather data. Our studies reveal the challenge while existing 3DSS methods encounter adverse-weather data, showing the great value of SemanticSTF in steering the future endeavor along this very meaningful research direction. In addition, we design a domain randomization technique that alternatively randomizes the geometry styles of point clouds and aggregates their embeddings, ultimately leading to a generalizable model that can improve 3DSS under various adverse weather effectively. The SemanticSTF and related codes are available at https://github.com/xiaoaoran/SemanticSTF.",
  "The SemanticSTF and related codes are available at https://github.com/xiaoaoran/SemanticSTF.\nAuthors: Aoran Xiao, Jiaxing Huang, Weihao Xuan, Ruijie Ren, Kangcheng Liu, Dayan Guan, A. E. Saddik, Shijian Lu, Eric P. Xing\nVenue: Computer Vision and Pattern Recognition\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work introduces SemanticSTF, an adverse-weather point cloud dataset that provides dense point-level annotations and allows to study 3DSS under various adverse weather conditions, and designs a domain randomization technique that alternatively randomizes the geometry styles of point clouds and aggregates their embeddings, ultimately leading to a generalizable model that can improve 3D semantic segmentation underVarious adverse weather effectively.'}",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 719cff0d9a4cfcafb7507b7f301838655f3f3dbf\nTitle: Direct measurement of Ne-Mg-Si nuclei in cosmic rays with DAMPE\nYear: 2023\nAbstract: A precise measurement of the cosmic-ray spectra provides important information on their origin, acceleration and propagation processes in the Galaxy. The Dark Matter Particle Explorer (DAMPE) is a satellite-based cosmic-ray experiment that has been operational for more than 7 years. Since its launch in December 2015, it is continuously collecting data on high-energy cosmic particles with very good statistics and particle identification capabilities, thanks to a large geometric factor and a good charge resolution. In this contribution, the direct measurement of the intermediate mass cosmic rays is presented, in particular the observation of the cosmic-ray Ne, Mg and Si nuclei, which are thought to be mainly produced and accelerated in astrophysical sources.\nAuthors: E. Casilli, Francesco Alemanno, Q. An, P. Azzarello, F. Barbato, X. Bi, I. Cagnoli, M. Cai, E. Catanzani,",
  "Authors: E. Casilli, Francesco Alemanno, Q. An, P. Azzarello, F. Barbato, X. Bi, I. Cagnoli, M. Cai, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, J. Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, C. Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco, M. Gao, F. Gargano, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, L. Jiang, Wei Jiang, Y. Jiang, J. Kong, A. Kotenko,",
  "Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, L. Jiang, Wei Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, Hong-mei Su, Meng Su, H. Sun, Zhigang Sun,",
  "J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, Hong-mei Su, Meng Su, H. Sun, Zhigang Sun, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hongying Zhao, Xu Zhao, C. Zhou,",
  "C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hongying Zhao, Xu Zhao, C. Zhou, Yanzi Zhu, C. Altomare, P. Bernardini, F. de Palma, Essna Ghose, A. Surdo\nVenue: International Conference on Rebooting Computing\nTldr: None",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 747c188af4df6c33421078ddfa450b648a9cbfc6\nTitle: Probing hadronic cross sections in the TeV - PeV regime with DAMPE through machine learning techniques\nYear: 2023\nAbstract: Thanks to its large calorimeter\nAuthors: P. Coppin, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, F. de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng,",
  "M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, Luyang Jiang, Wei Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, Tao Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu,",
  "Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, Tao Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, H. Su, Meng Su, H. Sun, Zhigang Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yinong Wei, Di Wu, Jian Wu, Li Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zijun Xu, Zunlei Xu,",
  "Ying Wang, Y. Wang, D. Wei, J. Wei, Yinong Wei, Di Wu, Jian Wu, Li Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zijun Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hong-yun Zhao, Xu Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: {'model': 'tldr@v2.0.0', 'text': None}",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 7ab88e8c5f6cbe53a653aa504574782b71fc2e5c\nTitle: Point-like Source Catalog Observed by DAMPE\nYear: 2023\nAbstract: The DArk Matter Particle Explorer (DAMPE) is a high-energy cosmic ray and gamma-ray detector located in space. Over a period of seven years since its launch on December 17, 2015, DAMPE has surveyed the entire sky and collected an extensive dataset of more than 300,000 photons with energies above 2 GeV. To analyze the gamma-ray data obtained by DAMPE, instrument response functions (IRFs) have been derived, and a specialized software called DmpST has been developed. In this context, we present the results of the DAMPE gamma-ray point-like source catalog. This catalog provides valuable information about the detected gamma-ray sources, which includes details such as the positions, energy spectra, and flux measurements of these point-like gamma-ray sources. By studying these sources, scientists can gain insights into various astrophysical phenomena, including the emission processes and distribution of gamma-ray sources in the universe.",
  "By studying these sources, scientists can gain insights into various astrophysical phenomena, including the emission processes and distribution of gamma-ray sources in the universe.\nAuthors: K. Duan, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Y. Cui, I. De Mitri, Francesco de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D.",
  "Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guangshun Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, Lujie Jiang, Yao Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Z.",
  "M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, H. Su, Meng Su, Hao-Lun Sun, Zhigang Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Yuanzhu Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, Li Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J.",
  "Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Ya Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hong-yun Zhao, Xu Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: None",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 815ba42bacfe231664de6c4ab1f46b6c54bd1950\nTitle: DArk Matter Particle Explorer: 7 years in Space\nYear: 2023\nAbstract: The DArk Matter Particle Explorer (DAMPE) is a pioneering calorimetric experiment that has been successfully operating in space since December 2015, designed to detect cosmic rays up to unprecedentedly high energies thanks to the fine-grained thick BGO calorimeter and relatively large geometric factor. Among the scientific goals of DAMPE are the precise measurements of cosmic-ray electron plus positron spectrum, including the detection of possible indirect dark matter signatures, spectral measurements of primary and secondary cosmic-ray species, and gamma-ray physics. For electrons and gamma rays, it covers an energy range from GeV to about 10 TeV, with an outstanding energy resolution close to 1%. Proton and ion cosmic rays can be measured up to hundreds of TeV in kinetic energy. In this contribution, we first give an overview of the DAMPE mission and its on-orbit operation status.",
  "Proton and ion cosmic rays can be measured up to hundreds of TeV in kinetic energy. In this contribution, we first give an overview of the DAMPE mission and its on-orbit operation status. Then, we highlight the key scientific results, including the measurements of the BCNO group, boron-to-carbon ratio, proton plus helium spectrum beyond 100 TeV, gamma-ray physics and more. Finally, the ongoing efforts for lepton, light, and heavy hadron cosmic rays are briefly discussed along with the new data analysis techniques.\nAuthors: A. Tykhonov, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, Paolo Bernardini, Xiao-Jun Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Zi-Yuan Chen, P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, Francesco de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G.",
  "Zi-Yuan Chen, P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, Francesco de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, Piergiorgio Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, L. Jiang, Wei Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, Wei Liang Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F.",
  "Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, Wei Liang Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, Pengxiong Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, Xiaozhong Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Shangguan Zhi, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, Hong-mei Su, Meng Su, Hao-Lun Sun, Zhigang Sun, A. Surdo, X. Teng, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei,",
  "Hong-mei Su, Meng Su, Hao-Lun Sun, Zhigang Sun, A. Surdo, X. Teng, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zizhong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Ya Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hongying Zhao, Xu Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: None",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 82aefa38673ab37a5c8c2d4931ad623651941be7\nTitle: Observational signatures of Schwarzschild-MOG black holes in scalar\u2013tensor\u2013vector gravity: images of the accretion disk\nYear: 2023\nAbstract: None\nAuthors: Shiyang Hu, Chen Deng, Sen Guo, Xin Wu, Enwei Liang\nVenue: The European Physical Journal C\nTldr: None",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 83aa9762c0fa099e6f893bb895e287a18b482d7e\nTitle: Evaluating emotional labor from a career management perspective\nYear: 2023\nAbstract: Emotional labor claims its significance as the key indicator both of the psychological health of contemporary employees, and the productivity of service-based businesses depending upon genuine emotional input of employees. By far, research on emotional labor of employees in an organizational context is still lacking. This study aims to explore the relationships among emotional labor, organizational support, career competences and career commitment to investigate how emotional labor interacts with the organizational context and affects the career management of the employee. Data were collected from a sample of 387 frontline employees working at two luxury hotel brands in China. Structural equation modeling (SEM) was utilized to estimate the relationships among the constructs. It is demonstrated by the findings that organizational support mediates positively on emotional labor, which exerts positive influences on career competences and career commitment. Sound handling of emotional labor, boosted by a supportive organizational environment, has been ascertained to positively predict long-term career paths of the employees at the company.",
  "It is demonstrated by the findings that organizational support mediates positively on emotional labor, which exerts positive influences on career competences and career commitment. Sound handling of emotional labor, boosted by a supportive organizational environment, has been ascertained to positively predict long-term career paths of the employees at the company. This study provides insights into how the tourism and hospitality industry can optimize the functions of emotional labor for in enhancing service quality and customer satisfaction, as well as promoting the psychological well-being of the employees.\nAuthors: Yunhong Hu, Wei Tu, Li Zhou, Xin Wu, Qi Yan\nVenue: Frontiers in Psychology\nTldr: None",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 83cf0caccd1d55c7af171604eca38c85e379a1cf\nTitle: Penetrating particle ANalyzer (PAN)\nYear: 2023\nAbstract: The Penetrating particle Analyzer (PAN) is a compact magnetic spectrometer with relatively low power budget allowing it to be used in deep space and interplanetary missions for cosmic rays, solar physics and space weather studies. It can precisely measure and monitor the flux, composition, and direction of highly penetrating particles in the range between 100 MeV/n and 10 GeV/n. The device consists of permanent magnet sections, silicon strip detectors, scintillating detectors and silicon pixel detectors. At the current stage of the R&D, the first smaller prototype, called Mini.PAN, was built. Mini.PAN is designed to demonstrate the capabilities and performance of the instrument concept.",
  "The device consists of permanent magnet sections, silicon strip detectors, scintillating detectors and silicon pixel detectors. At the current stage of the R&D, the first smaller prototype, called Mini.PAN, was built. Mini.PAN is designed to demonstrate the capabilities and performance of the instrument concept. The key component of Mini.PAN is the fine-pitched and thin\nAuthors: D. Sukhonos, G. Ambrosi, P. Azzarello, M. Barbanera, Benedikt Bergmann, P. Burian, F. Cadoux, Y. Favre, J. Hulsman, D. Marra, T. Iizawa, M. Ionica, Eduardo Mancini, L. Nicola, M. Paniccia, G. Silvestre, P. Smolyanskiy, Jerry Stauffer, Adrien Stil, P. Thonet, P. Xie, Xin Wu\nVenue: International Conference on Rebooting Computing\nTldr: None",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 84a36e19f9394f22b34f79756fa9628a795e02ea\nTitle: LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset\nYear: 2023\nAbstract: Studying how people interact with large language models (LLMs) in real-world scenarios is increasingly important due to their widespread use in various applications. In this paper, we introduce LMSYS-Chat-1M, a large-scale dataset containing one million real-world conversations with 25 state-of-the-art LLMs. This dataset is collected from 210K unique IP addresses in the wild on our Vicuna demo and Chatbot Arena website. We offer an overview of the dataset's content, including its curation process, basic statistics, and topic distribution, highlighting its diversity, originality, and scale. We demonstrate its versatility through four use cases: developing content moderation models that perform similarly to GPT-4, building a safety benchmark, training instruction-following models that perform similarly to Vicuna, and creating challenging benchmark questions.",
  "We demonstrate its versatility through four use cases: developing content moderation models that perform similarly to GPT-4, building a safety benchmark, training instruction-following models that perform similarly to Vicuna, and creating challenging benchmark questions. We believe that this dataset will serve as a valuable resource for understanding and advancing LLM capabilities. The dataset is publicly available at https://huggingface.co/datasets/lmsys/lmsys-chat-1m.",
  "We believe that this dataset will serve as a valuable resource for understanding and advancing LLM capabilities. The dataset is publicly available at https://huggingface.co/datasets/lmsys/lmsys-chat-1m.\nAuthors: Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Tianle Li, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zhuohan Li, Zi Lin, Eric P. Xing, Joseph E. Gonzalez, Ion Stoica, Haotong Zhang\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper introduces LMSYS-Chat-1M, a large-scale dataset containing one million real-world conversations with 25 state-of-the-art LLMs, and demonstrates its versatility through four use cases: developing content moderation models that perform similarly to GPT-4, building a safety benchmark, training instruction-following models that performs similarly to Vicuna, and creating challenging benchmark questions.'}",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 8a6ac6d5f8967f2112672a9274b541f515a7380f\nTitle: POLAR-2, the next generation of GRB polarization detector\nYear: 2023\nAbstract: The POLAR-2 Gamma-Ray Burst (GRB) Polarimetry mission is a follow-up to the successful POLAR mission. POLAR collected six months of data in 2016-2017 on board the Tiangong-2 Chinese Space laboratory. From a polarization study on 14 GRBs, POLAR measured an overall low polarization and a hint for an unexpected complexity in the time evolution of polarization during GRBs. Energy-dependent measurements of the GRB polarization will be presented by N. de Angelis in GA21-09 (August 2nd). These results demonstrate the need for measurements with significantly improved accuracy. Moreover, the recent discovery of gravitational waves and their connection to GRBs justifies a high-precision GRB polarimeter that can provide both high-precision polarimetry and detection of very faint GRBs.",
  "These results demonstrate the need for measurements with significantly improved accuracy. Moreover, the recent discovery of gravitational waves and their connection to GRBs justifies a high-precision GRB polarimeter that can provide both high-precision polarimetry and detection of very faint GRBs. The POLAR-2 polarimeter is based on the same Compton scattering measurement principle as POLAR, but with an extended energy range and an order of magnitude increase in total effective area for polarized events. Proposed and developed by a joint effort of Switzerland, China, Poland and Germany, the device was selected for installation on the China Space Station and is scheduled to start operation for at least 2 years in 2025.\nAuthors: Nicolas Produit, M. Kole, Xin Wu, Nicolas De Angelis, Hancheng Li, D. Rybka, A. Pollo, S. Mianowski, J. Greiner, J. Burgess, Jianchao Sun, Shuang-Nan Zhang\nVenue: International Conference on Rebooting Computing\nTldr: None",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 8cc1cd002bfc36a8cba8bcbe63d32eacc656097f\nTitle: StyleRF: Zero-Shot 3D Style Transfer of Neural Radiance Fields\nYear: 2023\nAbstract: 3D style transfer aims to render stylized novel views of a 3D scene with multiview consistency. However, most existing work suffers from a three-way dilemma over accurate geometry reconstruction, high-quality stylization, and being generalizable to arbitrary new styles. We propose StyleRF (Style Radiance Fields), an innovative 3D style transfer technique that resolves the three-way dilemma by performing style transformation within the feature space of a radiance field. StyleRF employs an explicit grid of high-level features to represent 3D scenes, with which highfidelity geometry can be reliably restored via volume rendering. In addition, it transforms the grid features according to the reference style which directly leads to high-quality zero-shot style transfer. StyleRF consists of two innovative designs.",
  "In addition, it transforms the grid features according to the reference style which directly leads to high-quality zero-shot style transfer. StyleRF consists of two innovative designs. The first is sampling-invariant content transformation that makes the transformation invariant to the holistic statistics of the sampled 3D points and accordingly ensures multi-view consistency. The second is deferred style transformation of 2D feature maps which is equivalent to the transformation of 3D points but greatly reduces memory footprint without degrading multi-view consistency. Extensive experiments show that StyleRF achieves superior 3D stylization quality with precise geometry reconstruction and it can generalize to various new styles in a zero-shot manner.",
  "Extensive experiments show that StyleRF achieves superior 3D stylization quality with precise geometry reconstruction and it can generalize to various new styles in a zero-shot manner. Project website: https://kunhao-liu.github.io/StyleRF/\nAuthors: Kunhao Liu, Fangneng Zhan, Yiwen Chen, Jiahui Zhang, Yingchen Yu, Abdulmotaleb El Saddik, Shijian Lu, E. Xing\nVenue: Computer Vision and Pattern Recognition\nTldr: {'model': 'tldr@v2.0.0', 'text': 'StyleRF (Style Radiance Fields), an innovative 3D style transfer technique that resolves the three-way dilemma by performing style transformation within the feature space of a radiance field, achieves superior 3D stylization quality with precise geometry reconstruction and it can generalize to various new styles in a zero-shot manner.'}",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 953e415f1fd006e968aa13b49cd7523856c0c0fe\nTitle: Fusing Models with Complementary Expertise\nYear: 2023\nAbstract: Training AI models that generalize across tasks and domains has long been among the open problems driving AI research. The emergence of Foundation Models made it easier to obtain expert models for a given task, but the heterogeneity of data that may be encountered at test time often means that any single expert is insufficient. We consider the Fusion of Experts (FoE) problem of fusing outputs of expert models with complementary knowledge of the data distribution and formulate it as an instance of supervised learning. Our method is applicable to both discriminative and generative tasks and leads to significant performance improvements in image and text classification, text summarization, multiple-choice QA, and automatic evaluation of generated text. We also extend our method to the\"frugal\"setting where it is desired to reduce the number of expert model evaluations at test time.",
  "We also extend our method to the\"frugal\"setting where it is desired to reduce the number of expert model evaluations at test time.\nAuthors: Hongyi Wang, Felipe Maia Polo, Yuekai Sun, Souvik Kundu, Eric P. Xing, M. Yurochkin\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work considers the Fusion of Experts (FoE) problem of fusing outputs of expert models with complementary knowledge of the data distribution and formulate it as an instance of supervised learning and leads to significant performance improvements in image and text classification, text summarization, multiple-choice QA, and automatic evaluation of generated text.'}",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 96d6fc4281e739c0e5bc1ea4b7b14ea1ab3bce52\nTitle: Measurement of Heavy Nulei beyond Iron in Cosmic Rays with the DAMPE Experiment\nYear: 2023\nAbstract: None\nAuthors: Haoran Sun, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, F. de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng,",
  "M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, Luyang Jiang, Wei Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu,",
  "Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, H. Su, Meng Su, H. Sun, Zhigang Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yifeng Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zizhong Xu,",
  "Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yifeng Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zizhong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hongying Zhao, Xu Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: None",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 9a99b8f8c1999de1ac723e99a708931b53a573ec\nTitle: Recent Advances in Decellularized Extracellular Matrix-Based Bioinks for 3D Bioprinting in Tissue Engineering\nYear: 2023\nAbstract: In recent years, three-dimensional (3D) bioprinting has been widely utilized as a novel manufacturing technique by more and more researchers to construct various tissue substitutes with complex architectures and geometries. Different biomaterials, including natural and synthetic materials, have been manufactured into bioinks for tissue regeneration using 3D bioprinting. Among the natural biomaterials derived from various natural tissues or organs, the decellularized extracellular matrix (dECM) has a complex internal structure and a variety of bioactive factors that provide mechanistic, biophysical, and biochemical signals for tissue regeneration and remodeling. In recent years, more and more researchers have been developing the dECM as a novel bioink for the construction of tissue substitutes.",
  "In recent years, more and more researchers have been developing the dECM as a novel bioink for the construction of tissue substitutes. Compared with other bioinks, the various ECM components in dECM-based bioink can regulate cellular functions, modulate the tissue regeneration process, and adjust tissue remodeling. Therefore, we conducted this review to discuss the current status of and perspectives on dECM-based bioinks for bioprinting in tissue engineering. In addition, the various bioprinting techniques and decellularization methods were also discussed in this study.\nAuthors: Man Zhe, Xin Wu, Peiyun Yu, Jiawei Xu, Ming Liu, Guang Yang, Zhou Xiang, F. Xing, U. Ritz\nVenue: Materials\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The current status of and perspectives on dECM-based bioinks for bioprinting in tissue engineering are discussed and the various biopprinting techniques and decellularization methods were discussed in this study.'}",
  "Faculty Name: eric xing\nMetadata:\nPaperid: 9d4302e77ab4f6f39a4c040b9b53e075c62797ae\nTitle: Evaluation of thermal comfort in air-conditioned rooms based on structure/control-related parameters and data-mining method\nYear: 2023\nAbstract: None\nAuthors: S. Zhao, Lin He, Xin Wu, Guowen Xu, Junlong Xie, Shanshan Cai\nVenue: International Journal of Air-Conditioning and Refrigeration\nTldr: None",
  "Faculty Name: eric xing\nMetadata:\nPaperid: a06a4a38668c4737ab2ce80badc177ea3f520456\nTitle: Cuttlefish: Low-Rank Model Training without All the Tuning\nYear: 2023\nAbstract: Recent research has shown that training low-rank neural networks can effectively reduce the total number of trainable parameters without sacrificing predictive accuracy, resulting in end-to-end speedups. However, low-rank model training necessitates adjusting several additional factorization hyperparameters, such as the rank of the factorization at each layer. In this paper, we tackle this challenge by introducing Cuttlefish, an automated low-rank training approach that eliminates the need for tuning factorization hyperparameters. Cuttlefish leverages the observation that after a few epochs of full-rank training, the stable rank (i.e., an approximation of the true rank) of each layer stabilizes at a constant value. Cuttlefish switches from full-rank to low-rank training once the stable ranks of all layers have converged, setting the dimension of each factorization to its corresponding stable rank.",
  "Cuttlefish switches from full-rank to low-rank training once the stable ranks of all layers have converged, setting the dimension of each factorization to its corresponding stable rank. Our results show that Cuttlefish generates models up to 5.6 times smaller than full-rank models, and attains up to a 1.2 times faster end-to-end training process while preserving comparable accuracy. Moreover, Cuttlefish outperforms state-of-the-art low-rank model training methods and other prominent baselines. The source code for our implementation can be found at: https://github.com/hwang595/Cuttlefish.",
  "Moreover, Cuttlefish outperforms state-of-the-art low-rank model training methods and other prominent baselines. The source code for our implementation can be found at: https://github.com/hwang595/Cuttlefish.\nAuthors: Hongyi Wang, Saurabh Agarwal, Pongsakorn U-chupala, Yoshiki Tanaka, Eric P. Xing, Dimitris Papailiopoulos\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper introduces Cuttlefish, an automated low-rank training approach that eliminates the need for tuning factorization hyperparameters, and generates models up to 5.6 times smaller than full-rank models, and attains up to a 1.2 times faster end-to-end training process while preserving comparable accuracy.'}",
  "Faculty Name: eric xing\nMetadata:\nPaperid: a0a79dad89857a96f8f71b14238e5237cbfc4787\nTitle: Judging LLM-as-a-judge with MT-Bench and Chatbot Arena\nYear: 2023\nAbstract: Evaluating large language model (LLM) based chat assistants is challenging due to their broad capabilities and the inadequacy of existing benchmarks in measuring human preferences. To address this, we explore using strong LLMs as judges to evaluate these models on more open-ended questions. We examine the usage and limitations of LLM-as-a-judge, including position, verbosity, and self-enhancement biases, as well as limited reasoning ability, and propose solutions to mitigate some of them. We then verify the agreement between LLM judges and human preferences by introducing two benchmarks: MT-bench, a multi-turn question set; and Chatbot Arena, a crowdsourced battle platform. Our results reveal that strong LLM judges like GPT-4 can match both controlled and crowdsourced human preferences well, achieving over 80% agreement, the same level of agreement between humans.",
  "Our results reveal that strong LLM judges like GPT-4 can match both controlled and crowdsourced human preferences well, achieving over 80% agreement, the same level of agreement between humans. Hence, LLM-as-a-judge is a scalable and explainable way to approximate human preferences, which are otherwise very expensive to obtain. Additionally, we show our benchmark and traditional benchmarks complement each other by evaluating several variants of LLaMA and Vicuna. The MT-bench questions, 3K expert votes, and 30K conversations with human preferences are publicly available at https://github.com/lm-sys/FastChat/tree/main/fastchat/llm_judge.",
  "The MT-bench questions, 3K expert votes, and 30K conversations with human preferences are publicly available at https://github.com/lm-sys/FastChat/tree/main/fastchat/llm_judge.\nAuthors: Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, E. Xing, Haotong Zhang, Joseph Gonzalez, Ion Stoica\nVenue: Neural Information Processing Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The results reveal that strong LLM judges like GPT-4 can match both controlled and crowdsourced human preferences well, achieving over 80% agreement, the same level of agreement between humans, and LLM-as-a-judge is a scalable and explainable way to approximate human preferences, which are otherwise very expensive to obtain.'}",
  "Faculty Name: eric xing\nMetadata:\nPaperid: a1a18645ee975e8b8fa0e9f922353c0ed6da361b\nTitle: Does compressing activations help model parallel training?\nYear: 2023\nAbstract: Large-scale Transformer models are known for their exceptional performance in a range of tasks, but training them can be difficult due to the requirement for communication-intensive model parallelism. One way to improve training speed is to compress the message size in communication. Previous approaches have primarily focused on compressing gradients in a data parallelism setting, but compression in a model-parallel setting is an understudied area. We have discovered that model parallelism has fundamentally different characteristics than data parallelism. In this work, we present the first empirical study on the effectiveness of compression methods for model parallelism. We implement and evaluate three common classes of compression algorithms - pruning-based, learning-based, and quantization-based - using a popular Transformer training framework. We evaluate these methods across more than 160 settings and 8 popular datasets, taking into account different hyperparameters, hardware, and both fine-tuning and pre-training stages.",
  "We evaluate these methods across more than 160 settings and 8 popular datasets, taking into account different hyperparameters, hardware, and both fine-tuning and pre-training stages. We also provide analysis when the model is scaled up. Finally, we provide insights for future development of model parallelism compression algorithms.\nAuthors: S. Bian, Dacheng Li, Hongyi Wang, Eric P. Xing, S. Venkataraman\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work presents the first empirical study on the effectiveness of compression methods for model parallelism, and implements and evaluates three common classes of compression algorithms - pruning-based, learning- based, and quantization-based - using a popular Transformer training framework.'}",
  "Faculty Name: eric xing\nMetadata:\nPaperid: a3c4a5c18ef9bfffd9c8aac0dc2b75b8f18b9f7c\nTitle: Effects of Coupling Constants on Chaos of Charged Particles in the Einstein\u2013\u00c6ther Theory\nYear: 2023\nAbstract: There are two free coupling parameters\u00a0c13\u00a0and\u00a0c14\u00a0in the Einstein\u2013\u00c6ther metric describing a non-rotating black hole. This metric is the Reissner\u2013Nordstr\u00f6m black hole solution when\u00a00\u22642c13<c14<2, but it is not for\u00a00\u2264c14<2c13<2. When the black hole is immersed in an external asymptotically uniform magnetic field, the Hamiltonian system describing the motion of charged particles around the black hole is not integrable; however, the Hamiltonian allows for the construction of explicit symplectic integrators. The proposed fourth-order explicit symplectic scheme is used to investigate the dynamics of charged particles because it exhibits excellent long-term performance in conserving the Hamiltonian.",
  "The proposed fourth-order explicit symplectic scheme is used to investigate the dynamics of charged particles because it exhibits excellent long-term performance in conserving the Hamiltonian. No universal rule can be given to the dependence of regular and chaotic dynamics on varying one or two parameters\u00a0c13\u00a0and\u00a0c14\u00a0in the two cases of\u00a00\u22642c13<c14<2\u00a0and\u00a00\u2264c14<2c13<2. The distributions of order and chaos in the binary parameter space\u00a0(c13,c14)\u00a0rely on different combinations of the other parameters and the initial conditions.\nAuthors: Caiyu Liu, Xin Wu\nVenue: Universe\nTldr: None",
  "Faculty Name: eric xing\nMetadata:\nPaperid: a5bf216fc2dfc7f9e1d3fe6b8b06986758b60577\nTitle: A PCA-based Method for Electron-Proton Discrimination of the DAMPE Experiment\nYear: 2023\nAbstract: None\nAuthors: M. Cui, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, Francesco de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M.",
  "Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, L. Jiang, Weizhong Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu,",
  "Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, H. Su, Meng Su, H. Sun, Zhigang Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Yuanzhu Wang, D. Wei, J. Wei, Yifeng Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu,",
  "Wang, Ying Wang, Yuanzhu Wang, D. Wei, J. Wei, Yifeng Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hongying Zhao, Xun Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: None",
  "Faculty Name: eric xing\nMetadata:\nPaperid: a71dca7b72a8fb8f1f337721a2a0042faf9bd70b\nTitle: Cosmic Ray Carbon and Oxygen Flux Measurements with the DAMPE Experiment\nYear: 2023\nAbstract: The DArk Matter Particle Explorer (DAMPE), a space-based high-energy particle detector\nAuthors: Yifeng Wei, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, Francesco de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, J. Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang,",
  "Francesco de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, J. Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, Luyang Jiang, Wei Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N.",
  "X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, H. Su, Meng Su, H. Sun, Zhigang Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu,",
  "L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zizhong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hongying Zhao, Xu Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: None",
  "Faculty Name: eric xing\nMetadata:\nPaperid: a815c3209e7baff4466dbf6e129129511f842b7e\nTitle: Making Scalable Meta Learning Practical\nYear: 2023\nAbstract: Despite its flexibility to learn diverse inductive biases in machine learning programs, meta learning (i.e., learning to learn) has long been recognized to suffer from poor scalability due to its tremendous compute/memory costs, training instability, and a lack of efficient distributed training support. In this work, we focus on making scalable meta learning practical by introducing SAMA, which combines advances in both implicit differentiation algorithms and systems. Specifically, SAMA is designed to flexibly support a broad range of adaptive optimizers in the base level of meta learning programs, while reducing computational burden by avoiding explicit computation of second-order gradient information, and exploiting efficient distributed training techniques implemented for first-order gradients. Evaluated on multiple large-scale meta learning benchmarks, SAMA showcases up to 1.7/4.8x increase in throughput and 2.0/3.8x decrease in memory consumption respectively on single-/multi-GPU setups compared to other baseline meta learning algorithms.",
  "Evaluated on multiple large-scale meta learning benchmarks, SAMA showcases up to 1.7/4.8x increase in throughput and 2.0/3.8x decrease in memory consumption respectively on single-/multi-GPU setups compared to other baseline meta learning algorithms. Furthermore, we show that SAMA-based data optimization leads to consistent improvements in text classification accuracy with BERT and RoBERTa large language models, and achieves state-of-the-art results in both small- and large-scale data pruning on image classification tasks, demonstrating the practical applicability of scalable meta learning across language and vision domains.\nAuthors: Sang Keun Choe, Sanket Vaibhav Mehta, Hwijeen Ahn, W. Neiswanger, Pengtao Xie, Emma Strubell, Eric P. Xing\nVenue: Neural Information Processing Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'SAMA is designed to flexibly support a broad range of adaptive optimizers in the base level of meta learning programs, while reducing computational burden by avoiding explicit computation of second-order gradient information, and exploiting efficient distributed training techniques implemented for first-order gradients.'}",
  "Faculty Name: eric xing\nMetadata:\nPaperid: a91026808c2139b79e4daf8df8fbe5008f389f9f\nTitle: Erratum: New insight into the shape coexistence and shape evolution of \n<mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"><mml:mmultiscripts><mml:mi>Yb</mml:mi><mml:mprescripts /><mml:none /><mml:mn>157</mml:mn></mml:mmultiscripts></mml:math>\n [Phys. Rev.",
  "Rev. C \n<b>83</b>\n, 014318 (2011)]\nYear: 2023\nAbstract: None\nAuthors: C. Xu, H. Hua, Xiao Li, J. Meng, Z. Li, F. Xu, Y. Shi, H. Liu, Shengyao Zhang, Z. Li, L. Zhu, Xin Wu, G. Li, C. He, S. G. Zhou, S. Y. Wang, Y. Ye, D. Jiang, T. Zheng, J. Lou, L. Ma, E. Wang, Y. Y. Cheng, C. He\nVenue: Physical Review C\nTldr: None",
  "Faculty Name: eric xing\nMetadata:\nPaperid: aa8a3b4d472e707dc019a93498f52f6aaf5b9a7b\nTitle: Applicability of the 0\u20131 test for chaos in magnetized Kerr\u2013Newman spacetimes\nYear: 2023\nAbstract: None\nAuthors: Daqi Yang, Xin Wu\nVenue: The European Physical Journal C\nTldr: None",
  "Faculty Name: eric xing\nMetadata:\nPaperid: ab70103b8cc85fd1cd52200aa134c58c7e9c0e03\nTitle: FedNAR: Federated Optimization with Normalized Annealing Regularization\nYear: 2023\nAbstract: Weight decay is a standard technique to improve generalization performance in modern deep neural network optimization, and is also widely adopted in federated learning (FL) to prevent overfitting in local clients. In this paper, we first explore the choices of weight decay and identify that weight decay value appreciably influences the convergence of existing FL algorithms. While preventing overfitting is crucial, weight decay can introduce a different optimization goal towards the global objective, which is further amplified in FL due to multiple local updates and heterogeneous data distribution. To address this challenge, we develop {\\it Federated optimization with Normalized Annealing Regularization} (FedNAR), a simple yet effective and versatile algorithmic plug-in that can be seamlessly integrated into any existing FL algorithms. Essentially, we regulate the magnitude of each update by performing co-clipping of the gradient and weight decay.",
  "Essentially, we regulate the magnitude of each update by performing co-clipping of the gradient and weight decay. We provide a comprehensive theoretical analysis of FedNAR's convergence rate and conduct extensive experiments on both vision and language datasets with different backbone federated optimization algorithms. Our experimental results consistently demonstrate that incorporating FedNAR into existing FL algorithms leads to accelerated convergence and heightened model accuracy. Moreover, FedNAR exhibits resilience in the face of various hyperparameter configurations. Specifically, FedNAR has the ability to self-adjust the weight decay when the initial specification is not optimal, while the accuracy of traditional FL algorithms would markedly decline. Our codes are released at \\href{https://github.com/ljb121002/fednar}{https://github.com/ljb121002/fednar}.",
  "Our codes are released at \\href{https://github.com/ljb121002/fednar}{https://github.com/ljb121002/fednar}.\nAuthors: Junbo Li, Ang Li, Chong Tian, Qirong Ho, Eric P. Xing, Hongyi Wang\nVenue: Neural Information Processing Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper develops FedNAR, a simple yet effective and versatile algorithmic plug-in that can be seamlessly integrated into any existing FL algorithms and has the ability to self-adjust the weight decay when the initial specification is not optimal, while the accuracy of traditional FL algorithms would markedly decline.'}",
  "Faculty Name: eric xing\nMetadata:\nPaperid: abd11a40c2b51a3af211302141db7f4a94d71497\nTitle: Measurements of the boron-to-carbon and boron-to-oxygen flux ratios in cosmic rays with DAMPE\nYear: 2023\nAbstract: Boron nuclei in cosmic rays (CRs) are believed to be mainly produced by the fragmentation of heavier nuclei, such as carbon and oxygen, via collisions with the interstellar matter. Therefore, the boron-to-carbon \ufb02ux ratio (B/C) and the boron-to-oxygen \ufb02ux ratio (B/O) are very essential probes of the CR propagation. With a large geometric factor and a good charge resolution, the DArk Matter Particle Explorer (DAMPE)\nAuthors: C. Yue, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen,",
  "Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, Francesco de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, Piergiorgio Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, L. Jiang, Wei Jiang, Y. Jiang,",
  "Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, L. Jiang, Wei Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, Wei Liang Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, Pengxiong Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Shangguan Zhi, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, H. Su,",
  "E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Shangguan Zhi, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, H. Su, Meng Su, H. Sun, Zhigang Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Yuanzhu Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zizhong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Ya Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang,",
  "Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Ya Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hong-yun Zhao, Xu Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: None",
  "Faculty Name: eric xing\nMetadata:\nPaperid: aca66f06cc3f988ebfc0420b3f969466a6984fef\nTitle: Federated Learning as Variational Inference: A Scalable Expectation Propagation Approach\nYear: 2023\nAbstract: The canonical formulation of federated learning treats it as a distributed optimization problem where the model parameters are optimized against a global loss function that decomposes across client loss functions. A recent alternative formulation instead treats federated learning as a distributed inference problem, where the goal is to infer a global posterior from partitioned client data (Al-Shedivat et al., 2021). This paper extends the inference view and describes a variational inference formulation of federated learning where the goal is to find a global variational posterior that well-approximates the true posterior. This naturally motivates an expectation propagation approach to federated learning (FedEP), where approximations to the global posterior are iteratively refined through probabilistic message-passing between the central server and the clients. We conduct an extensive empirical study across various algorithmic considerations and describe practical strategies for scaling up expectation propagation to the modern federated setting.",
  "We conduct an extensive empirical study across various algorithmic considerations and describe practical strategies for scaling up expectation propagation to the modern federated setting. We apply FedEP on standard federated learning benchmarks and find that it outperforms strong baselines in terms of both convergence speed and accuracy.\nAuthors: Han Guo, P. Greengard, Hongyi Wang, A. Gelman, Yoon Kim, Eric P. Xing\nVenue: International Conference on Learning Representations\nTldr: {'model': 'tldr@v2.0.0', 'text': 'An extensive empirical study across various algorithmic considerations and describes practical strategies for scaling up expectation propagation to the modern federated setting and applies FedEP on standard federated learning benchmarks and finds that it outperforms strong baselines in terms of both convergence speed and accuracy.'}",
  "Faculty Name: eric xing\nMetadata:\nPaperid: ae98f67ff27c9a817a62e1b52a3f2cc1c20bf94f\nTitle: Integrating symbol similarities with knowledge\u00a0graph embedding for entity alignment: an unsupervised framework\nYear: 2023\nAbstract: None\nAuthors: Tingting Jiang, Chenyang Bu, Yi Zhu, Xin Wu\nVenue: Intelligent Computing\nTldr: None",
  "Faculty Name: eric xing\nMetadata:\nPaperid: ae9cc1f7ba5c905684f5c4211dbb7f0bb2cd4458\nTitle: Measurement of Ultra-High-Energy Diffuse Gamma-Ray Emission of the Galactic Plane from 10\u00a0TeV to 1\u00a0PeV with LHAASO-KM2A.\nYear: 2023\nAbstract: The diffuse Galactic \u03b3-ray emission, mainly produced via interactions between cosmic rays and the interstellar medium and/or radiation field, is a very important probe of the distribution, propagation, and interaction of cosmic rays in the Milky\u00a0Way. In this Letter, we report the measurements of diffuse \u03b3 rays from the Galactic plane between 10\u00a0TeV and 1\u00a0PeV energies, with the square kilometer array of the Large High Altitude Air Shower Observatory (LHAASO). Diffuse emissions from the inner (15\u00b0<l<125\u00b0, |b|<5\u00b0) and outer (125\u00b0<l<235\u00b0, |b|<5\u00b0) Galactic plane are detected with 29.1\u03c3 and 12.7\u03c3 significance, respectively.",
  "Diffuse emissions from the inner (15\u00b0<l<125\u00b0, |b|<5\u00b0) and outer (125\u00b0<l<235\u00b0, |b|<5\u00b0) Galactic plane are detected with 29.1\u03c3 and 12.7\u03c3 significance, respectively. The outer Galactic plane diffuse emission is detected for the first time in the very- to ultra-high-energy domain (E>10\u2009\u2009TeV). The energy spectrum in the inner Galaxy regions can be described by a power-law function with an index of -2.99\u00b10.04, which is different from the curved spectrum as expected from hadronic interactions between locally measured cosmic rays and the line-of-sight integrated gas content. Furthermore, the measured flux is higher by a factor of \u223c3 than the prediction. A similar spectrum with an index of -2.99\u00b10.07 is found in the outer Galaxy region, and the absolute flux for 10\u2272E\u227260\u2009\u2009TeV is again higher than the prediction for hadronic cosmic ray interactions. The latitude distributions of the diffuse emission are consistent with the gas distribution, while the longitude distributions show clear deviation from the gas distribution.",
  "The latitude distributions of the diffuse emission are consistent with the gas distribution, while the longitude distributions show clear deviation from the gas distribution. The LHAASO measurements imply that either additional emission sources exist or cosmic ray intensities have spatial variations.\nAuthors: Z. Cao, F. Aharonian, Q. An, Axikegu, Y. Bai, Y. Bao, D. Bastieri, X. Bi, Y. Bi, J. Cai, Q. Cao, W. Cao, Z. Cao, J. Chang, J. Chang, A. Chen, E. Chen, Liang Chen, Lin Chen, Long Chen, M. Chen, M. Chen, Q. Chen, S. Chen, S. Z. Chen, T. Chen, Y. Chen, N. Cheng, Y. Cheng, M. Cui, S. Cui, X. Cui, Y. Cui, B. Dai, H. Dai, Z. Dai, Danzengluobu, D. Volpe, X. Dong, K. Duan, J. Fan, Y. Fan, J. Fang, K. Fang, C. Feng, L. Feng, S.",
  "Y. Cui, B. Dai, H. Dai, Z. Dai, Danzengluobu, D. Volpe, X. Dong, K. Duan, J. Fan, Y. Fan, J. Fang, K. Fang, C. Feng, L. Feng, S. Feng, X. Feng, Y. Feng, S. Gabici, B. Gao, C. Gao, L. Gao, Q. Gao, W. Gao, W. Gao, M. Ge, L. Geng, G. Giacinti, G. Gong, Q. Gou, M. Gu, F. Guo, X. Guo, Y. Guo, Y. Guo, Y. Han, H. He, Haoyu He, J. Y. He, X. He, Y. He, M. Heller, Y. Hor, B. Hou, C. Hou, X. Hou, H. Hu, Q. Hu, S. Hu, D. Huang, T. Q. Huang, W. Huang, X. Huang, X. Y. Huang, Y. Huang, Z. Huang, X. Ji, H.",
  "Hor, B. Hou, C. Hou, X. Hou, H. Hu, Q. Hu, S. Hu, D. Huang, T. Q. Huang, W. Huang, X. Huang, X. Y. Huang, Y. Huang, Z. Huang, X. Ji, H. Jia, K. Jia, K. Jiang, X. W. Jiang, Z. Jiang, M. Jin, M. Kang, T. Ke, D. Kuleshov, K. Kurinov, B. Li, Cheng Li, Cong Li, D. Li, F. Li, H. B. Li, H. C. Li, H. Li, J. Li, Jian Li, Jie Li, K. Li, W. Li, X. Li, Xin Li, Y. Li, Zhe Li, Zhuo Li, E. Liang, Y. Liang, S. Lin, B. Liu, C. Liu, D. Liu, H. Liu, H. Liu, J. Liu, J. Liu, J. Liu, M. Liu, R. Liu, S. M. Liu, W. Liu, Y. Liu, Y. N.",
  "S. Lin, B. Liu, C. Liu, D. Liu, H. Liu, H. Liu, J. Liu, J. Liu, J. Liu, M. Liu, R. Liu, S. M. Liu, W. Liu, Y. Liu, Y. N. Liu, R. Lu, Q. Luo, H. Lv, B. Ma, L. Ma, X. Ma, J. Mao, Z. Min, W. Mitthumsiri, H. Mu, Y. Nan, A. Neronov, Z. Ou, B. Pang, P. Pattarakijwanich, Z. Pei, M. Qi, Y. Qi, B. Qiao, J. Qin, D. Ruffolo, A. S\u00e1iz, D. Semikoz, C. Shao, L. Shao, O. Shchegolev, X. Sheng, F. Shu, H. Song, Y. Stenkin, V. Stepanov, Y. Su, Q. Sun, X. Sun, Z. Sun, P. Tam, Q. Tang, Z. Tang, W. Tian, C. Wang, C.",
  "X. Sheng, F. Shu, H. Song, Y. Stenkin, V. Stepanov, Y. Su, Q. Sun, X. Sun, Z. Sun, P. Tam, Q. Tang, Z. Tang, W. Tian, C. Wang, C. Wang, G. W. Wang, H. Wang, H. H. Wang, J. C. Wang, K. Wang, L. Wang, L. Y. Wang, P. Wang, R. Wang, W. Wang, X. G. Wang, X. Y. Wang, Y. Wang, Y. Wang, Y. J. Wang, Z. H. Wang, Z. X. Wang, Zhen Wang, Z. Wang, D. Wei, J. Wei, Y. J. Wei, T. Wen, C. Y. Wu, H. Wu, S. Wu, Xin Wu, Y. Wu, S. Xi, J. Xia, J. Xia, G. Xiang, D. Xiao, G. Xiao, G. Xin, Y. Xin, Yangang Xing, Z. Xiong, D. Xu, R. Xu, R. Xu,",
  "Xin Wu, Y. Wu, S. Xi, J. Xia, J. Xia, G. Xiang, D. Xiao, G. Xiao, G. Xin, Y. Xin, Yangang Xing, Z. Xiong, D. Xu, R. Xu, R. Xu, W. Xu, L. Xue, Dong Yan, J. Yan, T. Yan, C. Yang, F. Yang, F. Yang, H. W. Yang, J. Y. Yang, L. L. Yang, M. Yang, R. Yang, S. Yang, Y. Yao, Z. Yao, Y. Ye, L. Yin, N. Yin, X. You, Z. You, Y. Yu, Q. Yuan, H. Yue, H. Zeng, T. Zeng, W. Zeng, M. Zha, B. Zhang, F. Zhang, H. Zhang, H. Zhang, J. Zhang, L. X. Zhang, Li Zhang, P. Zhang, P. Zhang, R. Zhang, S. B. Zhang, S. Zhang, S. Zhang, X. Zhang, X. Zhang, Y. Zhang, Yi.",
  "Zhang, H. Zhang, H. Zhang, J. Zhang, L. X. Zhang, Li Zhang, P. Zhang, P. Zhang, R. Zhang, S. B. Zhang, S. Zhang, S. Zhang, X. Zhang, X. Zhang, Y. Zhang, Yi. Zhang, Yong Zhang, B. Zhao, J. Zhao, Liang Zhao, L. Zhao, S. Zhao, F. Zheng, B. Zhou, H. Zhou, J. Zhou, M. Zhou, P. Zhou, R. Zhou, X. Zhou, C. Zhu, F. Zhu, H. Zhu, K. Zhu, X. Zuo\nVenue: Physical Review Letters\nTldr: None",
  "Faculty Name: eric xing\nMetadata:\nPaperid: b1e645b0028ab543e2f8b823a0aad7ee72091f32\nTitle: Metasurface Deflector Enhanced Grating Coupler for Perfectly Vertical Coupling\nYear: 2023\nAbstract: We propose a perfectly vertical coupling scheme based on metasurface deflectors (meta-deflectors) and grating couplers (GCs). An approach for optimizing the GCs based on the Gaussian-fitting using the genetic algorithm is proposed. An meta-deflector based on amorphous silicon (a-Si) pillars is designed to the optimal coupling angle of the GC to ensure good coupling efficiency (CE). Simulations predict peak vertical CE to be 78% at the wavelength of 2 \u03bcm, with 1 dB bandwidth \u226535 nm. The design process of GC and meta-deflector is provided in detail, and the influence of fabrication error on the CE is analyzed.\nAuthors: Xin Wu, Yang Qiu, Shaonan Zheng, Xingyan Zhao, Yuan Dong, Qize Zhong, L. Jia, Ting Hu\nVenue: Photonics\nTldr: None",
  "Faculty Name: eric xing\nMetadata:\nPaperid: b9ab633b1e9eec9c810627d881da6d172bd2cebe\nTitle: Forest Fire Smoke Detection Research Based on the Random Forest Algorithm and Sub-Pixel Mapping Method\nYear: 2023\nAbstract: In order to locate forest fire smoke more precisely and expand existing forest fire monitoring methods, this research employed Himawari-8 data with a sub-pixel positioning concept in smoke detection. In this study, Himawari-8 data of forest fire smoke in Xichang and Linzhi were selected. An improved sub-pixel mapping method based on random forest results was proposed to realize the identification and sub-pixel positioning of smoke. More spatial details of forest fire smoke were restored in the final results. The continuous monitoring of smoke indicated the dynamic changes therein. The accuracy evaluation of smoke detection was realized using a confusion matrix. Based on the improved sub-pixel mapping method, the overall accuracies were 87.95% and 86.32%. Compared with the raw images, the smoke contours of the improved sub-pixel mapping results were clearer and smoother.",
  "Based on the improved sub-pixel mapping method, the overall accuracies were 87.95% and 86.32%. Compared with the raw images, the smoke contours of the improved sub-pixel mapping results were clearer and smoother. The improved sub-pixel mapping method outperforms traditional classification methods in locating smoke range. Moreover, it especially made a breakthrough in the limitations of the pixel scale and in realizing sub-pixel positioning. Compared with the results of the classic PSA method, there were fewer \u201cspots\u201d and \u201choles\u201d after correction. The final results of this study show higher accuracies of smoke discrimination, with it becoming the basis for another method of forest fire monitoring.\nAuthors: Xihao Li, Gui Zhang, Sanqing Tan, Zhi Yang, Xin Wu\nVenue: Forests\nTldr: None",
  "Faculty Name: eric xing\nMetadata:\nPaperid: cb5bfd9718f2703ad77281980d2050f52d4f6883\nTitle: A Magnetically Controlled Guidewire Robot System with Steering and Propulsion Capabilities for Vascular Interventional Surgery\nYear: 2023\nAbstract: Magnetically manipulated interventional robotic systems offer outstanding advantages for improving vascular interventions, including minimizing radiation exposure to physicians and increasing the controllability of magnetic interventional devices in hard\u2010to\u2010reach vessels. However, automatic control of magnetic guidewires (MGs) is still challenging in terms of modeling of guidewires and trajectory planning. Herein, a magnetically controlled guidewire robotic system (MCGRS) with steering and propulsion capabilities is proposed based on adequate modeling and trajectory planning methods. The steering kinematics of MG is first modeled by constant curvature theory. Then, a continuum mechanics model is built to predict the deformation of the magnetic tip by combining the dipole model and the Cosserat\u2010rod model. Moreover, a trajectory planning algorithm is developed to navigate the MG through vessels.",
  "The steering kinematics of MG is first modeled by constant curvature theory. Then, a continuum mechanics model is built to predict the deformation of the magnetic tip by combining the dipole model and the Cosserat\u2010rod model. Moreover, a trajectory planning algorithm is developed to navigate the MG through vessels. Furthermore, trajectory following experiments within three vascular phantoms confirm that the proposed model and algorithm are reliable and capable of navigating the MG through the desired trajectory. Finally, two extra navigation experiments are implemented in 3D vascular phantom, which show that the MCGRS can be remotely controlled to manipulate the MG to actively steer and reach the target site. The system and methods will build the foundation for automatic control of MG and help to improve the autonomy.",
  "Finally, two extra navigation experiments are implemented in 3D vascular phantom, which show that the MCGRS can be remotely controlled to manipulate the MG to actively steer and reach the target site. The system and methods will build the foundation for automatic control of MG and help to improve the autonomy.\nAuthors: Shixiong Fu, Binghan Chen, Dong Li, Jianguo Han, Sheng Xu, Shu Wang, Chenyang Huang, Ming Qiu, Si Cheng, Xin Wu, Li Zhang, Shiwei Du, Tiantian Xu\nVenue: Advanced Intelligent Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A magnetically controlled guidewire robotic system (MCGRS) with steering and propulsion capabilities is proposed based on adequate modeling and trajectory planning methods that will build the foundation for automatic control of MG and help to improve the autonomy.'}",
  "Faculty Name: eric xing\nMetadata:\nPaperid: cc48851430aca07e19f7f48c1733b009ea654bdf\nTitle: Measurement of the p+He energy spectrum with the DAMPE space mission\nYear: 2023\nAbstract: None\nAuthors: Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, F. de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden,",
  "Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco, M. Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, Luyao Jiang, Wei Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W.",
  "Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, H. Su, Meng Su, H. Sun, Zhigang Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu, Zunlei Xu, G. Xue,",
  "D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hongying Zhao, Xu Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: None",
  "Faculty Name: eric xing\nMetadata:\nPaperid: cd76c60e754330964796ec980528b00ad38346a5\nTitle: Study of hadronic cross-sections with cosmic ray Carbon from GeV to TeV by the DAMPE experiment\nYear: 2023\nAbstract: None\nAuthors: E. Xu, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Y. Cui, I. De Mitri, F. de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, J. Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M.",
  "Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, J. Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, Luyang Jiang, Wei Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu,",
  "Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, Hong-mei Su, Meng Su, H. Sun, Zhigang Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yifeng Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu,",
  "Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yifeng Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hongying Zhao, Xu Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: None",
  "Faculty Name: eric xing\nMetadata:\nPaperid: d1c1061841cf16e8739a582308ea17ae0e8465cf\nTitle: Latest results on searching for fractionally charged particles with the DAMPE experiment\nYear: 2023\nAbstract: The existence of fractionally charged particles (FCP) is foreseen in extensions of or beyond the Standard Model of particle physics. Most of the previously conducted searches for FCPs in cosmic rays were based on experiments underground or at high altitudes. However, there have been few searches for FCPs in cosmic rays carried out in orbit other than AMS-01 flown by a space shuttle and BESS by a balloon at the top of the atmosphere. In this study, we conduct an FCP search in space based on on-orbit data obtained using the Dark Matter Particle Explorer (DAMPE) satellite over a period of five years. Unlike underground experiments, which require an FCP energy of the order of hundreds of GeV, our FCP search starts at only a few GeV. An upper limit of 6 .",
  "Unlike underground experiments, which require an FCP energy of the order of hundreds of GeV, our FCP search starts at only a few GeV. An upper limit of 6 . 2 \u00d7 10 \u2212 10 cm \u2212 2 sr \u2212 1 s \u2212 1 is obtained for the flux. Our results demonstrate that DAMPE exhibits higher sensitivity than experiments of similar types by three orders of magnitude that more stringently restricts the conditions for the existence of FCP in primary cosmic rays.\nAuthors: Chengming Liu, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, Francesco de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz,",
  "P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, Francesco de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, Luyang Jiang, Wei Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo,",
  "Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, Pengxiong Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, H. Su, Meng Su, H. Sun, Zhigang Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yining Wei, Di Wu,",
  "Zhigang Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hong-yun Zhao, Xu Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: None",
  "Faculty Name: eric xing\nMetadata:\nPaperid: d2c03c788ad3fbd6d783cbbc4393c31b1a260691\nTitle: Enhancing the Generalization for Text Classification through Fusion of Backward Features\nYear: 2023\nAbstract: Generalization has always been a keyword in deep learning. Pretrained models and domain adaptation technology have received widespread attention in solving the problem of generalization. They are all focused on finding features in data to improve the generalization ability and to prevent overfitting. Although they have achieved good results in various tasks, those models are unstable when classifying a sentence whose label is positive but still contains negative phrases. In this article, we analyzed the attention heat map of the benchmarks and found that previous models pay more attention to the phrase rather than to the semantic information of the whole sentence. Moreover, we proposed a method to scatter the attention away from opposite sentiment words to avoid a one-sided judgment. We designed a two-stream network and stacked the gradient reversal layer and feature projection layer within the auxiliary network.",
  "Moreover, we proposed a method to scatter the attention away from opposite sentiment words to avoid a one-sided judgment. We designed a two-stream network and stacked the gradient reversal layer and feature projection layer within the auxiliary network. The gradient reversal layer can reverse the gradient of features in the training stage so that the parameters are optimized following the reversed gradient in the backpropagation stage. We utilized an auxiliary network to extract the backward features and then fed them into the main network to merge them with normal features extracted by the main network. We applied this method to the three baselines of TextCNN, BERT, and RoBERTa using sentiment analysis and sarcasm detection datasets. The results show that our method can improve the sentiment analysis datasets by 0.5% and the sarcasm detection datasets by 2.1%.\nAuthors: D. Seng, Xin Wu\nVenue: Italian National Conference on Sensors\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A method to scatter the attention away from opposite sentiment words to avoid a one-sided judgment is proposed and can improve the sentiment analysis datasets by 0.5% and the sarcasm detection datasets by 2.1%.'}",
  "Faculty Name: eric xing\nMetadata:\nPaperid: d9bbc9aca54ea5c62a7a91c1a763789ba259975f\nTitle: Evaluation of hydraulic fracturing of horizontal wells in tight reservoirs based on the deep neural network with physical constraints\nYear: 2023\nAbstract: None\nAuthors: H. Qu, Jian-long Zhang, Fu-Jian Zhou, Yan Peng, Zhengfu Pan, Xin Wu\nVenue: Petroleum Science\nTldr: None",
  "Faculty Name: eric xing\nMetadata:\nPaperid: da07ca45e25c0a632f5b66ad63358e98a8d70af6\nTitle: Exploring Fundamental Particle Acceleration and Loss Processes in Heliophysics through an Orbiting X-ray Instrument in the Jovian System\nYear: 2023\nAbstract: Jupiter's magnetosphere is considered to be the most powerful particle accelerator in the Solar System, accelerating electrons from eV to 70 MeV and ions to GeV energies. How electromagnetic processes drive energy and particle flows, producing and removing energetic particles, is at the heart of Heliophysics. Particularly, the 2013 Decadal Strategy for Solar and Space Physics was to\"Discover and characterize fundamental processes that occur both within the heliosphere and throughout the universe\". The Jovian system offers an ideal natural laboratory to investigate all of the universal processes highlighted in the previous Decadal. The X-ray waveband has been widely used to remotely study plasma across astrophysical systems. The majority of astrophysical emissions can be grouped into 5 X-ray processes: fluorescence, thermal/coronal, scattering, charge exchange and particle acceleration.",
  "The X-ray waveband has been widely used to remotely study plasma across astrophysical systems. The majority of astrophysical emissions can be grouped into 5 X-ray processes: fluorescence, thermal/coronal, scattering, charge exchange and particle acceleration. The Jovian system offers perhaps the only system that presents a rich catalog of all of these X-ray emission processes and can also be visited in-situ, affording the special possibility to directly link fundamental plasma processes with their resulting X-ray signatures. This offers invaluable ground-truths for astrophysical objects beyond the reach of in-situ exploration (e.g. brown dwarfs, magnetars or galaxy clusters that map the cosmos). Here, we show how coupling in-situ measurements with in-orbit X-ray observations of Jupiter's radiation belts, Galilean satellites, Io Torus, and atmosphere addresses fundamental heliophysics questions with wide-reaching impact across helio- and astrophysics. New developments like miniaturized X-ray optics and radiation-tolerant detectors, provide compact, lightweight, wide-field X-ray instruments perfectly suited to the Jupiter system, enabling this exciting new possibility.",
  "New developments like miniaturized X-ray optics and radiation-tolerant detectors, provide compact, lightweight, wide-field X-ray instruments perfectly suited to the Jupiter system, enabling this exciting new possibility.\nAuthors: William Dunn, G. Berland, E. Roussos, George Clark, P. Kollmann, D. Turner, Charly Feldman, Tom Stallard, G. Branduardi\u2010Raymont, E. Woodfield, I. J. Rae, L. Ray, J. Carter, Simon Lindsay, Zhonghua Yao, Robert Marshall, A. Jaynes, Y. Ezoe, M. Numazawa, G. Hospodarsky, Xin Wu, D. Weigt, C. Jackman, K. Mori, Q. N\u00e9non, R. Desai, L. Blum, T. Nordheim, Jan-Uwe Ness, Dennis Bodewits, T. Kimura, Wen Li, H. Smith, Dimitrios Millas, A. Wibisono, N. Achilleos, D. Koutroumpa, S. McEntee, H. Collier, Anil Bhardwaj, A. Martindale, S. Wolk, S. Badman, Ralph P. Kraft\nVenue: Vol.",
  "55, Issue 3 (Heliophysics 2024 Decadal Whitepapers)\nTldr: None",
  "Faculty Name: eric xing\nMetadata:\nPaperid: dcb4f2b9b0e6da0d629878d1ad0469aee3df2020\nTitle: Understanding Masked Autoencoders via Hierarchical Latent Variable Models\nYear: 2023\nAbstract: Masked autoencoder (MAE), a simple and effective self-supervised learning framework based on the reconstruction of masked image regions, has recently achieved prominent success in a variety of vision tasks. Despite the emergence of intriguing empirical observations on MAE, a theoretically principled understanding is still lacking. In this work, we formally characterize and justify existing empirical in-sights and provide theoretical guarantees of MAE. We formulate the underlying data-generating process as a hierarchical latent variable model, and show that under reasonable assumptions, MAE provably identifies a set of latent variables in the hierarchical model, explaining why MAE can extract high-level information from pixels. Further, we show how key hyperparameters in MAE (the masking ratio and the patch size) determine which true latent variables to be recovered, therefore influencing the level of semantic information in the representation. Specifically, extremely large or small masking ratios inevitably lead to low-level representations.",
  "Further, we show how key hyperparameters in MAE (the masking ratio and the patch size) determine which true latent variables to be recovered, therefore influencing the level of semantic information in the representation. Specifically, extremely large or small masking ratios inevitably lead to low-level representations. Our theory offers coherent explanations of existing empirical observations and provides insights for potential empirical improvements and fundamental limitations of the masked-reconstruction paradigm. We conduct extensive experiments to validate our theoretical insights.\nAuthors: Lingjing Kong, Martin Q. Ma, Guan-Hong Chen, E. Xing, Yuejie Chi, Louis-Philippe Morency, Kun Zhang\nVenue: Computer Vision and Pattern Recognition\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work formally characterize and justify existing empirical in-sights and provide theoretical guarantees of MAE, and formulate the underlying data-generating process as a hierarchical latent variable model, and shows that under reasonable assumptions, MAE provably identifies a set of latent variables in the hierarchical model.'}",
  "Faculty Name: eric xing\nMetadata:\nPaperid: e6dbe34d154591618ef78d56d5e8a50583b5f9d1\nTitle: Contextualized Networks Reveal Heterogeneous Transcriptomic Regulation in Tumors at Sample-Specific Resolution\nYear: 2023\nAbstract: Cancers are shaped by somatic mutations, microenvironment, and patient background, each altering gene expression and regulation in complex ways, resulting in heterogeneous cellular states and dynamics. Inferring gene regulatory network (GRN) models from expression data can help characterize this regulation-driven heterogeneity, but network inference requires many statistical samples, traditionally limiting GRNs to cluster-level analyses that ignore intra-cluster heterogeneity. We propose to move beyond cluster-based analyses by using contextualized learning, a multi-task learning paradigm which allows us to infer sample-specific models using phenotypic, molecular, and environmental information pertinent to the model, encoded as the model\u2019s \u201ccontext\u201d to be conditioned on.",
  "We propose to move beyond cluster-based analyses by using contextualized learning, a multi-task learning paradigm which allows us to infer sample-specific models using phenotypic, molecular, and environmental information pertinent to the model, encoded as the model\u2019s \u201ccontext\u201d to be conditioned on. We unify three network model classes (Correlation, Markov, Neighborhood) and estimate context-specific GRNs for 7997 tumors across 25 tumor types, with each network contextualized by copy number and driver mutation profiles, tumor microenvironment, and patient demographics. Contextualized GRNs provide a structured view of expression dynamics at sample-specific resolution, which reveal co-expression modules in correlation networks (CNs), as well as cliques and independent regulatory elements in Markov Networks (MNs) and Neighborhood Regression Networks (NNs). Our generative modeling approach allows us to predict GRNs for unseen tumor types based on a pan-cancer model of how somatic mutations affect gene regulation. Finally, contextualized networks enable GRN-based precision oncology, explaining known biomarkers in terms of network-mediated effects, and leading to novel subtypings for thyroid, brain, and gastrointestinal tumors that improve survival prognosis.",
  "Finally, contextualized networks enable GRN-based precision oncology, explaining known biomarkers in terms of network-mediated effects, and leading to novel subtypings for thyroid, brain, and gastrointestinal tumors that improve survival prognosis.\nAuthors: Caleb N. Ellington, B. Lengerich, Thomas B.K. Watkins, Jie-Ying Yang, Hanxi Xiao, M. Kellis, Eric P. Xing\nVenue: bioRxiv\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Contextualized networks enable GRN-based precision oncology, explaining known biomarkers in terms of network-mediated effects, and leading to novel subtypings for thyroid, brain, and gastrointestinal tumors that improve survival prognosis.'}",
  "Faculty Name: eric xing\nMetadata:\nPaperid: e7e497e0a5dc0d1d8be63cbba1b361ff6964dd25\nTitle: Forest Cover Change Monitoring Using Sub-Pixel Mapping with Edge-Matching Correction\nYear: 2023\nAbstract: Sentinel-2 serves as a crucial data source for monitoring forest cover change. In this study, a sub-pixel mapping of forest cover is performed on Sentinel-2 images, downscaling the spatial resolution of the positioned results to 2.5 m, enabling sub-pixel-level forest cover monitoring. A novel sub-pixel mapping with edge-matching correction is proposed on the basis of the Sentinel-2 images, combining edge-matching technology to extract the forest boundary of Jilin-1 images at sub-meter level as spatial constraint information for sub-pixel mapping. This approach enables accurate mapping of forest cover, surpassing traditional pixel-level monitoring in terms of accuracy and robustness. The corrected mapping method allows more spatial detail to be restored at forest boundaries, monitoring forest changes at a smaller scale, which is highly similar to actual forest boundaries on the surface.",
  "This approach enables accurate mapping of forest cover, surpassing traditional pixel-level monitoring in terms of accuracy and robustness. The corrected mapping method allows more spatial detail to be restored at forest boundaries, monitoring forest changes at a smaller scale, which is highly similar to actual forest boundaries on the surface. The overall accuracy of the modified sub-pixel mapping method reaches 93.15%, an improvement of 1.96% over the conventional Sub-pixel-pixel Spatial Attraction Model (SPSAM). Additionally, the kappa coefficient improved by 0.15 to reach 0.892 during the correction. In summary, this study introduces a new method of forest cover monitoring, enhancing the accuracy and efficiency of acquiring forest resource information. This approach provides a fresh perspective in the field of forest cover monitoring, especially for monitoring small deforestation and forest degradation activities.",
  "In summary, this study introduces a new method of forest cover monitoring, enhancing the accuracy and efficiency of acquiring forest resource information. This approach provides a fresh perspective in the field of forest cover monitoring, especially for monitoring small deforestation and forest degradation activities.\nAuthors: Siran Xia, Zhi Yang, Gui Zhang, Xin Wu\nVenue: Forests\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A new method of forest cover monitoring is introduced, enhancing the accuracy and efficiency of acquiring forest resource information and combining edge-matching technology to extract the forest boundary of Jilin-1 images at sub-meter level as spatial constraint information for sub-pixel mapping.'}",
  "Faculty Name: eric xing\nMetadata:\nPaperid: ec772c1f1a994d0377030e3110adc00263b31cfc\nTitle: Analysis of cosmic lithium, beryllium and boron with the DAMPE mission\nYear: 2023\nAbstract: None\nAuthors: A. Parenti, Zhan-Fang Chen, I. De Mitri, M. Stolpovskiy, Li Wu, E. Xu, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, Francesco de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang,",
  "Francesco de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, Luyang Jiang, Wei Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N.",
  "X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, H. Su, Meng Su, H. Sun, Zhigang Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, Sha Wu, Xin Wu, Z. Xia, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu, Zunlei Xu, G. Xue,",
  "Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, Sha Wu, Xin Wu, Z. Xia, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hongying Zhao, Xu Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: None",
  "Faculty Name: eric xing\nMetadata:\nPaperid: ec9b461093bbcdccfec86052f7b815547b0650dd\nTitle: Energy-dependent polarization of Gamma-Ray Bursts' prompt emission with the POLAR and POLAR-2 instruments\nYear: 2023\nAbstract: Gamma-Ray Bursts are among the most powerful events in the Universe. Despite half a century of observations of these transient sources, many open questions remain about their nature. Polarization measurements of the GRB prompt emission have long been theorized to be able to answer most of these questions. With the aim of characterizing the polarization of these prompt emissions, a compact Compton polarimeter, called POLAR, has been launched to space in September 2016. Time integrated polarization analysis of the POLAR GRB catalog have shown that the prompt emission is lowly polarized or fully unpolarized. However, time resolved analysis depicted strong hints of an evolving polarization angle within single pulses, washing out the polarization degree in time integrated analyses. Here we will for the first time present energy resolved polarization measurements with the POLAR data.",
  "However, time resolved analysis depicted strong hints of an evolving polarization angle within single pulses, washing out the polarization degree in time integrated analyses. Here we will for the first time present energy resolved polarization measurements with the POLAR data. The novel analysis, performed on several GRBs, will provide new insights and alter our understanding of GRB polarization. The analysis was performed using the 3ML framework to fit polarization parameters versus energy in parallel to the spectral parameters. Although limited by statistics, the results could provide a very relevant input to disentangle between existing theoretical models. In order to gather more statistics per GRB and perform joint time and energy resolved analysis, a successor instrument, called POLAR-2, is under development with a launch window early 2025 to the CSS. After presenting the first energy resolved polarization results of the POLAR mission, we will present the prospects for such measurements with the upcoming POLAR-2 mission.",
  "After presenting the first energy resolved polarization results of the POLAR mission, we will present the prospects for such measurements with the upcoming POLAR-2 mission.\nAuthors: Nicolas De Angelis, J. Burgess, F. Cadoux, J. Greiner, M. Kole, Hancheng Li, S. Mianowski, A. Pollo, Nicolas Produit, D. Rybka, Jianchao Sun, Xin Wu, S. Zhang\nVenue: International Conference on Rebooting Computing\nTldr: None",
  "Faculty Name: eric xing\nMetadata:\nPaperid: fdf9f4c09451e847e0bd1b251621ca56e0eb491b\nTitle: Memory-adaptive Depth-wise Heterogenous Federated Learning\nYear: 2023\nAbstract: Federated learning is a promising paradigm that allows multiple clients to collaboratively train a model without sharing the local data. However, the presence of heterogeneous devices in federated learning, such as mobile phones and IoT devices with varying memory capabilities, would limit the scale and hence the performance of the model could be trained. The mainstream approaches to address memory limitations focus on width-slimming techniques, where different clients train subnetworks with reduced widths locally and then the server aggregates the subnetworks. The global model produced from these methods suffers from performance degradation due to the negative impact of the actions taken to handle the varying subnetwork widths in the aggregation phase. In this paper, we introduce a memory-adaptive depth-wise learning solution in FL called FeDepth, which adaptively decomposes the full model into blocks according to the memory budgets of each client and trains blocks sequentially to obtain a full inference model.",
  "In this paper, we introduce a memory-adaptive depth-wise learning solution in FL called FeDepth, which adaptively decomposes the full model into blocks according to the memory budgets of each client and trains blocks sequentially to obtain a full inference model. Our method outperforms state-of-the-art approaches, achieving 5% and more than 10% improvements in top-1 accuracy on CIFAR-10 and CIFAR-100, respectively. We also demonstrate the effectiveness of depth-wise fine-tuning on ViT. Our findings highlight the importance of memory-aware techniques for federated learning with heterogeneous devices and the success of depth-wise training strategy in improving the global model's performance.\nAuthors: Kai Zhang, Yutong Dai, Hongyi Wang, Eric P. Xing, Xun Chen, Lichao Sun\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A memory-adaptive depth-wise learning solution in FL called FeDepth, which adaptively decomposes the full model into blocks according to the memory budgets of each client and trains blocks sequentially to obtain a full inference model, which outperforms state-of-the-art approaches.'}",
  "List of 2023 Open Access papers by eric xing are:\nSlimPajama-DC: Understanding Data Combinations for LLM Training\nFusing Models with Complementary Expertise\nMaking Scalable Meta Learning Practical\n3D Open-vocabulary Segmentation with Foundation Models\nSqueeze, Recover and Relabel: Dataset Condensation at ImageNet Scale From A New Perspective\nOne-for-All: Generalized LoRA for Parameter-Efficient Fine-tuning\nDefending Against Malicious Behaviors in Federated Learning with Blockchain\nImproved Logical Reasoning of Language Models via Differentiable Symbolic Programming\nJais and Jais-chat: Arabic-Centric Foundation and Instruction-Tuned Open Generative Large Language Models\nKD-DLGAN: Data Limited Image Generation via Knowledge Distillation\n3D Semantic Segmentation in the Wild: Learning Generalized Models for Adverse-Condition Point Clouds\nCuttlefish: Low-Rank Model Training without All the Tuning\nDoes compressing activations help model parallel training?",
  "Federated Learning as Variational Inference: A Scalable Expectation Propagation Approach\nMemory-adaptive Depth-wise Heterogenous Federated Learning\nIdentification of Nonlinear Latent Hierarchical Models\nStyleRF: Zero-Shot 3D Style Transfer of Neural Radiance Fields\nJudging LLM-as-a-judge with MT-Bench and Chatbot Arena\nUnderstanding Masked Autoencoders via Hierarchical Latent Variable Models\nLightSeq: Sequence Level Parallelism for Distributed Training of Long Context Transformers\nLMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset\nFedNAR: Federated Optimization with Normalized Annealing Regularization\nUS residents' preferences for sharing of electronic health record and genetic information: a discrete choice experiment.",
  "Contextualized Policy Recovery: Modeling and Interpreting Medical Decisions with Adaptive Imitation Learning\nGET: a foundation model of transcription across human cell types\nContextualized Networks Reveal Heterogeneous Transcriptomic Regulation in Tumors at Sample-Specific Resolution\nResearch on the Training Path of Live E-commerce Talents Oriented by Industry Development\nRecent progresses on the gamma-ray observations of DAMPE\nEffective Multi-Agent Deep Reinforcement Learning Control with Relative Entropy Regularization\nConvolutional Neural Network Measurement of Non-Fiducial Electrons Cosmic-Rays Using the DAMPE Experiment.",
  "Visible and Infrared Image Fusion of Forest Fire Scenes Based on Generative Adversarial Networks with Multi-Classification and Multi-Level Constraints\nThe split delivery vehicle routing problem with time windows and three-dimensional loading constraints\nA Novel Definition of Fuzzy Difference on Non-increasing Fuzzy Real Numbers\nAnalysis of Individual Cosmic-Ray Proton and Helium Fluxes towards PeV Energies with DAMPE\nThe First LHAASO Catalog of Gamma-Ray Sources\nMachine Learning for Predicting Forest Fire Occurrence in Changsha: An Innovative Investigation into the Introduction of a Forest Fuel Factor\nViT-Based Terrain Recognition System for wearable soft exosuit\nCarbon Flux with DAMPE Using Machine Learning Methods\nAcupuncture Alleviates CUMS-Induced Depression-Like Behaviors by Restoring Prefrontal Cortex Neuroplasticity\nInfluence of sensor array on MS/AE source location accuracy in rock mass\nGpr35 shapes gut microbial ecology to modulate hepatic steatosis.\nAn innovative divertor concept, the fish tail divertor,",
  "An innovative divertor concept, the fish tail divertor, for reducing the surface temperature on the divertor target plate in EAST tokamak experiments\nSpecial issue on wearable robots and intelligent device\nThe response linearity of energy measurement up to TeV in the DAMPE experiment\nCharacterization of Asphaltene Deposition Behavior in Diluted Heavy Oil under High-Pressure Conditions\nPractical Probabilistic Model-based Deep Reinforcement Learning by Integrating Dropout Uncertainty and Trajectory Sampling\nRealization of thousand-second improved confinement plasma with Super I-mode in Tokamak EAST\nA new anti-colon cancer tumor pathway of Phenyllactic acid by reducing adhesion of Fusobacterium nucleatum\nPoverty Alleviation Resettlement and Household Natural Resources Dependence: A Case Study from Ankang Prefecture,",
  "China\nA study of Forbush Decreases effects with DAMPE experiment\nDirect measurement of Ne-Mg-Si nuclei in cosmic rays with DAMPE\nProbing hadronic cross sections in the TeV - PeV regime with DAMPE through machine learning techniques\nPoint-like Source Catalog Observed by DAMPE\nDArk Matter Particle Explorer: 7 years in Space\nObservational signatures of Schwarzschild-MOG black holes in scalar\u2013tensor\u2013vector gravity: images of the accretion disk\nEvaluating emotional labor from a career management perspective\nPenetrating particle ANalyzer (PAN)\nPOLAR-2,",
  "the next generation of GRB polarization detector\nMeasurement of Heavy Nulei beyond Iron in Cosmic Rays with the DAMPE Experiment\nRecent Advances in Decellularized Extracellular Matrix-Based Bioinks for 3D Bioprinting in Tissue Engineering\nEvaluation of thermal comfort in air-conditioned rooms based on structure/control-related parameters and data-mining method\nEffects of Coupling Constants on Chaos of Charged Particles in the Einstein\u2013\u00c6ther Theory\nA PCA-based Method for Electron-Proton Discrimination of the DAMPE Experiment\nCosmic Ray Carbon and Oxygen Flux Measurements with the DAMPE Experiment\nErratum: New insight into the shape coexistence and shape evolution of \n<mml:math xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"><mml:mmultiscripts><mml:mi>Yb</mml:mi><mml:mprescripts /><mml:none /><mml:mn>157</mml:mn></mml:mmultiscripts></mml:math>\n [Phys. Rev.",
  "Rev. C \n<b>83</b>\n, 014318 (2011)]\nApplicability of the 0\u20131 test for chaos in magnetized Kerr\u2013Newman spacetimes\nMeasurements of the boron-to-carbon and boron-to-oxygen flux ratios in cosmic rays with DAMPE\nIntegrating symbol similarities with knowledge\u00a0graph embedding for entity alignment: an unsupervised framework\nMeasurement of Ultra-High-Energy Diffuse Gamma-Ray Emission of the Galactic Plane from 10\u00a0TeV to 1\u00a0PeV with LHAASO-KM2A.",
  "Metasurface Deflector Enhanced Grating Coupler for Perfectly Vertical Coupling\nForest Fire Smoke Detection Research Based on the Random Forest Algorithm and Sub-Pixel Mapping Method\nA Magnetically Controlled Guidewire Robot System with Steering and Propulsion Capabilities for Vascular Interventional Surgery\nMeasurement of the p+He energy spectrum with the DAMPE space mission\nStudy of hadronic cross-sections with cosmic ray Carbon from GeV to TeV by the DAMPE experiment\nLatest results on searching for fractionally charged particles with the DAMPE experiment\nEnhancing the Generalization for Text Classification through Fusion of Backward Features\nEvaluation of hydraulic fracturing of horizontal wells in tight reservoirs based on the deep neural network with physical constraints\nExploring Fundamental Particle Acceleration and Loss Processes in Heliophysics through an Orbiting X-ray Instrument in the Jovian System\nForest Cover Change Monitoring Using Sub-Pixel Mapping with Edge-Matching Correction\nAnalysis of cosmic lithium, beryllium and boron with the DAMPE mission\nEnergy-dependent polarization of Gamma-Ray Bursts' prompt emission with the POLAR and POLAR-2 instruments",
  "Name: Malihe    Alikhani\nDesignation: Assistant Professor, Northeastern University\nLinks: alikhani-malihe.html, alikhani-malihe.html, alikhani-malihe.html\n\nName: Taylor    Berg-Kirkpatrick\nDesignation: Assistant Professor, University of California, San Diego\nLinks: berg-kirkpatrick-taylor.html, berg-kirkpatrick-taylor.html, berg-kirkpatrick-taylor.html\n\nName: Jeffrey    Bigham\nDesignation: Associate Professor\nLinks: bigham-jeffrey.html, bigham-jeffrey.html, bigham-jeffrey.html\n\nName: Yonatan    Bisk\nDesignation: Assistant Professor\nLinks: bisk-yonatan.html, bisk-yonatan.html, bisk-yonatan.html\n\nName: Ralf    Brown\nDesignation: Senior Systems Scientist/Chair of Admissions\nLinks: brown-ralf.html, brown-ralf.html, brown-ralf.html\n\nName: Jamie     Callan\nDesignation: Professor\nLinks: callan-jamie.html, callan-jamie.html,",
  "html, brown-ralf.html, brown-ralf.html\n\nName: Jamie     Callan\nDesignation: Professor\nLinks: callan-jamie.html, callan-jamie.html, callan-jamie.html\n\nName: Justine    Cassell\nDesignation: Professor (On Leave)\nLinks: cassell-justine.html, cassell-justine.html, cassell-justine.html\n\nName: William    Cohen\nDesignation: Director of Research Engineering, Google AI\nLinks: cohen-william.html, cohen-william.html, cohen-william.html\n\nName: Mona    Diab\nDesignation: LTI Director and Tenured Professor\nLinks: diab-mona.html, diab-mona.html, diab-mona.html\n\nName: Fernando    Diaz\nDesignation: Associate Professor\nLinks: diaz-fernando.html, diaz-fernando.html, diaz-fernando.html\n\nName: Christopher    Dyer\nDesignation: Senior Staff Scientist, DeepMind\nLinks: dyer-christopher.html, dyer-christopher.html,",
  "html, diaz-fernando.html, diaz-fernando.html\n\nName: Christopher    Dyer\nDesignation: Senior Staff Scientist, DeepMind\nLinks: dyer-christopher.html, dyer-christopher.html, dyer-christopher.html\n\nName: Scott    Fahlman\nDesignation: Professor Emeritus\nLinks: fahlman-scott.html, fahlman-scott.html, fahlman-scott.html\n\nName: Robert    Frederking\nDesignation: Associate Dean for PhD Programs and Chair for MLT Program\nLinks: frederking-robert.html, frederking-robert.html, frederking-robert.html\n\nName: Daniel    Fried\nDesignation: Assistant Professor\nLinks: fried-daniel.html, fried-daniel.html, fried-daniel.html\n\nName: Madhavi    Ganapathiraju\nDesignation: Associate Professor, University of Pittsburgh\nLinks: ganapathiraju-madhavi.html, ganapathiraju-madhavi.html, ganapathiraju-madhavi.",
  "html, fried-daniel.html\n\nName: Madhavi    Ganapathiraju\nDesignation: Associate Professor, University of Pittsburgh\nLinks: ganapathiraju-madhavi.html, ganapathiraju-madhavi.html, ganapathiraju-madhavi.html\n\nName: Matt    Gormley\nDesignation: Assistant Teaching Professor\nLinks: gormley-matt.html, gormley-matt.html, gormley-matt.html\n\nName: Matthias    Grabmair\nDesignation: Assistant Professor, Technical University of Munich, Germany\nLinks: grabmair-matthias.html, grabmair-matthias.html, grabmair-matthias.html\n\nName: Alexander    Hauptmann\nDesignation: Research Professor\nLinks: hauptmann-alexander.html, hauptmann-alexander.html, hauptmann-alexander.html\n\nName: Daphne    Ippolito\nDesignation: Assistant Professor\nLinks: ippolito-daphne.html, ippolito-daphne.html, ippolito-daphne.",
  "html, hauptmann-alexander.html\n\nName: Daphne    Ippolito\nDesignation: Assistant Professor\nLinks: ippolito-daphne.html, ippolito-daphne.html, ippolito-daphne.html\n\nName: Lu    Jiang\nDesignation: Staff Research Scientist, Google\nLinks: jiang-lu.html, jiang-lu.html, jiang-lu.html\n\nName: Alon    Lavie\nDesignation: Consulting Professor\nLinks: lavie-alon.html, lavie-alon.html, lavie-alon.html\n\nName: Lori    Levin\nDesignation: Research Professor\nLinks: levin-lori.html, levin-lori.html, levin-lori.html\n\nName: Lei    Li\nDesignation: Assistant Professor\nLinks: bio.html, bio.html, bio.html\n\nName: Brian    MacWhinney\nDesignation: Professor (On Leave)\nLinks: macwhinney-brian.html, macwhinney-brian.html, macwhinney-brian.",
  "html, bio.html, bio.html\n\nName: Brian    MacWhinney\nDesignation: Professor (On Leave)\nLinks: macwhinney-brian.html, macwhinney-brian.html, macwhinney-brian.html\n\nName: Michael    Mauldin\nDesignation: Adjunct Research Computer Scientist\nLinks: mauldin-michael.html, mauldin-michael.html, mauldin-michael.html\n\nName: Florian    Metze\nDesignation: Adjunct Professor\nLinks: metze-florian.html, metze-florian.html, metze-florian.html\n\nName: Teruko    Mitamura\nDesignation: Research Professor\nLinks: mitamura-teruko.html, mitamura-teruko.html, mitamura-teruko.html\n\nName: Tom    Mitchell\nDesignation: E. Fredkin University Professor\nLinks: mitchell-tom.html, mitchell-tom.html, mitchell-tom.html\n\nName: Louis-Philippe     Morency\nDesignation: Leonardo Associate Professor of Computer Science (On Leave)\nLinks: morency-louis-philippe.html,",
  "html, mitchell-tom.html, mitchell-tom.html\n\nName: Louis-Philippe     Morency\nDesignation: Leonardo Associate Professor of Computer Science (On Leave)\nLinks: morency-louis-philippe.html, morency-louis-philippe.html, morency-louis-philippe.html\n\nName: David    Mortensen\nDesignation: Assistant Research Professor\nLinks: mortensen-david.html, mortensen-david.html, mortensen-david.html\n\nName: Jack    Mostow\nDesignation: Research Professor Emeritus\nLinks: mostow-jack.html, mostow-jack.html, mostow-jack.html\n\nName: Graham    Neubig\nDesignation: Associate Professor\nLinks: neubig-graham.html, neubig-graham.html, neubig-graham.html\n\nName: Eric    Nyberg\nDesignation: Professor\nLinks: nyberg-eric.html, nyberg-eric.html, nyberg-eric.html\n\nName: Kemal    Oflazer\nDesignation: Teaching Professor\nLinks: oflazer-kemal.html,",
  "html\n\nName: Eric    Nyberg\nDesignation: Professor\nLinks: nyberg-eric.html, nyberg-eric.html, nyberg-eric.html\n\nName: Kemal    Oflazer\nDesignation: Teaching Professor\nLinks: oflazer-kemal.html, oflazer-kemal.html, oflazer-kemal.html\n\nName: Bhiksha    Raj\nDesignation: Professor\nLinks: raj-bhiksha.html, raj-bhiksha.html, raj-bhiksha.html\n\nName: Raj    Reddy\nDesignation: Moza Bint Nasser University Professor\nLinks: reddy-raj.html, reddy-raj.html, reddy-raj.html\n\nName: Roni    Rosenfeld\nDesignation: Professor\nLinks: rosenfeld-roni.html, rosenfeld-roni.html, rosenfeld-roni.html\n\nName: Carolyn    Ros\u00e9\nDesignation: Professor\nLinks: ros\u00e9-carolyn.html, ros\u00e9-carolyn.html, ros\u00e9-carolyn.",
  "html, rosenfeld-roni.html, rosenfeld-roni.html\n\nName: Carolyn    Ros\u00e9\nDesignation: Professor\nLinks: ros\u00e9-carolyn.html, ros\u00e9-carolyn.html, ros\u00e9-carolyn.html\n\nName: Alexander    Rudnicky\nDesignation: Research Professor Emeritus\nLinks: rudnicky-alexander.html, rudnicky-alexander.html, rudnicky-alexander.html\n\nName: Norman    Sadeh\nDesignation: Professor\nLinks: sadeh-norman.html, sadeh-norman.html, sadeh-norman.html\n\nName: Maarten    Sap\nDesignation: Assistant Professor\nLinks: sap-maarten.html, sap-maarten.html, sap-maarten.html\n\nName: Thomas    Schaaf\nDesignation: Principal Research Scientist, 3M | M*Modal\nLinks: schaaf-thomas.html, schaaf-thomas.html, schaaf-thomas.html\n\nName: Michael    Shamos\nDesignation: Distinguished Career Professor\nLinks: shamos-michael.html, shamos-michael.",
  "3M | M*Modal\nLinks: schaaf-thomas.html, schaaf-thomas.html, schaaf-thomas.html\n\nName: Michael    Shamos\nDesignation: Distinguished Career Professor\nLinks: shamos-michael.html, shamos-michael.html, shamos-michael.html\n\nName: Rita    Singh\nDesignation: Associate Research Professor\nLinks: singh-rita.html, singh-rita.html, singh-rita.html\n\nName: Ravi    Starzl\nDesignation: Adjunct Professor\nLinks: starzl-ravi.html, starzl-ravi.html, starzl-ravi.html\n\nName: Richard    Stern\nDesignation: Professor\nLinks: stern-richard.html, stern-richard.html, stern-richard.html\n\nName: Emma    Strubell\nDesignation: Assistant Professor\nLinks: strubell-emma.html, strubell-emma.html, strubell-emma.html\n\nName: Yulia    Tsvetkov\nDesignation: Assistant Professor, University of Washington\nLinks: tsvetkov-yulia.html, tsvetkov-yulia.",
  "html, strubell-emma.html, strubell-emma.html\n\nName: Yulia    Tsvetkov\nDesignation: Assistant Professor, University of Washington\nLinks: tsvetkov-yulia.html, tsvetkov-yulia.html, tsvetkov-yulia.html\n\nName: Alexander    Waibel\nDesignation: Professor (On Leave)\nLinks: waibel-alexander.html, waibel-alexander.html, waibel-alexander.html\n\nName: Shinji    Watanabe\nDesignation: Associate Professor\nLinks: watanabe-shinji.html, watanabe-shinji.html, watanabe-shinji.html\n\nName: Sean    Welleck\nDesignation: Assistant Professor\nLinks: welleck-sean.html, welleck-sean.html, welleck-sean.html\n\nName: Monika    Woszczyna\nDesignation: Head of Speech Technology Group, Multimodal Technologies Inc.",
  "html, welleck-sean.html, welleck-sean.html\n\nName: Monika    Woszczyna\nDesignation: Head of Speech Technology Group, Multimodal Technologies Inc.\nLinks: woszczyna-monika.html, woszczyna-monika.html, woszczyna-monika.html\n\nName: Eric  P.  Xing\nDesignation: Professor (On Leave)\nLinks: xing-eric.html, xing-eric.html, xing-eric.html\n\nName: Chenyan    Xiong\nDesignation: Associate Professor\nLinks: xiong-chenyan.html, xiong-chenyan.html, xiong-chenyan.html\n\nName: Yiming    Yang\nDesignation: Professor\nLinks: yiming-yang.html, yiming-yang.html, yiming-yang.html",
  "Title: Scott Fahlman -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Scott Fahlman, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Core Faculty\" name=\"categories-1\"/>\n<meta content=\"AI;Knowledge Representation and Reasoning;Natural Language Processing and Computational Linguistics\" name=\"categories-2\"/>\n<meta content=\"Yes\" name=\"show-categories-2\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Scott Fahlman - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Scott Fahlman, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Scott\"/>\n<meta content=\"Lastname\" property=\"profile:Fahlman\"/>\n<meta content=\"http://lti.",
  "Faculty Member at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Scott\"/>\n<meta content=\"Lastname\" property=\"profile:Fahlman\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/fahlman-scott.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nScott \n                        Fahlman\nProfessor Emeritus, Language Technologies Institute\nComputer Science Department\nContact\n6417 \u2014Gates & Hillman Centers\nsef(through)cs.cmu.edu\n412-268-2575\nResearch Area\nAI, Knowledge Representation and Reasoning, Natural Language Processing and Computational Linguistics\nResearch\nI am interested in artificial intelligence and its application to real-world problems.",
  "cmu.edu\n412-268-2575\nResearch Area\nAI, Knowledge Representation and Reasoning, Natural Language Processing and Computational Linguistics\nResearch\nI am interested in artificial intelligence and its application to real-world problems. Over the years, I have worked in many areas of AI, including knowledge representation, planning, image processing, machine learning, massively parallel approaches to search and inference, and the development of improved learning algorithms for artificial neural networks.\nMy current project is Scone, an open-source knowledge representation system and inference engine that can be used as a component in a variety of knowledge-based systems. Scone puts particular emphasis on efficiency, scalability (up to millions of entities and statements) and ease of use. One goal of our research is to support natural-language understanding, all the way from text or speech to a language-independent representation that we can reason about. This requires extensive use of background knowledge not included in the text itself. We are also working to extend Scone's capabilities for \"episodic\" representation and reasoning, by which we mean actions, events, sequences of actions, plans, goals and explanations.\nI have also worked on programming languages and software-development environments that support an incremental, evolutionary software-development style.",
  "We are also working to extend Scone's capabilities for \"episodic\" representation and reasoning, by which we mean actions, events, sequences of actions, plans, goals and explanations.\nI have also worked on programming languages and software-development environments that support an incremental, evolutionary software-development style. This work has been done in Common Lisp, Dylan and Java.\n\nLinks:",
  "Faculty Name: fernando diaz\nMetadata:\nPaperid: 023ea96250244e082b961657a95545638d9f8329\nTitle: Cost analysis of three-dimensional radiation therapy versus intensity-modulated chemoradiotherapy for locally advanced cervical cancer in Peruvian citizens\nYear: 2023\nAbstract: Background and objectives The standard treatment for locally advanced cervical cancer (CC) is chemoradiotherapy (CTRT) followed by high-dose-rate brachytherapy (HDRBT). The ideal scenario would be under novel intensity-modulated radiation therapy (IMRT) volumetric-modulated arc therapy (VMAT) radiation techniques over three-dimensional (3D) radiation therapy. However, radiotherapy (RT) centres in low- and middle-income countries have limited equipment for teletherapy services like HDRBT. This is why the 3D modality is still in use. The objective of this study was to analyse costs in a comparison of 3D versus IMRT versus VMAT based on clinical staging.",
  "This is why the 3D modality is still in use. The objective of this study was to analyse costs in a comparison of 3D versus IMRT versus VMAT based on clinical staging. Materials and methods From 02/01/2022 to 05/01/2023 a prospective registry of the costs for oncological management was carried out for patients with locally advanced CC who received CTRT \u00b1 HDRBT. This included the administration of radiation with chemotherapy. The cost associated with patient and family transfers and hours in the hospital was also identified. These expenses were used to project the direct and indirect costs of 3D versus IMRT versus VMAT. Results The treatment regimens for stage IIIC2, including 3D and novel techniques, are those with the highest costs. The administration of 3D RT for IIIC2 and novel IMRT or VMAT techniques, is $3,881.69, $3,374.76, and $2,862.80, respectively.",
  "The administration of 3D RT for IIIC2 and novel IMRT or VMAT techniques, is $3,881.69, $3,374.76, and $2,862.80, respectively. The indirect cost from stage IIB to IIIC1 in descending order is IMRT, 3D and VMAT, but in IIIC2 the novel technique regimens reduce by up to 33.99% compared to 3D. Conclusion In RT centres with an available supply of RT equipment, VMAT should be preferred over IMRT/3D since it reduces costs and toxicity. However, in RT centres where demand exceeds supply in the VMAT technique planning systems, the use of 3D teletherapy over IMRT/VMAT could continue to be used in patients with stage IIB to IIIC1.",
  "However, in RT centres where demand exceeds supply in the VMAT technique planning systems, the use of 3D teletherapy over IMRT/VMAT could continue to be used in patients with stage IIB to IIIC1.\nAuthors: Jos\u00e9 Fernando Robles D\u00edaz\nVenue: ecancermedicalscience\nTldr: {'model': 'tldr@v2.0.0', 'text': 'In RT centres with an available supply of RT equipment, VMAT should be preferred over IMRT/3D since it reduces costs and toxicity and in RT centres where demand exceeds supply in the VMAT technique planning systems, the use of 3D teletherapy over IM RT/VMAT could continue to be used in patients with stage IIB to IIIC1.'}",
  "Faculty Name: fernando diaz\nMetadata:\nPaperid: 11c44e8f63b8fb6e726cbf9c1fcd56b21053df44\nTitle: PLATFORM BASED ON DATA ANALYTICS AND STATISTICS TO PREDICT AND MONITOR THE INTEGRATED AND INTELLIGENT ENERGY MANAGEMENT OF ENERGY-INTENSIVE BUILDINGS\nYear: 2023\nAbstract: ABSTRACT: \nCurrently, large buildings are often equipped with building management systems (BMS), but either because of the type of control or the difficulty of interacting with them, they do not allow optimization policies to be implemented. As far as energy efficiency is concerned, optimization strategies often result from the analysis of monitored data by a specialist, which slows down both decision making and implementation. \nAware of this problem, this project arises, in which a complementary platform to the BMS systems is developed to provide them with greater intelligence.",
  "As far as energy efficiency is concerned, optimization strategies often result from the analysis of monitored data by a specialist, which slows down both decision making and implementation. \nAware of this problem, this project arises, in which a complementary platform to the BMS systems is developed to provide them with greater intelligence. For its design, the Puerta del Hierro Hospital in Madrid has been taken as a pilot case, from the data captured by its own BMS and using the 6 SIGMA methodology, algorithms have been developed capable of optimizing the production systems themselves, thus helping to make up for the weaknesses in the operation of the systems and reducing energy consumption, minimizing the environmental impact and allowing to obtain the maximum performance of its assets. \nThe platform uses the information gathered by the BMS and weather forecasts to predict a building's energy demand and, based on this, optimize energy production at any given moment.\nKeywords: Commissioning, Energy efficiency, Smart building, Degree-days, BMS, 6 SIGMA.",
  "The platform uses the information gathered by the BMS and weather forecasts to predict a building's energy demand and, based on this, optimize energy production at any given moment.\nKeywords: Commissioning, Energy efficiency, Smart building, Degree-days, BMS, 6 SIGMA.\nAuthors: Juan Manuel GALLARDO SALAZAR, Alicia Desiree MANCERAS RODRIGUEZ, Fernando DIAZ RODRIGUEZ, Fernando MORENO ABRAS, Rogelio ZUBIZARRETA JIMENEZ\nVenue: DYNA ENERGIA Y SOSTENIBILIDAD\nTldr: None",
  "Faculty Name: fernando diaz\nMetadata:\nPaperid: 217fce1552139ca00ac113b2124a36365fa579ca\nTitle: Impact of outpatient radiotherapy on direct non-medical cost in patients in the Central Macro Region of Peru 2021\nYear: 2023\nAbstract: Background Financial toxicity arises in cancer patients due to the objective financial burden of the disease or treatment, being associated with worse clinical outcomes. Direct non-medical spending on cancer patients undergoing radiotherapy in Peru under its publicly funded health system has not been described. Objective To know the expenses related to the transfer of the radiotherapy outpatient. Methodology For patients who started radiation therapy in 2021, treatment demographics and expenses related to transporting the patient from home to the radiation therapy center were prospectively collected. Association and connection tests were used, such as the Mann\u2013Whitney/Kruskal\u2013Wallis U-test and Spearman\u2019s Rho. A value of p < 0.05 is considered statistically significant. Results 398 patients were collected, with average weekly expenses for transportation, lodging and food of $17.04, $6.69 and $45.91, respectively.",
  "A value of p < 0.05 is considered statistically significant. Results 398 patients were collected, with average weekly expenses for transportation, lodging and food of $17.04, $6.69 and $45.91, respectively. Confirmation was positive between weekly spending and remoteness, likewise it was negative between effective teletherapy and remoteness, both analyses being statistically significant. Conclusion The expense associated with transfer for radiotherapy is high, exceeding the average monthly income of the patient, as a consequence they have a worse therapeutic result, and may cause financial toxicity in cancer patients.\nAuthors: Jos\u00e9 Fernando Robles D\u00edaz\nVenue: ecancermedicalscience\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The expense associated with transfer for radiotherapy is high, exceeding the average monthly income of the patient, as a consequence they have a worse therapeutic result, and may cause financial toxicity in cancer patients.'}",
  "Faculty Name: fernando diaz\nMetadata:\nPaperid: 414fc2423dbd9bcfd7870ea856485f51a4fc3e62\nTitle: Comparative Efficacy of First and Second Generation long-acting injectable antipsychotic upon schizophrenic patients: a systematic review and network meta-analysis\nYear: 2023\nAbstract: Introduction: Long-acting injectable antipsychotics (LAIA) can lead the course of treatment with the potential to increase adherence in schizophrenia treatment. The objective of this systematic review and network meta-analysis is to find the efficacy of SG-LAIAs, FG-LAIAs compared to each other for schizophrenia. \nMethods: This systematic review and network meta-analysis was designed following the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA), with registration in Prospero (ID CRD42019128700). A database in MEDLINE, EMBASE, Web of Science, and Scopus, until June 17, 2020, with an actualization from June 2020 to September 14, 2021.",
  "A database in MEDLINE, EMBASE, Web of Science, and Scopus, until June 17, 2020, with an actualization from June 2020 to September 14, 2021.\u00a0 \nResults: The SMDs for the four (80%) antipsychotics that significantly reduced PANSS score compared with placebo ranged between \u20130\u00b772 (95% CrI \u20130\u00b799 to \u20130\u00b746) for haloperidol to \u20130\u00b745 (\u20130\u00b754 to \u20130\u00b737) for paliperidone. 8 studies reported usable results for negative symptoms and positive symptoms (Four antipsychotics compared). The SMDs for the three (75%) antipsychotics that significantly reduced negative symptoms compared with placebo ranged between \u20130\u00b740 (95% CrI \u20130\u00b753 to \u20130\u00b726) for aripiprazole to \u20130\u00b732 (\u20130\u00b744 to \u20130\u00b719) for risperidone.",
  "The SMDs for the three (100%) drugs that significantly reduced positive symptoms compared with placebo ranged between \u20130\u00b750 (95% CrI \u20130\u00b763 to \u20130\u00b737) for aripiprazole to \u20130\u00b719 (\u20130\u00b757 to 0\u00b720) for zuclopenthixol. \nDiscussion: We found evidence suggesting that all long-acting injectable antipsychotics, except for zuclopenthixol, are equally efficient in reducing symptoms in schizophrenia, \nConclusions: Most LAIAs are equally efficient at reducing overall symptoms, and differences between individual LAIAs are non-significant.",
  "Discussion: We found evidence suggesting that all long-acting injectable antipsychotics, except for zuclopenthixol, are equally efficient in reducing symptoms in schizophrenia, \nConclusions: Most LAIAs are equally efficient at reducing overall symptoms, and differences between individual LAIAs are non-significant.\nAuthors: Erasmo Sauceo-Uribe, P. J. Gonz\u00e1lez-Mallozzi, Ra\u00fal Ricardo Medrano-Garza, Fernando D\u00edaz Gonz\u00e1lez-Colmenero, Farid Carranza-Navarro, P. L. Castillo-Morales, Paloma C. Leyva-Camacho, Yessica Herrera-Montemayor, Mauricio Vidal-Tijerina, M. K. Enr\u00edquez-Navarro, Samantha B. Medrano, Stefan Fern\u00e1ndez-Zambrano, Claudia Magdalena Mancias-Guerra, Claudia Lizeth Saucedo-Mancias, Manuel Ramiro Sanchez-Ramirez\nVenue: Archivos de Neurociencias\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Evidence is found suggesting that all long-acting injectable antipsychotics, except for zuclopenthixol, are equally efficient in reducing symptoms in schizophrenia, and differences between individual LAIAs are non-significant.'}",
  "Faculty Name: fernando diaz\nMetadata:\nPaperid: 442b8568036949fc51734ef47f41313d9afef6db\nTitle: Discordance Between Social Vulnerability and Cancer-Related Mortality in Border Counties - A Letter to the Editor Regarding \u201cLocal Social Vulnerability as a Predictor for Cancer-Related Mortality Among US Counties\u201d\nYear: 2023\nAbstract: This letter to the editor remarks on results of a recently published study and highlights the need for multinational and interinstitutional registries so health departments in the US and Latin American countries can accurately capture cancer incidence and mortality data.\nAuthors: M. LaPelusa, F. Diaz, Patricia Mae G Santos, H. Verduzco-Aguirre, E. Soto-P\u00e9rez-de-Celis\nVenue: The Oncologist\nTldr: {'model': 'tldr@v2.0.0', 'text': None}",
  "Faculty Name: fernando diaz\nMetadata:\nPaperid: 53e57edca377b168c010cfed423f1b90f56007a4\nTitle: Understanding of the Effect of the Adsorption of Atom and Cluster Silver on Chitosan: An In Silico Analysis\nYear: 2023\nAbstract: In this work, the structural, electronic, and optical stability properties of the chitosan monomer (M-Ch) and atomic silver complex are reported, as well as a unitary cell of a silver cluster in the gas phase and acetic acid. The generalized gradient approximation HSEh1PBE/def2-TZVPP50 results established the structures\u2019 anionic charge (Q = \u22121|e|) and the doublet state (M = 2). The high cohesive energy indicates structural stability, and the quantum-mechanical descriptors show a high polarity and low chemical reactivity. Also, the quantum-mechanical descriptors present a low work function that shows the structures are suitable for applications in light-emitting diodes. Finally, the electronic behavior observed by the |HOMO-LUMO| gap energy changes depending on the atomic silver incorporated into the complex.",
  "Also, the quantum-mechanical descriptors present a low work function that shows the structures are suitable for applications in light-emitting diodes. Finally, the electronic behavior observed by the |HOMO-LUMO| gap energy changes depending on the atomic silver incorporated into the complex.\nAuthors: A. Rodr\u00edguez-Ju\u00e1rez, Veronica Carmona-\u00c1lvarez, F. D\u00edaz-Monge, E. Chigo-Anota, O. Zaca-Moran\nVenue: Molecules\nTldr: None",
  "Faculty Name: fernando diaz\nMetadata:\nPaperid: 55704caaf3d31e1795a1ca0c3bed9e77ae3a3c95\nTitle: Best-Case Retrieval Evaluation: Improving the Sensitivity of Reciprocal Rank with Lexicographic Precision\nYear: 2023\nAbstract: Across a variety of ranking tasks, researchers use reciprocal rank to measure the effectiveness for users interested in exactly one relevant item. Despite its widespread use, evidence suggests that reciprocal rank is brittle when discriminating between systems. This brittleness, in turn, is compounded in modern evaluation settings where current, high-precision systems may be difficult to distinguish. We address the lack of sensitivity of reciprocal rank by introducing and connecting it to the concept of best-case retrieval, an evaluation method focusing on assessing the quality of a ranking for the most satisfied possible user across possible recall requirements. This perspective allows us to generalize reciprocal rank and define a new preference-based evaluation we call lexicographic precision or lexiprecision. By mathematical construction, we ensure that lexiprecision preserves differences detected by reciprocal rank, while empirically improving sensitivity and robustness across a broad set of retrieval and recommendation tasks.",
  "This perspective allows us to generalize reciprocal rank and define a new preference-based evaluation we call lexicographic precision or lexiprecision. By mathematical construction, we ensure that lexiprecision preserves differences detected by reciprocal rank, while empirically improving sensitivity and robustness across a broad set of retrieval and recommendation tasks.\nAuthors: Fernando Diaz\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work addresses the lack of sensitivity of reciprocal rank by introducing and connecting it to the concept of best-case retrieval, an evaluation method focusing on assessing the quality of a ranking for the most satisfied possible user across possible recall requirements.'}",
  "Faculty Name: fernando diaz\nMetadata:\nPaperid: 567f6bc975deb3d728feec9bfcf7d4036ceabb12\nTitle: Fairness Through Domain Awareness: Mitigating Popularity Bias For Music Discovery\nYear: 2023\nAbstract: As online music platforms grow, music recommender systems play a vital role in helping users navigate and discover content within their vast musical databases. At odds with this larger goal, is the presence of popularity bias, which causes algorithmic systems to favor mainstream content over, potentially more relevant, but niche items. In this work we explore the intrinsic relationship between music discovery and popularity bias. To mitigate this issue we propose a domain-aware, individual fairness-based approach which addresses popularity bias in graph neural network (GNNs) based recommender systems. Our approach uses individual fairness to reflect a ground truth listening experience, i.e., if two songs sound similar, this similarity should be reflected in their representations. In doing so, we facilitate meaningful music discovery that is robust to popularity bias and grounded in the music domain. We apply our BOOST methodology to two discovery based tasks, performing recommendations at both the playlist level and user level.",
  "In doing so, we facilitate meaningful music discovery that is robust to popularity bias and grounded in the music domain. We apply our BOOST methodology to two discovery based tasks, performing recommendations at both the playlist level and user level. Then, we ground our evaluation in the cold start setting, showing that our approach outperforms existing fairness benchmarks in both performance and recommendation of lesser-known content. Finally, our analysis explains why our proposed methodology is a novel and promising approach to mitigating popularity bias and improving the discovery of new and niche content in music recommender systems.\nAuthors: Rebecca Salganik, Fernando Diaz, G. Farnadi\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes a domain-aware, individual fairness-based approach which addresses popularity bias in graph neural network (GNNs) based recommender systems and applies the BOOST methodology to two discovery based tasks, performing recommendations at both the playlist level and user level.'}",
  "Faculty Name: fernando diaz\nMetadata:\nPaperid: 574fe6378d43b1f1f2e8467bda1574292d6c586d\nTitle: Females translate male mRNA transferred during mating\nYear: 2023\nAbstract: Although RNA is found in the seminal fluid of diverse organisms, it is unknown whether this RNA is functional within females. Here, we develop an experimental proteomic method called VESPA (Variant Enabled SILAC Proteomic Analysis) to test the hypothesis that Drosophila male seminal fluid RNA is translated by females. We find strong evidence for 67 male-derived, female-translated proteins (mdFTPs) in female lower reproductive tracts at six hours postmating, many with predicted functions relevant to reproduction. Gene knockout experiments indicate that genes coding for mdFTPs play diverse roles in postmating interactions, with effects on fertilization efficiency, and the formation and persistence of the insemination reaction mass, a trait hypothesized to be involved in sexual conflict. These findings advance our understanding of reproduction by revealing a novel mechanism of postmating molecular interactions between the sexes that strengthens and extends male influences on reproductive outcomes in previously unrecognized ways.",
  "These findings advance our understanding of reproduction by revealing a novel mechanism of postmating molecular interactions between the sexes that strengthens and extends male influences on reproductive outcomes in previously unrecognized ways. Given the diverse species known to carry RNA in seminal fluid, this discovery has broad significance for understanding molecular mechanisms of cooperation and conflict during reproduction.\nAuthors: Luciano M. Matzkin, J. Bono, Helen K. Pigage, Carson W. Allan, Fernando D\u00edaz, J. McCoy, Clinton C. Green, Jeffrey B. Callan, Stephen P. Delahunt\nVenue: bioRxiv\nTldr: {'model': 'tldr@v2.0.0', 'text': 'An experimental proteomic method is developed to test the hypothesis that Drosophila male seminal fluid RNA is translated by females, finding strong evidence for 67 male-derived, female-translated proteins in female lower reproductive tracts at six hours postmating, many with predicted functions relevant to reproduction.'}",
  "Faculty Name: fernando diaz\nMetadata:\nPaperid: 5e1ba2d4416333dd6f6a31a4ff4221b40dfb74b1\nTitle: Overview of the TREC 2021 Fair Ranking Track\nYear: 2023\nAbstract: The TREC Fair Ranking Track aims to provide a platform for participants to develop and evaluate novel retrieval algorithms that can provide a fair exposure to a mixture of demographics or attributes, such as ethnicity, that are represented by relevant documents in response to a search query. For example, particular demographics or attributes can be represented by the documents' topical content or authors. The 2021 Fair Ranking Track adopted a resource allocation task. The task focused on supporting Wikipedia editors who are looking to improve the encyclopedia's coverage of topics under the purview of a WikiProject. WikiProject coordinators and/or Wikipedia editors search for Wikipedia documents that are in need of editing to improve the quality of the article.",
  "The task focused on supporting Wikipedia editors who are looking to improve the encyclopedia's coverage of topics under the purview of a WikiProject. WikiProject coordinators and/or Wikipedia editors search for Wikipedia documents that are in need of editing to improve the quality of the article. The 2021 Fair Ranking track aimed to ensure that documents that are about, or somehow represent, certain protected characteristics receive a fair exposure to the Wikipedia editors, so that the documents have an fair opportunity of being improved and, therefore, be well-represented in Wikipedia. The under-representation of particular protected characteristics in Wikipedia can result in systematic biases that can have a negative human, social, and economic impact, particularly for disadvantaged or protected societal groups.\nAuthors: Asia J. Biega, Fernando Diaz, Michael D. Ekstrand, Sebastian Kohlmeier\nVenue: Text Retrieval Conference\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The 2021 Fair Ranking track aimed to ensure that documents that are about, or somehow represent, certain protected characteristics receive a fair exposure to the Wikipedia editors, so that the documents have an fair opportunity of being improved and, therefore, be well-represented in Wikipedia.'}",
  "Faculty Name: fernando diaz\nMetadata:\nPaperid: 70753c30b5eef5fd9bf8673cee4b586105f47c20\nTitle: Cross-border utilization of cancer care by patients in the US and Mexico \u2013 a survey of Mexican oncologists\nYear: 2023\nAbstract: None\nAuthors: M. LaPelusa, H. Verduzco-Aguirre, F. Diaz, F. Aldaco, E. Soto-P\u00e9rez-de-Celis\nVenue: Globalization and Health\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The type of care sought, as well as the reasons for seeking it, differ between US and Mexico-based patients, highlighting unmet needs for patients with cancer in both countries and calling for policy changes to improve outcomes in border regions.'}",
  "Faculty Name: fernando diaz\nMetadata:\nPaperid: a76e7e394112a26116446a2920467a2702de5f56\nTitle: Pre-vaccination CD56 dimCD16 +NK cell abundance and T h1/T h17 ratio predict responsiveness to conjugated pneumococcal vaccine in older adults\nYear: 2023\nAbstract: \n Older adults are at high risk of morbidity and mortality from Streptococcus pneumoniae (pneumococcus) infections. There are two available vaccines for pneumococcus: T-cell-independent capsular polysaccharide Pneumovax and T-cell-dependent conjugated Prevnar. However, how older adults respond to these vaccines at the cellular level and whether there are baseline predictors for responsiveness, is not known. To address this, we recruited older adults (60+ yrs), who are vaccinated with Prevnar (n=19) or Pneumovax (n=20). Vaccine responsiveness was quantified using opsonophagocytic assays, which revealed that both vaccines induce strong responses. Interestingly, sex was associated with Prevnar responses, where women mounted stronger responses than men.",
  "Vaccine responsiveness was quantified using opsonophagocytic assays, which revealed that both vaccines induce strong responses. Interestingly, sex was associated with Prevnar responses, where women mounted stronger responses than men. Pre-vaccination flow cytometry data showed that Th1 cells positively, Th17 cells negatively correlated with Prevnar responses. Furthermore, bulk RNA-seq data from PBMCs showed that baseline expression levels of cytotoxic genes (NCAM1, GNLY, PRF1) are negatively associated with Prevnar responses. scRNA-seq data from top and bottom responders showed that this cytotoxicity signature stems from CD56 dimCD16 +NK cells, where having more of these cells are detrimental to responses. Interestingly, women had significantly higher Th1, lower Th17 and lower CD16+ NK cells compared to men, which explains their stronger Prevnar responses. This is the first study to uncover older adults\u2019 responses to two pneumococcal vaccines; we uncovered an activated immune phenotype of Th and NK cell subsets that impedes responses to Prevnar. Interestingly, this phenotype only affected adjuvanted vaccine responses, providing an opportunity for precision vaccinology for pneumococcus disease.",
  "Interestingly, this phenotype only affected adjuvanted vaccine responses, providing an opportunity for precision vaccinology for pneumococcus disease.\n Supported by grants from National Institute of Health (R35 GM124922, R01 AG052608) and JAX cancer center (JAX-CC).\nAuthors: S. Ravichandran, F. E. D\u00edaz, Onur E Karakaslar, R. Marches, Robert J. Rossi, M. Nahm, D. Chaussabel, G. Kuchel, J. Banchereau, D. Ucar\nVenue: Journal of Immunology\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This is the first study to uncover older adults\u2019 responses to two pneumococcal vaccines; an activated immune phenotype of Th and NK cell subsets that impedes responses to Prevnar is uncovered.'}",
  "Faculty Name: fernando diaz\nMetadata:\nPaperid: b79041565cbd9da52daf97f73c4097eed0afd723\nTitle: Concomitant inhibition of PPAR\u03b3 and mTORC1 induces the differentiation of human monocytes into highly immunogenic dendritic cells.\nYear: 2023\nAbstract: None\nAuthors: F. Erra D\u00edaz, I. Mazzitelli, Luc\u00eda Bleichmar, C. Melucci, Asa Thibodeau, Tom\u00e1s Dalotto Moreno, R. Marches, G. Rabinovich, D. Ucar, J. Geffner\nVenue: Cell Reports\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is found that simultaneous inhibition of PPAR\u03b3 and the nutrient sensor mammalian target of rapamycin complex 1 (mTORC1) induces the differentiation of Mo-DCs with stronger phenotypic stability, superior immunogenicity, and a transcriptional profile characterized by a strong type I interferon signature.'}",
  "Faculty Name: fernando diaz\nMetadata:\nPaperid: c1b6e86b51df36f400a84c4fe8b1535c3f07f605\nTitle: Beyond Active Engagement: The Significance of Lurkers in a Polarized Twitter Debate\nYear: 2023\nAbstract: The emergence of new public forums in the shape of online social media has introduced unprecedented challenges to public discourse, including polarization, misinformation, and the emergence of echo chambers. While existing research has extensively studied the behavior of active users within echo chambers, little attention has been given to the hidden audience, also known as lurkers, who passively consume content without actively engaging. This study aims to estimate the share of the hidden audience and investigate their interplay with the echo chamber effect. Using Twitter as a case study, we analyze a polarized political debate to understand the engagement patterns and factors influencing the hidden audience's presence. Our findings reveal a relevant fraction of users that consume content without active interaction, which underscores the importance of considering their presence in online debates.",
  "Using Twitter as a case study, we analyze a polarized political debate to understand the engagement patterns and factors influencing the hidden audience's presence. Our findings reveal a relevant fraction of users that consume content without active interaction, which underscores the importance of considering their presence in online debates. Notably, our results indicate that the engagement of the hidden audience is primarily influenced by factors such as the reliability of media sources mentioned in tweets rather than the ideological stance of the user that produced the content. These findings highlight the need for a comprehensive understanding of the hidden audience's role in online debates and how they may influence public opinion.\nAuthors: Anees Baqir, Yijing Chen, Fernando Diaz-Diaz, Sercan Kiyak, Thomas Louf, Virginia Morini, Valentina Pansanella, M. Torricelli, Alessandro Galeazzi\nVenue: arXiv.org\nTldr: None",
  "Faculty Name: fernando diaz\nMetadata:\nPaperid: cbe6b6d58254ee2434d091ed7b8466e444ef892a\nTitle: Clusterin protects mature dendritic cells from reactive oxygen species mediated cell death\nYear: 2023\nAbstract: ABSTRACT Dendritic cells (DCs) play a key role in the induction of the adaptive immune response. They capture antigens in peripheral tissues and prime na\u00efve T lymphocytes, triggering the adaptive immune response. In the course of inflammatory processes DCs face stressful conditions including hypoxia, low pH and high concentrations of reactive oxygen species (ROS), among others. How DCs survive under these adverse conditions remain poorly understood. Clusterin is a protein highly expressed by tumors and usually associated with bad prognosis. It promotes cancer cell survival by different mechanisms such as apoptosis inhibition and promotion of autophagy. Here, we show that, upon maturation, human monocyte-derived DCs (MoDCs) up-regulate clusterin expression. Clusterin protects MoDCs from ROS-mediated toxicity, enhancing DC survival and promoting their ability to induce T cell activation.",
  "Here, we show that, upon maturation, human monocyte-derived DCs (MoDCs) up-regulate clusterin expression. Clusterin protects MoDCs from ROS-mediated toxicity, enhancing DC survival and promoting their ability to induce T cell activation. In line with these results, we found that clusterin is expressed by a population of mature LAMP3+ DCs, called mregDCs, but not by immature DCs in human cancer. The expression of clusterin by intratumoral DCs was shown to be associated with a transcriptomic profile indicative of cellular response to stress. These results uncover an important role for clusterin in DC physiology.",
  "The expression of clusterin by intratumoral DCs was shown to be associated with a transcriptomic profile indicative of cellular response to stress. These results uncover an important role for clusterin in DC physiology.\nAuthors: \u00c1lvaro L\u00f3pez Malizia, A. Merlotti, P. Bont\u00e9, Melina Sager, Yago Arribas De Sandoval, C. Goudot, F. Erra D\u00edaz, Pehu\u00e9n Pereyra-Gerber, A. Ceballos, S. Amigorena, J. Geffner, J. Sabatte\u0301\nVenue: Oncoimmunology\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is found that clusterin is expressed by a population of mature LAMP3+ DCs, called mregDCs, but not by immature DCs in human cancer, and this results uncover an important role for clusterin in DC physiology.'}",
  "Faculty Name: fernando diaz\nMetadata:\nPaperid: cda03f3d8b1eff888174c0dc4262e1dc73be2d49\nTitle: Population well-being and the COVID-19 vaccination program in Chile: evidence from Google Trends\nYear: 2023\nAbstract: None\nAuthors: F. D\u00edaz, Pablo A. Henr\u00edquez, Nicol\u00e1s Hardy, D. Ponce\nVenue: Public Health\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is found that mental well-being responds positively to the percentage of inoculated people, and this phenomenon appears to be permanent and affected by socioeconomic status, with the wealthier population experiencing greater improvements than the less wealthy.'}",
  "Faculty Name: fernando diaz\nMetadata:\nPaperid: cda71255a5e02e0d3a5fe99e711caea09417bf3f\nTitle: Transcriptional Misexpression in Hybrids between Species Linked by Gene Flow Is Associated With Patterns of Sequence Divergence\nYear: 2023\nAbstract: Abstract The extent to which hybridization disrupts a gene's pattern of expression likely governs its propensity for introgression, whereas its extent of molecular divergence can itself underlie such disruption. Together, these phenomena shape the landscape of sequence and transcriptional divergence across the genome as species diverge. To understand this process, we characterize gene expression inheritance, regulatory divergence, and molecular divergence in the reproductive transcriptomes of species linked by gene flow: the fruit flies Anastrepha fraterculus and A. obliqua, which show evidence of gene flow despite clear evolutionary divergence. We find that their transcriptional patterns are a mosaic between those typically observed within and between allopatric species. Transcripts showing transgressive expression in hybrids or cis-regulatory divergence between species are associated with greater sequence divergence.",
  "We find that their transcriptional patterns are a mosaic between those typically observed within and between allopatric species. Transcripts showing transgressive expression in hybrids or cis-regulatory divergence between species are associated with greater sequence divergence. This may reflect pleiotropic constraints that make them resistant to gene flow or they may be more likely to experience divergent selection. Although these more divergent gene classes are likely to be important contributors to species differences, they are relatively rare. Instead, most differentially regulated transcripts, including those linked to reproduction, show high degrees of dominance in hybrids and trans-regulated divergence between species, suggesting widespread genetic compatibility that potentially allowed for introgression. These findings provide insights into how postzygotic isolating mechanisms might evolve in the presence of gene flow: regions showing cis-regulatory divergence or transgressive expression contribute to reproductive isolation, whereas regions with dominant expression and trans-regulatory divergence allow for introgression. These patterns create a genomic mosaic of transcriptional regulation that is tied to sequence divergence.",
  "These patterns create a genomic mosaic of transcriptional regulation that is tied to sequence divergence.\nAuthors: Fernando D\u00edaz, J. Wolf, R. D. de Brito\nVenue: Genome Biology and Evolution\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Analysis of reproductive transcriptomes of fruit flies linked by gene flow provides insights into how postzygotic isolating mechanisms might evolve in the presence of gene flow: regions showing cis-regulatory divergence or transgressive expression contribute to reproductive isolation, whereas regions with dominant expression and trans-regulations allow for introgression.'}",
  "Faculty Name: fernando diaz\nMetadata:\nPaperid: e59a99c198ee4012e34fd79d7cb33be75d0a120d\nTitle: Amplification-free, highly sensitive electrochemical DNA-based sensor for simultaneous detection of stx1 and stx2 genes of Shiga toxin-producing E. coli (STEC)\nYear: 2023\nAbstract: None\nAuthors: L. Wasiewska, F. Diaz, S. Teixeira, C. Burgess, G. Duffy, A. O\u2019Riordan\nVenue: Electrochimica Acta\nTldr: None",
  "Faculty Name: fernando diaz\nMetadata:\nPaperid: edde6245557416c5911a5e29c5ea93bf2deabf1f\nTitle: A Bibliometric Analysis on Cooperatives in Circular Economy and Eco-Innovation Studies\nYear: 2023\nAbstract: Cooperatives address societal challenges embracing values beyond mere profit-oriented production. Considering the ongoing shift to achieve efficient use of resources and increased circularity, cooperatives should be better equipped to incorporate circular economy (CE) and eco-innovation (EI) into their strategies (compared to regular enterprises). This paper reviews the scholarly literature focusing on the application of CE and EI within cooperative studies with the aim to understand the relationships between these topics, identify the existing scholarly communities, and to observe salient research themes. This study refined the method of van den Hoven and Rubalcaba (2016) to conduct a two-step bibliographic review of documents: a thematic analysis of citation data from Scopus (including a manual review of 16 papers) was followed by a bibliometric analysis of 101 documents from Web of Science (using R-Studio\u2019s Biblioshiny).",
  "Our results identified three intellectual clusters of cooperative studies focusing on the downstream of CE: (1) industrial ecology; (2) recycling; and (3) waste management. Our study also revealed an emerging scholarly field focused on cooperatives and CE, and with little attention to EI. These findings aim at catalyzing the integration of cooperatives more effectively into scholarly discussions, suggesting that environmental sustainability should be recognized as an additional principle of the cooperative identity\u2014providing a wider perspective that enhances interest in the research of these topics and their interconnections.\nAuthors: Asia Guerreschi, Fernando J. D\u00edaz L\u00f3pez\nVenue: Sustainability\nTldr: None",
  "List of 2023 Open Access papers by fernando diaz are:\nAmplification-free, highly sensitive electrochemical DNA-based sensor for simultaneous detection of stx1 and stx2 genes of Shiga toxin-producing E. coli (STEC)\nDiscordance Between Social Vulnerability and Cancer-Related Mortality in Border Counties - A Letter to the Editor Regarding \u201cLocal Social Vulnerability as a Predictor for Cancer-Related Mortality Among US Counties\u201d\nCross-border utilization of cancer care by patients in the US and Mexico \u2013 a survey of Mexican oncologists\nFemales translate male mRNA transferred during mating\nTranscriptional Misexpression in Hybrids between Species Linked by Gene Flow Is Associated With Patterns of Sequence Divergence\nPopulation well-being and the COVID-19 vaccination program in Chile: evidence from Google Trends\nPre-vaccination CD56 dimCD16 +NK cell abundance and T h1/T h17 ratio predict responsiveness to conjugated pneumococcal vaccine in older adults\nBest-Case Retrieval Evaluation: Improving the Sensitivity of Reciprocal Rank with Lexicographic Precision\nFairness Through Domain Awareness: Mitigating Popularity Bias For Music Discovery\nOverview of the TREC 2021 Fair Ranking Track\nCost analysis of three-dimensional radiation",
  "vaccine in older adults\nBest-Case Retrieval Evaluation: Improving the Sensitivity of Reciprocal Rank with Lexicographic Precision\nFairness Through Domain Awareness: Mitigating Popularity Bias For Music Discovery\nOverview of the TREC 2021 Fair Ranking Track\nCost analysis of three-dimensional radiation therapy versus intensity-modulated chemoradiotherapy for locally advanced cervical cancer in Peruvian citizens\nImpact of outpatient radiotherapy on direct non-medical cost in patients in the Central Macro Region of Peru 2021\nPLATFORM BASED ON DATA ANALYTICS AND STATISTICS TO PREDICT AND MONITOR THE INTEGRATED AND INTELLIGENT ENERGY MANAGEMENT OF ENERGY-INTENSIVE BUILDINGS\nA Bibliometric Analysis on Cooperatives in Circular Economy and Eco-Innovation Studies\nComparative Efficacy of First and Second Generation long-acting injectable antipsychotic upon schizophrenic patients: a systematic review and network meta-analysis\nConcomitant inhibition of PPAR\u03b3 and mTORC1 induces the differentiation of human monocytes into highly immunogenic dendritic cells.",
  "Studies\nComparative Efficacy of First and Second Generation long-acting injectable antipsychotic upon schizophrenic patients: a systematic review and network meta-analysis\nConcomitant inhibition of PPAR\u03b3 and mTORC1 induces the differentiation of human monocytes into highly immunogenic dendritic cells.\nClusterin protects mature dendritic cells from reactive oxygen species mediated cell death\nUnderstanding of the Effect of the Adsorption of Atom and Cluster Silver on Chitosan: An In Silico Analysis",
  "Title: Robert Frederking -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Robert Federking, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Core Faculty\" name=\"categories-1\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Robert Frederking - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Robert Federking, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Robert\"/>\n<meta content=\"Lastname\" property=\"profile:Frederking\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/frederking-robert.",
  "cmu.edu//people/faculty/frederking-robert.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nRobert \n                        Frederking\nAssociate Dean for PhD Programs and Chair for MLT Program, Language Technologies Institute\nContact\n6515 \u2014Gates & Hillman Centers\nref(through)cs.cmu.edu\n412-268-6656\n\nLinks:",
  "Title: Daniel Fried -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Daniel Fried, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Core Faculty\" name=\"categories-1\"/>\n<meta content=\"Conversational AI;Discourse and Pragmatics;Intelligent Agents and Dialogue;Multimodal AI;Natural Language Processing and Computational Linguistics\" name=\"categories-2\"/>\n<meta content=\"Yes\" name=\"show-categories-2\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Daniel Fried - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Daniel Fried,",
  "Faculty Member at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Daniel\"/>\n<meta content=\"Lastname\" property=\"profile:Fried\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/fried-daniel.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nDaniel \n                        Fried\nAssistant Professor, Language Technologies Institute\nContact\n6411 \u2014Gates & Hillman Centers\ndfried(through)andrew.cmu.edu\nResearch Area\nConversational AI, Discourse and Pragmatics, Intelligent Agents and Dialogue, Multimodal AI, Natural Language Processing and Computational Linguistics\nEducation\nMaster of Science in Intelligent Information Systems\nPersonal Website\n\nLinks:\nhttps://dpfried.github.io/",
  "Title: Madhavi Ganapathiraju -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Madhavi Ganapathiraju, Adjunct Faculty at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Adjunct Faculty\" name=\"categories-1\"/>\n<meta content=\"Ph.D.",
  "in Language and Information Technology\" name=\"degrees\"/>\n<meta content=\"Alumni;Faculty\" name=\"global-categories\"/>\n<meta content=\"Madhavi Ganapathiraju - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Madhavi Ganapathiraju, Adjunct Faculty at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Madhavi\"/>\n<meta content=\"Lastname\" property=\"profile:Ganapathiraju\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/ganapathiraju-madhavi.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nMadhavi \n                        Ganapathiraju\nAssociate Professor, University of Pittsburgh\nContact\nmadhavi(through)pitt.edu\nEducation\nPh.D.",
  "in Language and Information Technology, CMU LTI\n2007\nPersonal Website\nDoctoral Thesis\n\nLinks:\nhttps://www.isb.pitt.edu/people/faculty/madhavi-ganapathiraju-phd",
  "Title: Matt Gormley -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Matt Gormley, Affiliated Faculty at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Affiliated Faculty\" name=\"categories-1\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Matt Gormley - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Matt Gormley, Affiliated Faculty at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Matt\"/>\n<meta content=\"Lastname\" property=\"profile:Gormley\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/gormley-matt.",
  "cmu.edu//people/faculty/gormley-matt.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nMatt \n                        Gormley\nAssistant Teaching Professor, Language Technologies Institute\nContact\n8227 \u2014Gates & Hillman Centers\nmgormley(through)cs.cmu.edu\n412-268-7205\nPersonal Website\n\nLinks:\nhttp://www.cs.cmu.edu/~mgormley/",
  "Title: Matthias Grabmair -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Matthias Grabmair, Adjunct Faculty at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Adjunct Faculty\" name=\"categories-1\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Matthias Grabmair - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Matthias Grabmair, Adjunct Faculty at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Matthias\"/>\n<meta content=\"Lastname\" property=\"profile:Grabmair\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/grabmair-matthias.",
  "cmu.edu//people/faculty/grabmair-matthias.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nMatthias \n                        Grabmair\nAssistant Professor, Technical University of Munich, Germany\nContact\nmgrabmai(through)andrew.cmu.edu\n\nLinks:",
  "Faculty Name: graham neubig\nMetadata:\nPaperid: 03c7f61b0c6bc4c480ed6da4e9d7dda104ddfec3\nTitle: Cross-Modal Fine-Tuning: Align then Refine\nYear: 2023\nAbstract: Fine-tuning large-scale pretrained models has led to tremendous progress in well-studied modalities such as vision and NLP. However, similar gains have not been observed in many other modalities due to a lack of relevant pretrained models. In this work, we propose ORCA, a general cross-modal fine-tuning framework that extends the applicability of a single large-scale pretrained model to diverse modalities. ORCA adapts to a target task via an align-then-refine workflow: given the target input, ORCA first learns an embedding network that aligns the embedded feature distribution with the pretraining modality. The pretrained model is then fine-tuned on the embedded data to exploit the knowledge shared across modalities.",
  "The pretrained model is then fine-tuned on the embedded data to exploit the knowledge shared across modalities. Through extensive experiments, we show that ORCA obtains state-of-the-art results on 3 benchmarks containing over 60 datasets from 12 modalities, outperforming a wide range of hand-designed, AutoML, general-purpose, and task-specific methods. We highlight the importance of data alignment via a series of ablation studies and demonstrate ORCA's utility in data-limited regimes.\nAuthors: Junhong Shen, Liam Li, L. Dery, Corey Staten, M. Khodak, Graham Neubig, Ameet Talwalkar\nVenue: International Conference on Machine Learning\nTldr: {'model': 'tldr@v2.0.0', 'text': \"This work proposes ORCA, a general cross-modal fine-tuning framework that extends the applicability of a single large-scale pretrained model to diverse modalities and highlights the importance of data alignment via a series of ablation studies and demonstrates ORCA's utility in data-limited regimes.\"}",
  "Faculty Name: graham neubig\nMetadata:\nPaperid: 11a571eaab42a6ffb1d938635a093315e392756d\nTitle: ChatGPT MT: Competitive for High- (but Not Low-) Resource Languages\nYear: 2023\nAbstract: Large language models (LLMs) implicitly learn to perform a range of language tasks, including machine translation (MT). Previous studies explore aspects of LLMs\u2019 MT capabilities. However, there exist a wide variety of languages for which recent LLM MT performance has never before been evaluated. Without published experimental evidence on the matter, it is difficult for speakers of the world\u2019s diverse languages to know how and whether they can use LLMs for their languages. We present the first experimental evidence for an expansive set of 204 languages, along with MT cost analysis, using the FLORES-200 benchmark. Trends reveal that GPT models approach or exceed traditional MT model performance for some high-resource languages (HRLs) but consistently lag for low-resource languages (LRLs), under-performing traditional MT for 84.1% of languages we covered.",
  "Trends reveal that GPT models approach or exceed traditional MT model performance for some high-resource languages (HRLs) but consistently lag for low-resource languages (LRLs), under-performing traditional MT for 84.1% of languages we covered. Our analysis reveals that a language\u2019s resource level is the most important feature in determining ChatGPT\u2019s relative ability to translate it, and suggests that ChatGPT is especially disadvantaged for LRLs and African languages.\nAuthors: Nathaniel R. Robinson, Perez Ogayo, David R. Mortensen, Graham Neubig\nVenue: Conference on Machine Translation\nTldr: {'model': 'tldr@v2.0.0', 'text': \"This work presents the first experimental evidence for an expansive set of 204 languages, along with MT cost analysis, using the FLORES-200 benchmark, and reveals that a language\u2019s resource level is the most important feature in determining ChatGPT's relative ability to translate it, and suggests thatChatGPT is especially disadvantaged for LRLs and African languages.\"}",
  "Faculty Name: graham neubig\nMetadata:\nPaperid: 17605c43ca3eb982c99642052ddc21a93d116594\nTitle: GlobalBench: A Benchmark for Global Progress in Natural Language Processing\nYear: 2023\nAbstract: Despite the major advances in NLP, significant disparities in NLP system performance across languages still exist. Arguably, these are due to uneven resource allocation and sub-optimal incentives to work on less resourced languages. To track and further incentivize the global development of equitable language technology, we introduce GlobalBench. Prior multilingual benchmarks are static and have focused on a limited number of tasks and languages. In contrast, GlobalBench is an ever-expanding collection that aims to dynamically track progress on all NLP datasets in all languages. Rather than solely measuring accuracy, GlobalBench also tracks the estimated per-speaker utility and equity of technology across all languages, providing a multi-faceted view of how language technology is serving people of the world. Furthermore, GlobalBench is designed to identify the most under-served languages, and rewards research efforts directed towards those languages.",
  "Furthermore, GlobalBench is designed to identify the most under-served languages, and rewards research efforts directed towards those languages. At present, the most under-served languages are the ones with a relatively high population, but nonetheless overlooked by composite multilingual benchmarks (like Punjabi, Portuguese, and Wu Chinese). Currently, GlobalBench covers 966 datasets in 190 languages, and has 1,128 system submissions spanning 62 languages.",
  "Currently, GlobalBench covers 966 datasets in 190 languages, and has 1,128 system submissions spanning 62 languages.\nAuthors: Yueqi Song, Catherine Cui, Simran Khanuja, Pengfei Liu, FAHIM FAISAL, Alissa Ostapenko, Genta Indra Winata, Alham Fikri Aji, Samuel Cahyawijaya, Yulia Tsvetkov, Antonios Anastasopoulos, Graham Neubig\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work introduces GlobalBench, an ever-expanding collection that aims to dynamically track progress on all NLP datasets in all languages and tracks the estimated per-speaker utility and equity of technology across all languages, providing a multi-faceted view of how language technology is serving people of the world.'}",
  "Faculty Name: graham neubig\nMetadata:\nPaperid: 1786a2f9140ed7211b21302977de64e948b92308\nTitle: Learning Performance-Improving Code Edits\nYear: 2023\nAbstract: The waning of Moore's Law has shifted the focus of the tech industry towards alternative methods for continued performance gains. While optimizing compilers are a standard tool to help increase program efficiency, programmers continue to shoulder much responsibility in crafting and refactoring code with better performance characteristics. In this paper, we investigate the ability of large language models (LLMs) to suggest functionally correct, performance improving code edits. We hypothesize that language models can suggest such edits in ways that would be impractical for static analysis alone. We investigate these questions by curating a large-scale dataset of Performance-Improving Edits, PIE. PIE contains trajectories of programs, where a programmer begins with an initial, slower version and iteratively makes changes to improve the program's performance. We use PIE to evaluate and improve the capacity of large language models. Specifically, use examples from PIE to fine-tune multiple variants of CODEGEN, a billion-scale Transformer-decoder model.",
  "We use PIE to evaluate and improve the capacity of large language models. Specifically, use examples from PIE to fine-tune multiple variants of CODEGEN, a billion-scale Transformer-decoder model. Additionally, we use examples from PIE to prompt OpenAI's CODEX using a few-shot prompting. By leveraging PIE, we find that both CODEX and CODEGEN can generate performance-improving edits, with speedups of more than 2.5x for over 25% of the programs, for C++ and Python, even after the C++ programs were compiled using the O3 optimization level. Crucially, we show that PIE allows CODEGEN, an open-sourced and 10x smaller model than CODEX, to match the performance of CODEX on this challenging task. Overall, this work opens new doors for creating systems and methods that can help programmers write efficient code.",
  "Crucially, we show that PIE allows CODEGEN, an open-sourced and 10x smaller model than CODEX, to match the performance of CODEX on this challenging task. Overall, this work opens new doors for creating systems and methods that can help programmers write efficient code.\nAuthors: Aman Madaan, Alex Shypula, Uri Alon, Milad Hashemi, Parthasarathy Ranganathan, Yiming Yang, Graham Neubig, A. Yazdanbakhsh\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper investigates the ability of large language models (LLMs) to suggest functionally correct, performance improving code edits, and hypothesizes that language models can suggest such edits in ways that would be impractical for static analysis alone.'}",
  "Faculty Name: graham neubig\nMetadata:\nPaperid: 31366ff634fc905affd78dbd8ddc9a872c006a87\nTitle: CodeBERTScore: Evaluating Code Generation with Pretrained Models of Code\nYear: 2023\nAbstract: Since the rise of neural natural-language-to-code models (NL->Code) that can generate long expressions and statements rather than a single next-token, one of the major problems has been reliably evaluating their generated output. In this paper, we propose CodeBERTScore: an evaluation metric for code generation, which builds on BERTScore (Zhang et al., 2020). Instead of encoding only the generated tokens as in BERTScore, CodeBERTScore also encodes the natural language input preceding the generated code, thus modeling the consistency between the generated code and its given natural language context as well. We perform an extensive evaluation of CodeBERTScore across four programming languages. We find that CodeBERTScore achieves a higher correlation with human preference and with functional correctness than all existing metrics. That is, generated code that receives a higher score by CodeBERTScore is more likely to be preferred by humans, as well as to function correctly when executed.",
  "We find that CodeBERTScore achieves a higher correlation with human preference and with functional correctness than all existing metrics. That is, generated code that receives a higher score by CodeBERTScore is more likely to be preferred by humans, as well as to function correctly when executed. We release five language-specific pretrained models to use with our publicly available code. Our language-specific models have been downloaded more than 1,000,000 times from the Huggingface Hub. Our code and data are available at https://github.com/neulab/code-bert-score\nAuthors: Shuyan Zhou, Uri Alon, Sumit Agarwal, Graham Neubig\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is found that generated code that receives a higher score by CodeBERTScore is more likely to be preferred by humans, as well as to function correctly when executed, than all existing metrics.'}",
  "Faculty Name: graham neubig\nMetadata:\nPaperid: 405f1a5602867c66e015491c26d2be5504eed458\nTitle: Neural Machine Translation for the Indigenous Languages of the Americas: An Introduction\nYear: 2023\nAbstract: Neural models have drastically advanced state of the art for machine translation (MT) between high-resource languages. Traditionally, these models rely on large amounts of training data, but many language pairs lack these resources. However, an important part of the languages in the world do not have this amount of data. Most languages from the Americas are among them, having a limited amount of parallel and monolingual data, if any. Here, we present an introduction to the interested reader to the basic challenges, concepts, and techniques that involve the creation of MT systems for these languages. Finally, we discuss the recent advances and findings and open questions, product of an increased interest of the NLP community in these languages.",
  "Here, we present an introduction to the interested reader to the basic challenges, concepts, and techniques that involve the creation of MT systems for these languages. Finally, we discuss the recent advances and findings and open questions, product of an increased interest of the NLP community in these languages.\nAuthors: Manuel Mager, R. Bhatnagar, Graham Neubig, Ngoc Thang Vu, Katharina Kann\nVenue: AMERICASNLP\nTldr: {'model': 'tldr@v2.0.0', 'text': 'An introduction to the interested reader to the basic challenges, concepts, and techniques that involve the creation of MT systems for high- resource languages between high-resource languages.'}",
  "Faculty Name: graham neubig\nMetadata:\nPaperid: 43c0f77f116f986b53eb04f5c9b33f10132ded55\nTitle: User-Centric Evaluation of OCR Systems for Kwak\u2019wala\nYear: 2023\nAbstract: There has been recent interest in improving optical character recognition (OCR) for endangered languages, particularly because a large number of documents and books in these languages are not in machine-readable formats. The performance of OCR systems is typically evaluated using automatic metrics such as character and word error rates. While error rates are useful for the comparison of different models and systems, they do not measure whether and how the transcriptions produced from OCR tools are useful to downstream users. In this paper, we present a human-centric evaluation of OCR systems, focusing on the Kwak'wala language as a case study. With a user study, we show that utilizing OCR reduces the time spent in the manual transcription of culturally valuable documents -- a task that is often undertaken by endangered language community members and researchers -- by over 50%. Our results demonstrate the potential benefits that OCR tools can have on downstream language documentation and revitalization efforts.",
  "With a user study, we show that utilizing OCR reduces the time spent in the manual transcription of culturally valuable documents -- a task that is often undertaken by endangered language community members and researchers -- by over 50%. Our results demonstrate the potential benefits that OCR tools can have on downstream language documentation and revitalization efforts.\nAuthors: Shruti Rijhwani, Daisy Rosenblum, Michayla King, Antonios Anastasopoulos, Graham Neubig\nVenue: COMPUTEL\nTldr: {'model': 'tldr@v2.0.0', 'text': \"This paper presents a human-centric evaluation of OCR systems, focusing on the Kwak'wala language as a case study, and shows that utilizing OCR reduces the time spent in the manual transcription of culturally valuable documents by over 50%.\"}",
  "Faculty Name: graham neubig\nMetadata:\nPaperid: 4d74a5048b884e8bb3842240abf98915c619c8f8\nTitle: Multi-Dimensional Evaluation of Text Summarization with In-Context Learning\nYear: 2023\nAbstract: Evaluation of natural language generation (NLG) is complex and multi-dimensional. Generated text can be evaluated for fluency, coherence, factuality, or any other dimensions of interest. Most frameworks that perform such multi-dimensional evaluation require training on large manually or synthetically generated datasets. In this paper, we study the efficacy of large language models as multi-dimensional evaluators using in-context learning, obviating the need for large training datasets. Our experiments show that in-context learning-based evaluators are competitive with learned evaluation frameworks for the task of text summarization, establishing state-of-the-art on dimensions such as relevance and factual consistency. We then analyze the effects of factors such as the selection and number of in-context examples on performance. Finally, we study the efficacy of in-context learning based evaluators in evaluating zero-shot summaries written by large language models such as GPT-3.",
  "We then analyze the effects of factors such as the selection and number of in-context examples on performance. Finally, we study the efficacy of in-context learning based evaluators in evaluating zero-shot summaries written by large language models such as GPT-3.\nAuthors: Sameer Jain, Vaishakh Keshava, Swarnashree Mysore Sathyendra, Patrick Fernandes, Pengfei Liu, Graham Neubig, Chunting Zhou\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The experiments show that in-context learning-based evaluators are competitive with learned evaluation frameworks for the task of text summarization, establishing state-of-the-art on dimensions such as relevance and factual consistency.'}",
  "Faculty Name: graham neubig\nMetadata:\nPaperid: 5ea8eedcb31859c5730dd1da3804e1be529ffabb\nTitle: A Gold Standard Dataset for the Reviewer Assignment Problem\nYear: 2023\nAbstract: Many peer-review venues are either using or looking to use algorithms to assign submissions to reviewers. The crux of such automated approaches is the notion of the\"similarity score\"--a numerical estimate of the expertise of a reviewer in reviewing a paper--and many algorithms have been proposed to compute these scores. However, these algorithms have not been subjected to a principled comparison, making it difficult for stakeholders to choose the algorithm in an evidence-based manner. The key challenge in comparing existing algorithms and developing better algorithms is the lack of the publicly available gold-standard data that would be needed to perform reproducible research. We address this challenge by collecting a novel dataset of similarity scores that we release to the research community. Our dataset consists of 477 self-reported expertise scores provided by 58 researchers who evaluated their expertise in reviewing papers they have read previously. We use this data to compare several popular algorithms employed in computer science conferences and come up with recommendations for stakeholders.",
  "Our dataset consists of 477 self-reported expertise scores provided by 58 researchers who evaluated their expertise in reviewing papers they have read previously. We use this data to compare several popular algorithms employed in computer science conferences and come up with recommendations for stakeholders. Our main findings are as follows. First, all algorithms make a non-trivial amount of error. For the task of ordering two papers in terms of their relevance for a reviewer, the error rates range from 12%-30% in easy cases to 36%-43% in hard cases, highlighting the vital need for more research on the similarity-computation problem. Second, most existing algorithms are designed to work with titles and abstracts of papers, and in this regime the Specter+MFR algorithm performs best. Third, to improve performance, it may be important to develop modern deep-learning based algorithms that can make use of the full texts of papers: the classical TD-IDF algorithm enhanced with full texts of papers is on par with the deep-learning based Specter+MFR that cannot make use of this information.",
  "Third, to improve performance, it may be important to develop modern deep-learning based algorithms that can make use of the full texts of papers: the classical TD-IDF algorithm enhanced with full texts of papers is on par with the deep-learning based Specter+MFR that cannot make use of this information.\nAuthors: Ivan Stelmakh, J. Wieting, Graham Neubig, Nihar B. Shah\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A novel dataset of similarity scores provided by 58 researchers who evaluated their expertise in reviewing papers they have read previously is collected and used to compare several popular algorithms employed in computer science conferences and come up with recommendations for stakeholders.'}",
  "Faculty Name: graham neubig\nMetadata:\nPaperid: 659be1ff350634f50cc066d258ee6a45e697e552\nTitle: SigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing\nYear: 2023\nAbstract: In our submission to the SIGMORPHON 2023 Shared Task on interlinear glossing (IGT), we explore approaches to data augmentation and modeling across seven low-resource languages. For data augmentation, we explore two approaches: creating artificial data from the provided training data and utilizing existing IGT resources in other languages. On the modeling side, we test an enhanced version of the provided token classification baseline as well as a pretrained multilingual seq2seq model. Additionally, we apply post-correction using a dictionary for Gitksan, the language with the smallest amount of data. We find that our token classification models are the best performing, with the highest word-level accuracy for Arapaho and highest morpheme-level accuracy for Gitksan out of all submissions. We also show that data augmentation is an effective strategy, though applying artificial data pretraining has very different effects across both models tested.",
  "We find that our token classification models are the best performing, with the highest word-level accuracy for Arapaho and highest morpheme-level accuracy for Gitksan out of all submissions. We also show that data augmentation is an effective strategy, though applying artificial data pretraining has very different effects across both models tested.\nAuthors: Taiqi He, Lindia Tjuatja, Nathaniel R. Robinson, Shinji Watanabe, David R. Mortensen, Graham Neubig, L. Levin\nVenue: Special Interest Group on Computational Morphology and Phonology Workshop\nTldr: {'model': 'tldr@v2.0.0', 'text': 'In this submission to the SIGMORPHON 2023 Shared Task on interlinear glossing (IGT), approaches to data augmentation and modeling across seven low-resource languages are explored and token classification models are found to be the best performing.'}",
  "Faculty Name: graham neubig\nMetadata:\nPaperid: 74b05bba46db21e589a2cc0f916f81069b0368ef\nTitle: Bridging the Gap: A Survey on Integrating (Human) Feedback for Natural Language Generation\nYear: 2023\nAbstract: Many recent advances in natural language generation have been fueled by training large language models on internet-scale data. However, this paradigm can lead to models that generate toxic, inaccurate, and unhelpful content, and automatic evaluation metrics often fail to identify these behaviors. As models become more capable, human feedback is an invaluable signal for evaluating and improving models. This survey aims to provide an overview of the recent research that has leveraged human feedback to improve natural language generation. First, we introduce an encompassing formalization of feedback, and identify and organize existing research into a taxonomy following this formalization. Next, we discuss how feedback can be described by its format and objective, and cover the two approaches proposed to use feedback (either for training or decoding): directly using the feedback or training feedback models. We also discuss existing datasets for human-feedback data collection, and concerns surrounding feedback collection.",
  "Next, we discuss how feedback can be described by its format and objective, and cover the two approaches proposed to use feedback (either for training or decoding): directly using the feedback or training feedback models. We also discuss existing datasets for human-feedback data collection, and concerns surrounding feedback collection. Finally, we provide an overview of the nascent field of AI feedback, which exploits large language models to make judgments based on a set of principles and minimize the need for human intervention.\nAuthors: Patrick Fernandes, Aman Madaan, Emmy Liu, Ant\u00f3nio Farinhas, Pedro Henrique Martins, Amanda Bertsch, Jos\u00e9 G. C. de Souza, Shuyan Zhou, Tongshuang Sherry Wu, Graham Neubig, Andr\u00e9 F. T. Martins\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'An overview of the recent research that has leveraged human feedback to improve natural language generation and the nascent field of AI feedback, which exploits large language models to make judgments based on a set of principles and minimize the need for human intervention is provided.'}",
  "Faculty Name: graham neubig\nMetadata:\nPaperid: 7a5b44ea10a51708e18786595c8d70b18950da11\nTitle: FacTool: Factuality Detection in Generative AI - A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios\nYear: 2023\nAbstract: The emergence of generative pre-trained models has facilitated the synthesis of high-quality text, but it has also posed challenges in identifying factual errors in the generated text. In particular: (1) A wider range of tasks now face an increasing risk of containing factual errors when handled by generative models. (2) Generated texts tend to be lengthy and lack a clearly defined granularity for individual facts. (3) There is a scarcity of explicit evidence available during the process of fact checking. With the above challenges in mind, in this paper, we propose FacTool, a task and domain agnostic framework for detecting factual errors of texts generated by large language models (e.g., ChatGPT). Experiments on four different tasks (knowledge-based QA, code generation, mathematical reasoning, and scientific literature review) show the efficacy of the proposed method.",
  "Experiments on four different tasks (knowledge-based QA, code generation, mathematical reasoning, and scientific literature review) show the efficacy of the proposed method. We release the code of FacTool associated with ChatGPT plugin interface at https://github.com/GAIR-NLP/factool .\nAuthors: Ethan Chern, Steffi Chern, Shiqi Chen, Weizhe Yuan, Kehua Feng, Chunting Zhou, Junxian He, Graham Neubig, Pengfei Liu\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper proposes FacTool, a task and domain agnostic framework for detecting factual errors of texts generated by large language models (e.g., ChatGPT), and demonstrates the efficacy of the proposed method.'}",
  "Faculty Name: graham neubig\nMetadata:\nPaperid: 88884b8806262a4095036041e3567d450dba39f7\nTitle: Active Retrieval Augmented Generation\nYear: 2023\nAbstract: Despite the remarkable ability of large language models (LMs) to comprehend and generate language, they have a tendency to hallucinate and create factually inaccurate output. Augmenting LMs by retrieving information from external knowledge resources is one promising solution. Most existing retrieval augmented LMs employ a retrieve-and-generate setup that only retrieves information once based on the input. This is limiting, however, in more general scenarios involving generation of long texts, where continually gathering information throughout generation is essential. In this work, we provide a generalized view of active retrieval augmented generation, methods that actively decide when and what to retrieve across the course of the generation. We propose Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens.",
  "We propose Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens. We test FLARE along with baselines comprehensively over 4 long-form knowledge-intensive generation tasks/datasets. FLARE achieves superior or competitive performance on all tasks, demonstrating the effectiveness of our method. Code and datasets are available at https://github.com/jzbjyb/FLARE.\nAuthors: Zhengbao Jiang, Frank F. Xu, Luyu Gao, Zhiqing Sun, Qian Liu, Jane Dwivedi-Yu, Yiming Yang, Jamie Callan, Graham Neubig\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens.'}",
  "Faculty Name: graham neubig\nMetadata:\nPaperid: 8e8a1489bf4d782d2435cdeb93f7d1f165747c63\nTitle: Large Language Models Enable Few-Shot Clustering\nYear: 2023\nAbstract: Unlike traditional unsupervised clustering, semi-supervised clustering allows users to provide meaningful structure to the data, which helps the clustering algorithm to match the user's intent. Existing approaches to semi-supervised clustering require a significant amount of feedback from an expert to improve the clusters. In this paper, we ask whether a large language model can amplify an expert's guidance to enable query-efficient, few-shot semi-supervised text clustering. We show that LLMs are surprisingly effective at improving clustering. We explore three stages where LLMs can be incorporated into clustering: before clustering (improving input features), during clustering (by providing constraints to the clusterer), and after clustering (using LLMs post-correction). We find incorporating LLMs in the first two stages can routinely provide significant improvements in cluster quality, and that LLMs enable a user to make trade-offs between cost and accuracy to produce desired clusters.",
  "We find incorporating LLMs in the first two stages can routinely provide significant improvements in cluster quality, and that LLMs enable a user to make trade-offs between cost and accuracy to produce desired clusters. We release our code and LLM prompts for the public to use.\nAuthors: Vijay Viswanathan, Kiril Gashteovski, Carolin (Haas) Lawrence, Tongshuang Sherry Wu, Graham Neubig\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is found that incorporating LLMs in the first two stages can routinely provide significant improvements in cluster quality, and that LLMs enable a user to make trade-offs between cost and accuracy to produce desired clusters.'}",
  "Faculty Name: graham neubig\nMetadata:\nPaperid: 9bce3661f01825ad56dc9d2b3d254fd9e3792360\nTitle: Solving NLP Problems through Human-System Collaboration: A Discussion-based Approach\nYear: 2023\nAbstract: Humans work together to solve common problems by having discussions, explaining, and agreeing or disagreeing with each other. Similarly, if a system can have discussions with humans when solving tasks, it can improve the system's performance and reliability. In previous research on explainability, it has only been possible for the system to make predictions and for humans to ask questions about them rather than having a mutual exchange of opinions. This research aims to create a dataset and computational framework for systems that discuss and refine their predictions through dialogue. Through experiments, we show that the proposed system can have beneficial discussions with humans improving the accuracy by up to 25 points in the natural language inference task.",
  "This research aims to create a dataset and computational framework for systems that discuss and refine their predictions through dialogue. Through experiments, we show that the proposed system can have beneficial discussions with humans improving the accuracy by up to 25 points in the natural language inference task.\nAuthors: Masahiro Kaneko, Graham Neubig, Naoaki Okazaki\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This research aims to create a dataset and computational framework for systems that discuss and refine their predictions through dialogue and shows that the proposed system can have beneficial discussions with humans improving the accuracy by up to 25 points in the natural language inference task.'}",
  "Faculty Name: graham neubig\nMetadata:\nPaperid: b4987da792dd45a84232cfb06d71b1c2ec488f38\nTitle: Crossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting\nYear: 2023\nAbstract: Idioms are common in everyday language, but often pose a challenge to translators because their meanings do not follow from the meanings of their parts. Despite significant advances, machine translation systems still struggle to translate idiomatic expressions. We provide a simple characterization of idiomatic translation and related issues. This allows us to conduct a synthetic experiment revealing a tipping point at which transformer-based machine translation models correctly default to idiomatic translations. To expand multilingual resources, we compile a dataset of ~4k natural sentences containing idiomatic expressions in French, Finnish, and Japanese. To improve translation of natural idioms, we introduce two straightforward yet effective techniques: the strategic upweighting of training loss on potentially idiomatic sentences, and using retrieval-augmented models.",
  "To improve translation of natural idioms, we introduce two straightforward yet effective techniques: the strategic upweighting of training loss on potentially idiomatic sentences, and using retrieval-augmented models. This not only improves the accuracy of a strong pretrained MT model on idiomatic sentences by up to 13% in absolute accuracy, but also holds potential benefits for non-idiomatic sentences.\nAuthors: Emmy Liu, Aditi Chaudhary, Graham Neubig\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'To improve translation of natural idioms, this work introduces two straightforward yet effective techniques: the strategic upweighting of training loss on potentially idiomatic sentences, and using retrieval-augmented models.'}",
  "Faculty Name: graham neubig\nMetadata:\nPaperid: c432aff446d55e72a28394a1508e760cc9a25c08\nTitle: Why do Nearest Neighbor Language Models Work?\nYear: 2023\nAbstract: Language models (LMs) compute the probability of a text by sequentially computing a representation of an already-seen context and using this representation to predict the next word. Currently, most LMs calculate these representations through a neural network consuming the immediate previous context. However recently, retrieval-augmented LMs have shown to improve over standard neural LMs, by accessing information retrieved from a large datastore, in addition to their standard, parametric, next-word prediction. In this paper, we set out to understand why retrieval-augmented language models, and specifically why k-nearest neighbor language models (kNN-LMs) perform better than standard parametric LMs, even when the k-nearest neighbor component retrieves examples from the same training set that the LM was originally trained on. To this end, we perform a careful analysis of the various dimensions over which kNN-LM diverges from standard LMs, and investigate these dimensions one by one.",
  "To this end, we perform a careful analysis of the various dimensions over which kNN-LM diverges from standard LMs, and investigate these dimensions one by one. Empirically, we identify three main reasons why kNN-LM performs better than standard LMs: using a different input representation for predicting the next tokens, approximate kNN search, and the importance of softmax temperature for the kNN distribution. Further, we incorporate these insights into the model architecture or the training procedure of the standard parametric LM, improving its results without the need for an explicit retrieval component. The code is available at https://github.com/frankxu2004/knnlm-why.\nAuthors: Frank F. Xu, Uri Alon, Graham Neubig\nVenue: International Conference on Machine Learning\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper identifies three main reasons why k-nearest neighbor language models (kNN-LM) perform better than standard LMs: using a different input representation for predicting the next tokens, approximate kNN search, and the importance of softmax temperature for the kNN distribution.'}",
  "Faculty Name: graham neubig\nMetadata:\nPaperid: c5207241406586f4263b235667e004b71ea68953\nTitle: Syntax and Semantics Meet in the \u201cMiddle\u201d: Probing the Syntax-Semantics Interface of LMs Through Agentivity\nYear: 2023\nAbstract: Recent advances in large language models have prompted researchers to examine their abilities across a variety of linguistic tasks, but little has been done to investigate how models handle the interactions in meaning across words and larger syntactic forms\u2014i.e. phenomena at the intersection of syntax and semantics. We present the semantic notion of agentivity as a case study for probing such interactions. We created a novel evaluation dataset by utilitizing the unique linguistic properties of a subset of optionally transitive English verbs. This dataset was used to prompt varying sizes of three model classes to see if they are sensitive to agentivity at the lexical level, and if they can appropriately employ these word-level priors given a specific syntactic context. Overall, GPT-3 text-davinci-003 performs extremely well across all experiments, outperforming all other models tested by far.",
  "Overall, GPT-3 text-davinci-003 performs extremely well across all experiments, outperforming all other models tested by far. In fact, the results are even better correlated with human judgements than both syntactic and semantic corpus statistics. This suggests that LMs may potentially serve as more useful tools for linguistic annotation, theory testing, and discovery than select corpora for certain tasks.\nAuthors: Lindia Tjuatja, Emmy Liu, L. Levin, Graham Neubig\nVenue: STARSEM\nTldr: {'model': 'tldr@v2.0.0', 'text': 'GPT-3 text-davinci-003 performs extremely well across all experiments, outperforming all other models tested by far and suggests that LMs may potentially serve as more useful tools for linguistic annotation, theory testing, and discovery than select corpora for certain tasks.'}",
  "Faculty Name: graham neubig\nMetadata:\nPaperid: cc1705fe421c70d85254b557634bd4669fdd49b0\nTitle: DataFinder: Scientific Dataset Recommendation from Natural Language Descriptions\nYear: 2023\nAbstract: Modern machine learning relies on datasets to develop and validate research ideas. Given the growth of publicly available data, finding the right dataset to use is increasingly difficult. Any research question imposes explicit and implicit constraints on how well a given dataset will enable researchers to answer this question, such as dataset size, modality, and domain. We operationalize the task of recommending datasets given a short natural language description of a research idea, to help people find relevant datasets for their needs. Dataset recommendation poses unique challenges as an information retrieval problem; datasets are hard to directly index for search and there are no corpora readily available for this task. To facilitate this task, we build the DataFinder Dataset which consists of a larger automatically-constructed training set (17.5K queries) and a smaller expert-annotated evaluation set (392 queries).",
  "To facilitate this task, we build the DataFinder Dataset which consists of a larger automatically-constructed training set (17.5K queries) and a smaller expert-annotated evaluation set (392 queries). Using this data, we compare various information retrieval algorithms on our test set and present a superior bi-encoder retriever for text-based dataset recommendation. This system, trained on the DataFinder Dataset, finds more relevant search results than existing third-party dataset search engines. To encourage progress on dataset recommendation, we release our dataset and models to the public.\nAuthors: Vijay Viswanathan, Luyu Gao, Tongshuang Sherry Wu, Pengfei Liu, Graham Neubig\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work operationalizes the task of recommending datasets given a short natural language description of a research idea, to help people find relevant datasets for their needs, and builds the DataFinder Dataset, a larger automatically-constructed training set and a smaller expert-annotated evaluation set.'}",
  "Faculty Name: graham neubig\nMetadata:\nPaperid: d5dd7230cccace7e77095d3b5fd8394850f59170\nTitle: Multi-lingual and Multi-cultural Figurative Language Understanding\nYear: 2023\nAbstract: Figurative language permeates human communication, but at the same time is relatively understudied in NLP. Datasets have been created in English to accelerate progress towards measuring and improving figurative language processing in language models (LMs). However, the use of figurative language is an expression of our cultural and societal experiences, making it difficult for these phrases to be universally applicable. In this work, we create a figurative language inference dataset, \\datasetname, for seven diverse languages associated with a variety of cultures: Hindi, Indonesian, Javanese, Kannada, Sundanese, Swahili and Yoruba. Our dataset reveals that each language relies on cultural and regional concepts for figurative expressions, with the highest overlap between languages originating from the same region. We assess multilingual LMs' abilities to interpret figurative language in zero-shot and few-shot settings.",
  "Our dataset reveals that each language relies on cultural and regional concepts for figurative expressions, with the highest overlap between languages originating from the same region. We assess multilingual LMs' abilities to interpret figurative language in zero-shot and few-shot settings. All languages exhibit a significant deficiency compared to English, with variations in performance reflecting the availability of pre-training and fine-tuning data, emphasizing the need for LMs to be exposed to a broader range of linguistic and cultural variation during training.\nAuthors: Anubha Kabra, Emmy Liu, Simran Khanuja, Alham Fikri Aji, Genta Indra Winata, Samuel Cahyawijaya, Anuoluwapo Aremu, Perez Ogayo, Graham Neubig\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': \"This work assesses multilingual LMs' abilities to interpret figurative language in zero-shot and few-shot settings, and reveals that each language relies on cultural and regional concepts for figurative expressions, with the highest overlap between languages originating from the same region.\"}",
  "Faculty Name: graham neubig\nMetadata:\nPaperid: d6ae4c0679bdceb029f652efd2a854ac5ade772f\nTitle: It\u2019s MBR All the Way Down: Modern Generation Techniques Through the Lens of Minimum Bayes Risk\nYear: 2023\nAbstract: Minimum Bayes Risk (MBR) decoding is a method for choosing the outputs of a machine learning system based not on the output with the highest probability, but the output with the lowest risk (expected error) among multiple candidates. It is a simple but powerful method: for an additional cost at inference time, MBR provides reliable several-point improvements across metrics for a wide variety of tasks without any additional data or training. Despite this, MBR is not frequently applied in NLP works, and knowledge of the method itself is limited. We first provide an introduction to the method and the recent literature. We show that several recent methods that do not reference MBR can be written as special cases of MBR; this reformulation provides additional theoretical justification for the performance of these methods, explaining some results that were previously only empirical.",
  "We first provide an introduction to the method and the recent literature. We show that several recent methods that do not reference MBR can be written as special cases of MBR; this reformulation provides additional theoretical justification for the performance of these methods, explaining some results that were previously only empirical. We provide theoretical and empirical results about the effectiveness of various MBR variants and make concrete recommendations for the application of MBR in NLP models, including future directions in this area.\nAuthors: Amanda Bertsch, Alex Xie, Graham Neubig, Matthew R. Gormley\nVenue: BIGPICTURE\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is shown that several recent methods that do not reference MBR can be written as special cases of MBR; this reformulation provides additional theoretical justification for the performance of these methods, explaining some results that were previously only empirical.'}",
  "Faculty Name: graham neubig\nMetadata:\nPaperid: dbc368bc8b49347dd27679894524fa62f88492c9\nTitle: Unlimiformer: Long-Range Transformers with Unlimited Length Input\nYear: 2023\nAbstract: Since the proposal of transformers, these models have been limited to bounded input lengths, because of their need to attend to every token in the input. In this work, we propose Unlimiformer: a general approach that wraps any existing pretrained encoder-decoder transformer, and offloads the cross-attention computation to a single k-nearest-neighbor (kNN) index, while the returned kNN distances are the attention dot-product scores. This kNN index can be kept on either the GPU or CPU memory and queried in sub-linear time; this way, we can index practically unlimited input sequences, while every attention head in every decoder layer retrieves its top-k keys, instead of attending to every key. We evaluate Unlimiformer on several long-document and book-summarization benchmarks, showing that it can process even 500k token-long inputs from the BookSum dataset, without any input truncation at test time.",
  "We evaluate Unlimiformer on several long-document and book-summarization benchmarks, showing that it can process even 500k token-long inputs from the BookSum dataset, without any input truncation at test time. We demonstrate that Unlimiformer improves pretrained models such as BART and Longformer by extending them to unlimited inputs without additional learned weights and without modifying their code. We make our code and models publicly available at https://github.com/abertsch72/unlimiformer .\nAuthors: Amanda Bertsch, Uri Alon, Graham Neubig, Matthew R. Gormley\nVenue: Neural Information Processing Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes Unlimiformer: a general approach that wraps any existing pretrained encoder-decoder transformer, and offloads the cross-attention computation to a single k-nearest-neighbor (kNN) index, while the returned kNN distances are the attention dot-product scores.'}",
  "Faculty Name: graham neubig\nMetadata:\nPaperid: e41482f4ee984f17382f6cdd900df094d928be06\nTitle: WebArena: A Realistic Web Environment for Building Autonomous Agents\nYear: 2023\nAbstract: With advances in generative AI, there is now potential for autonomous agents to manage daily tasks via natural language commands. However, current agents are primarily created and tested in simplified synthetic environments, leading to a disconnect with real-world scenarios. In this paper, we build an environment for language-guided agents that is highly realistic and reproducible. Specifically, we focus on agents that perform tasks on the web, and create an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management. Our environment is enriched with tools (e.g., a map) and external knowledge bases (e.g., user manuals) to encourage human-like task-solving. Building upon our environment, we release a set of benchmark tasks focusing on evaluating the functional correctness of task completions. The tasks in our benchmark are diverse, long-horizon, and designed to emulate tasks that humans routinely perform on the internet.",
  "Building upon our environment, we release a set of benchmark tasks focusing on evaluating the functional correctness of task completions. The tasks in our benchmark are diverse, long-horizon, and designed to emulate tasks that humans routinely perform on the internet. We experiment with several baseline agents, integrating recent techniques such as reasoning before acting. The results demonstrate that solving complex tasks is challenging: our best GPT-4-based agent only achieves an end-to-end task success rate of 14.41%, significantly lower than the human performance of 78.24%. These results highlight the need for further development of robust agents, that current state-of-the-art large language models are far from perfect performance in these real-life tasks, and that WebArena can be used to measure such progress.",
  "These results highlight the need for further development of robust agents, that current state-of-the-art large language models are far from perfect performance in these real-life tasks, and that WebArena can be used to measure such progress.\nAuthors: Shuyan Zhou, Frank F. Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, Yonatan Bisk, Daniel Fried, Uri Alon, Graham Neubig\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper builds an environment for language-guided agents that is highly realistic and reproducible, and creates an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management.'}",
  "Faculty Name: graham neubig\nMetadata:\nPaperid: e69684fb06a7b1fe621d7ef0c97fc2ca0e122c43\nTitle: Prompt2Model: Generating Deployable Models from Natural Language Instructions\nYear: 2023\nAbstract: Large language models (LLMs) enable system builders today to create competent NLP systems through prompting, where they only need to describe the task in natural language and provide a few examples. However, in other ways, LLMs are a step backward from traditional special-purpose NLP models; they require extensive computational resources for deployment and can be gated behind APIs. In this paper, we propose Prompt2Model, a general-purpose method that takes a natural language task description like the prompts provided to LLMs, and uses it to train a special-purpose model that is conducive to deployment. This is done through a multi-step process of retrieval of existing datasets and pretrained models, dataset generation using LLMs, and supervised fine-tuning on these retrieved and generated datasets.",
  "This is done through a multi-step process of retrieval of existing datasets and pretrained models, dataset generation using LLMs, and supervised fine-tuning on these retrieved and generated datasets. Over three tasks, we demonstrate that given the same few-shot prompt as input, Prompt2Model trains models that outperform the results of a strong LLM, gpt-3.5-turbo, by an average of 20% while being up to 700 times smaller. We also show that this data can be used to obtain reliable performance estimates of model performance, enabling model developers to assess model reliability before deployment. Prompt2Model is available open-source at https://github.com/neulab/prompt2model.\nAuthors: Vijay Viswanathan, Chenyang Zhao, Amanda Bertsch, Tongshuang Sherry Wu, Graham Neubig\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper proposes Prompt2Model, a general-purpose method that takes a natural language task description like the prompts provided to LLMs, and uses it to train a special-purpose model that is conducive to deployment.'}",
  "Faculty Name: graham neubig\nMetadata:\nPaperid: e7b3b692b0816821aafc0d354749bc3802cbf6ac\nTitle: Computational Language Acquisition with Theory of Mind\nYear: 2023\nAbstract: Unlike current state-of-the-art language models, young children actively acquire language through interactions with their surrounding environment and caretakers. One mechanism that has been argued to be critical to language learning is the ability to infer the mental states of other agents in social environments, coined Theory of Mind (ToM) by Premack&Woodruff (1978). Drawing inspiration from the modern operationalized versions of ToM implemented in Rabinowitz et al. (2018) and Zhu et al. (2021), we build language-learning agents equipped with ToM, and measure its effects on the learning process. We model ToM by giving the speaker agent an internal listener model that is trained alongside the speaker and used to rerank potential utterances. We experiment with varying task difficulty, hypothesizing that models will acquire more complex language to adapt to stronger environmental pressures.",
  "We model ToM by giving the speaker agent an internal listener model that is trained alongside the speaker and used to rerank potential utterances. We experiment with varying task difficulty, hypothesizing that models will acquire more complex language to adapt to stronger environmental pressures. We find that training speakers with a highly weighted ToM listener component leads to performance gains in our image referential game setting. We also find some evidence that increasing task difficulty in the training process results in more fluent and precise utterances in evaluation. This suggests the potential utility of further incorporating ToM, as well as other insights from child language acquisition, into computational models of language acquisition.\nAuthors: Andy T. Liu, Hao Zhu, Emmy Liu, Yonatan Bisk, Graham Neubig\nVenue: International Conference on Learning Representations\nTldr: {'model': 'tldr@v2.0.0', 'text': \"It is found that training speakers with a highly weighted ToM listener component leads to performance gains in the authors' image referential game setting, and suggests the potential utility of further incorporating ToM, as well as other insights from child language acquisition, into computational models of language acquisition.\"}",
  "Faculty Name: graham neubig\nMetadata:\nPaperid: f640e89fcede075b4bde3b2fa0dc78f591589ba3\nTitle: Improving Factuality of Abstractive Summarization via Contrastive Reward Learning\nYear: 2023\nAbstract: Modern abstractive summarization models often generate summaries that contain hallucinated or contradictory information. In this paper, we propose a simple but effective contrastive learning framework that incorporates recent developments in reward learning and factuality metrics. Empirical studies demonstrate that the proposed framework enables summarization models to learn from feedback of factuality metrics using contrastive reward learning, leading to more factual summaries by human evaluations. This suggests that further advances in learning and evaluation algorithms can feed directly into providing more factual summaries. Code and human evaluation results will be publicly available at \\url{https://github.com/EthanC111/factuality_summarization}.",
  "This suggests that further advances in learning and evaluation algorithms can feed directly into providing more factual summaries. Code and human evaluation results will be publicly available at \\url{https://github.com/EthanC111/factuality_summarization}.\nAuthors: Ethan Chern, Zhiruo Wang, Sanjan Das, Bhavuk Sharma, Pengfei Liu, Graham Neubig\nVenue: TRUSTNLP\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Empirical studies demonstrate that the proposed framework enables summarization models to learn from feedback of factuality metrics using contrastive reward learning, leading to more factual summaries by human evaluations, suggesting that further advances in learning and evaluation algorithms can feed directly into providing morefactuality summaries.'}",
  "Faculty Name: graham neubig\nMetadata:\nPaperid: fd80f7f3673fc6ca02f192d5d73426f11a4be659\nTitle: The Devil Is in the Errors: Leveraging Large Language Models for Fine-grained Machine Translation Evaluation\nYear: 2023\nAbstract: Automatic evaluation of machine translation (MT) is a critical tool driving the rapid iterative development of MT systems. While considerable progress has been made on estimating a single scalar quality score, current metrics lack the informativeness of more detailed schemes that annotate individual errors, such as Multidimensional Quality Metrics (MQM). In this paper, we help fill this gap by proposing AutoMQM, a prompting technique which leverages the reasoning and in-context learning capabilities of large language models (LLMs) and asks them to identify and categorize errors in translations. We start by evaluating recent LLMs, such as PaLM and PaLM-2, through simple score prediction prompting, and we study the impact of labeled data through in-context learning and finetuning.",
  "We start by evaluating recent LLMs, such as PaLM and PaLM-2, through simple score prediction prompting, and we study the impact of labeled data through in-context learning and finetuning. We then evaluate AutoMQM with PaLM-2 models, and we find that it improves performance compared to just prompting for scores (with particularly large gains for larger models) while providing interpretability through error spans that align with human annotations.\nAuthors: Patrick Fernandes, Daniel Deutsch, M. Finkelstein, Parker Riley, Andr\u00e9 F. T. Martins, Graham Neubig, Ankush Garg, J. Clark, Markus Freitag, Orhan Firat\nVenue: Conference on Machine Translation\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper proposes AutoMQM, a prompting technique which leverages the reasoning and in-context learning capabilities of large language models (LLMs) and asks them to identify and categorize errors in translations, and finds that it improves performance compared to just prompting for scores.'}",
  "List of 2023 Open Access papers by graham neubig are:\nCross-Modal Fine-Tuning: Align then Refine\nChatGPT MT: Competitive for High- (but Not Low-) Resource Languages\nGlobalBench: A Benchmark for Global Progress in Natural Language Processing\nLearning Performance-Improving Code Edits\nCodeBERTScore: Evaluating Code Generation with Pretrained Models of Code\nNeural Machine Translation for the Indigenous Languages of the Americas: An Introduction\nUser-Centric Evaluation of OCR Systems for Kwak\u2019wala\nMulti-Dimensional Evaluation of Text Summarization with In-Context Learning\nA Gold Standard Dataset for the Reviewer Assignment Problem\nSigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing\nBridging the Gap: A Survey on Integrating (Human) Feedback for Natural Language Generation\nFacTool: Factuality Detection in Generative AI - A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios\nActive Retrieval Augmented Generation\nLarge Language Models Enable Few-Shot Clustering\nSolving NLP Problems through Human-System Collaboration: A Discussion-based Approach\nCrossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss",
  "Augmented Framework for Multi-Task and Multi-Domain Scenarios\nActive Retrieval Augmented Generation\nLarge Language Models Enable Few-Shot Clustering\nSolving NLP Problems through Human-System Collaboration: A Discussion-based Approach\nCrossing the Threshold: Idiomatic Machine Translation through Retrieval Augmentation and Loss Weighting\nWhy do Nearest Neighbor Language Models Work?\nSyntax and Semantics Meet in the \u201cMiddle\u201d: Probing the Syntax-Semantics Interface of LMs Through Agentivity\nDataFinder: Scientific Dataset Recommendation from Natural Language Descriptions\nMulti-lingual and Multi-cultural Figurative Language Understanding\nIt\u2019s MBR All the Way Down: Modern Generation Techniques Through the Lens of Minimum Bayes Risk\nUnlimiformer: Long-Range Transformers with Unlimited Length Input\nWebArena: A Realistic Web Environment for Building Autonomous Agents\nPrompt2Model: Generating Deployable Models from Natural Language Instructions\nComputational Language Acquisition with Theory of Mind\nImproving Factuality of Abstractive Summarization via Contrastive Reward Learning\nThe Devil Is in the Errors: Leveraging Large Language Models for Fine-grained Machine Translation Evaluation",
  "Title: Alexander Hauptmann -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Alexander Hauptmann, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Core Faculty\" name=\"categories-1\"/>\n<meta content=\"Information Extraction, Summarization and Question Answering;Information Retrieval, Text Mining and Analytics;Machine Learning;Multimodal Computing and Interaction\" name=\"categories-2\"/>\n<meta content=\"Yes\" name=\"show-categories-2\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Alexander Hauptmann - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Alexander Hauptmann,",
  "Faculty Member at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Alexander\"/>\n<meta content=\"Lastname\" property=\"profile:Hauptmann\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/hauptmann-alexander.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nAlexander \n                        Hauptmann\nResearch Professor, Language Technologies Institute\nContact\n5519 \u2014Gates & Hillman Centers\nalex(through)cs.cmu.edu\n412-268-1448\nResearch Area\nInformation Extraction, Summarization and Question Answering, Information Retrieval, Text Mining and Analytics, Machine Learning, Multimodal Computing and Interaction\nResearch\nMy research interests revolve around the integration of text, image, video, and audio analysis.",
  "edu\n412-268-1448\nResearch Area\nInformation Extraction, Summarization and Question Answering, Information Retrieval, Text Mining and Analytics, Machine Learning, Multimodal Computing and Interaction\nResearch\nMy research interests revolve around the integration of text, image, video, and audio analysis. In the Informedia Project we built the News-on-Demand application, which is an instantiation of the Informedia Digital Video Library idea, based completely on automatic methods for processing television and radio news. Through the combination of the strengths of speech recognition, natural language processing, information retrieval and interface design, the system is able to overcome some of the shortfalls inherent in each of the component technologies.My goal is to utilize large corpora of \"found data\", i.e., data that is already available through the Internet or other readily accessible open sources, to improve speech and natural language processing by exploiting advantages across different modalities. It has become clear in recent years that large volumes of text, image, video, and audio can be easily stored and made available for research and applications. However, most of these sources were not produced with computer processing in mind.",
  "It has become clear in recent years that large volumes of text, image, video, and audio can be easily stored and made available for research and applications. However, most of these sources were not produced with computer processing in mind. My intention is to design and build intelligent, understanding programs that help process data from these sources and make the data useful for other applications. This data can be used to improve speech recognition, image understanding, natural language processing, machine learning as well as information retrieval. The challenge is to find the right data, process it into suitable form for training, learning or re-use and build mechanisms that can successfully utilize this data.Speech and multimedia technology are about to make a major impact on our daily interaction with computers. What is needed at this point are clear demonstrations of the advantages of integrated speech and multimedia interfaces.\nCV\n(brief)\n\nLinks:",
  "Title: Daphne Ippolito -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Daphne Ippolito, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Core Faculty\" name=\"categories-1\"/>\n<meta content=\"Creativity;Language Technology Application Areas/Issues;Natural Language Generation;Privacy and Security\" name=\"categories-2\"/>\n<meta content=\"Yes\" name=\"show-categories-2\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Daphne Ippolito - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Daphne Ippolito,",
  "Faculty Member at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Daphne\"/>\n<meta content=\"Lastname\" property=\"profile:Ippolito\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/ippolito-daphne.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nDaphne \n                        Ippolito\nAssistant Professor, Language Technologies Institute\nContact\n3525 \u2014Newell-Simon Hall\ndaphnei(through)cmu.edu\nResearch Area\nCreativity, Language Technology Application Areas/Issues, Natural Language Generation, Privacy and Security\nPersonal Website\n\nLinks:\nhttps://daphnei.com/",
  "List of 2023 Open Access papers by jack mostow are:",
  "Faculty Name: jamie callan\nMetadata:\nPaperid: 197d5fbc3764ff18186275545d0764d5b1c7659b\nTitle: Conversational Search with Random Walks over Entity Graphs\nYear: 2023\nAbstract: The entities that emerge during a conversation can be used to model topics, but not all entities are equally useful for this task. Modeling the conversation with entity graphs and predicting each entity's centrality in the conversation provides additional information that improves the retrieval of answer passages for the current question. Experiments show that using random walks to estimate entity centrality on conversation entity graphs improves top precision answer passage ranking over competitive transformer-based baselines.\nAuthors: Gustavo Gon\u00e7alves, Jo\u00e3o Magalh\u00e3es, Jamie Callan\nVenue: International Conference on the Theory of Information Retrieval\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Experiments show that using random walks to estimate entity centrality on conversation entity graphs improves top precision answer passage ranking over competitive transformer-based baselines.'}",
  "Faculty Name: jamie callan\nMetadata:\nPaperid: 1e0a4ff0c5d2d850ff5907e310ffcedc9cad9718\nTitle: KALE: Using a K-Sparse Projector for Lexical Expansion\nYear: 2023\nAbstract: Recent research has proposed retrieval approaches based on sparse representations and inverted indexes, with terms produced by neural language models and leveraging the advantages from both neural retrieval and lexical matching. This paper proposes KALE, a new lightweight method of this family that uses a small model with a k-sparse projector to convert dense representations into a sparse set of entries from a latent vocabulary. The KALE vocabulary captures semantic concepts than perform well when used in isolation, and perform better when extending the original lexical vocabulary, this way improving first-stage retrieval accuracy. Experiments with the MSMARCOv1 passage retrieval dataset, the TREC Deep Learning dataset, and BEIR datasets, examined the effectiveness of KALE under varying conditions. Results show that the KALE terms can replace the original lexical vocabulary, with gains in accuracy and efficiency.",
  "Experiments with the MSMARCOv1 passage retrieval dataset, the TREC Deep Learning dataset, and BEIR datasets, examined the effectiveness of KALE under varying conditions. Results show that the KALE terms can replace the original lexical vocabulary, with gains in accuracy and efficiency. Combining KALE with the original lexical vocabulary, or with other learned terms, can further improve retrieval accuracy with only a modest increase in computational cost.\nAuthors: Lu\u00eds Borges, Bruno Martins, Jamie Callan\nVenue: International Conference on the Theory of Information Retrieval\nTldr: {'model': 'tldr@v2.0.0', 'text': 'KALE is a new lightweight method that uses a small model with a k-sparse projector to convert dense representations into a sparse set of entries from a latent vocabulary, which can replace the original lexical vocabulary with gains in accuracy and efficiency.'}",
  "Faculty Name: jamie callan\nMetadata:\nPaperid: 6b7eefa15c0a461afeab4fa13cf862c5340fdc2a\nTitle: CSurF: Sparse Lexical Retrieval through Contextualized Surface Forms\nYear: 2023\nAbstract: Lexical exact-match systems perform text retrieval efficiently with sparse matching signals and fast retrieval through inverted lists, but naturally suffer from the mismatch between lexical surface form and implicit term semantics. This paper proposes to directly bridge the surface form space and the term semantics space in lexical exact-match retrieval via contextualized surface forms (CSF). Each CSF pairs a lexical surface form with a context source, and is represented by a lexical form weight and a contextualized semantic vector representation. This framework is able to perform sparse lexicon-based retrieval by learning to represent each query and document as a \"bag-of-CSFs\", simultaneously addressing two key factors in sparse retrieval: vocabulary expansion of surface form and semantic representation of term meaning. At retrieval time, it efficiently matches CSFs through exact-match of learned surface forms, and effectively scores each CSF pair via contextual semantic representations, leading to joint improvement in both term match and term scoring.",
  "At retrieval time, it efficiently matches CSFs through exact-match of learned surface forms, and effectively scores each CSF pair via contextual semantic representations, leading to joint improvement in both term match and term scoring. Multiple experiments show that this approach successfully resolves the main mismatch issues in lexical exact-match retrieval and outperforms state-of-the-art lexical exact-match systems, reaching comparable accuracy as lexical all-to-all soft match systems as an efficient exact-match-based system.\nAuthors: Zhen Fan, Luyu Gao, Jamie Callan\nVenue: International Conference on the Theory of Information Retrieval\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper proposes to directly bridge the surface form space and the term semantics space in lexical exact-match retrieval via contextualized surface forms (CSF), reaching comparable accuracy as lexical all-to-all soft match systems as an efficient exact- match-based system.'}",
  "Faculty Name: jamie callan\nMetadata:\nPaperid: 88884b8806262a4095036041e3567d450dba39f7\nTitle: Active Retrieval Augmented Generation\nYear: 2023\nAbstract: Despite the remarkable ability of large language models (LMs) to comprehend and generate language, they have a tendency to hallucinate and create factually inaccurate output. Augmenting LMs by retrieving information from external knowledge resources is one promising solution. Most existing retrieval augmented LMs employ a retrieve-and-generate setup that only retrieves information once based on the input. This is limiting, however, in more general scenarios involving generation of long texts, where continually gathering information throughout generation is essential. In this work, we provide a generalized view of active retrieval augmented generation, methods that actively decide when and what to retrieve across the course of the generation. We propose Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens.",
  "We propose Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens. We test FLARE along with baselines comprehensively over 4 long-form knowledge-intensive generation tasks/datasets. FLARE achieves superior or competitive performance on all tasks, demonstrating the effectiveness of our method. Code and datasets are available at https://github.com/jzbjyb/FLARE.\nAuthors: Zhengbao Jiang, Frank F. Xu, Luyu Gao, Zhiqing Sun, Qian Liu, Jane Dwivedi-Yu, Yiming Yang, Jamie Callan, Graham Neubig\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens.'}",
  "Faculty Name: jamie callan\nMetadata:\nPaperid: ac9ee72a5cd611e9143e385f668af662583721ee\nTitle: Multi-Objective Improvement of Android Applications\nYear: 2023\nAbstract: Non-functional properties, such as runtime or memory use, are important to mobile app users and developers, as they affect user experience. Previous work on automated improvement of non-functional properties in mobile apps failed to address the inherent trade-offs between such properties. We propose a practical approach and the first open-source tool, GIDroid (2023), for multi-objective automated improvement of Android apps. In particular, we use Genetic improvement, a search-based technique that navigates the space of software variants to find improved software. We use a simulation-based testing framework to greatly improve the speed of search. GIDroid contains three state-of-the-art multi-objective algorithms, and two new mutation operators, which cache the results of method calls. Genetic improvement relies on testing to validate patches. Previous work showed that tests in open-source Android applications are scarce. We thus wrote tests for 21 versions of 7 Android apps, creating a new benchmark for performance improvements.",
  "Genetic improvement relies on testing to validate patches. Previous work showed that tests in open-source Android applications are scarce. We thus wrote tests for 21 versions of 7 Android apps, creating a new benchmark for performance improvements. We used GIDroid to improve versions of mobile apps where developers had previously found improvements to runtime, memory, and bandwidth use. Our technique automatically re-discovers 64% of existing improvements. We then applied our approach to current versions of software in which there were no known improvements. We were able to improve execution time by up to 35%, and memory use by up to 33% in these apps.\nAuthors: Jamie Callan, J. Petke\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes a practical approach and the first open-source tool, GIDroid, for multi-objective automated improvement of Android apps, and uses Genetic improvement, a search-based technique that navigates the space of software variants to find improved software.'}",
  "List of 2023 Open Access papers by jamie callan are:\nConversational Search with Random Walks over Entity Graphs\nKALE: Using a K-Sparse Projector for Lexical Expansion\nCSurF: Sparse Lexical Retrieval through Contextualized Surface Forms\nActive Retrieval Augmented Generation\nMulti-Objective Improvement of Android Applications",
  "Faculty Name: jeffrey bigham\nMetadata:\nPaperid: 0e84679cf0945a2868245ba2be68c90453e48f2e\nTitle: Screen Correspondence: Mapping Interchangeable Elements between UIs\nYear: 2023\nAbstract: Understanding user interface (UI) functionality is a useful yet challenging task for both machines and people. In this paper, we investigate a machine learning approach for screen correspondence, which allows reasoning about UIs by mapping their elements onto previously encountered examples with known functionality and properties. We describe and implement a model that incorporates element semantics, appearance, and text to support correspondence computation without requiring any labeled examples. Through a comprehensive performance evaluation, we show that our approach improves upon baselines by incorporating multi-modal properties of UIs. Finally, we show three example applications where screen correspondence facilitates better UI understanding for humans and machines: (i) instructional overlay generation, (ii) semantic UI element search, and (iii) automated interface testing.",
  "Finally, we show three example applications where screen correspondence facilitates better UI understanding for humans and machines: (i) instructional overlay generation, (ii) semantic UI element search, and (iii) automated interface testing.\nAuthors: Jason Wu, Amanda Swearngin, Xiaoyi Zhang, Jeffrey Nichols, Jeffrey P. Bigham\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper describes and implements a model that incorporates element semantics, appearance, and text to support correspondence computation without requiring any labeled examples, and shows that this approach improves upon baselines by incorporating multi-modal properties of UIs.'}",
  "Faculty Name: jeffrey bigham\nMetadata:\nPaperid: 3f261fb980858e39129af5bc8a6c8565d7bb8329\nTitle: Exploring Stigmergic Collaboration and Task Modularity Through an Expert Crowdsourcing Annotation System: The Case of Storm Phenomena in the Euro-Atlantic Region\nYear: 2023\nAbstract: Extreme weather events, such as windstorms, hurricanes, and heat waves, exert a significant impact on global natural catastrophes and pose substantial challenges for weather forecasting systems. To enhance the accuracy and preparedness for extreme weather events, this study explores the potential of using expert crowdsourcing in storm forecasting research through the application of stigmergic collaboration. We present the development and implementation of an expert Crowdsourcing for Semantic Annotation of Atmospheric Phenomena (eCSAAP) system, designed to leverage the collective knowledge and experience of meteorological experts. Through a participatory co-creation process, we iteratively developed a web-based annotation tool capable of capturing multi-faceted insights from weather data and generating visualizations for expert crowdsourcing campaigns.",
  "Through a participatory co-creation process, we iteratively developed a web-based annotation tool capable of capturing multi-faceted insights from weather data and generating visualizations for expert crowdsourcing campaigns. In this context, this article investigates the intrinsic coordination among experts engaged in crowdsourcing tasks focused on the semantic annotation of extreme weather events. The study brings insights about the behavior of expert crowds by considering the cognitive biases and highlighting the impact of existing annotations on the quality of data gathered from the crowd and the collective knowledge generated. The insights regarding the crowdsourcing dynamics, particularly stigmergy, offer a promising starting point for utilizing stigmergic collaboration as an effective coordination mechanism for weather experts in crowdsourcing platforms but also in other domains requiring expertise-driven collective intelligence.",
  "The insights regarding the crowdsourcing dynamics, particularly stigmergy, offer a promising starting point for utilizing stigmergic collaboration as an effective coordination mechanism for weather experts in crowdsourcing platforms but also in other domains requiring expertise-driven collective intelligence.\nAuthors: Dennis Paulino, Ant\u00f3nio Correia, M. Yagui, Jo\u00e3o Barroso, Margarida L. R. Liberato, A. Vivacqua, Andrea Grover, Jeffrey P. Bigham, Hugo Paredes\nVenue: IEEE Access\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The intrinsic coordination among experts engaged in crowdsourcing tasks focused on the semantic annotation of extreme weather events is investigated, bringing insights about the behavior of expert crowds by considering the cognitive biases and highlighting the impact of existing annotations on the quality of data gathered from the crowd and the collective knowledge generated.'}",
  "Faculty Name: jeffrey bigham\nMetadata:\nPaperid: 7ee7d32c3e7f01f49c40e5ba7e0b4d5e9ea040c9\nTitle: Nonverbal Communication through Expressive Objects\nYear: 2023\nAbstract: Augmentative and alternative communication (AAC) devices enable speech-based communication, but generating speech is not the only resource needed to have a successful conversation. Being able to signal one wishes to take a turn by raising a hand or providing some other cue is critical in securing a turn to speak. Experienced conversation partners know how to recognize the nonverbal communication an augmented communicator (AC) displays, but these same nonverbal gestures can be hard to interpret by people who meet an AC for the first time. Prior work has identified motion through robots and expressive objects as a modality that can support communication. In this work, we work closely with an AAC user to understand how motion through a physical expressive object can support their communication. We present our process and resulting lessons on the designed object and the co-design process.",
  "Prior work has identified motion through robots and expressive objects as a modality that can support communication. In this work, we work closely with an AAC user to understand how motion through a physical expressive object can support their communication. We present our process and resulting lessons on the designed object and the co-design process.\nAuthors: Stephanie Valencia, Mark Steidl, Michael L. Rivera, Cynthia L. Bennett, Jeffrey P. Bigham, H. Admoni\nVenue: Communications of the ACM\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work works closely with an AAC user to understand how motion through a physical expressive object can support their communication and presents the process and resulting lessons on the designed object and the co-design process.'}",
  "Faculty Name: jeffrey bigham\nMetadata:\nPaperid: 8ab27849799286459465d2262f926354093b20a9\nTitle: USB: A Unified Summarization Benchmark Across Tasks and Domains\nYear: 2023\nAbstract: While the NLP community has produced numerous summarization benchmarks, none provide the rich annotations required to simultaneously address many important problems related to control and reliability. We introduce a Wikipedia-derived benchmark, complemented by a rich set of crowd-sourced annotations, that supports $8$ interrelated tasks: (i) extractive summarization; (ii) abstractive summarization; (iii) topic-based summarization; (iv) compressing selected sentences into a one-line summary; (v) surfacing evidence for a summary sentence; (vi) predicting the factual accuracy of a summary sentence; (vii) identifying unsubstantiated spans in a summary sentence; (viii) correcting factual errors in summaries. We compare various methods on this benchmark and discover that on multiple tasks, moderately-sized fine-tuned models consistently outperform much larger few-shot prompted language models.",
  "We compare various methods on this benchmark and discover that on multiple tasks, moderately-sized fine-tuned models consistently outperform much larger few-shot prompted language models. For factuality-related tasks, we also evaluate existing heuristics to create training data and find that training on them results in worse performance than training on $20\\times$ less human-labeled data. Our articles draw from $6$ domains, facilitating cross-domain analysis. On some tasks, the amount of training data matters more than the domain where it comes from, while for other tasks training specifically on data from the target domain, even if limited, is more beneficial.\nAuthors: Kundan Krishna, Prakhar Gupta, S. Ramprasad, Byron C. Wallace, Jeffrey P. Bigham, Zachary Chase Lipton\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A Wikipedia-derived benchmark is introduced, complemented by a rich set of crowd-sourced annotations, that supports interrelated tasks and finds that on multiple tasks, moderately-sized fine-tuned models consistently outperform much larger few-shot prompted language models.'}",
  "Faculty Name: jeffrey bigham\nMetadata:\nPaperid: 98abc6de98a24d599cf009a9670eaa5c97cba9bb\nTitle: WebUI: A Dataset for Enhancing Visual UI Understanding with Web Semantics\nYear: 2023\nAbstract: Modeling user interfaces (UIs) from visual information allows systems to make inferences about the functionality and semantics needed to support use cases in accessibility, app automation, and testing. Current datasets for training machine learning models are limited in size due to the costly and time-consuming process of manually collecting and annotating UIs. We crawled the web to construct WebUI, a large dataset of 400,000 rendered web pages associated with automatically extracted metadata. We analyze the composition of WebUI and show that while automatically extracted data is noisy, most examples meet basic criteria for visual UI modeling. We applied several strategies for incorporating semantics found in web pages to increase the performance of visual UI understanding models in the mobile domain, where less labeled data is available: (i) element detection, (ii) screen classification and (iii) screen similarity.",
  "We applied several strategies for incorporating semantics found in web pages to increase the performance of visual UI understanding models in the mobile domain, where less labeled data is available: (i) element detection, (ii) screen classification and (iii) screen similarity.\nAuthors: Jason Wu, Siyan Wang, Siman Shen, Yi-Hao Peng, Jeffrey Nichols, Jeffrey P. Bigham\nVenue: International Conference on Human Factors in Computing Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work crawled the web to construct WebUI, a large dataset of 400,000 rendered web pages associated with automatically extracted metadata, and analyzed the composition of WebUI to show that while automatically extracted data is noisy, most examples meet basic criteria for visual UI modeling.'}",
  "Faculty Name: jeffrey bigham\nMetadata:\nPaperid: c84f0a204827065338c412ace037952900a1a279\nTitle: Never-ending Learning of User Interfaces\nYear: 2023\nAbstract: Machine learning models have been trained to predict semantic information about user interfaces (UIs) to make apps more accessible, easier to test, and to automate. Currently, most models rely on datasets of static screenshots that are labeled by human annotators, a process that is costly and surprisingly error-prone for certain tasks. For example, workers labeling whether a UI element is \u201ctappable\u201d from a screenshot must guess using visual signifiers, and do not have the benefit of tapping on the UI element in the running app and observing the effects. In this paper, we present the Never-ending UI Learner, an app crawler that automatically installs real apps from a mobile app store and crawls them to infer semantic properties of UIs by interacting with UI elements, discovering new and challenging training examples to learn from, and continually updating machine learning models designed to predict these semantics.",
  "The Never-ending UI Learner so far has crawled for more than 5,000 device-hours, performing over half a million actions on 6,000 apps to train three computer vision models for i) tappability prediction, ii) draggability prediction, and iii) screen similarity.\nAuthors: Jason Wu, Rebecca Krosnick, E. Schoop, Amanda Swearngin, Jeffrey P. Bigham, Jeffrey Nichols\nVenue: ACM Symposium on User Interface Software and Technology\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The Never-ending UI Learner is presented, an app crawler that automatically installs real apps from a mobile app store and crawls them to infer semantic properties of UIs by interacting with UI elements, discovering new and challenging training examples to learn from, and continually updating machine learning models designed to predict these semantics.'}",
  "Faculty Name: jeffrey bigham\nMetadata:\nPaperid: d757a58200254625c3326a32a1da6fa8eaa2eff3\nTitle: Latent Phrase Matching for Dysarthric Speech\nYear: 2023\nAbstract: Many consumer speech recognition systems are not tuned for people with speech disabilities, resulting in poor recognition and user experience, especially for severe speech differences. Recent studies have emphasized interest in personalized speech models from people with atypical speech patterns. We propose a query-by-example-based personalized phrase recognition system that is trained using small amounts of speech, is language agnostic, does not assume a traditional pronunciation lexicon, and generalizes well across speech difference severities. On an internal dataset collected from 32 people with dysarthria, this approach works regardless of severity and shows a 60% improvement in recall relative to a commercial speech recognition system. On the public EasyCall dataset of dysarthric speech, our approach improves accuracy by 30.5%. Performance degrades as the number of phrases increases, but consistently outperforms ASR systems when trained with 50 unique phrases.",
  "On the public EasyCall dataset of dysarthric speech, our approach improves accuracy by 30.5%. Performance degrades as the number of phrases increases, but consistently outperforms ASR systems when trained with 50 unique phrases.\nAuthors: Colin S. Lea, Dianna Yee, Jaya Narain, Zifang Huang, Lauren Tooley, Jeffrey P. Bigham, Leah Findlater\nVenue: Interspeech\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A query-by-example-based personalized phrase recognition system that is trained using small amounts of speech, is language agnostic, does not assume a traditional pronunciation lexicon, and generalizes well across speech difference severities is proposed.'}",
  "Faculty Name: jeffrey bigham\nMetadata:\nPaperid: dc73363f3a550abc41fefdc182763e183531869f\nTitle: Towards Automated Accessibility Report Generation for Mobile Apps\nYear: 2023\nAbstract: Many apps have basic accessibility issues, like missing labels or low contrast. Automated tools can help app developers catch basic issues, but can be laborious or require writing dedicated tests. We propose a system, motivated by a collaborative process with accessibility stakeholders at a large technology company, to generate whole app accessibility reports by combining varied data collection methods (e.g., app crawling, manual recording) with an existing accessibility scanner. Many such scanners are based on single-screen scanning, and a key problem in whole app accessibility reporting is to effectively de-duplicate and summarize issues collected across an app. To this end, we developed a screen grouping model with 96.9% accuracy (88.8% F1-score) and UI element matching heuristics with 97% accuracy (98.2% F1-score).",
  "To this end, we developed a screen grouping model with 96.9% accuracy (88.8% F1-score) and UI element matching heuristics with 97% accuracy (98.2% F1-score). We combine these technologies in a system to report and summarize unique issues across an app, and enable a unique pixel-based ignore feature to help engineers and testers better manage reported issues across their app's lifetime. We conducted a qualitative evaluation with 18 accessibility-focused engineers and testers which showed this system can enhance their existing accessibility testing toolkit and address key limitations in current accessibility scanning tools.",
  "We conducted a qualitative evaluation with 18 accessibility-focused engineers and testers which showed this system can enhance their existing accessibility testing toolkit and address key limitations in current accessibility scanning tools.\nAuthors: Amanda Swearngin, Jason Wu, Xiaoyi Zhang, Esteban Gomez, Jen Coughenour, Rachel Stukenborg, Bhavya Garg, Greg Hughes, Adriana Hilliard, Jeffrey P Bigham, Jeffrey Nichols\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': \"A system to generate whole app accessibility reports by combining varied data collection methods (e.g., app crawling, manual recording) with an existing accessibility scanner and enables a unique pixel-based ignore feature to help engineers and testers better manage reported issues across their app's lifetime.\"}",
  "Faculty Name: jeffrey bigham\nMetadata:\nPaperid: f29922cbfaf825d5e1d4986dc01bda74b4d88e04\nTitle: From User Perceptions to Technical Improvement: Enabling People Who Stutter to Better Use Speech Recognition\nYear: 2023\nAbstract: Consumer speech recognition systems do not work as well for many people with speech differences, such as stuttering, relative to the rest of the general population. However, what is not clear is the degree to which these systems do not work, how they can be improved, or how much people want to use them. In this paper, we first address these questions using results from a 61-person survey from people who stutter and find participants want to use speech recognition but are frequently cut off, misunderstood, or speech predictions do not represent intent. In a second study, where 91 people who stutter recorded voice assistant commands and dictation, we quantify how dysfluencies impede performance in a consumer-grade speech recognition system.",
  "In a second study, where 91 people who stutter recorded voice assistant commands and dictation, we quantify how dysfluencies impede performance in a consumer-grade speech recognition system. Through three technical investigations, we demonstrate how many common errors can be prevented, resulting in a system that cuts utterances off 79.1% less often and improves word error rate from 25.4% to 9.9%.\nAuthors: Colin S. Lea, Zifang Huang, Jaya Narain, Lauren Tooley, Dianna Yee, Dung Tien Tran, P. Georgiou, Jeffrey P. Bigham, Leah Findlater\nVenue: International Conference on Human Factors in Computing Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Through three technical investigations, it is demonstrated how many common errors can be prevented, resulting in a system that cuts utterances off 79.1% less often and improves word error rate from 25.4% to 9.9%.'}",
  "List of 2023 Open Access papers by jeffrey bigham are:\nScreen Correspondence: Mapping Interchangeable Elements between UIs\nExploring Stigmergic Collaboration and Task Modularity Through an Expert Crowdsourcing Annotation System: The Case of Storm Phenomena in the Euro-Atlantic Region\nNonverbal Communication through Expressive Objects\nUSB: A Unified Summarization Benchmark Across Tasks and Domains\nWebUI: A Dataset for Enhancing Visual UI Understanding with Web Semantics\nNever-ending Learning of User Interfaces\nLatent Phrase Matching for Dysarthric Speech\nFrom User Perceptions to Technical Improvement: Enabling People Who Stutter to Better Use Speech Recognition\nTowards Automated Accessibility Report Generation for Mobile Apps",
  "Title: Lu Jiang -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Lu Jiang, Adjunct Faculty at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Adjunct Faculty\" name=\"categories-1\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Lu Jiang - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Lu Jiang, Adjunct Faculty at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Lu\"/>\n<meta content=\"Lastname\" property=\"profile:Jiang\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/jiang-lu.",
  "cmu.edu//people/faculty/jiang-lu.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nLu \n                        Jiang\nStaff Research Scientist, Google\nContact\nlujiang(through)google.com\nPersonal Website\n\nLinks:\nhttp://www.lujiang.info/",
  "Faculty Name: justine cassell\nMetadata:\nPaperid: 24bff26f19051b1413d1e343322c1ae4bba05428\nTitle: When to generate hedges in peer-tutoring interactions\nYear: 2023\nAbstract: This paper explores the application of machine learning techniques to predict where hedging occurs in peer-tutoring interactions. The study uses a naturalistic face-to-face dataset annotated for natural language turns, conversational strategies, tutoring strategies, and nonverbal behaviors. These elements are processed into a vector representation of the previous turns, which serves as input to several machine learning models, including MLP and LSTM. The results show that embedding layers, capturing the semantic information of the previous turns, significantly improves the model\u2019s performance. Additionally, the study provides insights into the importance of various features, such as interpersonal rapport and nonverbal behaviors, in predicting hedges by using Shapley values for feature explanation. We discover that the eye gaze of both the tutor and the tutee has a significant impact on hedge prediction. We further validate this observation through a follow-up ablation study.",
  "We discover that the eye gaze of both the tutor and the tutee has a significant impact on hedge prediction. We further validate this observation through a follow-up ablation study.\nAuthors: Alafate Abulimiti, C. Clavel, Justine Cassell\nVenue: SIGDIAL Conferences\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The results show that embedding layers, capturing the semantic information of the previous turns, significantly improves the model\u2019s performance and provides insights into the importance of various features, such as interpersonal rapport and nonverbal behaviors, in predicting hedges by using Shapley values for feature explanation.'}",
  "Faculty Name: justine cassell\nMetadata:\nPaperid: 74fedee9d809ec766a2089a89435fa7dd1346693\nTitle: How About Kind of Generating Hedges using End-to-End Neural Models?\nYear: 2023\nAbstract: Hedging is a strategy for softening the impact of a statement in conversation. In reducing the strength of an expression, it may help to avoid embarrassment (more technically, \u201cface threat\u201d) to one\u2019s listener. For this reason, it is often found in contexts of instruction, such as tutoring. In this work, we develop a model of hedge generation based on i) fine-tuning state-of-the-art language models trained on human-human tutoring data, followed by ii) reranking to select the candidate that best matches the expected hedging strategy within a candidate pool using a hedge classifier. We apply this method to a natural peer-tutoring corpus containing a significant number of disfluencies, repetitions, and repairs. The results show that generation in this noisy environment is feasible with reranking. By conducting an error analysis for both approaches, we reveal the challenges faced by systems attempting to accomplish both social and task-oriented goals in conversation.",
  "The results show that generation in this noisy environment is feasible with reranking. By conducting an error analysis for both approaches, we reveal the challenges faced by systems attempting to accomplish both social and task-oriented goals in conversation.\nAuthors: Alafate Abulimiti, C. Clavel, Justine Cassell\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work develops a model of hedge generation based on fine-tuning state-of-the-art language models trained on human-human tutoring data, followed by reranking to select the candidate that best matches the expected hedging strategy within a candidate pool using a hedge classifier.'}",
  "Faculty Name: justine cassell\nMetadata:\nPaperid: a82f56482b9e63714ea0d1948ac3aa6edb092001\nTitle: Beyond Single-Mindedness: A Figure-Ground Reversal for the Cognitive Sciences\nYear: 2023\nAbstract: A fundamental fact about human minds is that they are never truly alone: all minds are steeped in situated interaction. That social interaction matters is recognized by any experimentalist who seeks to exclude its influence by studying individuals in isolation. On this view, interaction complicates cognition. Here, we explore the more radical stance that interaction co-constitutes cognition: that we benefit from looking beyond single minds toward cognition as a process involving interacting minds. All around the cognitive sciences, there are approaches that put interaction center stage. Their diverse and pluralistic origins may obscure the fact that collectively, they harbor insights and methods that can respecify foundational assumptions and fuel novel interdisciplinary work. What might the cognitive sciences gain from stronger interactional foundations? This represents, we believe, one of the key questions for the future.",
  "Their diverse and pluralistic origins may obscure the fact that collectively, they harbor insights and methods that can respecify foundational assumptions and fuel novel interdisciplinary work. What might the cognitive sciences gain from stronger interactional foundations? This represents, we believe, one of the key questions for the future. Writing as a transdisciplinary collective assembled from across the classic cognitive science hexagon and beyond, we highlight the opportunity for a figure-ground reversal that puts interaction at the heart of cognition. The interactive stance is a way of seeing that deserves to be a key part of the conceptual toolkit of cognitive scientists.",
  "Writing as a transdisciplinary collective assembled from across the classic cognitive science hexagon and beyond, we highlight the opportunity for a figure-ground reversal that puts interaction at the heart of cognition. The interactive stance is a way of seeing that deserves to be a key part of the conceptual toolkit of cognitive scientists.\nAuthors: Mark Dingemanse, Andreas Liesenfeld, Marlou Rasenberg, Saul Albert, F. Ameka, Abeba Birhane, Dimitris Bolis, Justine Cassell, Rebecca Clift, E. Cuffari, H. Jaegher, C. Novaes, N. Enfield, Riccardo Fusaroli, E. Gregoromichelaki, E. Hutchins, Ivana Konvalinka, D. Milton, J. R\u0105czaszek-Leonardi, V. Reddy, F. Rossano, David Schlangen, J. Seibt, E. Stokoe, L. Suchman, C. Vesper, T. Wheatley, Martina Wiltschko\nVenue: Cognitive Sciences\nTldr: None",
  "Faculty Name: justine cassell\nMetadata:\nPaperid: b3efaa75beada858414a5ba2346dec317203633c\nTitle: \"You might think about slightly revising the title\u201d: Identifying Hedges in Peer-tutoring Interactions\nYear: 2023\nAbstract: Hedges have an important role in the management of rapport. In peer-tutoring, they are notably used by tutors in dyads experiencing low rapport to tone down the impact of instructions and negative feedback.Pursuing the objective of building a tutoring agent that manages rapport with teenagers in order to improve learning, we used a multimodal peer-tutoring dataset to construct a computational framework for identifying hedges. We compared approaches relying on pre-trained resources with others that integrate insights from the social science literature. Our best performance involved a hybrid approach that outperforms the existing baseline while being easier to interpret. We employ a model explainability tool to explore the features that characterize hedges in peer-tutoring conversations, and we identify some novel features, and the benefits of a such a hybrid model approach.",
  "Our best performance involved a hybrid approach that outperforms the existing baseline while being easier to interpret. We employ a model explainability tool to explore the features that characterize hedges in peer-tutoring conversations, and we identify some novel features, and the benefits of a such a hybrid model approach.\nAuthors: Yann Raphalen, C. Clavel, Justine Cassell\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A model explainability tool is employed to explore the features that characterize hedges in peer-tutoring conversations, and some novel features, and the benefits of a such a hybrid model approach are identified.'}",
  "List of 2023 Open Access papers by justine cassell are:\nWhen to generate hedges in peer-tutoring interactions\nHow About Kind of Generating Hedges using End-to-End Neural Models?\nBeyond Single-Mindedness: A Figure-Ground Reversal for the Cognitive Sciences\n\"You might think about slightly revising the title\u201d: Identifying Hedges in Peer-tutoring Interactions",
  "List of 2023 Open Access papers by kemal oflazer are:\nAbstractive summarization with deep reinforcement learning using semantic similarity rewards",
  "Title: Alon Lavie -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Alon Lavie, Adjunct Faculty at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Adjunct Faculty\" name=\"categories-1\"/>\n<meta content=\"Machine Translation;Natural Language Processing and Computational Linguistics\" name=\"categories-2\"/>\n<meta content=\"Yes\" name=\"show-categories-2\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Alon Lavie - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Alon Lavie, Adjunct Faculty at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Alon\"/>\n<meta content=\"Lastname\" property=\"profile:Lavie\"/>\n<meta content=\"http://lti.cmu.",
  "Adjunct Faculty at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Alon\"/>\n<meta content=\"Lastname\" property=\"profile:Lavie\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/lavie-alon.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nAlon \n                        Lavie\nConsulting Professor, Language Technologies Institute\nVice President of Language Technologies, Unbabel\nContact\nalavie(through)cs.cmu.edu\nResearch Area\nMachine Translation, Natural Language Processing and Computational Linguistics\nResearch\nSince joining Carnegie Mellon in 1996, my research has focused primarily on machine translation (MT) and natural language processing (NLP). In particular, I'm interested in NLP technologies applied to language translation and multilingual processing problems.",
  "Natural Language Processing and Computational Linguistics\nResearch\nSince joining Carnegie Mellon in 1996, my research has focused primarily on machine translation (MT) and natural language processing (NLP). In particular, I'm interested in NLP technologies applied to language translation and multilingual processing problems. My current research investigates machine translation adaptation approaches with human feedback; and syntax-driven statistical and hybrid approaches to MT, applied to both high-resource language pairs and low-resource and minority languages. One of my main focus areas has been developing novel syntax-based methods for acquiring the resources necessary for MT. I have also actively worked on frameworks for multi-engine machine translation (MEMT) and on developing automatic metrics for MT evaluation (particularly, METEOR). In the past, I worked extensively on developing parsing approaches for accurate annotation of grammatical relations (GRs) in spoken language data, on robust parsing algorithms for analysis of spoken language, and on the design and development of speech-to-speech machine translation systems.\nIn 2009, I co-founded Safaba Translation Solutions, where I serve as chairman of the board, president and CTO.",
  "In 2009, I co-founded Safaba Translation Solutions, where I serve as chairman of the board, president and CTO. Safaba develops automated translation solutions for large global enterprises that allow them to migrate and maintain large volumes of content in all the languages in their markets. We also develop advanced solutions that integrate machine translation (MT) technology into the workflow processes used by commercial language service providers (LSPs).\nPersonal Website\n\nLinks:\nhttp://www.cs.cmu.edu/~alavie/",
  "Faculty Name: lei li\nMetadata:\nPaperid: 01d95a39a3a3f333768a1c123eabaa066bf0d20f\nTitle: P53 protein and the diseases in central nervous system\nYear: 2023\nAbstract: P53 protein is the product of P53 gene, which is a well acknowledged tumor suppressor gene. The function of P53 and the relevant mechanisms of anti-neoplasm have raised the interest of researchers since many years ago. It is demonstrated that P53 is a basic cell cycle regulator and a strong inhibitor for versatile cancers in humans. However, most research focuses on other organs and systems instead of the central nervous system (CNS). In fact, in recent years, more and more studies have been suggesting that P53 plays a significant role in multiple CNS tumors and other diseases and disorders such as cerebral stroke and neurodegenerative diseases. In this work, we mainly reviewed the P53\u2019s relationship with CNS tumors, cerebral stroke and neurodegenerative diseases, together with the relevant mechanisms, aiming to summarize the research achievements and providing new insight to the future study on diseases in CNS.",
  "In this work, we mainly reviewed the P53\u2019s relationship with CNS tumors, cerebral stroke and neurodegenerative diseases, together with the relevant mechanisms, aiming to summarize the research achievements and providing new insight to the future study on diseases in CNS.\nAuthors: Li Lei, Qixiong Lu, Guifang Ma, Tao Li, Jiahong Deng, Weijia Li\nVenue: Frontiers in Genetics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The P53\u2019s relationship with CNS tumors, cerebral stroke and neurodegenerative diseases, together with the relevant mechanisms are reviewed, aiming to summarize the research achievements and provide new insight to the future study on diseases in CNS.'}",
  "Faculty Name: lei li\nMetadata:\nPaperid: 0c840a5a5e483ff48cec60e81aa0b0bfa1a99498\nTitle: A Study of Yuediao Folk Music Knowledge Development in Zhoukou, Henan Province, China\nYear: 2023\nAbstract: None\nAuthors: Lei Li, Awirut Thotham\nVenue: Education Quarterly Reviews\nTldr: None",
  "Faculty Name: lei li\nMetadata:\nPaperid: 1386e5712607e293f0b0288a133540e60aaeae67\nTitle: Influence of banded \u03b5-martensite and deformation twin on cryogenic toughness of Fe-Mn-xAl-C steel\nYear: 2023\nAbstract: None\nAuthors: Leilei Li, G. Niu, N. Gong, Hongfei Liu, Xuelin Wang, Chengjia Shang, Yong Wang, Huibin Wu\nVenue: Journal of Materials Research and Technology\nTldr: None",
  "Faculty Name: lei li\nMetadata:\nPaperid: 3c92fd24ea2a49aeba4b368abe3ef13cbce40987\nTitle: Long-tailed Extreme Multi-label Text Classification by the Retrieval of Generated Pseudo Label Descriptions\nYear: 2023\nAbstract: Extreme Multi-label Text Classification (XMTC) has been a tough challenge in machine learning research and applications due to the sheer sizes of the label spaces and the severe data scarcity problem associated with the long tail of rare labels in highly skewed distributions. This paper addresses the challenge of tail label prediction by leveraging the power of dense neural retrieval model in mapping input documents (as queries) to relevant label descriptions. To further enhance the quality of label descriptions, we propose to generate pseudo label descriptions from a trained bag-of-words (BoW) classifier, which demonstrates better classification performance under severe scarce data conditions.The proposed approach achieves the state-of-the-art (SOTA) performance of overall label prediction on XMTC benchmark datasets and especially outperforms the SOTA models in the tail label prediction. We also provide a theoretical analysis for relating the BoW and neural models w.r.t. performance lower bound.",
  "We also provide a theoretical analysis for relating the BoW and neural models w.r.t. performance lower bound.\nAuthors: Ruohong Zhang, Yau-Shian Wang, Yiming Yang, Donghan Yu, Tom Vu, Li Lei\nVenue: Findings\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper addresses the challenge of tail label prediction by leveraging the power of dense neural retrieval model in mapping input documents to relevant label descriptions and generates pseudo label descriptions from a trained bag-of-words (BoW) classifier, which demonstrates better classification performance under severe scarce data conditions.'}",
  "Faculty Name: lei li\nMetadata:\nPaperid: 45e961e87f86888cbe0a117b7a21335690e13c17\nTitle: Oral phage therapy with microencapsulated phage A221 against Escherichia coli infections in weaned piglets\nYear: 2023\nAbstract: None\nAuthors: Xinyu Mao, Yuxin Wu, Runwen Ma, Lei Li, Leping Wang, Yizhou Tan, Ziyong Li, Hui Liu, Kaiou Han, Yajie Cao, Yinan Li, Hao Peng, Xun Li, Chuan-Huo Hu, Xiaoye Wang\nVenue: BMC Veterinary Research\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Oral microencapsulated phage A221 has a good therapeutic effect on bacterial diarrhea of weaned piglets, which provides guidance for the clinical application of phage therapy in the future.'}",
  "Faculty Name: lei li\nMetadata:\nPaperid: 4fac3037fb156bcc42be6d7dbfb90cb933f80f91\nTitle: Correction: Polydopamine-functionalized selenium nanoparticles as an efficient photoresponsive antibacterial platform\nYear: 2023\nAbstract: Correction for \u2018Polydopamine-functionalized selenium nanoparticles as an efficient photoresponsive antibacterial platform\u2019 by Meng Sun et al., RSC Adv., 2023, 13, 9998\u201310004, https://doi.org/10.1039/D2RA07737J.\nAuthors: Meng Sun, Ping Gao, Bao Wang, Xiangyang Li, Donghan Shao, Yan-Jun Xu, Leijiao Li, Yunhui Li, Jianwei Zhu, Wenliang Li, Yingxue Xue\nVenue: RSC Advances\nTldr: {'model': 'tldr@v2.0.0', 'text': None}",
  "Faculty Name: lei li\nMetadata:\nPaperid: 56de9c4c63ee74757be1b203d2ea852690087ded\nTitle: Hence, Socrates is mortal: A Benchmark for Natural Language Syllogistic Reasoning\nYear: 2023\nAbstract: Syllogistic reasoning, a typical form of deductive reasoning, is a critical capability widely required in natural language understanding tasks, such as text entailment and question answering. To better facilitate research on syllogis-tic reasoning, we develop a benchmark called S YLLO B ASE that differs from existing syllo-gistic datasets in three aspects: (1) Covering a complete taxonomy of syllogism reasoning patterns; (2) Containing both automatically and manually constructed samples; and (3) Involving both the generation and understanding tasks. We automatically construct 50k template-based syllogism samples by mining syllogism patterns from Wikidata and ConceptNet. To improve our dataset\u2019s naturalness and challenge, we apply GPT-3 to paraphrase the template-based data and further manually rewrite 1,000 samples as the test set.",
  "To improve our dataset\u2019s naturalness and challenge, we apply GPT-3 to paraphrase the template-based data and further manually rewrite 1,000 samples as the test set. State-of-the-art pre-trained language models can achieve the best generation ROUGE-L of 38.72 by T5 and the best multi-choice accuracy of 72.77% by RoBERTa on S YLLO B ASE , which indicates the great challenge of learning diverse syllo-gistic reasoning types on S YLLO B ASE .",
  "Our datasets are released at https://github.com/ casually-PYlearner\nAuthors: Yongkang Wu, Meng Han, Yutao Zhu, Lei Li, Xinyu Zhang, Ruofei Lai, Xiaoguang Li, Yuanhang Ren, Zhicheng Dou, Zhao Cao\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A benchmark called S YLLO B ASE that differs from existing syllo-gistic datasets in three aspects, covering a complete taxonomy of syllogism reasoning patterns; containing both automatically and manually constructed samples; and involving both the generation and understanding tasks.'}",
  "Faculty Name: lei li\nMetadata:\nPaperid: 6d91a5ce236d4f97a69eb326296133e7f0a352ba\nTitle: Research on torsional stiffness of flexspline-flexible bearing contact pair in harmonic drive based on macro-micro scale modeling\nYear: 2023\nAbstract: The flexspline and flexible bearing constitute a critical contact pair in a harmonic drive system, and their torsional stiffness has a significant impact on the performance characteristics manifested by the harmonic drive. In this study, a micro scale three-dimensional fractal model was combined with a macro scale finite element simulation method to establish an equivalent torsional stiffness model for the flexspline-flexible bearing contact pair (FS-FB contact pair), which enables the theoretical prediction of the torsional stiffness of this contact pair. A torsional stiffness testing platform was constructed for a harmonic drive, and the consistency between the experimental results of the torsional stiffness curve and the theoretical predictions validates the effectiveness of the proposed model. The influences of torque, installation eccentricity, and deformation coefficient on the torsional stiffness of the FS-FB contact pair were also discussed.",
  "The influences of torque, installation eccentricity, and deformation coefficient on the torsional stiffness of the FS-FB contact pair were also discussed. The results indicate that the torsional stiffness of the FS-FB contact pair increases nonlinearly with an increase in torque. On the other hand, the torsional stiffness of the FS-FB contact pair decreases with an increase in installation eccentricity, and increases before subsequently decreasing with an increase in deformation coefficient. Moreover, as torque increases, the impact of installation eccentricity and deformation coefficient on the torsional stiffness diminishes. This article provides a theoretical reference for the optimization design and performance enhancement of harmonic drives.\nAuthors: Qiushi Hu, Hengtao Li, Guang Wang, Leitao Li\nVenue: Frontiers in Materials\nTldr: None",
  "Faculty Name: lei li\nMetadata:\nPaperid: 7005e58d3b5593c4be1d9e2933825d0a99ca93cc\nTitle: Low-Voltage Solution-Processed Zinc-Doped CuI Thin Film Transistors with NOR Logic and Artificial Synaptic Function\nYear: 2023\nAbstract: Low-voltage Zn-doped CuI thin film transistors (TFTs) gated by chitosan dielectric were fabricated at a low temperature. The Zn-doped CuI TFT exhibited a more superior on/off current ratio than CuI TFT due to the substitution or supplementation of copper vacancies by Zn ions. The Zn-doped CuI films were characterized by scanning electron microscope, X-ray diffraction, and X-ray photoelectron spectroscopy. The Zn-doped CuI TFTs exhibited an on/off current ratio of 1.58 \u00d7 104, a subthreshold swing of 70 mV/decade, and a field effect mobility of 0.40 cm2V\u22121s\u22121, demonstrating good operational stability.",
  "The Zn-doped CuI TFTs exhibited an on/off current ratio of 1.58 \u00d7 104, a subthreshold swing of 70 mV/decade, and a field effect mobility of 0.40 cm2V\u22121s\u22121, demonstrating good operational stability. Due to the electric-double-layer (EDL) effect and high specific capacitance (17.3 \u03bcF/cm2) of chitosan gate dielectric, Zn-doped CuI TFT operates at a voltage below \u22122 V. The threshold voltage is \u22120.2 V. In particular, we have prepared Zn-doped CuI TFTs with two in-plane gates and NOR logic operation is implemented on such TFTs. In addition, using the ion relaxation effect and EDL effect of chitosan film, a simple pain neuron simulation is realized on such a p-type TFTs for the first time through the bottom gate to regulate the carrier transport of the channel. This p-type device has promising applications in low-cost electronic devices, complementary electronic circuit, and biosensors.",
  "This p-type device has promising applications in low-cost electronic devices, complementary electronic circuit, and biosensors.\nAuthors: Xiaomin Gan, Wei Dou, Wei-Tzu Hou, Xingchen A. Yuan, Liu Lei, Yulan Zhou, Jia Yang, Diandian Chen, Weichang Zhou, Dongsheng Tang\nVenue: Nanomaterials\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A simple pain neuron simulation is realized on such a p-type TFTs for the first time through the bottom gate to regulate the carrier transport of the channel, which has promising applications in low-cost electronic devices, complementary electronic circuit, and biosensors.'}",
  "Faculty Name: lei li\nMetadata:\nPaperid: 73c9f93d448a359c744447af6daa0b599fb9be4b\nTitle: Optimizing Heat Treatment to Improve the Microstructures and Mechanical Properties of 5CrNiMoV Steel\nYear: 2023\nAbstract: A strategy combining intercritical quenching, pre-tempering, and tempering processes was implemented to optimize the microstructures and mechanical properties of 5CrNiMoV steel. By intercritically quenching at 1050 \u00b0C, pr-tempering at 600 \u00b0C, and tempering at 550 \u00b0C, the steel exhibited a comprehensive performance with a yield strength of 1120 MPa, an ultimate tensile strength of 1230 MPa, and an elongation of 8.2%. The high strength of the steel is attributed to the presence of tempered martensite and abundant secondary carbides. The favorable ductility is mainly provided by the pearlite inherited from intercritical quenching and tempering.",
  "The high strength of the steel is attributed to the presence of tempered martensite and abundant secondary carbides. The favorable ductility is mainly provided by the pearlite inherited from intercritical quenching and tempering. Additionally, the precipitation of secondary carbides not only enhances precipitation strengthening, but also reduces the dislocation density and lattice strain of the matrix, thereby enhancing strength and ductility. This study offers a scheme for producing strong and ductile 5CrNiMoV steel.\nAuthors: Wanhui Huang, Li-sheng Lei, G. Fang\nVenue: Metals\nTldr: None",
  "Faculty Name: lei li\nMetadata:\nPaperid: 75b68d0903af9d9f6e47ce3cf7e1a7d27ec811dc\nTitle: Provable Robust Watermarking for AI-Generated Text\nYear: 2023\nAbstract: We study the problem of watermarking large language models (LLMs) generated text -- one of the most promising approaches for addressing the safety challenges of LLM usage. In this paper, we propose a rigorous theoretical framework to quantify the effectiveness and robustness of LLM watermarks. We propose a robust and high-quality watermark method, Unigram-Watermark, by extending an existing approach with a simplified fixed grouping strategy. We prove that our watermark method enjoys guaranteed generation quality, correctness in watermark detection, and is robust against text editing and paraphrasing. Experiments on three varying LLMs and two datasets verify that our Unigram-Watermark achieves superior detection accuracy and comparable generation quality in perplexity, thus promoting the responsible use of LLMs. Code is available at https://github.com/XuandongZhao/Unigram-Watermark.",
  "Experiments on three varying LLMs and two datasets verify that our Unigram-Watermark achieves superior detection accuracy and comparable generation quality in perplexity, thus promoting the responsible use of LLMs. Code is available at https://github.com/XuandongZhao/Unigram-Watermark.\nAuthors: Xuandong Zhao, P. Ananth, Lei Li, Yu-Xiang Wang\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A robust and high-quality watermark method, Unigram-Watermark, is proposed by extending an existing approach with a simplified fixed grouping strategy that enjoys guaranteed generation quality, correctness in watermark detection, and is robust against text editing and paraphrasing.'}",
  "Faculty Name: lei li\nMetadata:\nPaperid: 75d672cf3e648bdbeb9bbe31e91d8d721b550304\nTitle: Combining non-negative matrix factorization with graph Laplacian regularization for predicting drug-miRNA associations based on multi-source information fusion\nYear: 2023\nAbstract: Increasing evidences suggest that miRNAs play a key role in the occurrence and progression of many complex human diseases. Therefore, targeting dysregulated miRNAs with small molecule drugs in the clinical has become a new treatment. Nevertheless, it is high cost and time-consuming for identifying miRNAs-targeted with drugs by biological experiments. Thus, more reliable computational method for identification associations of drugs with miRNAs urgently need to be developed. In this study, we proposed an efficient method, called GNMFDMA, to predict potential associations of drug with miRNA by combining graph Laplacian regularization with non-negative matrix factorization. We first calculated the overall similarity matrices of drugs and miRNAs according to the collected different biological information.",
  "In this study, we proposed an efficient method, called GNMFDMA, to predict potential associations of drug with miRNA by combining graph Laplacian regularization with non-negative matrix factorization. We first calculated the overall similarity matrices of drugs and miRNAs according to the collected different biological information. Subsequently, the new drug-miRNA association adjacency matrix was reformulated based on the K nearest neighbor profiles so as to put right the false negative associations. Finally, graph Laplacian regularization collaborative non-negative matrix factorization was used to calculate the association scores of drugs with miRNAs. In the cross validation, GNMFDMA obtains AUC of 0.9193, which outperformed the existing methods. In addition, case studies on three common drugs (i.e., 5-Aza-CdR, 5-FU and Gemcitabine), 30, 31 and 34 of the top-50 associations inferred by GNMFDMA were verified. These results reveal that GNMFDMA is a reliable and efficient computational approach for identifying the potential drug-miRNA associations.",
  "These results reveal that GNMFDMA is a reliable and efficient computational approach for identifying the potential drug-miRNA associations.\nAuthors: Mei-Neng Wang, Yu Li, Li-lan Lei, D. Ding, Xue-Jun Xie\nVenue: Frontiers in Pharmacology\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The proposed GNMFDMA is a reliable and efficient computational approach for identifying the potential drug-miRNA associations and outperformed the existing methods.'}",
  "Faculty Name: lei li\nMetadata:\nPaperid: 7a47828ca29d646967e100bfcd8c9457c682bb38\nTitle: Integrated Valve Product Fluid Simulation and Test Verification\nYear: 2023\nAbstract: The integrated valve product\u2019s main function is to electrolytic oxygen generation subsystem to produce hydrogen and oxygen to realize automatic discharge, to maintain the space station astronauts in orbit around in comfort and safety, high reliability, easy maintenance, and the device should be easy replacement of human-computer ergonomics requirements to ensure long-term on-orbit operation station. Based on the above requirements, an integrated valve product based on environmental control and a health protection system is designed. The integrated product includes hydrogen normal and backup emission branches, oxygen normal and backup emission branches. Through fluid simulation and experimental verification, it is verified that the flow rate and other key indicators of the integrated valve product meet the requirements, which has certain reference and guiding significance for the design of similar integrated products in the future.",
  "The integrated product includes hydrogen normal and backup emission branches, oxygen normal and backup emission branches. Through fluid simulation and experimental verification, it is verified that the flow rate and other key indicators of the integrated valve product meet the requirements, which has certain reference and guiding significance for the design of similar integrated products in the future.\nAuthors: Lei-Lei Li, Baorong Liu, Shengbo Gong, Jian Zhao, Q. Tao, Xu Zhou, Yingli Xu, Menglei Guo\nVenue: Journal of Physics: Conference Series\nTldr: None",
  "Faculty Name: lei li\nMetadata:\nPaperid: 7fcd5d8f8b492533444a8179a07888df267da5a4\nTitle: Editorial: Strategies for functional polymeric nanocomposites and its multifunctional applications\nYear: 2023\nAbstract: The development of nanomaterial\u2019s has greatly contributed to the development of modern medicine and optics, and polymers are an important support and branch of nanomaterial\u2019s. They are non-toxic and harmless, can be degraded into small fragments in the body, and are finally excreted without causing inflammation. Due to their many advantages, biodegradable polymers have attracted more and more attention. In this Research Topic, we focus on reviewing and introducing some polymers for wound repair, drug loading or with special optical properties. These articles are categorized into three themes: 1) polydopamine for wound repair; 2) dendrimers as drug carriers; 3) optical polymers.",
  "In this Research Topic, we focus on reviewing and introducing some polymers for wound repair, drug loading or with special optical properties. These articles are categorized into three themes: 1) polydopamine for wound repair; 2) dendrimers as drug carriers; 3) optical polymers.\nAuthors: Qinqing Wang, A. Prasannan, Nimita Jebaranjitham J., Leijiao Li, Wenliang Li\nVenue: Frontiers in Chemistry\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This Research Topic focuses on reviewing and introducing some polymers for wound repair, drug loading or with special optical properties, and categorized into three themes: 1) polydopamine for wounds repair; 2) dendrimers as drug carriers; 3) optical polymers.'}",
  "Faculty Name: lei li\nMetadata:\nPaperid: 81a0ff93d7a3678330c0fb362fab427217bf2483\nTitle: Population pharmacokinetic analysis and dosing regimen optimization of teicoplanin in critically ill patients with sepsis\nYear: 2023\nAbstract: Objectives: Teicoplanin has been extensively used in the treatment for infections caused by gram-positive bacteria including methicillin-resistant Staphylococcus aureus (MRSA). However, current teicoplanin treatment is challenging due to relatively low and variable concentrations under standard dosage regimens. This study aimed to investigate the population pharmacokinetics (PPK) characteristics of teicoplanin in adult sepsis patients and provide recommendations for optimal teicoplanin dosing regimens. Methods: A total of 249 serum concentration samples from 59 septic patients were prospectively collected in the intensive care unit (ICU). Teicoplanin concentrations were detected, and patients\u2019 clinical data were recorded. PPK analysis was performed using a non-linear, mixed-effect modeling approach. Monte Carlo simulations were performed to evaluate currently recommended dosing and other dosage regimens.",
  "Teicoplanin concentrations were detected, and patients\u2019 clinical data were recorded. PPK analysis was performed using a non-linear, mixed-effect modeling approach. Monte Carlo simulations were performed to evaluate currently recommended dosing and other dosage regimens. The optimal dosing regimens were defined and compared by different pharmacokinetic/pharmacodynamic parameters, including trough concentration (Cmin), the ratio of 24-h area under the concentration-time curve to the minimum inhibitory concentration (AUC0-24/MIC), as well as the probability of target attainment (PTA) and the cumulative fraction of response (CFR) against MRSA. Results: A two-compartment model adequately described the data. The final model parameter estimates for clearance, central compartment volume of distribution, intercompartmental clearance and peripheral compartment volume were 1.03 L/h, 20.1 L, 3.12 L/h and 101 L, respectively. Glomerular filtration rate (GFR) was the only covariate that significantly affected teicoplanin clearance.",
  "Glomerular filtration rate (GFR) was the only covariate that significantly affected teicoplanin clearance. Model-based simulations revealed that 3 or 5 loading doses of 12/15 mg/kg every 12 h followed by a maintenance dose of 12/15 mg/kg every 24 h\u201372 h for patients with different renal functions were required to achieve a target Cmin of 15 mg/L and a target AUC0-24/MIC of 610. For MRSA infections, PTAs and CFRs were not satisfactory for simulated regimens. Prolonging the dosing interval may be easier to achieve the target AUC0-24/MIC than reducing the unit dose for renal insufficient patients. Conclusion: A PPK model for teicoplanin in adult septic patients was successfully developed. Model-based simulations revealed that current standard doses may result in undertherapeutic Cmin and AUC, and a single dose of at least 12 mg/kg may be needed.",
  "Conclusion: A PPK model for teicoplanin in adult septic patients was successfully developed. Model-based simulations revealed that current standard doses may result in undertherapeutic Cmin and AUC, and a single dose of at least 12 mg/kg may be needed. AUC0-24/MIC should be preferred as the PK/PD indicator of teicoplanin, if AUC estimation is unavailable, in addition to routine detection of teicoplanin Cmin on Day 4, follow-up therapeutic drug monitoring at steady-state is recommended.\nAuthors: Chao-Yang Chen, M. Xie, J. Gong, Ning Yu, Ran Wei, Lili Lei, Siru Zhao, Ruoming Li, Xiu Dong, Xiang-lin Zhang, Ying Zhou, Shuangling Li, Yi-min Cui\nVenue: Frontiers in Pharmacology\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A PPK model for teicoplanin in adult septic patients was successfully developed and revealed that current standard doses may result in undertherapeutic Cmin and AUC, and a single dose of at least 12 mg/kg may be needed.'}",
  "Faculty Name: lei li\nMetadata:\nPaperid: 8a9ff288d3800863ec80c5abe3998f0d35f2d6da\nTitle: MCM6 is a Poor Prognostic Biomarker and Promotes Progression in Breast Cancer.\nYear: 2023\nAbstract: BACKGROUND\nBreast cancer is the commonest global malignancy and the primary cause of carcinoma death. MCM6 is vital to carcinogenesis, but the pathogenesis of MCM6 remains unclear.",
  "METHODS\nMCM6 expression in patients with breast cancer was examined through The Cancer Genome Atlas (TCGA) database, immunohistochemistry, Quantitative Real-Time PCR (qRT\u2012PCR) and Western blotting. The prognostic factors were assessed by the Kaplan\u2012Meier method and Cox regression. On the basis of the key factors selected by multivariable Cox regression analysis, a nomogram risk prediction model was adopted for clinical risk assessment. The TCGA database was utilized to determine how MCM6 is correlated with chemotherapy sensitivity, immune checkpoint-related genes (ICGs), tumor-infiltrating immune cells, along with tumor mutation burden (TMB) and methylation. The impact of MCM6 on carcinoma cells was investigated in terms of proliferation, cell cycle as well as migrating and invasive behavior through CCK assays, flow cytometry, wound healing assays, Transwell assays and xenotransplantation experiments.",
  "RESULTS\nMCM6 expression was upregulated, which is closely associated with the size of the tumor (p = 0.001) and lymph node metastasis (p = 0.012) in patients with breast cancer. Multivariate analysis revealed MCM6 to be an independent risk factor for prognosis in patients with breast carcinoma. The nomograph prediction model included MCM6, age, ER, M and N stage, which displayed good discrimination with a C index of 0.817 and good calibration. Overexpression of MCM6 correlated with chemotherapy sensitivity, immune checkpoint-related genes (ICGs), tumor-infiltrating immune cells, tumor mutation burden (TMB), and methylation. Silencing MCM6 significantly inhibited proliferation, prolonged the G1 phase of the cell cycle, and restrained the proliferation, migration and invasive behavior of cancerous cells and inhibited tumor growth in vivo.",
  "CONCLUSIONS\nOur research shows that MCM6 is highly expressed in breast cancer and can be used as an independent prognostic factor, which is expected to become a new target for the treatment of breast cancer in the future.\nAuthors: Zi Lei, Peng Wang, Da-Qi Jia, Lei Li, Yi-peng Wu, Yuan Yang, Guo-Qing Pan\nVenue: Frontiers in Bioscience\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Research shows that MCM6 is highly expressed in breast cancer and can be used as an independent prognostic factor, which is expected to become a new target for the treatment of breast cancer in the future.'}",
  "Faculty Name: lei li\nMetadata:\nPaperid: 8c2fae4c9622fefe0e7594e7637175d2bb4e2125\nTitle: Variation of virtual temperature and wind in the atmospheric boundary layer over the pearl river estuary during 2011\u20132020\nYear: 2023\nAbstract: Most studies of the effects of urbanisation on local climate have been based on ground observation data. In contrast, we used observation data from a boundary layer radar wind profiler, radio-acoustic sounding system, and automatic meteorological station located at Shenzhen Bao\u2019an International Airport to analyse changes in wind and virtual temperature in the upper level atmosphere, with a top height of 1,200 m, over the Pearl River Estuary between 2011 and 2020. Our results show that during the decade evaluated, the wind speed and virtual temperature of the upper level atmosphere over the Pearl River Estuary changed very significantly and faster than the changes observed at ground level. During the study period, the linear warming rate of the virtual temperature of the upper level atmosphere reached 0.24\u00b0C/a, whereas that on the land surface was 0.17\u00b0C/a.",
  "During the study period, the linear warming rate of the virtual temperature of the upper level atmosphere reached 0.24\u00b0C/a, whereas that on the land surface was 0.17\u00b0C/a. The mean decreases in the upper level atmosphere and land surface wind speeds were \u22120.12 and \u22120.05 m/s\u00b7a, respectively. Additionally, the rate of change in the upper level climate was faster in winter than in summer for both wind speed and virtual temperature. These changes in the climate of the upper level atmosphere over the Pearl River Estuary may be related to the rapid increase in the number of high-rise buildings in the region during that decade, which generally negatively affected the atmospheric environment.\nAuthors: Lei Li, Qian-Jin Zhou, P. Chan, Hong-Long Yang\nVenue: Frontiers in Environmental Science\nTldr: None",
  "Faculty Name: lei li\nMetadata:\nPaperid: 8e54fd15fb5f8c035a772ecdfdebd8c9449d4656\nTitle: Numerical simulation research on the overturning of gantry crane by downbursts\nYear: 2023\nAbstract: None\nAuthors: Jia-Chen Su, Lei Li, P. Chan, Qian-Jin Zhou, Hong-Long Yang\nVenue: Heliyon\nTldr: None",
  "Faculty Name: lei li\nMetadata:\nPaperid: 937bb21fe0836419762ea8410ce989e4840052ec\nTitle: Wavefront shaping improves the transparency of the scattering media: a review\nYear: 2023\nAbstract: Abstract. Significance Wavefront shaping (WFS) can compensate for distortions by optimizing the wavefront of the input light or reversing the transmission matrix of the media. It is a promising field of research. A thorough understanding of principles and developments of WFS is important for optical research. Aim To provide insight into WFS for researchers who deal with scattering in biomedicine, imaging, and optical communication, our study summarizes the basic principles and methods of WFS and reviews recent progress. Approach The basic principles, methods of WFS, and the latest applications of WFS in focusing, imaging, and multimode fiber (MMF) endoscopy are described. The practical challenges and prospects of future development are also discussed. Results Data-driven learning-based methods are opening up new possibilities for WFS. High-resolution imaging through MMFs can support small-diameter endoscopy in the future.",
  "The practical challenges and prospects of future development are also discussed. Results Data-driven learning-based methods are opening up new possibilities for WFS. High-resolution imaging through MMFs can support small-diameter endoscopy in the future. Conclusion The rapid development of WFS over the past decade has shown that the best solution is not to avoid scattering but to find ways to correct it or even use it. WFS with faster speed, more optical modes, and more modulation degrees of freedom will continue to drive exciting developments in various fields.\nAuthors: Chunxu Ding, Rongjun Shao, Qiaozhi He, Lei S Li, Jiamiao Yang\nVenue: Journal of Biomedical Optics\nTldr: None",
  "Faculty Name: lei li\nMetadata:\nPaperid: a499e33f815180fa77c5067b0dfc0dc540940da0\nTitle: p53 deacetylation alleviates calcium oxalate deposition-induced renal fibrosis by inhibiting ferroptosis.\nYear: 2023\nAbstract: None\nAuthors: Zehua Ye, Yu-qi Xia, Lei Li, Bojun Li, Lijia Chen, Wei-min Yu, Y. Ruan, T. Rao, Xiangjun Zhou, F. Cheng\nVenue: Biomedicine & pharmacotherapy = Biomedecine & pharmacotherapie\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is concluded that ferroptosis is one of the critical mechanisms contributing to CaOx crystal-induced renal fibrosis, and the pharmacological induction of ferroPTosis via sirtuin 1-mediated p53 deacetylation may be a potential target for preventing renal Fibrosis in patients with nephrolithiasis.'}",
  "Faculty Name: lei li\nMetadata:\nPaperid: a61f910a00c60bbf8b9ba1eae7c1757bb0b36426\nTitle: PTTG1 reprograms asparagine metabolism to promote hepatocellular carcinoma progression.\nYear: 2023\nAbstract: Hepatocellular carcinoma (HCC) is the most common type of primary liver cancer and has a poor prognosis. Pituitary tumor transforming gene 1 (PTTG1) is highly expressed in HCC, suggesting it could play an important role in hepatocellular carcinogenesis. Here, we evaluated the impact of PTTG1 deficiency on HCC development using a diethylnitrosamine (DEN)-induced HCC mouse model and a hepatitis B virus regulatory X protein (HBx)-induced spontaneous HCC mouse model. PTTG1 deficiency significantly suppressed DEN- and HBx-induced hepatocellular carcinogenesis. Mechanistically, PTTG1 promoted asparagine synthetase (ASNS) transcription by binding to its promoter, and asparagine levels were correspondingly increased.",
  "PTTG1 deficiency significantly suppressed DEN- and HBx-induced hepatocellular carcinogenesis. Mechanistically, PTTG1 promoted asparagine synthetase (ASNS) transcription by binding to its promoter, and asparagine levels were correspondingly increased. The elevated levels of asparagine subsequently activated the mTOR pathway to facilitate HCC progression. In addition, asparaginase treatment reversed the proliferation induced by PTTG1 overexpression. Furthermore, HBx promoted ASNS and asparagine metabolism by upregulating PTTG1 expression. Overall, PTTG1 is involved in the reprogramming of asparagine metabolism to promote HCC progression and may serve as a therapeutic and diagnostic target for HCC.",
  "Furthermore, HBx promoted ASNS and asparagine metabolism by upregulating PTTG1 expression. Overall, PTTG1 is involved in the reprogramming of asparagine metabolism to promote HCC progression and may serve as a therapeutic and diagnostic target for HCC.\nAuthors: Qi Zhou, Leijia Li, Feifei Sha, Yiming Lei, Xuanen Tian, Lingjun Chen, Yan Chen, Huiling Liu, Yunwei Guo\nVenue: Cancer Research\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Overall, PTTG1 is involved in the reprogramming of asparagine metabolism to promote HCC progression and may serve as a therapeutic and diagnostic target for HCC.'}",
  "Faculty Name: lei li\nMetadata:\nPaperid: a64ab230ee2d32f91a05fa2881fb159d90187ee0\nTitle: Study on thermal stability and biocompatibility of bimodal microstructure in Cr\u2013Mn\u2013N austenitic stainless steel\nYear: 2023\nAbstract: None\nAuthors: G. Niu, Leilei Li, Haoxiu Chen, C. Gu, Jinxu Liu, N. Gong, Hui-bin Wu\nVenue: Journal of Materials Research and Technology\nTldr: None",
  "Faculty Name: lei li\nMetadata:\nPaperid: acd17a514d5aa3fbdb150205641aa05400e7e96b\nTitle: Phosphorus Availability Affects the Photosynthesis and Antioxidant System of Contrasting Low-P-Tolerant Cotton Genotypes\nYear: 2023\nAbstract: Phosphorus (P) is an essential macronutrient, and an important component of plant metabolism. However, little is known about the effects of low P availability on P absorption, the photosynthetic electron transport chain, and the antioxidant system in cotton. This study used cotton genotypes (sensitive FJA and DLNTDH and tolerant BX014 and LuYuan343) with contrasting low-P tolerance in a hydroponic experiment under 15 \u00b5M, 50 \u00b5M, and 500 \u03bcM P concentrations. The results showed that low P availability reduced plant development and leaf area, shoot length, and dry weight in FJA and DLNADH, compared to BX014 and LuYuan343.",
  "The results showed that low P availability reduced plant development and leaf area, shoot length, and dry weight in FJA and DLNADH, compared to BX014 and LuYuan343. The low P availability decreased the gas-exchange parameters such as the net photosynthetic rate, transpiration rate, and stomatal conductance, and increased the intercellular CO2 concentration. Chlorophyll a fluorescence demonstrated that the leaves\u2019 absorption and trapped-energy flux were largely steady. In contrast, considerable gains in absorption and trapped-energy flux per reaction center resulted from decreases in the electron transport per reaction center under low-P conditions. In addition, low P availability reduced the activities of antioxidant enzymes and increased the content of malondialdehyde in the cotton genotypes, especially in FJA and DLNTDH. Moreover, low P availability reduced the activity of PEPC and generated a decline in the content of ATP and NADPH. Our research can provide a theoretical physiological basis for the growth and tolerance of cotton under low-P conditions.",
  "Moreover, low P availability reduced the activity of PEPC and generated a decline in the content of ATP and NADPH. Our research can provide a theoretical physiological basis for the growth and tolerance of cotton under low-P conditions.\nAuthors: Mirezhatijiang Kayoumu, A. Iqbal, N. Muhammad, Xiaotong Li, Leilei Li, Xiangru Wang, Huiping Gui, Qian Qi, Sijia Ruan, Ruishi Guo, Xiling Zhang, M. Song, Qiang Dong\nVenue: Antioxidants\nTldr: None",
  "Faculty Name: lei li\nMetadata:\nPaperid: aea4876c3a5b596ef95a828baea8b3d9022cda62\nTitle: Failure Analysis and Improvement of Check Valve Reverse Cut-off Seal\nYear: 2023\nAbstract: Given the failure of reverse cut-off seal performance in the test process of the check valve, the fault location and mechanism analysis were carried out, and the improvement measures were proposed and verified by the test. It is analyzed that the main reason for the failure is the unreasonable design of the moving pair and the welding position of the check valve, which makes the sealing pair cannot fit effectively after the welding of the check valve, leading to the failure of the reverse cut-off seal. By controlling the ratio of the length of the guide surface to the diameter of the guide surface to 1.25, and controlling the distance between the welding position and the sealing pair to 10mm, the failure problem of the reverse cut-off seal of the check valve caused by the unreasonable design of the moving pair and the weld position is successfully solved. The effectiveness of the improved scheme of the check valve is verified by the test.",
  "The effectiveness of the improved scheme of the check valve is verified by the test.\nAuthors: Lei-Lei Li, Jian Zhao, Sheng-bo Gong, Baoguo Liu, H. Zhang, Xiao-lei Zhou, Lilei Miao, Peng Li\nVenue: Journal of Physics: Conference Series\nTldr: None",
  "Faculty Name: lei li\nMetadata:\nPaperid: af7115085a46a2b884c38164050c0a4f23fb92af\nTitle: Integrated Transcriptome and Small RNA Sequencing Analyses Reveals Insights into the Molecular Mechanism of Seed Germination in Mung Bean\nYear: 2023\nAbstract: None\nAuthors: Yan-yan Pu, Liwen Wang, Leilei Li, Yujun Si, Shubin Xie, Yunzhe Cong, Dong Wang, Yongchao Gong, Rumei Tian, Xue Chen, Xiao-yue Zhang, Min Liu, H. Ding, Nana Li\nVenue: Phyton\nTldr: None",
  "Faculty Name: lei li\nMetadata:\nPaperid: affdee29f2c6d34e839e9e9a15afd6aa1c9b5af8\nTitle: Polydopamine-functionalized selenium nanoparticles as an efficient photoresponsive antibacterial platform\nYear: 2023\nAbstract: A photoresponsive therapeutic antibacterial platform was designed and constructed using polydopamine-functionalized selenium nanoparticles as a carrier loaded with indocyanine green (Se@PDA-ICG). The therapeutic platform was confirmed by characterization and the antibacterial activity of Se@PDA-ICG against Staphylococcus aureus (S. aureus) and Escherichia coli (E. coli) was investigated. Under 808 nm laser irradiation, the antibacterial rate of Se@PDA-ICG against E. coli and S. aureus was 100% at 125 \u03bcg mL\u22121.",
  "Under 808 nm laser irradiation, the antibacterial rate of Se@PDA-ICG against E. coli and S. aureus was 100% at 125 \u03bcg mL\u22121. Furthermore, in a mouse wound infection model, the wound closure rate of the Se@PDA-ICG photoresponse group was 88.74% compared with 45.8% for the control group after 8 days of treatment, indicating that it could effectively kill bacteria and dramatically accelerate the wound healing process. These results suggested that Se@PDA-ICG could be a promising photo-activated antibacterial candidate material for biomedical applications.\nAuthors: Meng Sun, P. Gao, Bao Wang, Xiangyang Li, Donghan Shao, Yan Xu, Leijiao Li, Yunhui Li, Jianwei Zhu, Wenliang Li, Yingxue Xue\nVenue: RSC Advances\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Results suggested that Se@PDA-ICG could be a promising photo-activated antibacterial candidate material for biomedical applications.'}",
  "Faculty Name: lei li\nMetadata:\nPaperid: b2274c9fcd2d2c56e64441b4f93013d83faa24cb\nTitle: An ultrahigh-fidelity 3D holographic display using scattering to homogenize the angular spectrum\nYear: 2023\nAbstract: A three-dimensional (3D) holographic display (3DHD) can preserve all the volumetric information about an object. However, the poor fidelity of 3DHD constrains its applications. Here, we present an ultrahigh-fidelity 3D holographic display that uses scattering for homogenization of angular spectrum. A scattering medium randomizes the incident photons and homogenizes the angular spectrum distribution. The redistributed field is recorded by a photopolymer film with numerous modulation modes and a half-wavelength scale pixel size. We have experimentally improved the contrast of a focal spot to 6 \u00d7 106 and tightened its spatial resolution to 0.5 micrometers, respectively ~300 and 4.4 times better than digital approaches.",
  "We have experimentally improved the contrast of a focal spot to 6 \u00d7 106 and tightened its spatial resolution to 0.5 micrometers, respectively ~300 and 4.4 times better than digital approaches. By exploiting the spatial multiplexing ability of the photopolymer and the transmission channel selection capability of the scattering medium, we have realized a dynamic holographic display of 3D spirals consisting of 20 foci across 1 millimeter \u00d7 1 millimeter \u00d7 26 millimeters with uniform intensity.\nAuthors: Jiamiao Yang, Lei S Li, Qiaozhi He, Chengmingyue Li, Yuan Qu, Lihong V Wang\nVenue: Science Advances\nTldr: None",
  "Faculty Name: lei li\nMetadata:\nPaperid: b3a587d4cbe94d5e86f80ef7cce0b80fd9bf5bcd\nTitle: Gut microbiota in patients with kidney stones: a systematic review and meta-analysis\nYear: 2023\nAbstract: None\nAuthors: Tianhui Yuan, Yu-qi Xia, Bojun Li, Wei-min Yu, T. Rao, Zehua Ye, Xinzhou Yan, Baofeng Song, Lei Li, Fangyou Lin, F. Cheng\nVenue: BMC Microbiology\nTldr: {'model': 'tldr@v2.0.0', 'text': 'There is a characteristic gut microbiota dysbiosis in kidney stone patients and individualized therapies like microbial supplementation, probiotic or synbiotic preparations and adjusted diet patterns based on individual gut microbial characteristics of patients may be more effective in preventing stone formation and recurrence.'}",
  "Faculty Name: lei li\nMetadata:\nPaperid: be141055e9c7d70d37a1ec9499d7455c6816d146\nTitle: A Multilabel Learning-Based Automatic Annotation Method for Semantic Roles in English Text\nYear: 2023\nAbstract: With the increasing amount of textual information in the Internet, smart semantic comprehension is a practical demand. Among, automatic annotation for semantic roles remains the fundamental part for effective semantic comprehension. Although machine learning-based methods had received much attention in recent years, they mostly divided each sentences into separable parts for calculation. To deal with such challenge, this paper introduces multilabel learning to propose a novel automatic annotation method for semantic roles in English text. In the semantic representation of words, the method uses convolutional neural networks to extract local feature information of words from the character level. Such design can alleviate the problem of inconspicuous semantic features caused by random initialization of unregistered words. Secondly, in the process of implication recognition, by combining the interactive attention mechanism to construct a capsule for each implication relation separately, the recognition of the final implication relation is completed in the way of categorical learning.",
  "Secondly, in the process of implication recognition, by combining the interactive attention mechanism to construct a capsule for each implication relation separately, the recognition of the final implication relation is completed in the way of categorical learning. At last, some experiments are conducted on real-world data to verify the proposed method with being compared with several typical relevant methods. The obtained results show that the proposal achieves better Macro-F1 results on eight datasets compared to seven algorithms. Besides, the proposal also performs better than others in the sensitivity testing, as its performance can remain stable with the increase of noise input. In summary, the proposal can achieve good results and show strong capability in semantic role labeling tasks.\nAuthors: Li-Wen Lei, Hao Wang\nVenue: IEEE Access\nTldr: {'model': 'tldr@v2.0.0', 'text': None}",
  "Faculty Name: lei li\nMetadata:\nPaperid: c0bdff1f8bd63083641061a1996f844380f91b58\nTitle: Antimicrobial properties of heterojunction BiSnSbO_6-ZnO composites in wastewater treatment\nYear: 2023\nAbstract: None\nAuthors: J. Chen, M. Shan, Haojia Zhu, Shichuan Zhang, Jingmei Li, Leijiao Li\nVenue: Environmental science and pollution research international\nTldr: None",
  "Faculty Name: lei li\nMetadata:\nPaperid: c10808e5183ece07057050d1896ba81031d6640b\nTitle: Effect of instant surgery compared with traditional management on paediatric complicated acute appendicitis post\u2010surgery wound: A meta\u2010analysis\nYear: 2023\nAbstract: A meta\u2010analysis study to assess the influence of instant surgery (IS) compared with conservative therapy (CT) on paediatric complicated acute appendicitis (CAA) post\u2010surgery wounds. A comprehensive literature examination until January 2023 was implemented, and 2098 linked studies were appraised. The picked studies contained 66\u2009674 subjects with paediatric CAA post\u2010surgery wounds in the picked studies' baseline; 64\u2009643 of them were using IS, and 2031 were using CT. The odds ratio (OR) in addition to 95% confidence intervals (CIs) were used to calculate the consequence of the IS compared with the CT on paediatric CAA post\u2010surgery wounds using the dichotomous and continuous styles and a fixed or random model.",
  "The odds ratio (OR) in addition to 95% confidence intervals (CIs) were used to calculate the consequence of the IS compared with the CT on paediatric CAA post\u2010surgery wounds using the dichotomous and continuous styles and a fixed or random model. The IS had a significantly higher wound infection (OR, 4.97; 95% CI, 2.35\u201310.54, P <\u2009.001) with moderate heterogeneity (I2 =\u200957%) compared with the CT in a paediatric CAA post\u2010surgery wound. However, no significant difference was found between IS and CT in total antibiotic duration (MD, \u22125.34; 95% CI,\u221212.67 to \u22121.98, P =\u2009.15) with high heterogeneity (I2 =\u200995%) in paediatric CAA post\u2010surgery wounds. The IS had a significantly higher wound infection; however, no significant difference was found in total antibiotic duration compared with the CT in paediatric CAA post\u2010surgery wounds. Although precautions should be taken when commerce with the consequences because most of the studies picked for this meta\u2010analysis had low sample sizes.",
  "The IS had a significantly higher wound infection; however, no significant difference was found in total antibiotic duration compared with the CT in paediatric CAA post\u2010surgery wounds. Although precautions should be taken when commerce with the consequences because most of the studies picked for this meta\u2010analysis had low sample sizes.\nAuthors: Xiansheng Cao, Xuejing Geng, Chunlei Zhang, Jun-Hao Chen, Chao Zhang, Qi Liu, Tianyu Wu, Lei Li\nVenue: International Wound Journal\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A meta\u2010analysis study to assess the influence of instant surgery (IS) compared with conservative therapy (CT) on paediatric complicated acute appendicitis (CAA) post\u2010surgery wounds found no significant difference in total antibiotic duration and wound infection.'}",
  "Faculty Name: lei li\nMetadata:\nPaperid: c25d2a27f1abe169d7b68078071b6698f0980469\nTitle: Protecting Language Generation Models via Invisible Watermarking\nYear: 2023\nAbstract: Language generation models have been an increasingly powerful enabler for many applications. Many such models offer free or affordable API access, which makes them potentially vulnerable to model extraction attacks through distillation. To protect intellectual property (IP) and ensure fair use of these models, various techniques such as lexical watermarking and synonym replacement have been proposed. However, these methods can be nullified by obvious countermeasures such as\"synonym randomization\". To address this issue, we propose GINSEW, a novel method to protect text generation models from being stolen through distillation. The key idea of our method is to inject secret signals into the probability vector of the decoding steps for each target token. We can then detect the secret message by probing a suspect model to tell if it is distilled from the protected one. Experimental results show that GINSEW can effectively identify instances of IP infringement with minimal impact on the generation quality of protected APIs.",
  "We can then detect the secret message by probing a suspect model to tell if it is distilled from the protected one. Experimental results show that GINSEW can effectively identify instances of IP infringement with minimal impact on the generation quality of protected APIs. Our method demonstrates an absolute improvement of 19 to 29 points on mean average precision (mAP) in detecting suspects compared to previous methods against watermark removal attacks.\nAuthors: Xuandong Zhao, Yu-Xiang Wang, Lei Li\nVenue: International Conference on Machine Learning\nTldr: {'model': 'tldr@v2.0.0', 'text': 'GINSEW, a novel method to protect text generation models from being stolen through distillation by injecting secret signals into the probability vector of the decoding steps for each target token, is proposed.'}",
  "Faculty Name: lei li\nMetadata:\nPaperid: c5bb69bbe1d41153d40a9eb31c4af077390c2d99\nTitle: The effects of pharmaceutical interventions on potentially inappropriate medications in older patients: a systematic review and meta-analysis\nYear: 2023\nAbstract: Introduction Potentially inappropriate medications (PIMs) is a particular concern in older patients and is associated with negative health outcomes. As various interventions have been developed to manage it, we performed a systematic review and meta-analysis to evaluate the effect of pharmaceutical interventions on outcomes of PIMs in older patients. Methods Meta-analysis of eligible randomized controlled trials (RCTs) was conducted to report the outcomes of pharmaceutical interventions in older patients searching from the databases of Cochrane Library, PubMed, Embase, Web of Science, Clinicaltrials.gov, SinoMed and Chinese Clinical Trial Registry (ChiCTR). The PRISMA guidelines were followed and the protocol was registered in PROSPERO (CRD42019134754). Cochrane bias risk assessment tool and the modified Jadad scale were used to assess the risk bias. RevMan software was used for data processing, analysis and graphical plotting.",
  "The PRISMA guidelines were followed and the protocol was registered in PROSPERO (CRD42019134754). Cochrane bias risk assessment tool and the modified Jadad scale were used to assess the risk bias. RevMan software was used for data processing, analysis and graphical plotting. Results Sixty-five thousand, nine hundred seventy-one patients in 14 RCTs were included. Of the primary outcomes, pharmaceutical interventions could significantly reduce the incidence of PIMs in older patients (OR\u2009=\u20090.51, 95% CI: 0.42, 0.62; p\u2009<\u20090.001), and the number of PIMs per person (MD\u2009=\u2009-0.41, 95%CI: \u22120.51, \u22120.31; p\u2009<\u20090.001), accompanying by a low heterogeneity. Subgroup analysis showed that the application of computer-based clinical decision support for pharmacological interventions could remarkably decrease the incidence of PIMs and two assessment tools were more effective.",
  "Subgroup analysis showed that the application of computer-based clinical decision support for pharmacological interventions could remarkably decrease the incidence of PIMs and two assessment tools were more effective. Of the secondary outcomes, the meta-analysis showed that pharmacological interventions could reduce the number of drugs used per person (MD\u2009=\u2009-0.94, 95%CI: \u22121.51, \u22120.36; p\u2009=\u20090.001) and 30-day readmission rate (OR\u2009=\u20090.58, 95%CI: 0.36, 0.92; p\u2009=\u20090.02), accompanying by a low heterogeneity. However, the pharmaceutical interventions demonstrated no significant improvement on all-cause mortality and the number of falls. Conclusion Our findings supported the efficacy of pharmaceutical interventions to optimize the use and management of drugs in older patients. Systematic review registration https://clinicaltrials.gov/, CRD42019134754.",
  "However, the pharmaceutical interventions demonstrated no significant improvement on all-cause mortality and the number of falls. Conclusion Our findings supported the efficacy of pharmaceutical interventions to optimize the use and management of drugs in older patients. Systematic review registration https://clinicaltrials.gov/, CRD42019134754.\nAuthors: Shuang Zhou, Rui Li, Xiaolin Zhang, Yutong Zong, Lili Lei, Zhenhui Tao, Minxue Sun, Hua Liu, Ying Zhou, Yi-min Cui\nVenue: Frontiers in Public Health\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The efficacy of pharmaceutical interventions to optimize the use and management of drugs in older patients is supported by a systematic review and meta-analysis of randomized controlled trials.'}",
  "Faculty Name: lei li\nMetadata:\nPaperid: dd3c82415e5704c60703e86a051ab3a003b0122b\nTitle: Intraoperative molecular imaging: 3rd biennial clinical trials update\nYear: 2023\nAbstract: Abstract. Significance This third biennial intraoperative molecular imaging (IMI) conference shows how optical contrast agents have been applied to develop clinically significant endpoints that improve precision cancer surgery. Aim National and international experts on IMI presented ongoing clinical trials in cancer surgery and preclinical work. Previously known dyes (with broader applications), new dyes, novel nonfluorescence-based imaging techniques, pediatric dyes, and normal tissue dyes were discussed. Approach Principal investigators presenting at the Perelman School of Medicine Abramson Cancer Center\u2019s third clinical trials update on IMI were selected to discuss their clinical trials and endpoints. Results Dyes that are FDA-approved or currently under clinical investigation in phase 1, 2, and 3 trials were discussed. Sections on how to move benchwork research to the bedside were also included.",
  "Results Dyes that are FDA-approved or currently under clinical investigation in phase 1, 2, and 3 trials were discussed. Sections on how to move benchwork research to the bedside were also included. There was also a dedicated section for pediatric dyes and nonfluorescence-based dyes that have been newly developed. Conclusions IMI is a valuable adjunct in precision cancer surgery and has broad applications in multiple subspecialties. It has been reliably used to alter the surgical course of patients and in clinical decision making. There remain gaps in the utilization of IMI in certain subspecialties and potential for developing newer and improved dyes and imaging techniques.",
  "It has been reliably used to alter the surgical course of patients and in clinical decision making. There remain gaps in the utilization of IMI in certain subspecialties and potential for developing newer and improved dyes and imaging techniques.\nAuthors: P. Bou-Samra, N. Muhammad, Austin Chang, Ritesh Karsalia, F. Azari, G. Kennedy, W. Stummer, J. Tanyi, Linda Martin, A. Vahrmeijer, Barbara Smith, E. Rosenthal, Patrick Wagner, David Rice, Amy Lee, Abdelhafeez H. Abdelhafeez, M. Malek, G. Kohanbash, Wilson Barry Edwards, E. Henderson, J. Skj\u00f8th-Rasmussen, Ryan Orosco, Summer L. Gibbs, R. Farnam, L. Shankar, B. Sumer, Anand T. N. Kumar, L. Marcu, Lei S Li, Victor Greuv, E. Delikatny, John Y. K. Lee, S. Singhal\nVenue: Journal of Biomedical Optics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'IMI has been reliably used to alter the surgical course of patients and in clinical decision making and remains a valuable adjunct in precision cancer surgery and has broad applications in multiple subspecialties.'}",
  "Faculty Name: lei li\nMetadata:\nPaperid: de54ffba68e0a65b7d9070538e2e84a7d58ced36\nTitle: Establishment of a N1-methyladenosine-related risk signature for breast carcinoma by bioinformatics analysis and experimental validation\nYear: 2023\nAbstract: None\nAuthors: Leilei Li, Wenhui Yang, Daqi Jia, Shiqi Zheng, Yu Gao, G. Wang\nVenue: Breast Cancer\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A m^1A RNA methylation regulator-related prognostic model was constructed, and a nomogram based on the prognostic model was constructed to provide a theoretical reference for individual counseling and clinical preventive intervention in BRCA.'}",
  "Faculty Name: lei li\nMetadata:\nPaperid: f3ccbd6795a89dc98558679482da836b3c12fac8\nTitle: Effect of intragranular \u03ba carbides and intergranular precipitates on the hot deformation mechanism and dynamic recrystallization mechanism of Fe-28Mn-11Al-1.5C-5Cr lightweight steel\nYear: 2023\nAbstract: None\nAuthors: Jinxu Liu, Leilei Li, Shanwu Yang, Chao Ding, Enmao Wang, Xinpan Yu, Huibin Wu, G. Niu\nVenue: Journal of Materials Research and Technology\nTldr: None",
  "Faculty Name: lei li\nMetadata:\nPaperid: f7912c9af20f95cddaa3c959246ff63d34ab3a57\nTitle: Comprehensive Analysis of Cuproptosis Genes and Identification of Cuproptosis Subtypes in Breast Cancer\nYear: 2023\nAbstract: Background Copper-induced death (cuproptosis) is copper-dependent regulated cell death, which is different from known death mechanisms and is dependent on mitochondrial respiration. However, its effect on breast cancer (BRCA) is unclear. Objective The objective of this study is to explore the important clinical significance of cuproptosis genes and to provide a new idea for guiding the personalized immunotherapy strategy of BRCA patients. Materials and Methods We collected cuproptosis genes from published work. The gene alteration, differential expression, and prognostic value of cuproptosis genes were explored in BRCA based on TCGA database. We identified two subtypes (clusters A and B) by performing unsupervised clustering. The difference between two clusters was deeply explored, including clinical features, differential expressed genes (DEGs), pathways, and immune cell infiltration.",
  "We identified two subtypes (clusters A and B) by performing unsupervised clustering. The difference between two clusters was deeply explored, including clinical features, differential expressed genes (DEGs), pathways, and immune cell infiltration. Based on the DEGs between two clusters, a cuproptosis score was constructed and its predictive capability for overall survival of BRCA patients was validated. Results and Discussion Patients with high cuproptosis score have worse survival status, with an increased infiltration level of most immune cells. Further analysis suggested that BRCA patients with high cuproptosis score may be sensitive to immune checkpoint inhibitor (ICI) treatment. Conclusion Our findings may improve our understanding of cuproptosis in BRCA and may distinguish patients suitable for ICI treatment.\nAuthors: Jialin Li, Lei Li, Yi Dong, B. Zhong, W. Yin\nVenue: Combinatorial chemistry & high throughput screening\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The findings may improve the understanding of cuproptosis in BRCA and may distinguish patients suitable for ICI treatment.'}",
  "List of 2023 Open Access papers by lei li are:\nEstablishment of a N1-methyladenosine-related risk signature for breast carcinoma by bioinformatics analysis and experimental validation\nPopulation pharmacokinetic analysis and dosing regimen optimization of teicoplanin in critically ill patients with sepsis\nThe effects of pharmaceutical interventions on potentially inappropriate medications in older patients: a systematic review and meta-analysis\nP53 protein and the diseases in central nervous system\nCorrection: Polydopamine-functionalized selenium nanoparticles as an efficient photoresponsive antibacterial platform\nEditorial: Strategies for functional polymeric nanocomposites and its multifunctional applications\nPolydopamine-functionalized selenium nanoparticles as an efficient photoresponsive antibacterial platform\nAntimicrobial properties of heterojunction BiSnSbO_6-ZnO composites in wastewater treatment\nResearch on torsional stiffness of flexspline-flexible bearing contact pair in harmonic drive based on macro-micro scale modeling\nIntegrated Valve Product Fluid Simulation and Test Verification\nFailure Analysis and Improvement of Check Valve Reverse Cut-off Seal\nA Study of Yuediao Folk Music Knowledge Development in Zhoukou, Henan Province,",
  "Henan Province, China\nInfluence of banded \u03b5-martensite and deformation twin on cryogenic toughness of Fe-Mn-xAl-C steel\nStudy on thermal stability and biocompatibility of bimodal microstructure in Cr\u2013Mn\u2013N austenitic stainless steel\nEffect of intragranular \u03ba carbides and intergranular precipitates on the hot deformation mechanism and dynamic recrystallization mechanism of Fe-28Mn-11Al-1.5C-5Cr lightweight steel\nWavefront shaping improves the transparency of the scattering media: a review\nAn ultrahigh-fidelity 3D holographic display using scattering to homogenize the angular spectrum\nIntraoperative molecular imaging: 3rd biennial clinical trials update\nPTTG1 reprograms asparagine metabolism to promote hepatocellular carcinoma progression.",
  "A Multilabel Learning-Based Automatic Annotation Method for Semantic Roles in English Text\nVariation of virtual temperature and wind in the atmospheric boundary layer over the pearl river estuary during 2011\u20132020\nNumerical simulation research on the overturning of gantry crane by downbursts\nCombining non-negative matrix factorization with graph Laplacian regularization for predicting drug-miRNA associations based on multi-source information fusion\nPhosphorus Availability Affects the Photosynthesis and Antioxidant System of Contrasting Low-P-Tolerant Cotton Genotypes\nIntegrated Transcriptome and Small RNA Sequencing Analyses Reveals Insights into the Molecular Mechanism of Seed Germination in Mung Bean\nLow-Voltage Solution-Processed Zinc-Doped CuI Thin Film Transistors with NOR Logic and Artificial Synaptic Function\nOptimizing Heat Treatment to Improve the Microstructures and Mechanical Properties of 5CrNiMoV Steel\nOral phage therapy with microencapsulated phage A221 against Escherichia coli infections in weaned piglets\nHence,",
  "Socrates is mortal: A Benchmark for Natural Language Syllogistic Reasoning\nProvable Robust Watermarking for AI-Generated Text\nMCM6 is a Poor Prognostic Biomarker and Promotes Progression in Breast Cancer.\np53 deacetylation alleviates calcium oxalate deposition-induced renal fibrosis by inhibiting ferroptosis.\nGut microbiota in patients with kidney stones: a systematic review and meta-analysis\nEffect of instant surgery compared with traditional management on paediatric complicated acute appendicitis post\u2010surgery wound: A meta\u2010analysis\nProtecting Language Generation Models via Invisible Watermarking\nComprehensive Analysis of Cuproptosis Genes and Identification of Cuproptosis Subtypes in Breast Cancer\nLong-tailed Extreme Multi-label Text Classification by the Retrieval of Generated Pseudo Label Descriptions",
  "Title: Lori Levin -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Lori Levin, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Core Faculty\" name=\"categories-1\"/>\n<meta content=\"Corpus Annotation and Resources;Machine Translation;Natural Language Processing and Computational Linguistics\" name=\"categories-2\"/>\n<meta content=\"Yes\" name=\"show-categories-2\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Lori Levin - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Lori Levin, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Lori\"/>\n<meta content=\"Lastname\" property=\"profile:Levin\"/>\n<meta content=\"http://lti.cmu.",
  "Faculty Member at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Lori\"/>\n<meta content=\"Lastname\" property=\"profile:Levin\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/levin-lori.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nLori \n                        Levin\nResearch Professor, Language Technologies Institute\nContact\n5717 \u2014Gates & Hillman Centers\nlsl(through)cs.cmu.edu\n412-268-6193\nResearch Area\nCorpus Annotation and Resources, Machine Translation, Natural Language Processing and Computational Linguistics\nResearch\nThere are more than 6,000 human languages, but less than a hundred of them have robust language technologies such as search engines, spell checkers or speech recognition.",
  "Machine Translation, Natural Language Processing and Computational Linguistics\nResearch\nThere are more than 6,000 human languages, but less than a hundred of them have robust language technologies such as search engines, spell checkers or speech recognition. Nevertheless, speakers of the technologically poor languages may have uses for language technologies to access information related to education, politics, business, weather and health conditions \u2014 not to mention preservation of culture and community relationships. My work focuses on the linguistic aspects of language technologies, specifically the following:\nLanguage Technologies With Low Resources\nMany languages lack sufficient data for supervised or unsupervised machine learning. There may also be low-resource scenarios for technology-rich languages like English in specialized styles or subject areas.\u00a0 Such cases may call for hybrids of human-engineered knowledge and machine learning. The human engineered knowledge can be in the form of handwritten rules, priors or feature engineering.\nLanguage Universals and Typology\nWhen there is insufficient time or data to build an NLP system, it is useful to fall back on what is known about human languages in general or what is known about related languages. The field of linguistic typology and universals provides expectations for what languages might be like.",
  "Language Universals and Typology\nWhen there is insufficient time or data to build an NLP system, it is useful to fall back on what is known about human languages in general or what is known about related languages. The field of linguistic typology and universals provides expectations for what languages might be like. We are exploring how to use typology and universals to develop language technologies for new languages on short timelines or in low-resource scenarios.\nCorpus Annotation and Linguistic Resources\nWhen time and data are available, language technologies can be based on supervised learning from annotated data. The annotations may be for any level of linguistic knowledge from sounds to social hierarchies. My approach to annotation is based on the linguistic theory of construction grammar.\nPersonal Website\n\nLinks:\nhttp://www.cs.cmu.edu/~lsl/",
  "Faculty Name: lori levin\nMetadata:\nPaperid: 2cdc646a6b70418e7cbd7fbdb8bb113176c4659f\nTitle: Somatosensory and motor representations following bilateral transplants of the hands: A 6-year longitudinal case report on the first pediatric bilateral hand transplant patient\nYear: 2023\nAbstract: None\nAuthors: W. Gaetz, C. Dockstader, P. Furlong, S. Amaral, A. Vossough, E. Schwartz, T. Roberts, Lori S. Levin\nVenue: Brain Research\nTldr: {'model': 'tldr@v2.0.0', 'text': None}",
  "Faculty Name: lori levin\nMetadata:\nPaperid: 2f540bab03c2672715539ecf17ff4872ea521605\nTitle: Identifying Health-Related Quality of Life Domains after Upper Extremity Transplantation.\nYear: 2023\nAbstract: None\nAuthors: D. Tulsky, Pamela A. Kisala, Callie E Tyner, J. Slotkin, C. Kaufman, C. Dearth, A. Horan, S. Talbot, J. Shores, K. Azari, C. Cetrulo, G. Brandacher, C. Cooney, David E Victorson, M. Dooley, Lori S. Levin, Cdr Scott M Tintle\nVenue: Archives of Physical Medicine and Rehabilitation\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This study identified key constructs for use in evaluation of the potentially substantial physical, medical, social, and emotional effects of UET, including physical functioning and medical complications, positive and negative emotional functioning, and social participation, relationships, and independence.'}",
  "Faculty Name: lori levin\nMetadata:\nPaperid: 52a97ad16605c18e23c9750a388a26a9cdf12200\nTitle: Assessment of quality of life after upper extremity transplantation: Framework for patient-reported outcome scale domains\nYear: 2023\nAbstract: Upper extremity transplantation offers the promise of restored function and regained quality of life (QOL) for individuals who have sustained hand or arm amputation. However, a major challenge for this procedure becoming an accessible treatment option for patients is the lack of standard measures to document benefits to QOL. Patient-reported outcomes (PRO) measures are well-suited for this kind of intervention, where the perspective of the patient is central to defining treatment success. To date, qualitative work with experts, clinicians, and patients has been used to identify the most important domains of QOL for PRO item development. Specifically, our group\u2019s qualitative work has identified several domains of QOL that are unique to individuals who have received upper extremity transplants, which are distinct from topics covered by existing PRO measures.",
  "Specifically, our group\u2019s qualitative work has identified several domains of QOL that are unique to individuals who have received upper extremity transplants, which are distinct from topics covered by existing PRO measures. These include emotional and social aspects of upper extremity transplant, such as Expectations and Perceived Outcomes, Integration and Assimilation of Transplant, Fitting in, and Post-Surgical Challenges and Complications. The broad topic of Satisfaction with Transplant was subdivided into three subtopics: Function, Sensation, and Aesthetics. Satisfaction with Sensation was also identified as a unique domain not evaluated by existing PRO measures. This report operationalizes these eight QOL domains by presenting scoping definitions. This manuscript describes the work that has been completed for domain characterization as an early step toward developing standardized PRO measures to evaluate these important outcomes specific to upper extremity transplantation.",
  "This report operationalizes these eight QOL domains by presenting scoping definitions. This manuscript describes the work that has been completed for domain characterization as an early step toward developing standardized PRO measures to evaluate these important outcomes specific to upper extremity transplantation.\nAuthors: Callie E Tyner, J. Slotkin, Pamela A. Kisala, Lori S. Levin, Scott M. Tintle, D. Tulsky\nVenue: Frontiers in Psychology\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Qualitative work with experts, clinicians, and patients has identified several domains of QOL that are unique to individuals who have received upper extremity transplants, which are distinct from topics covered by existing PRO measures.'}",
  "Faculty Name: lori levin\nMetadata:\nPaperid: 659be1ff350634f50cc066d258ee6a45e697e552\nTitle: SigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing\nYear: 2023\nAbstract: In our submission to the SIGMORPHON 2023 Shared Task on interlinear glossing (IGT), we explore approaches to data augmentation and modeling across seven low-resource languages. For data augmentation, we explore two approaches: creating artificial data from the provided training data and utilizing existing IGT resources in other languages. On the modeling side, we test an enhanced version of the provided token classification baseline as well as a pretrained multilingual seq2seq model. Additionally, we apply post-correction using a dictionary for Gitksan, the language with the smallest amount of data. We find that our token classification models are the best performing, with the highest word-level accuracy for Arapaho and highest morpheme-level accuracy for Gitksan out of all submissions. We also show that data augmentation is an effective strategy, though applying artificial data pretraining has very different effects across both models tested.",
  "We find that our token classification models are the best performing, with the highest word-level accuracy for Arapaho and highest morpheme-level accuracy for Gitksan out of all submissions. We also show that data augmentation is an effective strategy, though applying artificial data pretraining has very different effects across both models tested.\nAuthors: Taiqi He, Lindia Tjuatja, Nathaniel R. Robinson, Shinji Watanabe, David R. Mortensen, Graham Neubig, L. Levin\nVenue: Special Interest Group on Computational Morphology and Phonology Workshop\nTldr: {'model': 'tldr@v2.0.0', 'text': 'In this submission to the SIGMORPHON 2023 Shared Task on interlinear glossing (IGT), approaches to data augmentation and modeling across seven low-resource languages are explored and token classification models are found to be the best performing.'}",
  "Faculty Name: lori levin\nMetadata:\nPaperid: 7a08051aac75a809737096e39820bf836908d4e1\nTitle: Construction Grammar Provides Unique Insight into Neural Language Models\nYear: 2023\nAbstract: Construction Grammar (CxG) has recently been used as the basis for probing studies that have investigated the performance of large pretrained language models (PLMs) with respect to the structure and meaning of constructions. In this position paper, we make suggestions for the continuation and augmentation of this line of research. We look at probing methodology that was not designed with CxG in mind, as well as probing methodology that was designed for specific constructions. We analyse selected previous work in detail, and provide our view of the most important challenges and research questions that this promising new field faces.",
  "We look at probing methodology that was not designed with CxG in mind, as well as probing methodology that was designed for specific constructions. We analyse selected previous work in detail, and provide our view of the most important challenges and research questions that this promising new field faces.\nAuthors: Leonie Weissweiler, Taiqi He, Naoki Otani, David R. Mortensen, L. Levin, Hinrich Sch\u00fctze\nVenue: CXGSNLP\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The view of the most important challenges and research questions that this promising new field of research faces is provided, and an analysis of selected previous work in detail is provided.'}",
  "Faculty Name: lori levin\nMetadata:\nPaperid: bf42c0462d1415cdde877c90d58da11545407b8a\nTitle: Generalized Glossing Guidelines: An Explicit, Human- and Machine-Readable, Item-and-Process Convention for Morphological Annotation\nYear: 2023\nAbstract: Interlinear glossing provides a vital type of morphosyntactic annotation, both for linguists and language revitalists, and numerous conventions exist for representing it formally and computationally. Some of these formats are human readable; others are machine readable. Some are easy to edit with general-purpose tools. Few represent non-concatentative processes like infixation, reduplication, mutation, truncation, and tonal overwriting in a consistent and formally rigorous way (on par with affixation). We propose an annotation convention\u00e2\u20ac\u201dGeneralized Glossing Guidelines (GGG) that combines all of these positive properties using an Item-and-Process (IP) framework. We describe the format, demonstrate its linguistic adequacy, and compare it with two other interlinear glossed text annotation schemes.",
  "We propose an annotation convention\u00e2\u20ac\u201dGeneralized Glossing Guidelines (GGG) that combines all of these positive properties using an Item-and-Process (IP) framework. We describe the format, demonstrate its linguistic adequacy, and compare it with two other interlinear glossed text annotation schemes.\nAuthors: David R. Mortensen, Ela Gulsen, Taiqi He, Nathaniel R. Robinson, Jonathan D. Amith, Lindia Tjuatja, L. Levin\nVenue: Special Interest Group on Computational Morphology and Phonology Workshop\nTldr: {'model': 'tldr@v2.0.0', 'text': 'An annotation convention is proposed that combines all of these positive properties using an Item-and-Process (IP) framework, and its linguistic adequacy is demonstrated, and it is compared with two other interlinear glossed text annotation schemes.'}",
  "Faculty Name: lori levin\nMetadata:\nPaperid: c5207241406586f4263b235667e004b71ea68953\nTitle: Syntax and Semantics Meet in the \u201cMiddle\u201d: Probing the Syntax-Semantics Interface of LMs Through Agentivity\nYear: 2023\nAbstract: Recent advances in large language models have prompted researchers to examine their abilities across a variety of linguistic tasks, but little has been done to investigate how models handle the interactions in meaning across words and larger syntactic forms\u2014i.e. phenomena at the intersection of syntax and semantics. We present the semantic notion of agentivity as a case study for probing such interactions. We created a novel evaluation dataset by utilitizing the unique linguistic properties of a subset of optionally transitive English verbs. This dataset was used to prompt varying sizes of three model classes to see if they are sensitive to agentivity at the lexical level, and if they can appropriately employ these word-level priors given a specific syntactic context. Overall, GPT-3 text-davinci-003 performs extremely well across all experiments, outperforming all other models tested by far.",
  "Overall, GPT-3 text-davinci-003 performs extremely well across all experiments, outperforming all other models tested by far. In fact, the results are even better correlated with human judgements than both syntactic and semantic corpus statistics. This suggests that LMs may potentially serve as more useful tools for linguistic annotation, theory testing, and discovery than select corpora for certain tasks.\nAuthors: Lindia Tjuatja, Emmy Liu, L. Levin, Graham Neubig\nVenue: STARSEM\nTldr: {'model': 'tldr@v2.0.0', 'text': 'GPT-3 text-davinci-003 performs extremely well across all experiments, outperforming all other models tested by far and suggests that LMs may potentially serve as more useful tools for linguistic annotation, theory testing, and discovery than select corpora for certain tasks.'}",
  "List of 2023 Open Access papers by lori levin are:\nSigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing\nConstruction Grammar Provides Unique Insight into Neural Language Models\nGeneralized Glossing Guidelines: An Explicit, Human- and Machine-Readable, Item-and-Process Convention for Morphological Annotation\nSyntax and Semantics Meet in the \u201cMiddle\u201d: Probing the Syntax-Semantics Interface of LMs Through Agentivity\nSomatosensory and motor representations following bilateral transplants of the hands: A 6-year longitudinal case report on the first pediatric bilateral hand transplant patient\nIdentifying Health-Related Quality of Life Domains after Upper Extremity Transplantation.\nAssessment of quality of life after upper extremity transplantation: Framework for patient-reported outcome scale domains",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: 00dcbf65e42f67b41953a5b6a409ccae6e354787\nTitle: Impact of Varicella Immunization and Public Health and Social Measures on Varicella Incidence: Insights from Surveillance Data in Shanghai, 2013\u20132022\nYear: 2023\nAbstract: To evaluate the impact of a two-dose VarV program on varicella incidence among the whole population, considering the influence of public health and social measures (PHSMs), we extracted surveillance data on varicella cases during 2013\u20132022 in Minhang, Shanghai. Then, we estimated the incidence trend of varicella through interrupted time-series analyses and quantified the impact of the immunization program and PHSMs using Serfling regression. We also explored the associations between PHSMs and varicella cases. The implementation of the two-dose VarV strategy was followed by a significant decrease in varicella incidence (\u22121.84% per month).",
  "We also explored the associations between PHSMs and varicella cases. The implementation of the two-dose VarV strategy was followed by a significant decrease in varicella incidence (\u22121.84% per month). After one year of the program, varicella incidence was estimated at a 45.25% reduction, which was higher in children (59.12% and 54.09%) than in adults (19.49%). The decrease attributed to PHSMs was 31.26% during 2020\u20132022, and school closing was identified as the most relevant PHSM (b = \u22128.03 cases, r = \u22120.67 with a 1-week lag). These findings indicate that the two-dose immunization program has more effectively reduced the varicella incidence compared with the one-dose vaccine, and interventions like school closings are also encouraged to serve as supplementary measures to prevent varicella epidemics.",
  "These findings indicate that the two-dose immunization program has more effectively reduced the varicella incidence compared with the one-dose vaccine, and interventions like school closings are also encouraged to serve as supplementary measures to prevent varicella epidemics.\nAuthors: Liming Shi, Jia Lu, Xiaodong Sun, Zhi Li, Liping Zhang, Yihan Lu, Ye Yao\nVenue: Vaccines\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The findings indicate that the two-dose immunization program has more effectively reduced the varicella incidence compared with the one-dose vaccine, and interventions like school closings are also encouraged to serve as supplementary measures to prevent varICElla epidemics.'}",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: 01796aa965bab046cd24077ad6cd0d5d4cd8e6c8\nTitle: Multi-Omics Unravels Metabolic Alterations in the Ileal Mucosa of Neonatal Piglets Receiving Total Parenteral Nutrition\nYear: 2023\nAbstract: Total parenteral nutrition (TPN) is life-saving therapy for the pediatric patients with intestinal failure (IF) who cannot tolerate enteral nutrition (EN). However, TPN-induced metabolic alterations are also a critical issue for the maintenance of intestinal homeostasis, and thus the global metabolomic signatures need to be addressed. In this study, ileal mucosal biopsies were collected from 12 neonatal Bama piglets receiving either EN or TPN for 14 days, and changes in the intestinal metabolism were examined by multi-omics (HM350 Metabolomics + Tandem Mass Tag (TMT)-based proteomics). As a result, a total of 240 compounds were identified by metabolomics, including 56 down-regulated and 9 up-regulated metabolites.",
  "As a result, a total of 240 compounds were identified by metabolomics, including 56 down-regulated and 9 up-regulated metabolites. Notably, tissue levels of fatty acyl-carnitines (decreased by 35\u201385%) and succinate (decreased by 89%) dramatically decreased in the TPN group, suggestive of disrupted processes of fatty acid oxidation (FAO) and the citrate cycle, respectively. Interestingly, however, no differences were found in the production of adenosine 5\u2032-triphosphate (ATP) between groups, suggesting that these dysregulated metabolites may have mainly led to the loss of bioactive compounds rather than energy deficit. Additionally, 4813 proteins were identified by proteomics in total, including 179 down-regulated and 329 up-regulated proteins. The analysis of protein\u2013protein interactions (PPI) indicated that most of the differentially expressed proteins were clustered into \u201clipid metabolism\u201d and \u201cinnate immune responses\u201d. In summary, this work provided new findings in TPN-induced intestinal metabolic alterations, which would be useful to the improvement of nutritional management for IF patients.",
  "In summary, this work provided new findings in TPN-induced intestinal metabolic alterations, which would be useful to the improvement of nutritional management for IF patients.\nAuthors: Jun-Kai Yan, Yuling Zhao, Luyang Jiang, Ying Wang, W. Cai\nVenue: Metabolites\nTldr: {'model': 'tldr@v2.0.0', 'text': 'New findings in TPN-induced intestinal metabolic alterations are provided, which would be useful to the improvement of nutritional management for IF patients.'}",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: 05828439f8a928df3e6036c3be766b430935da6a\nTitle: Accuracy of narrow band imaging for detecting the malignant transformation of oral potentially malignant disorders: A systematic review and meta-analysis\nYear: 2023\nAbstract: Objective Oral potentially malignant disorders (OPMDs) are a spectrum of diseases that harbor the potential of malignant transformation and developing into oral squamous cell carcinoma (OSCC). Narrow band imaging (NBI) has been clinically utilized for the adjuvant diagnosis of OPMD and OSCC. This study aimed to comprehensively evaluate the diagnostic accuracy of NBI for malignant transformations of OPMD by applying the intraepithelial papillary capillary loop (IPCL) classification approach. Methods Studies reporting the diagnostic validity of NBI in the detection of OPMD/OSCC were selected. Four databases were searched and 11 articles were included in the meta-analysis. We performed four subgroup analyses by defining IPCL I/II as negative diagnostic results and no/mild dysplasia as negative pathological outcome. Pooled data were analyzed using random-effects models.",
  "Four databases were searched and 11 articles were included in the meta-analysis. We performed four subgroup analyses by defining IPCL I/II as negative diagnostic results and no/mild dysplasia as negative pathological outcome. Pooled data were analyzed using random-effects models. Meta-regression analysis was performed to explore heterogeneity. Results After pooled analysis of the four subgroups, we found that subgroup 1, defining IPCL II and above as a clinically positive result, demonstrated the most optimal overall diagnostic accuracy for the malignant transformation of OPMDs, with a sensitivity and specificity of NBI of 0.87 (95% confidence interval (CI) [0.67, 0.96], p\u2009<\u20090.001) and 0.83 [95% CI (0.56, 0.95), p\u2009<\u20090.001], respectively; while the other 3 subgroups displayed relatively low sensitivity or specificity. Conclusions NBI is a promising and non-invasive adjunctive tool for identifying malignant transformations of OPMDs. The IPCL grading is currently a sound criterion for the clinical application of NBI.",
  "Conclusions NBI is a promising and non-invasive adjunctive tool for identifying malignant transformations of OPMDs. The IPCL grading is currently a sound criterion for the clinical application of NBI. After excluding potentially false positive results, these oral lesions classified as IPCL II or above are suggested to undergo biopsy for early and accurate diagnosis as well as management.\nAuthors: You Zhang, Yuqi Wu, Dan Pan, Zhenyu Zhang, Lu Jiang, Xiaodong Feng, Yuchen Jiang, Xiaobo Luo, Qianming Chen\nVenue: Frontiers in Surgery\nTldr: {'model': 'tldr@v2.0.0', 'text': 'NBI is a promising and non-invasive adjunctive tool for identifying malignant transformations of OPMDs and the IPCL grading is currently a sound criterion for the clinical application of NBI.'}",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: 05916c0933cb6cc434d4fcc469f928e13ae57689\nTitle: Recent progresses on the gamma-ray observations of DAMPE\nYear: 2023\nAbstract: None\nAuthors: Z. Shen, K. Duan, Zunlei Xu, Wei Jiang, Xiang Li, Xiao Yuan Huang, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, F. de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, J. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng,",
  "de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, J. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Y. Huang, M. Ionica, Luyao Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A.",
  "Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, H. Su, Meng Su, H. Sun, Zhiyu Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Yuanzhu Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu, G. Xue,",
  "Yuanzhu Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hong-yun Zhao, Xu Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: None",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: 065ac1f7c326429eb6c676a787e7a3f56b884b01\nTitle: Inchworm\u2010Like Soft Robot with Multimodal Locomotion Using an Acrylic Stick\u2010Constrained Dielectric Elastomer Actuator\nYear: 2023\nAbstract: Inchworm\u2010like robots have been increasingly investigated in recent years. However, most studies have focused on one or several locomotion modes, lacking in terms of inverted climbing, movement with a heavy load, and climbing a vertical plane. Herein, an inchworm\u2010like soft robot is actuated with multimodal locomotion using an acrylic stick\u2010constrained dielectric elastomer actuator (ASCDEA). By assembling the ASCDEA with a flexible support frame, a soft saddle\u2010like shape body is designed to provide the shape deformation ability for the robot. This design enables the robot to move under a heavy load. Two electroadhesion actuators are designed to implement the anchoring action. Additionally, a coordination control strategy is developed to synchronize the shape deformation and electroadhesion for multimodal locomotion.",
  "This design enables the robot to move under a heavy load. Two electroadhesion actuators are designed to implement the anchoring action. Additionally, a coordination control strategy is developed to synchronize the shape deformation and electroadhesion for multimodal locomotion. Experimental results confirm that the designed robot can move at a maximum velocity of 39.55\u2009mm\u2009s\u22121 (0.53 body length\u2009s\u22121) on an inverted plane. Moreover, the robot is capable of multimodal locomotion, including inverted climbing, vertical climbing, horizontal crawling, turning locomotion, and rapid movement with a heavy load. The developed soft robot can navigate through a confined horizontal tunnel while carrying a payload, cross a gap, circumvent obstacles, and is particularly robust owing to its compliance.\nAuthors: Tete Hu, Xinjiang Lu, Jin Liu\nVenue: Advanced Intelligent Systems\nTldr: None",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: 109d73d84c19b11329c15f58ec66d4c81136b383\nTitle: Associations of Morphological Changes in Skeletal Muscles of Preschool Children in China Following Physical Activity\nYear: 2023\nAbstract: Purpose: Physical activity (PA) is likely to be the most important modifiable factor in skeletal muscle development. However, the influence of PA on the skeletal muscle of preschool children has not been thoroughly investigated. The main objective of this study was to quantitatively measure PA, and then, to assess whether associations exist between site-specific muscle changes and PA in relation to sex and weight statuses in preschool children aged 3 to 4 years. Methods: A total of 86 healthy preschool children, aged 3\u20134 years, were instructed to wear an accelerometer for seven consecutive days. The number of steps taken daily, and minutes spent in moderate\u2013vigorous PA (MVPA) and total PA (TPA) were recorded. Muscle thickness was measured by B-mode ultrasonography using a 5\u201318 MHz scanning head.",
  "The number of steps taken daily, and minutes spent in moderate\u2013vigorous PA (MVPA) and total PA (TPA) were recorded. Muscle thickness was measured by B-mode ultrasonography using a 5\u201318 MHz scanning head. Muscle thickness was measured at seven sites: the lateral forearm, upper arm, abdomen, anterior and posterior thigh, and anterior and posterior lower leg. Results: There was no significant difference between boys and girls in terms of MVPA and TPA on weekdays and weekends. According to the linear regression models, after adjusting for daylight duration, the muscle of the posterior thigh was significantly positively associated (p < 0.05) with daily steps and MVPA on weekdays for boys and girls, respectively. Conclusions: We found that the muscle thickness of the posterior thigh in preschool children was significantly positively associated with PA, as measured by daily steps and MVPA. We suggest that for the overall health and well-being of preschool children, the levels of PA should be maintained and/or increased, and preferably transformed into a regular part of daily living.",
  "We suggest that for the overall health and well-being of preschool children, the levels of PA should be maintained and/or increased, and preferably transformed into a regular part of daily living.\nAuthors: Pengyu Deng, Hayao Ozaki, Toshiharu Natsume, Dandan Ke, Dajiang Lu, Koya Suzuki, Hisashi Naito\nVenue: Children\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is found that the muscle thickness of the posterior thigh in preschool children was significantly positively associated with PA, as measured by daily steps and MVPA, and should be maintained and/or increased, and preferably transformed into a regular part of daily living.'}",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: 1123d35433a7b8dfa6e4259e66c4446db9de21f2\nTitle: Enterococcus faecalis promotes the progression of colorectal cancer via its metabolite: biliverdin\nYear: 2023\nAbstract: None\nAuthors: Li Zhang, J. Liu, Mingxia Deng, Xiangliu Chen, Lushun Jiang, Jiajie Zhang, Lisheng Tao, Wei-Fu Yu, Yunqing Qiu\nVenue: Journal of Translational Medicine\nTldr: {'model': 'tldr@v2.0.0', 'text': 'BV, as the tumor-stimulating metabolite of Efa, generates proliferative and angiogenic effects on CRC, which is mainly mediated by the activation of PI3K/AKT/mTOR.'}",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: 123adc529134d1f318c9cb03633b73c3b8fe87db\nTitle: Paradoxical Induction of ALOX15/15B by Cortisol in Human Amnion Fibroblasts: Implications for Inflammatory Responses of the Fetal Membranes at Parturition\nYear: 2023\nAbstract: Inflammation of the fetal membranes is an indispensable event of parturition, with increasing prostaglandin E2 (PGE2) synthesis as one of the ultimate products that prime labor onset. In addition to PGE2, the fetal membranes also boast a large capacity for cortisol regeneration. It is intriguing how increased PGE2 synthesis is achieved in the presence of increasing amounts of classical anti-inflammatory glucocorticoids in the fetal membranes at parturition. 15(S)-hydroxyeicosatetraenoic acid (15(S)-HETE) synthesized by lipoxygenase 15/15B (ALOX15/15B) has been shown to enhance inflammation-induced PGE2 synthesis in amnion fibroblasts.",
  "15(S)-hydroxyeicosatetraenoic acid (15(S)-HETE) synthesized by lipoxygenase 15/15B (ALOX15/15B) has been shown to enhance inflammation-induced PGE2 synthesis in amnion fibroblasts. Here, we examined whether glucocorticoids could induce ALOX15/15B expression and 15(S)-HETE production to promote PGE2 synthesis in amnion fibroblasts at parturition. We found that cortisol and 15(S)-HETE abundance increased parallelly in the amnion at parturition. Cortisol induced ALOX15/15B expression and 15(S)-HETE production paradoxically in amnion fibroblasts. Mechanism study revealed that this paradoxical induction was mediated by p300-mediated histone acetylation and interaction of glucocorticoid receptor with transcription factors CREB and STAT3.",
  "Mechanism study revealed that this paradoxical induction was mediated by p300-mediated histone acetylation and interaction of glucocorticoid receptor with transcription factors CREB and STAT3. Conclusively, cortisol regenerated in the fetal membranes can paradoxically induce ALOX15/15B expression and 15(S)-HETE production in human amnion fibroblasts, which may further assist in the induction of PGE2 synthesis in the inflammatory responses of the fetal membranes for parturition.\nAuthors: Fan Zhang, Jiangwen Lu, Wen-jia Lei, M. Li, Fang Pan, Yiming Lin, Wangsheng Wang, K. Sun\nVenue: International Journal of Molecular Sciences\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Cortisol regenerated in the fetal membranes can paradoxically induce ALOX15/15B expression and 15(S)-HETE production in human amnion fibroblasts, which may further assist in the induction of PGE2 synthesis in the inflammatory responses of the Fetal membranes for parturition.'}",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: 1ddaf16b2c7a9ce4b81bf361d972e58d8afe03f1\nTitle: Reduced electron relaxation time of perovskite films via g-C3N4 quantum dot doping for high-performance perovskite solar cells\nYear: 2023\nAbstract: Perovskite film-quality is a crucial factor to improve the photovoltaic properties of perovskite solar cells, which is closely related to the morphology of crystallization grain size of the perovskite layer. However, defects and trap sites are inevitably generated on the surface and at the grain boundaries of the perovskite layer. Here, we report a convenient method for preparing dense and uniform perovskite films, employing g-C3N4 quantum dots doped into the perovskite layer by regulating proper proportions. This process produces perovskite films with dense microstructures and flat surfaces. As a result, the higher fill factor (0.78) and a power conversion efficiency of 20.02% are obtained by the defect passivation of g-C3N4QDs.",
  "This process produces perovskite films with dense microstructures and flat surfaces. As a result, the higher fill factor (0.78) and a power conversion efficiency of 20.02% are obtained by the defect passivation of g-C3N4QDs.\nAuthors: Lu-Lu Jiang, Meng-Meng Chen, Xiao-Dan Tang, Ying Tang, Shaoxin Li, Y. Li, Hang-Hui Li, Hairui Liu\nVenue: RSC Advances\nTldr: None",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: 20c90276bf415f9188897cb79e745b4d3870b448\nTitle: TMEM241 is a UDP-N-acetylglucosamine transporter required for M6P modification of NPC2 and cholesterol transport\nYear: 2023\nAbstract: None\nAuthors: Nan Zhao, Gang Deng, Pei-Xin Yuan, Ya-Fen Zhang, Lu-yi Jiang, Xiaolu Zhao, B. Song\nVenue: Journal of Lipid Research\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is shown that the previously unannotated protein TMEM241 is required for cholesterol egressing from lysosomes through amphotericin B-based genome-wide CRISPR-Cas9 KO screening and is a Golgi-localized UDP-GlcNAc transporter and loss ofTMEM241 causes cholesterol accumulation in lysoomes because of the impaired M6P-dependent lysOSomal targeting of NPC2.'}",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: 2386a482b661fd3b65d7509f6dd900020116d9a2\nTitle: Low-Light Image Enhancement via Structure Modeling and Guidance\nYear: 2023\nAbstract: This paper proposes a new framework for low-light image enhancement by simultaneously conducting the appearance as well as structure modeling. It employs the structural feature to guide the appearance enhancement, leading to sharp and realistic results. The structure modeling in our framework is implemented as the edge detection in low-light images. It is achieved with a modified generative model via designing a structure-aware feature extractor and generator. The detected edge maps can accurately emphasize the essential structural information, and the edge prediction is robust towards the noises in dark areas. Moreover, to improve the appearance modeling, which is implemented with a simple U-Net, a novel structure-guided enhancement module is proposed with structure-guided feature synthesis layers. The appearance modeling, edge detector, and enhancement module can be trained end-to-end. The experiments are conducted on representative datasets (sRGB and RAW domains), showing that our model consistently achieves SOTA performance on all datasets with the same architecture.",
  "The appearance modeling, edge detector, and enhancement module can be trained end-to-end. The experiments are conducted on representative datasets (sRGB and RAW domains), showing that our model consistently achieves SOTA performance on all datasets with the same architecture. The code is available at https://github.com/xiaogangOO/SMG-LLIE.\nAuthors: Xiaogang Xu, Ruixing Wang, Jiangbo Lu\nVenue: Computer Vision and Pattern Recognition\nTldr: {'model': 'tldr@v2.0.0', 'text': None}",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: 269a18fbff6f0079e7ea2463b96654ce6563c49a\nTitle: Coverage and impact of influenza vaccination among children in Minhang District, China, 2013\u20132020\nYear: 2023\nAbstract: Background Young children have a great disease burden and are particularly vulnerable to influenza. This study aimed to assess the direct effect of influenza vaccination among children and to evaluate the indirect benefit of immunizing children. Methods The influenza vaccination records for all children born during 2013\u20132019 in Minhang District and surveillance data for reported influenza cases were obtained from the Minhang CDC. 17,905 children were recorded in the vaccination system and included in this study. Descriptive epidemiology methods were used for data analysis, including an ecological approach to estimate the number of influenza cases averted by vaccination and linear regression to estimate the reduction in influenza cases in the general population per thousand additional childhood vaccination doses. Results During the study period, the annual vaccination coverage rate ranged from 10.40% in 2013\u20132014 to 27.62% in 2015\u20132016.",
  "Results During the study period, the annual vaccination coverage rate ranged from 10.40% in 2013\u20132014 to 27.62% in 2015\u20132016. The estimated number of influenza cases averted by vaccination ranged from a low of 0.28 (range: 0.23\u20130.34) during 2013\u20132014 (PF: 6.15%, range: 5.11\u20137.38%) to a high of 15.34 (range: 12.38\u201318.51) during 2017\u20132018 (PF: 16.54%, range: 13.79\u201319.30%). When increasing vaccination coverage rate by 10% in each town/street, a ratio of 7.27\u201310.69% cases could be further averted on the basis of observed cases. In four selected periods, the number of influenza cases in the general population was most significantly correlated with the cumulative childhood vaccination doses in the prior 2\u20135\u2009months, and the reduction in influenza cases ranged from 0.73 to 3.18 cases per thousand additional childhood vaccination doses.",
  "In four selected periods, the number of influenza cases in the general population was most significantly correlated with the cumulative childhood vaccination doses in the prior 2\u20135\u2009months, and the reduction in influenza cases ranged from 0.73 to 3.18 cases per thousand additional childhood vaccination doses. Conclusion Influenza vaccination among children is estimated to have direct effects in terms of averted cases and might provide an underlying indirect benefit to the general population. Vaccination coverage in high-coverage areas should be further expanded to avert more influenza cases.\nAuthors: Zhaowen Zhang, Liming Shi, Nian Liu, Biyun Jia, K. Mei, Li-ping Zhang, XuanZhao Zhang, Yihan Lu, Jia Lu, Ye Yao\nVenue: Frontiers in Public Health\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Influenza vaccination among children is estimated to have direct effects in terms of averted cases and might provide an underlying indirect benefit to the general population and vaccination coverage in high-coverage areas should be further expanded.'}",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: 274b363f94a741f38cad95f1ab68edaadf6fc0d9\nTitle: Analysis of Individual Cosmic-Ray Proton and Helium Fluxes towards PeV Energies with DAMPE\nYear: 2023\nAbstract: The DArk Matter Particle Explorer (DAMPE) is a satellite-borne experiment, in operation since 2015, aimed at studying cosmic rays and high-energy gamma rays. Proton and helium are the first-and second-most abundant components in cosmic rays. Given their smaller interaction cross sections with the interstellar medium, compared to heavier nuclei, they can travel larger distances, thereby becoming important probes to cosmic-ray sources as well as acceleration and propagation mechanisms. Recently, in the DAMPE collaboration, machine learning (ML) techniques were developed and deployed to improve particle tracking and identification and correct for the calorimeter readout saturation at high energies. This work presents a direct measurement of the energy spectra of cosmic-ray protons and helium nuclei, using 84 and 81 months of data, respectively, recorded by DAMPE.",
  "This work presents a direct measurement of the energy spectra of cosmic-ray protons and helium nuclei, using 84 and 81 months of data, respectively, recorded by DAMPE. Application of the above-mentioned ML techniques helps in extending the spectra to higher kinetic energies than those previously reported by DAMPE\nAuthors: A. Ruina, P. Coppin, A. Kotenko, Pengxiong Ma, M. Stolpovskiy, A. Tykhonov, C. Yue, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, F. de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R.",
  "Yu-Xin Cui, I. De Mitri, F. de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, Luyang Jiang, Wei Jiang, Y. Jiang, J. Kong, D. Kyratzis, S. Lei, W. Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, T. Ma, Xiao Ma, G. Marsella, M.",
  "Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, Z. Shangguan, E. Xu, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, H. Su, Meng Su, H. Sun, Zhigang Sun, A. Surdo, X. Teng, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu, Zunlei Xu, G.",
  "Ying Wang, Y. Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hongying Zhao, Xu Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: None",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: 290d3610fd394c3e9468402fbda8f74d35170b7e\nTitle: A phosphoglycerate mutase 1 allosteric inhibitor overcomes drug resistance to EGFR-targeted therapy via disrupting IL-6/JAK2/STAT3 signaling pathway in lung adenocarcinoma.\nYear: 2023\nAbstract: None\nAuthors: Q. Liang, Miaomiao Gong, Jing-hua Zou, M. Luo, Lu-lu Jiang, Cheng Wang, Ningzhe Shen, Mo-cong Zhang, Lu Xu, Hui-Min Lei, Ke-Ren Zhang, Rui Zhang, G. Zhuang, Liang Zhu, Hong-Zhuan Chen, Lu Zhou, Ying Shen\nVenue: Drug resistance updates\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is found that IL-6/JAK2/STAT3 signaling pathway is aberrantly activated in both erlotinib and osimertinib resistant cells and HKB99 remarkably restores EGFR inhibitor sensitivity and exerts synergistic tumoricidal effect.'}",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: 3169f069465a8c4e4dbc6a384081989dccd2af86\nTitle: Edge Preserving Implicit Surface Representation of Point Clouds\nYear: 2023\nAbstract: Learning implicit surface directly from raw data recently has become a very attractive representation method for 3D reconstruction tasks due to its excellent performance. However, as the raw data quality deteriorates, the implicit functions often lead to unsatisfactory reconstruction results. To this end, we propose a novel edge-preserving implicit surface reconstruction method, which mainly consists of a differentiable Laplican regularizer and a dynamic edge sampling strategy. Among them, the differential Laplican regularizer can effectively alleviate the implicit surface unsmoothness caused by the point cloud quality deteriorates; Meanwhile, in order to reduce the excessive smoothing at the edge regions of implicit suface, we proposed a dynamic edge extract strategy for sampling near the sharp edge of point cloud, which can effectively avoid the Laplacian regularizer from smoothing all regions. Finally, we combine them with a simple regularization term for robust implicit surface reconstruction.",
  "Finally, we combine them with a simple regularization term for robust implicit surface reconstruction. Compared with the state-of-the-art methods, experimental results show that our method significantly improves the quality of 3D reconstruction results. Moreover, we demonstrate through several experiments that our method can be conveniently and effectively applied to some point cloud analysis tasks, including point cloud edge feature extraction, normal estimation,etc.\nAuthors: Xiaogang Wang, Y. Cheng, Liang Wang, Jiangbo Lu, Kai Xu, Guoqiang Xiao\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes a novel edge-preserving implicit surface reconstruction method, which mainly consists of a differentiable Laplican regularizer and a dynamic edge sampling strategy that can effectively alleviate the implicit surface unsmoothness caused by the point cloud quality deteriorates.'}",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: 3355d79dc3d806d068833602aa5ef4011fe8f7d7\nTitle: Advances in gene therapy hold promise for treating hereditary hearing loss.\nYear: 2023\nAbstract: None\nAuthors: Luoying Jiang, Daqi Wang, Yingzi He, Y. Shu\nVenue: Molecular Therapy\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Three main gene therapy strategies-gene replacement, gene suppression, and gene editing are addressed, summarizing which strategy is most appropriate for particular monogenic diseases based on different pathogenic mechanisms and then focusing on their successful applications for HHL in preclinical trials.'}",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: 39195b5ed455a8b24edb0b5c3340974ae8e04fe4\nTitle: The efficacy and safety of asleep and awake subthalamic deep brain stimulation for Parkinson\u2019s disease patients: A 1-year follow-up\nYear: 2023\nAbstract: Introduction Traditional DBS is usually conducted under local anesthesia (LA) which is intolerable to some patients, DBS under general anesthesia (GA) was opted to extended surgical indication. This study aimed to compare the efficacy and safety of bilateral subthalamic deep brain stimulation (STN-DBS) for Parkinson\u2019s disease (PD) under asleep and awake anesthesia state in 1-year postoperative follow-up. Methods Twenty-one PD patients were assigned to asleep group and 25 patients to awake group. Patients received bilateral STN-DBS under different anesthesia state. The PD participants were interviewed and assessed preoperatively and at 1-year postoperative follow-up.",
  "Methods Twenty-one PD patients were assigned to asleep group and 25 patients to awake group. Patients received bilateral STN-DBS under different anesthesia state. The PD participants were interviewed and assessed preoperatively and at 1-year postoperative follow-up. Results At 1-year follow-up, compared surgical coordinate in two groups, the left-side Y of asleep group showed more posterior than awake group (Y was-2.39\u2009\u00b1\u20090.23 in asleep group, \u22121.46\u2009\u00b1\u20090.22 in awake group, p\u2009=\u20090.007). Compared with preoperative OFF MED state, MDS-UPDRS III scores in OFF MED/OFF STIM state remained unchanged, while in OFF MED/ON STIM state were significantly improved in awake and asleep groups, yet without significant difference. Compared with preoperative ON MED state, MDS-UPDRS III scores in ON MED/OFF STIM, and ON MED/ON STIM state remained unchanged in both groups.",
  "Compared with preoperative ON MED state, MDS-UPDRS III scores in ON MED/OFF STIM, and ON MED/ON STIM state remained unchanged in both groups. In non-motor outcomes, PSQI, HAMD, and HAMA score significantly improved in asleep group compared to awake group at 1-year follow-up (PSQI, HAMD, and HAMA score in 1-year follow-up were 9.81\u2009\u00b1\u20094.43; 10.00\u2009\u00b1\u20095.80; 5.71\u2009\u00b1\u20094.75 in awake group, 6.64\u2009\u00b1\u20094.14; 5.32\u2009\u00b1\u20093.78; 3.76\u2009\u00b1\u20093.87 in asleep group, p\u2009=\u20090.009; 0.008; 0.015, respectively), while there was no significant difference in PDQ-39, NMSS, ESS, PDSS score, and cognitive function.",
  "Anesthesia methods was significantly associated with improvement of HAMA and HAMD score (p\u2009=\u20090.029; 0.002, respectively). No difference in LEDD, stimulation parameters and adverse events was observed between two groups. Discussion Asleep STN-DBS may be considered a good alternative method for PD patients. It is largely consistent with awake STN-DBS in motor symptoms and safety. Yet, it showed higher improvement in terms of mood and sleep compared to awake group at 1-year follow-up.",
  "Discussion Asleep STN-DBS may be considered a good alternative method for PD patients. It is largely consistent with awake STN-DBS in motor symptoms and safety. Yet, it showed higher improvement in terms of mood and sleep compared to awake group at 1-year follow-up.\nAuthors: Wanru Chen, Changming Zhang, Nan Jiang, Lulu Jiang, Qiyu Guo, J. Gu, Wen-biao Xian, Yuting Ling, Yanmei Liu, Yifan Zheng, Lei Wu, Chao Yang, Shao-hua Xu, Yu Hu, Yang Yang, Jinhua Chen, Ruoheng Xuan, Yi Liu, Jinlong Liu, Ling Chen\nVenue: Frontiers in Aging Neuroscience\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Asleep STN-DBS may be considered a good alternative method for PD patients because it showed higher improvement in terms of mood and sleep compared to awake group at 1-year follow-up, and anesthesia methods was significantly associated with improvement of HAMA and HAMD score.'}",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: 3a1d327d404790445cd7cabe12b41679e5d5546c\nTitle: Decreased Expression of KLF4 Leading to Functional Deficit in Pediatric Patients with Intestinal Failure and Potential Therapeutic Strategy Using Decanoic Acid\nYear: 2023\nAbstract: Pediatric intestinal failure (IF) is the reduction in gut function to below the minimum necessary for the absorption of macronutrients and/or water and electrolytes, such that intravenous supplementation is required to maintain health and/or growth. The overall goal in treating IF is to achieve intestinal adaptation; however, the underlying mechanisms have not been fully understood. In this study, by performing single-cell RNA sequencing in pediatric IF patients, we found that decreased Kruppel-Like Factor 4 (KLF4) may serve as the hub gene responsible for the functional deficit in mature enterocytes in IF patients, leading to the downregulation of solute carrier (SLC) family transporters (e.g., SLC7A9) and, consequently, nutrient malabsorption.",
  "We also found that inducible KLF4 was highly sensitive to the loss of certain enteral nutrients: in a rodent model of total parenteral nutrition mimicking the deprivation of enteral nutrition, the expression of KLF4 dramatically decreased only at the tip of the villus and not at the bottom of crypts. By using IF patient-derived intestinal organoids and Caco-2 cells as in vitro models, we demonstrated that the supplementation of decanoic acid (DA) could significantly induce the expression of KLF4 along with SLC6A4 and SLC7A9, suggesting that DA may function as a potential therapeutic strategy to promote cell maturation and functional improvement. In summary, this study provides new insights into the mechanism of intestinal adaptation depending on KLF4, and proposed potential strategies for nutritional management using DA.\nAuthors: Jun-Kai Yan, Yuling Zhao, Luyang Jiang, Ying Wang, W. Cai\nVenue: Nutrients\nTldr: {'model': 'tldr@v2.0.0', 'text': 'New insights are provided into the mechanism of intestinal adaptation depending on Kruppel-Like Factor 4, and proposed potential strategies for nutritional management using DA are proposed.'}",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: 3dc80cea6704a2bc1d714e3bbd502846f3498743\nTitle: Carbon Flux with DAMPE Using Machine Learning Methods\nYear: 2023\nAbstract: DAMPE space-borne cosmic ray experiment has been collecting data since December 2015. Many high-impact results on the ion, electron and photon fluxes were obtained. This submission presents the carbon flux analysis with DAMPE using machine learning techniques. The readout electronics would saturate at energy deposits above several TeV in a single BGO bar of the DAMPE calorimeter. The total energy loss per event due to saturation can sometimes reach over a hundred TeV. We present a convolutional neural network model which can accurately recover the energy lost due to saturation and thus significantly increase the dynamic range of DAMPE. Another machine learning model combines the resolution of the hodoscopic BGO calorimeter and the high-resolution tracker of DAMPE to provide the best possible prediction of the direction of the incoming particle. This allows measuring charges at energies up to several hundred TeV. In this work, we present the application of these methods to carbon flux analysis.",
  "This allows measuring charges at energies up to several hundred TeV. In this work, we present the application of these methods to carbon flux analysis.\nAuthors: M. Stolpovskiy, Francesco Alemanno, C. Altomare, Qi An, P. Azzarello, F. Barbato, P. Bernardini, Xiaomei Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Yunqiang Cui, I. De Mitri, Francesco de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, Piergiorgio Fusco, Min Gao, F. Gargano, Essna Ghose,",
  "Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, Piergiorgio Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guangshun Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, Luyang Jiang, Weizhong Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, Tao Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia,",
  "P. Ma, Tao Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, H. Su, Meng Su, H. Sun, Zhiyu Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Yuanzhu Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zizhong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan,",
  "Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zizhong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hong-yun Zhao, Xu Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A convolutional neural network model is presented which can accurately recover the energy lost due to saturation and thus significantly increase the dynamic range of DAMPE.'}",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: 4f3a048d1e1873175a16a83179f8fd8938ba45c3\nTitle: Lactobacillus johnsonii Attenuates Liver Steatosis and Bile Acid Dysregulation in Parenteral Nutrition-Fed Rats\nYear: 2023\nAbstract: Parenteral nutrition (PN), a vital therapy for patients with intestinal failure, can lead to the development of parenteral nutrition-associated liver disease (PNALD). In this study, we aimed to investigate the role of Lactobacillus johnsonii (L. johnsonii) in a rat model of PNALD. Total parenteral nutrition (TPN)-fed rats were used to assess the role of L. johnsonii in liver steatosis, bile acid metabolism, gut microbiota, and hepatocyte apoptosis. We observed a depletion of L. johnsonii that was negatively correlated with the accumulation of glycochenodeoxycholic acid (GCDCA), a known apoptosis inducer, in rats subjected to TPN.",
  "We observed a depletion of L. johnsonii that was negatively correlated with the accumulation of glycochenodeoxycholic acid (GCDCA), a known apoptosis inducer, in rats subjected to TPN. L. johnsonii attenuated TPN-induced liver steatosis by inhibiting fatty acid synthesis and promoting fatty acid oxidation. TPN resulted in a decrease in bile acid synthesis and biliary bile secretion, which were partially restored by L. johnsonii treatment. The gut microbial profile revealed depletion of pathogenic bacteria in L. johnsonii-treated rats. L. johnsonii treatment reduced both hepatic GCDCA levels and hepatocyte apoptosis compared with the TPN group. In vitro, L. johnsonii treatment inhibited GCDCA-induced hepatocyte apoptosis via its bile salt hydrolase (BSH) activity. Our findings suggest that L. johnsonii protects against liver steatosis, bile acid dysregulation, and hepatocyte apoptosis in TPN-fed rats.",
  "In vitro, L. johnsonii treatment inhibited GCDCA-induced hepatocyte apoptosis via its bile salt hydrolase (BSH) activity. Our findings suggest that L. johnsonii protects against liver steatosis, bile acid dysregulation, and hepatocyte apoptosis in TPN-fed rats.\nAuthors: Juan Xu, Yongchang Zhou, Siyang Cheng, Yuling Zhao, Jun-Kai Yan, Ying Wang, Wei Cai, Luyang Jiang\nVenue: Metabolites\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The findings suggest that Lactobacillus johnsonii protects against liver steatosis, bile acid dysregulation, and hepatocyte apoptosis in TPN-fed rats.'}",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: 53a8712c48ddcd2bf1af30f9235f42b372f66980\nTitle: The response linearity of energy measurement up to TeV in the DAMPE experiment\nYear: 2023\nAbstract: The DArk Matter Particle Explorer (DAMPE) space mission is designed to measure cosmic rays and gamma rays. The key sub-detector of DAMPE is the Bismuth Germanium Oxide (BGO) Electromagnetic CALorimeter (ECAL), which measures the energies of electrons/gamma-rays ranging from 5 GeV - 10 TeV. A laser test carried out to study the response of the BGO ECAL to up to \u223c TeV energy deposition revealed that the BGO \ufb02uorescence response retains linearity at laser energy deposition densities higher than that induced by a \u223c 10 TeV electromagnetic shower. The energy measurements obtained from on-orbit data were also compared with Monte Carlo simulation results. The present study con\ufb01rms that there is no \ufb02uorescence quenching e\ufb00ect in the DAMPE BGO ECAL.",
  "The energy measurements obtained from on-orbit data were also compared with Monte Carlo simulation results. The present study con\ufb01rms that there is no \ufb02uorescence quenching e\ufb00ect in the DAMPE BGO ECAL.\nAuthors: Cong-Ying Zhao, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, Francesco de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, J. Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco,",
  "G. Donvito, D. Droz, J. Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, L. Jiang, Weizhong Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X.",
  "F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, H. Su, Meng Su, H. Sun, Zhigang Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zizhong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang,",
  "Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zizhong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Hongying Zhao, Xu Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: None",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: 55707013ab7912450a4632d13e8b919a58cb1077\nTitle: Auditing Gender Presentation Differences in Text-to-Image Models\nYear: 2023\nAbstract: Text-to-image models, which can generate high-quality images based on textual input, have recently enabled various content-creation tools. Despite significantly affecting a wide range of downstream applications, the distributions of these generated images are still not fully understood, especially when it comes to the potential stereotypical attributes of different genders. In this work, we propose a paradigm (Gender Presentation Differences) that utilizes fine-grained self-presentation attributes to study how gender is presented differently in text-to-image models. By probing gender indicators in the input text (e.g.,\"a woman\"or\"a man\"), we quantify the frequency differences of presentation-centric attributes (e.g.,\"a shirt\"and\"a dress\") through human annotation and introduce a novel metric: GEP. Furthermore, we propose an automatic method to estimate such differences.",
  "Furthermore, we propose an automatic method to estimate such differences. The automatic GEP metric based on our approach yields a higher correlation with human annotations than that based on existing CLIP scores, consistently across three state-of-the-art text-to-image models. Finally, we demonstrate the generalization ability of our metrics in the context of gender stereotypes related to occupations.\nAuthors: Yanzhe Zhang, Lucy Jiang, Greg Turk, Diyi Yang\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes a paradigm that utilizes fine-grained self-presentation attributes to study how gender is presented differently in text-to-image models and introduces a novel metric: GEP, which yields a higher correlation with human annotations than that based on existing CLIP scores.'}",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: 60bbc8ae6f5065419fe7d10e2b5e33415c97cdea\nTitle: Updates on immunological mechanistic insights and targeting of the oral lichen planus microenvironment\nYear: 2023\nAbstract: Oral lichen planus (OLP) is a chronic immune inflammatory disease that is an oral potentially malignant disorder (OPMD), occurs in the oral mucosa and affects approximately 0.5% to 4% of the general population. There are usually five types of OLP: reticular/papular, plaque-like, atrophic/erythematous, erosive/ulcerative, and bullous. Furthermore, the chance of causing oral squamous cell carcinoma (OSCC) is 1.4%. Although the etiology of OLP is still unknown, accumulating evidence supports that immune dysregulation may play a vital role in the pathogenesis of OLP, especially the massive production of various inflammatory cells and inflammatory mediators. In this review, we focus on the relationship between OLP and its immune microenvironment.",
  "In this review, we focus on the relationship between OLP and its immune microenvironment. We summarize current developments in the immunology of OLP, summarizing functional cell types and crucial cytokines in the OLP immune microenvironment and the underlying mechanisms of key signaling pathways in the OLP immune microenvironment. We highlight the application potential of targeted immune microenvironment therapy for OLP.\nAuthors: Xiaoting Deng, Ying Wang, Lu Jiang, Jing Li, Qianming Chen\nVenue: Frontiers in Immunology\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This review highlights the application potential of targeted immune microenvironment therapy for OLP and summarizes current developments in the immunology of OLP, summarizing functional cell types and crucial cytokines in the OLP immune micro environment and the underlying mechanisms of key signaling pathways in the NLP immunemicroenvironment.'}",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: 62f10f1942dc147b3ecc5d87bc40fa5ff6c2a33a\nTitle: HCC prediction models in chronic hepatitis B patients receiving entecavir or tenofovir: a systematic review and meta-analysis\nYear: 2023\nAbstract: None\nAuthors: Xiaolan Xu, Lushun Jiang, Yifan Zeng, Li-ya Pan, Zhuo-qi Lou, B. Ruan\nVenue: Virology Journal\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Considering the predictive performance of all four aspects, it is suggested that HCC-RESCUE was the best model to utilize in clinical practice, especially in primary care and low-income areas.'}",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: 68be46aa655f9f4aec8ed957758750808a97461b\nTitle: Changing incidence of hepatitis B and persistent infection risk in adults: a population-based follow-up study from 2011 in China\nYear: 2023\nAbstract: None\nAuthors: Xiaolan Xu, Chensi Wu, Zhuo-qi Lou, Chun-ting Peng, Lushun Jiang, Tianxian Wu, Taiwen Zeng, Yin Dong, B. Ruan\nVenue: BMC Public Health\nTldr: {'model': 'tldr@v2.0.0', 'text': 'HBV incidence in adult rural residents in China was decreasing and stayed low and protective antibodies were induced in only one third of cases, while seroconversion had no concern with gender or age.'}",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: 6f84a90299847f661a0b6a1fa8e71425b304b945\nTitle: Qualitative study of the association between psychosocial health and physical activity/sleep quality in toddlers\nYear: 2023\nAbstract: None\nAuthors: Chisa Tsuyuki, Koya Suzuki, Kanako Seo, Dandan Ke, Kyoko Tsuge, Pengyu Deng, Dajiang Lu, Hisashi Naito\nVenue: Scientific Reports\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A retrospective cohort study in 3-year-old children in Shanghai, China indicated that current physical activity had a direct and moderate impact on current psychosocial health evaluated using the Strength and Difficulties Questionnaire, and past sleep quality had slight impact on current psychosocial health.'}",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: 7098188e3b9d8cf8dcd4a3a009693baa1196fc0e\nTitle: Combining Spatiotemporally Global and Local Interpolations Improves Modeling of Annual Land Surface Temperature Cycles\nYear: 2023\nAbstract: Annual temperature cycle (ATC) models are widely used to characterize temporally continuous land surface temperature (LST) dynamics within an annual cycle. However, the existing ATC models ignore the spatiotemporally local correlations among adjacent LST pixels and are inadequate for capturing the complex relationships between LSTs and LST-related descriptors. To address these issues, we propose an improved ATC model (termed the ATC_GL), which combines both the spatiotemporally global and local interpolations. Using the random forest (RF) algorithm, the ATC_GL model quantifies the complex relationships between LSTs and LST-related descriptors such as the surface air temperature, normalized difference vegetation index, and digital elevation model. The performances of the ATC_GL and several extensively used LST reconstruction methods were compared under both clear-sky and overcast conditions.",
  "The performances of the ATC_GL and several extensively used LST reconstruction methods were compared under both clear-sky and overcast conditions. In the scenario with randomly missing LSTs, the accuracy of the ATC_GL was 2.3 K and 3.1 K higher than that of the ATCE (the enhanced ATC model) and the ATCO (the original ATC model), respectively. In the scenario with LST gaps of various sizes, the ATC_GL maintained the highest accuracy and was less sensitive to gap size when compared with the ATCH (the hybrid ATC model), Kriging interpolation, RSDAST (Remotely Sensed Daily Land Surface Temperature), and HIT (Hybrid Interpolation Technique). In the scenario of overcast conditions, the accuracy of the ATC_GL was 1.0 K higher than that of other LST reconstruction methods. The ATC_GL enriches the ATC model family and provides enhanced performance for generating spatiotemporally seamless LST products with high accuracy.",
  "In the scenario of overcast conditions, the accuracy of the ATC_GL was 1.0 K higher than that of other LST reconstruction methods. The ATC_GL enriches the ATC model family and provides enhanced performance for generating spatiotemporally seamless LST products with high accuracy.\nAuthors: Yangyi Chen, W. Zhan, Zihan Liu, Pan Dong, Hu Fu, Shiqi Miao, Yingying Ji, Lu-lu Jiang, Sida Jiang\nVenue: Land\nTldr: None",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: 719cff0d9a4cfcafb7507b7f301838655f3f3dbf\nTitle: Direct measurement of Ne-Mg-Si nuclei in cosmic rays with DAMPE\nYear: 2023\nAbstract: A precise measurement of the cosmic-ray spectra provides important information on their origin, acceleration and propagation processes in the Galaxy. The Dark Matter Particle Explorer (DAMPE) is a satellite-based cosmic-ray experiment that has been operational for more than 7 years. Since its launch in December 2015, it is continuously collecting data on high-energy cosmic particles with very good statistics and particle identification capabilities, thanks to a large geometric factor and a good charge resolution. In this contribution, the direct measurement of the intermediate mass cosmic rays is presented, in particular the observation of the cosmic-ray Ne, Mg and Si nuclei, which are thought to be mainly produced and accelerated in astrophysical sources.\nAuthors: E. Casilli, Francesco Alemanno, Q. An, P. Azzarello, F. Barbato, X. Bi, I. Cagnoli, M. Cai, E. Catanzani, Jin Chang,",
  "Authors: E. Casilli, Francesco Alemanno, Q. An, P. Azzarello, F. Barbato, X. Bi, I. Cagnoli, M. Cai, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, J. Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, C. Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco, M. Gao, F. Gargano, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, L. Jiang, Wei Jiang, Y. Jiang, J. Kong, A. Kotenko,",
  "Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, L. Jiang, Wei Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, Hong-mei Su, Meng Su, H. Sun, Zhigang Sun,",
  "J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, Hong-mei Su, Meng Su, H. Sun, Zhigang Sun, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hongying Zhao, Xu Zhao, C. Zhou,",
  "C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hongying Zhao, Xu Zhao, C. Zhou, Yanzi Zhu, C. Altomare, P. Bernardini, F. de Palma, Essna Ghose, A. Surdo\nVenue: International Conference on Rebooting Computing\nTldr: None",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: 747c188af4df6c33421078ddfa450b648a9cbfc6\nTitle: Probing hadronic cross sections in the TeV - PeV regime with DAMPE through machine learning techniques\nYear: 2023\nAbstract: Thanks to its large calorimeter\nAuthors: P. Coppin, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, F. de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng,",
  "M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, Luyang Jiang, Wei Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, Tao Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu,",
  "Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, Tao Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, H. Su, Meng Su, H. Sun, Zhigang Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yinong Wei, Di Wu, Jian Wu, Li Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zijun Xu, Zunlei Xu,",
  "Ying Wang, Y. Wang, D. Wei, J. Wei, Yinong Wei, Di Wu, Jian Wu, Li Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zijun Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hong-yun Zhao, Xu Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: {'model': 'tldr@v2.0.0', 'text': None}",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: 815ba42bacfe231664de6c4ab1f46b6c54bd1950\nTitle: DArk Matter Particle Explorer: 7 years in Space\nYear: 2023\nAbstract: The DArk Matter Particle Explorer (DAMPE) is a pioneering calorimetric experiment that has been successfully operating in space since December 2015, designed to detect cosmic rays up to unprecedentedly high energies thanks to the fine-grained thick BGO calorimeter and relatively large geometric factor. Among the scientific goals of DAMPE are the precise measurements of cosmic-ray electron plus positron spectrum, including the detection of possible indirect dark matter signatures, spectral measurements of primary and secondary cosmic-ray species, and gamma-ray physics. For electrons and gamma rays, it covers an energy range from GeV to about 10 TeV, with an outstanding energy resolution close to 1%. Proton and ion cosmic rays can be measured up to hundreds of TeV in kinetic energy. In this contribution, we first give an overview of the DAMPE mission and its on-orbit operation status.",
  "Proton and ion cosmic rays can be measured up to hundreds of TeV in kinetic energy. In this contribution, we first give an overview of the DAMPE mission and its on-orbit operation status. Then, we highlight the key scientific results, including the measurements of the BCNO group, boron-to-carbon ratio, proton plus helium spectrum beyond 100 TeV, gamma-ray physics and more. Finally, the ongoing efforts for lepton, light, and heavy hadron cosmic rays are briefly discussed along with the new data analysis techniques.\nAuthors: A. Tykhonov, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, Paolo Bernardini, Xiao-Jun Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Zi-Yuan Chen, P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, Francesco de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G.",
  "Zi-Yuan Chen, P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, Francesco de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, Piergiorgio Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, L. Jiang, Wei Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, Wei Liang Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F.",
  "Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, Wei Liang Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, Pengxiong Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, Xiaozhong Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Shangguan Zhi, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, Hong-mei Su, Meng Su, Hao-Lun Sun, Zhigang Sun, A. Surdo, X. Teng, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei,",
  "Hong-mei Su, Meng Su, Hao-Lun Sun, Zhigang Sun, A. Surdo, X. Teng, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zizhong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Ya Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hongying Zhao, Xu Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: None",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: 82c5b6d1191c273186094663a772bc93744cc559\nTitle: \u201cEasier or Harder, Depending on Who the Hearing Person Is\u201d: Codesigning Videoconferencing Tools for Small Groups with Mixed Hearing Status\nYear: 2023\nAbstract: With improvements in automated speech recognition and increased use of videoconferencing, real-time captioning has changed significantly. This shift toward broadly available but less accurate captioning invites exploration of the role hearing conversation partners play in shaping the accessibility of a conversation to d/Deaf and hard of hearing (DHH) captioning users. While recent work has explored DHH individuals\u2019 videoconferencing experiences with captioning, we focus on established groups\u2019 current practices and priorities for future tools to support more accessible online conversations. Our study consists of three codesign sessions, conducted with four groups (17 participants total, 10 DHH, 7 hearing). We found that established groups crafted social accessibility norms that met their relational contexts.",
  "Our study consists of three codesign sessions, conducted with four groups (17 participants total, 10 DHH, 7 hearing). We found that established groups crafted social accessibility norms that met their relational contexts. We also identify promising directions for future captioning design, including the need to standardize speaker identification and customization, opportunities to provide behavioral feedback during a conversation, and ways that videoconferencing platforms could enable groups to set and share norms.\nAuthors: Emma J. McDonnell, Soo Hyun Moon, Lucy Jiang, Steven M. Goodman, R. Kushalnagar, Jon E. Froehlich, Leah Findlater\nVenue: International Conference on Human Factors in Computing Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is found that established groups crafted social accessibility norms that met their relational contexts, and promising directions for future captioning design are identified, including the need to standardize speaker identification and customization, opportunities to provide behavioral feedback during a conversation, and ways that videoconferencing platforms could enable groups to set and share norms.'}",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: 908715ff810a15335968469d84dd3637c63edaf4\nTitle: How to drive corporate responsible innovation? A dual perspective from internal and external drivers of environmental protection enterprises\nYear: 2023\nAbstract: Responsible innovation has been widely concerned by the public sector and actively explored by scholars for its great role in supporting eco-innovation and sustainable development. However, as the main body of innovation, enterprises have not been fully recognized. Moreover, the research on the driving factors of responsible innovation is mostly the direct influence of a single factor, lacking the overall consideration of the internal and external environment. To bridge this research gap, this study, by deeply interviewing 13 entrepreneurs in environmental protection enterprises, clarified the concept of corporate responsible innovation and its four-dimensional framework (inclusion, anticipation, reflexivity, responsiveness), and then proposed the MPN-MSE driving factor model of corporate responsible innovation from the internal and external perspectives. The external factors include market pressure (M), policy pressure (P), and normative pressure (N), while the internal factors include responsible innovation motivation (M), responsible innovation system (S), and responsible innovation elements (E).",
  "The external factors include market pressure (M), policy pressure (P), and normative pressure (N), while the internal factors include responsible innovation motivation (M), responsible innovation system (S), and responsible innovation elements (E). The research findings provide an important theoretical contribution to the research of corporate responsible innovation.\nAuthors: Yi Li, Lu-jie Jiang, Peilin Yang\nVenue: Frontiers in Environmental Science\nTldr: None",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: 95221bcfb9dd0fb5aba2a0a76f25d66c9fd6e1ba\nTitle: Global mapping of urban thermal anisotropy reveals substantial potential biases for remotely sensed urban climates.\nYear: 2023\nAbstract: None\nAuthors: Huilin Du, W. Zhan, Zihan Liu, E. Scott Krayenhoff, T. Chakraborty, Lei Zhao, Lu-lu Jiang, Pan Dong, Long Li, F. Huang, Shasha Wang, Yuyue Xu\nVenue: Science Bulletin\nTldr: None",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: 96d6fc4281e739c0e5bc1ea4b7b14ea1ab3bce52\nTitle: Measurement of Heavy Nulei beyond Iron in Cosmic Rays with the DAMPE Experiment\nYear: 2023\nAbstract: None\nAuthors: Haoran Sun, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, F. de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng,",
  "M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, Luyang Jiang, Wei Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu,",
  "Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, H. Su, Meng Su, H. Sun, Zhigang Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yifeng Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zizhong Xu,",
  "Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yifeng Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zizhong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hongying Zhao, Xu Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: None",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: 9b385b5efd3508be0d7176d958887fee3e45efd7\nTitle: Effects of STN\u2010DBS surgery on cerebral glucose metabolism and distribution of DAT in Parkinson's disease\nYear: 2023\nAbstract: : Parkinson's disease (PD) is a neurodegenerative disorder that affects millions of people worldwide. Subthalamic nucleus (STN) deep brain stimulation (DBS) has been shown to be an effective treatment for PD; however, the effects of this surgery on cerebral metabolism and presynaptic dopamine transporter (DAT) distribution are still being studied.",
  "Subthalamic nucleus (STN) deep brain stimulation (DBS) has been shown to be an effective treatment for PD; however, the effects of this surgery on cerebral metabolism and presynaptic dopamine transporter (DAT) distribution are still being studied.\nAuthors: Gan-hua Luo, Xinchong Shi, Lulu Jiang, Lei Wu, C. Yi, Wen-biao Xian, Yanmei Liu, Fuhua Wen, H. Qian, Jie Chen, Xiaoli Fu, Jinlong Liu, Xiangsong Zhang, Ling Chen\nVenue: Brain and Behavior\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Subthalamic nucleus (STN) deep brain stimulation (DBS) has been shown to be an effective treatment for PD; however, the effects of this surgery on cerebral metabolism and presynaptic dopamine transporter (DAT) distribution are still being studied.'}",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: 9c4af5ff92dcf12b55845d8812175a8107f04b29\nTitle: Research on integrated coastal zone management from past to the future: a bibliometric analysis\nYear: 2023\nAbstract: Integrated coastal zone management (ICZM) has been regarded as an effective tool for achieving sustainable development of coastal ecosystems and reducing potential human health risks, but questions remain regarding its research status and future directions. Therefore, a bibliometric analysis was conducted using screened 6151 publications collected from Web of Science Core Collection databases. An exponential increase trend of publications revealed the continuous and strong research interests for ICZM worldwide. The most high-yield country, institution, category, and journal were USA, NOAA, Environmental Sciences, and Ocean & Coastal Management, respectively. Regarding the number of publications, academic influence, and international collaboration, the developed countries occupied the predominant positions. Co-word analysis reveals eight important topics: challenge, service, management and planning, method and technology, development, process, area, and system.",
  "Regarding the number of publications, academic influence, and international collaboration, the developed countries occupied the predominant positions. Co-word analysis reveals eight important topics: challenge, service, management and planning, method and technology, development, process, area, and system. Relevant future directions of the ICZM field were proposed based on the Sustainable Development Goals of the United Nations. This review addresses the question of what focal topics in the ICZM field and what should be focused on in future works by objective and quantitative methods. Our results provide valuable insights into the evolution of the ICZM field and the sustainable development of the coastal areas.\nAuthors: Luqing Jiang, Tang Yang, Xuyi Wang, Jing Yu, Jia Liu, Kuncheng Zhang\nVenue: Frontiers in Marine Science\nTldr: None",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: a5bf216fc2dfc7f9e1d3fe6b8b06986758b60577\nTitle: A PCA-based Method for Electron-Proton Discrimination of the DAMPE Experiment\nYear: 2023\nAbstract: None\nAuthors: M. Cui, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, Francesco de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M.",
  "Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, L. Jiang, Weizhong Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu,",
  "Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, H. Su, Meng Su, H. Sun, Zhigang Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Yuanzhu Wang, D. Wei, J. Wei, Yifeng Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu,",
  "Wang, Ying Wang, Yuanzhu Wang, D. Wei, J. Wei, Yifeng Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hongying Zhao, Xun Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: None",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: a71dca7b72a8fb8f1f337721a2a0042faf9bd70b\nTitle: Cosmic Ray Carbon and Oxygen Flux Measurements with the DAMPE Experiment\nYear: 2023\nAbstract: The DArk Matter Particle Explorer (DAMPE), a space-based high-energy particle detector\nAuthors: Yifeng Wei, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, Francesco de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, J. Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang,",
  "Francesco de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, J. Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, Luyang Jiang, Wei Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N.",
  "X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, H. Su, Meng Su, H. Sun, Zhigang Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu,",
  "L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zizhong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hongying Zhao, Xu Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: None",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: abd11a40c2b51a3af211302141db7f4a94d71497\nTitle: Measurements of the boron-to-carbon and boron-to-oxygen flux ratios in cosmic rays with DAMPE\nYear: 2023\nAbstract: Boron nuclei in cosmic rays (CRs) are believed to be mainly produced by the fragmentation of heavier nuclei, such as carbon and oxygen, via collisions with the interstellar matter. Therefore, the boron-to-carbon \ufb02ux ratio (B/C) and the boron-to-oxygen \ufb02ux ratio (B/O) are very essential probes of the CR propagation. With a large geometric factor and a good charge resolution, the DArk Matter Particle Explorer (DAMPE)\nAuthors: C. Yue, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z.",
  "An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, Francesco de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, Piergiorgio Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, L. Jiang, Wei Jiang, Y. Jiang, J.",
  "Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, L. Jiang, Wei Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, Wei Liang Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, Pengxiong Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Shangguan Zhi, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, H. Su, Meng Su, H.",
  "Rui Qiao, J. Rao, A. Ruina, Shangguan Zhi, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, H. Su, Meng Su, H. Sun, Zhigang Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Yuanzhu Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zizhong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Ya Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hong-yun Zhao,",
  "G. Yuan, Qiang Yuan, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Ya Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hong-yun Zhao, Xu Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: None",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: b4d94a380f2f7ba93013effe556705d96932a6c4\nTitle: CD8+ tissue-resident memory T cells induce oral lichen planus erosion via cytokine network\nYear: 2023\nAbstract: CD8+ tissue-resident memory T (CD8+ Trm) cells play key roles in many immune-inflammation-related diseases. However, their characteristics in the pathological process of oral lichen planus (OLP) remains unclear. Therefore, we investigated the function of CD8+ Trm cells in the process of OLP. By using single-cell RNA sequencing profiling and spatial transcriptomics, we revealed that CD8+ Trm cells were predominantly located in the lamina propria adjacent to the basement membrane and were significantly increased in patients with erosive oral lichen planus (EOLP) compared to those with non-erosive oral lichen planus (NEOLP).",
  "Furthermore, these cells displayed enhanced cytokine production, including IFN-\u03b3 (Interferon-gamma, a pro-inflammatory signaling molecule), TNF-\u03b1 (Tumor Necrosis Factor-alpha, a cytokine regulating inflammation), and IL-17 (Interleukin-17, a cytokine involved in immune response modulation), in patients with EOLP. And our clinical cohort of 1-year follow-up was also supported the above results in RNA level and protein level. In conclusion, our study provided a novel molecular mechanism for triggering OLP erosion by CD8+ Trm cells to secrete multiple cytokines, and new insight into the pathological development of OLP.\nAuthors: M. Qing, Dan Yang, Q. Shang, J. Peng, Jia-Qi Deng, Lu Jiang, Jing Li, H. Dan, Yu Zhou, Hao Xu, Qianming Chen\nVenue: eLife\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A novel molecular mechanism for triggering OLP erosion by CD8+ Trm cells to secrete multiple cytokines is provided, and new insight is provided into the pathological development of OLP.'}",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: b6d7b3022b1aeab290f1941e9a2a05fdb4cb96f3\nTitle: Efficient conversion of biomass waste to N/O co-doped hierarchical porous carbon for high performance supercapacitors\nYear: 2023\nAbstract: None\nAuthors: Huan Liu, Xiuli Huang, Menglei Zhou, Jian-Sen Gu, Maodong Xu, Luran Jiang, Maoqing Zheng, Shi-han Li, Z. Miao\nVenue: Journal of Analytical and Applied Pyrolysis\nTldr: None",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: bc2587ae1df64c64ce9a7614373e5a1d49051265\nTitle: Median mandibular flexure\u2014the unique physiological phenomenon of the mandible and its clinical significance in implant restoration\nYear: 2023\nAbstract: Mandibular flexure, characterized by unique biomechanical behaviors such as elastic bending and torsion under functional loading, has emerged as a crucial factor in oral clinical diagnosis and treatment. This paper presents a comprehensive review of the current research status on mandibular flexure, drawing insights from relevant studies retrieved from the PubMed database (www.ncbi.nlm.nih.gov/pubmed), including research conclusions, literature reviews, case reports, and authoritative reference books. This paper thoroughly explores the physiological mechanisms underlying mandibular flexure, discussing different concurrent deformation types and the essential factors influencing this process. Moreover, it explores the profound implications of mandibular flexure on clinical aspects such as bone absorption around dental implants, the precision of prosthesis fabrication, and the selection and design of superstructure materials. Based on the empirical findings, this review provides crucial clinical recommendations.",
  "Moreover, it explores the profound implications of mandibular flexure on clinical aspects such as bone absorption around dental implants, the precision of prosthesis fabrication, and the selection and design of superstructure materials. Based on the empirical findings, this review provides crucial clinical recommendations. Specifically, it is recommended to exert precise control over the patients mouth opening during impression-taking. Those with a high elastic modulus or bone-tissue-like properties should be prioritized when selecting superstructure materials. Moreover, this review underscores the significance of customizing framework design to accommodate individual variations in facial morphology and occlusal habits. Future research endeavors in this field have the potential to advance clinical diagnosis and treatment approaches, providing opportunities for improvement.\nAuthors: Jing Gao, Lu-lu Jiang, Baohong Zhao\nVenue: Frontiers in Bioengineering and Biotechnology\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A comprehensive review of the current research status on mandibular flexure is presented, drawing insights from relevant studies retrieved from the PubMed database, including research conclusions, literature reviews, case reports, and authoritative reference books.'}",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: c6d4e3a005e42b466abbe3739e0275a6f7cd72ff\nTitle: GRB 200829A: External-shock Origin of the Very Early Prompt Emission?\nYear: 2023\nAbstract: Long-duration GRB 200829A was detected by Fermi-GBM and Swift-BAT/XRT, and then rapidly observed by other ground-based telescopes. It has a weak \u03b3-ray emission in the very early phase and is followed by a bright spiky \u03b3-ray emission pulse. The radiation spectrum of the very early emission is best fitted by a power-law function with index \u223c\u22121.7. However, the bright spiky \u03b3-ray pulse, especially the time around the peak, exhibits a distinct two-component radiation spectrum, i.e., Band function combined with a blackbody radiation spectrum. We infer the photospheric properties and reveal a medium magnetization at a photospheric position by adopting the initial size of the outflow as r 0 = 109 cm. It implies that the Band component in this pulse may be formed during the dissipation of the magnetic field.",
  "We infer the photospheric properties and reveal a medium magnetization at a photospheric position by adopting the initial size of the outflow as r 0 = 109 cm. It implies that the Band component in this pulse may be formed during the dissipation of the magnetic field. The power-law radiation spectra found in the very early prompt emission may imply the external-shock origination of this phase. Then, we perform the Markov Chain Monte Carlo method fitting on the light curves of this burst, where the jet corresponding to the \u03b3-ray pulse at around 20 s is used to refresh the external shock. It is shown that the light curves of the very early phase and X-ray afterglow after 40 s, involving the X-ray bump at around 100 s, can be well modeled in the external-shock scenario. For the obtained initial outflow, we estimate the minimum magnetization factor of the jet based on the fact that the photospheric emission of this jet is missed in the very early phase.",
  "For the obtained initial outflow, we estimate the minimum magnetization factor of the jet based on the fact that the photospheric emission of this jet is missed in the very early phase.\nAuthors: Jing Li, D. Lin, R. Lu, Luyao Jiang, Wenqing Liang, Zhi-Lin Chen, Xiao-Yan Li, Xiang-Gao Wang, E. Liang\nVenue: Astrophysical Journal\nTldr: None",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: cc48851430aca07e19f7f48c1733b009ea654bdf\nTitle: Measurement of the p+He energy spectrum with the DAMPE space mission\nYear: 2023\nAbstract: None\nAuthors: Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, F. de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden,",
  "Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco, M. Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, Luyao Jiang, Wei Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W.",
  "Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, H. Su, Meng Su, H. Sun, Zhigang Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu, Zunlei Xu, G. Xue,",
  "D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hongying Zhao, Xu Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: None",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: cd76c60e754330964796ec980528b00ad38346a5\nTitle: Study of hadronic cross-sections with cosmic ray Carbon from GeV to TeV by the DAMPE experiment\nYear: 2023\nAbstract: None\nAuthors: E. Xu, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Y. Cui, I. De Mitri, F. de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, J. Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M.",
  "Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, J. Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, Luyang Jiang, Wei Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu,",
  "Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, Hong-mei Su, Meng Su, H. Sun, Zhigang Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yifeng Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu,",
  "Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yifeng Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hongying Zhao, Xu Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: None",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: d1c1061841cf16e8739a582308ea17ae0e8465cf\nTitle: Latest results on searching for fractionally charged particles with the DAMPE experiment\nYear: 2023\nAbstract: The existence of fractionally charged particles (FCP) is foreseen in extensions of or beyond the Standard Model of particle physics. Most of the previously conducted searches for FCPs in cosmic rays were based on experiments underground or at high altitudes. However, there have been few searches for FCPs in cosmic rays carried out in orbit other than AMS-01 flown by a space shuttle and BESS by a balloon at the top of the atmosphere. In this study, we conduct an FCP search in space based on on-orbit data obtained using the Dark Matter Particle Explorer (DAMPE) satellite over a period of five years. Unlike underground experiments, which require an FCP energy of the order of hundreds of GeV, our FCP search starts at only a few GeV. An upper limit of 6 .",
  "Unlike underground experiments, which require an FCP energy of the order of hundreds of GeV, our FCP search starts at only a few GeV. An upper limit of 6 . 2 \u00d7 10 \u2212 10 cm \u2212 2 sr \u2212 1 s \u2212 1 is obtained for the flux. Our results demonstrate that DAMPE exhibits higher sensitivity than experiments of similar types by three orders of magnitude that more stringently restricts the conditions for the existence of FCP in primary cosmic rays.\nAuthors: Chengming Liu, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Zhan-Fang Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, Francesco de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz,",
  "P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, I. De Mitri, Francesco de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, Luyang Jiang, Wei Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo,",
  "Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, Pengxiong Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, A. Parenti, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, M. Stolpovskiy, H. Su, Meng Su, H. Sun, Zhigang Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yining Wei, Di Wu,",
  "Zhigang Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, L. Wu, Sha Wu, Xin Wu, Z. Xia, E. Xu, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hong-yun Zhao, Xu Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: None",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: e036b4fe0f3ca758a2e04570a6bf42a75bd7fd3c\nTitle: PGAM1 Inhibition Promotes HCC Ferroptosis and Synergizes with Anti\u2010PD\u20101 Immunotherapy\nYear: 2023\nAbstract: The combination of immunotherapy and molecular targeted therapy exhibits promising therapeutic efficacy in hepatocellular carcinoma (HCC), but the underlying mechanism is still unclear. Here, phosphoglycerate mutase 1 (PGAM1) is identified as a novel immunometabolic target by using a bioinformatic algorithm based on multiple HCC datasets. PGAM1 is highly expressed in HCC and associated with a poor prognosis and a poor response to immunotherapy. In vitro and in vivo experiments indicate that targeting PGAM1 inhibited HCC cell growth and promoted the infiltration of CD8+ T\u2010cells due to decreased enzymatic activity.",
  "PGAM1 is highly expressed in HCC and associated with a poor prognosis and a poor response to immunotherapy. In vitro and in vivo experiments indicate that targeting PGAM1 inhibited HCC cell growth and promoted the infiltration of CD8+ T\u2010cells due to decreased enzymatic activity. Mechanistically, inhibition of PGAM1 promotes HCC cell ferroptosis by downregulating Lipocalin (LCN2) by inducing energy stress and ROS\u2010dependent AKT inhibition, which can also downregulate Programmed death 1\u2010ligand 1 (PD\u2010L1). Moreover, an allosteric PGAM1 inhibitor (KH3) exhibits good antitumor effects in patient\u2010derived xenograft (PDX) models and enhanced the efficacy of anti\u2010PD\u20101 immunotherapy in subcutaneous and orthotopic HCC models. Taken together, the findings demonstrate that PGAM1 inhibition exerts an antitumor effect by promoting ferroptosis and CD8+ T\u2010cell infiltration and can synergize with anti\u2010PD\u20101 immunotherapy in HCC. Targeting PGAM1 can be a promising new strategy of \u201ckilling two birds with one stone\u201d for HCC treatment.",
  "Targeting PGAM1 can be a promising new strategy of \u201ckilling two birds with one stone\u201d for HCC treatment.\nAuthors: Yi-min Zheng, Yining Wang, Zhou Lu, Jinkai Wan, Lu-lu Jiang, Danjun Song, Chuan-Yuan Wei, Chao Gao, G. Shi, Jian Zhou, Jia Fan, A. Ke, Lu Zhou, Jia-Bing Cai\nVenue: Advancement of science\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is demonstrated that PGAM1 inhibition exerts an antitumor effect by promoting ferroptosis and CD8+ T\u2010cell infiltration and can synergize with anti\u2010PD\u20101 immunotherapy in HCC.'}",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: e28b314bed6b71eb8f112b866ac77dbcb182bf0b\nTitle: BAC Transgenic Expression of Human TREM2-R47H Remodels Amyloid Plaques but Unable to Reprogram Plaque-associated Microglial Reactivity in 5xFAD Mice\nYear: 2023\nAbstract: Background Genetic study of late-onset Alzheimer\u2019s disease (AD) reveals that a rare Arginine-to-Histamine mutation at amino acid residue 47 (R47H) in Triggering Receptor Expressed on Myeloid Cells 2 (TREM2) results in increased disease risk. TREM2 plays critical roles in regulating microglial response to amyloid plaques in AD, leading to their clustering and activation surrounding the plaques. We previously showed that increasing human TREM2 gene dosage exerts neuroprotective effects against AD-related deficits in amyloid depositing mouse models of AD. However, the in vivo effects of the R47H mutation on human TREM2-mediated microglial reprogramming and neuroprotection remains poorly understood.",
  "We previously showed that increasing human TREM2 gene dosage exerts neuroprotective effects against AD-related deficits in amyloid depositing mouse models of AD. However, the in vivo effects of the R47H mutation on human TREM2-mediated microglial reprogramming and neuroprotection remains poorly understood. Method Here we created a BAC transgenic mouse model expressing human TREM2 with the R47H mutation in its cognate genomic context (BAC-TREM2-R47H). Importantly, the BAC used in this study was engineered to delete critical exons of other TREM-like genes on the BAC to prevent confounding effects of overexpressing multiple TREM-like genes. We crossed BAC-TREM2- R47H mice with 5xFAD [1], an amyloid depositing mouse model of AD, to evaluate amyloid pathologies and microglial phenotypes, transcriptomics and in situ expression of key TREM2-dosage dependent genes. We also compared the key findings in 5xFAD/BAC-TREM2-R47H to those observed in 5xFAD/BAC-TREM2 mice.",
  "We also compared the key findings in 5xFAD/BAC-TREM2-R47H to those observed in 5xFAD/BAC-TREM2 mice. Result Both BAC-TREM2 and BAC-TREM2-R47H showed proper expression of three splicing isoforms of TREM2 that are normally found in human. In 5xFAD background, elevated TREM2-R47H gene dosages significantly reduced the plaque burden, especially the filamentous type. The results were consistent with enhanced phagocytosis and altered NLRP3 inflammasome activation in BAC- TREM2-R47H microglia in vitro. However, unlike TREM2 overexpression, elevated TREM2- R47H in 5xFAD failed to ameliorate cognitive and transcriptomic deficits. In situ analysis of key TREM2-dosage dependent genes and microglial morphology uncovered that TREM2-R47H showed a loss-of-function phenotype in reprogramming of plaque-associated microglial reactivity and gene expression in 5xFAD.",
  "In situ analysis of key TREM2-dosage dependent genes and microglial morphology uncovered that TREM2-R47H showed a loss-of-function phenotype in reprogramming of plaque-associated microglial reactivity and gene expression in 5xFAD. Conclusion Our study demonstrated that the AD-risk variant has a previously unknown, mixture of partial and full loss of TREM2 functions in modulating microglial response in AD mouse brains. Together, our new BAC-TREM2-R47H model and prior BAC-TREM2 mice are invaluable resource to facilitate the therapeutic discovery that target human TREM2 and its R47H variant to ameliorate AD and other neurodegenerative disorders.\nAuthors: C.Y.",
  "Together, our new BAC-TREM2-R47H model and prior BAC-TREM2 mice are invaluable resource to facilitate the therapeutic discovery that target human TREM2 and its R47H variant to ameliorate AD and other neurodegenerative disorders.\nAuthors: C.Y. Daniel Lee, Amberlene J De La Rocha, Kellie Inouye, P. Langfelder, Anthony Daggett, X. Gu, Lu-Lin Jiang, Zoe Pamonag, Raymond G. Vaca, Jeffrey B. Richman, R. Kawaguchi, F. Gao, Huaxi Xu, X. W. Yang\nVenue: bioRxiv\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This study created a BAC transgenic mouse model expressing human TREM2 with the R47H mutation in its cognate genomic context and demonstrated that the AD-risk variant has a previously unknown, mixture of partial and full loss of TREM1 functions in modulating microglial response in AD mouse brains.'}",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: ea492b5bcb8fc9dc09637f8e89829916093a2536\nTitle: Single-cell immune profiling reveals immune responses in oral lichen planus\nYear: 2023\nAbstract: Introduction Oral lichen planus (OLP) is a common chronic inflammatory disorder of the oral mucosa with an unclear etiology. Several types of immune cells are involved in the pathogenesis of OLP. Methods We used single-cell RNA sequencing and immune repertoire sequencing to characterize the mucosal immune microenvironment of OLP. The presence of tissue-resident memory CD8+ T cells are validated by multiplex immunofluorescence. Results We generated a transcriptome atlas from four OLP biopsy samples and their paired peripheral blood mononuclear cells (PBMCs), and compared them with two healthy tissues and three healthy PBMCs samples. Our analysis revealed activated tissue-resident memory CD8+ T cells in OLP tissues. T cell receptor repertoires displayed apperant clonal expansion and preferrential gene pairing in OLP patients. Additionally, obvious BCR clonal expansion was observed in OLP lesions.",
  "Our analysis revealed activated tissue-resident memory CD8+ T cells in OLP tissues. T cell receptor repertoires displayed apperant clonal expansion and preferrential gene pairing in OLP patients. Additionally, obvious BCR clonal expansion was observed in OLP lesions. Plasmacytoid dendritic cells, a subtype that can promote dendritic cell maturation and enhance lymphocyte cytotoxicity, were identified in OLP. Conventional dendritic cells and macrophages are also found to exhibit pro-inflammatory activity in OLP. Cell-cell communication analysis reveals that fibroblasts might promote the recruitment and extravasation of immune cells into connective tissue. Discussion Our study provides insights into the immune ecosystem of OLP, serving as a valuable resource for precision diagnosis and therapy of OLP.",
  "Cell-cell communication analysis reveals that fibroblasts might promote the recruitment and extravasation of immune cells into connective tissue. Discussion Our study provides insights into the immune ecosystem of OLP, serving as a valuable resource for precision diagnosis and therapy of OLP.\nAuthors: Qionghua Li, Fei Wang, Yujie Shi, L. Zhong, S. Duan, Wenjing Kuang, Na Liu, En-jie Luo, Yu Zhou, Lu Jiang, H. Dan, Xiaobo Luo, Dunfang Zhang, Qianming Chen, X. Zeng, Taiwen Li\nVenue: Frontiers in Immunology\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Insight is provided into the immune ecosystem of OLP that reveals that fibroblasts might promote the recruitment and extravasation of immune cells into connective tissue, serving as a valuable resource for precision diagnosis and therapy of O LP.'}",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: ec772c1f1a994d0377030e3110adc00263b31cfc\nTitle: Analysis of cosmic lithium, beryllium and boron with the DAMPE mission\nYear: 2023\nAbstract: None\nAuthors: A. Parenti, Zhan-Fang Chen, I. De Mitri, M. Stolpovskiy, Li Wu, E. Xu, Francesco Alemanno, C. Altomare, Q. An, P. Azzarello, F. Barbato, P. Bernardini, X. Bi, I. Cagnoli, M. Cai, E. Casilli, E. Catanzani, Jin Chang, Dengyi Chen, Junling Chen, Z. Chen, P. Coppin, M. Cui, T. Cui, Yu-Xin Cui, Francesco de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang,",
  "Francesco de Palma, Adriano Di Giovanni, M. Di Santo, Qi Ding, T. Dong, Z. Dong, G. Donvito, D. Droz, Jingmin Duan, K. Duan, R. Fan, Yizhong Fan, F. Fang, K. Fang, Chang-Xue Feng, Lei Feng, M. Fernandez Alonso, J. M. Frieden, P. Fusco, Min Gao, F. Gargano, Essna Ghose, Ke Gong, Y. Gong, D. Guo, Jianhua Guo, Shuang Han, Yi-Ming Hu, Guanghan Huang, Xiao Yuan Huang, Y. Huang, M. Ionica, Luyang Jiang, Wei Jiang, Y. Jiang, J. Kong, A. Kotenko, D. Kyratzis, S. Lei, W. Li, Wen Li, Xiang Li, X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N.",
  "X. Li, Y. Liang, Chengming Liu, Hao Liu, Jie Liu, S. Liu, Yang Liu, F. Loparco, C. Luo, Miao Ma, P. Ma, T. Ma, Xiao Ma, G. Marsella, M. N. Mazziotta, D. Mo, X. Niu, Xu Pan, W. Peng, X. Peng, C. Perrina, E. Putti-Garcia, Rui Qiao, J. Rao, A. Ruina, Z. Shangguan, Weiming Shen, Z. Shen, Z. Shen, L. Silveri, Jing Song, H. Su, Meng Su, H. Sun, Zhigang Sun, A. Surdo, X. Teng, A. Tykhonov, J. Wang, L. Wang, Shen Wang, X. Wang, Y. Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, Sha Wu, Xin Wu, Z. Xia, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu, Zunlei Xu, G. Xue,",
  "Wang, Ying Wang, Y. Wang, D. Wei, J. Wei, Yining Wei, Di Wu, Jian Wu, Sha Wu, Xin Wu, Z. Xia, Hailun Xu, Jing Xu, Z. Xu, Zi-zong Xu, Zunlei Xu, G. Xue, Hai-Bo Yang, P. Yang, Y. Yang, H. Yao, Yu-hong Yu, G. Yuan, Qiang Yuan, C. Yue, J. Zang, Shenmin Zhang, W. Zhang, Yan Zhang, Y. Zhang, Yi Zhang, Y. Zhang, Y. Zhang, Yunlong Zhang, Zhe Zhang, Z. Zhang, Cong-Ying Zhao, Hongying Zhao, Xu Zhao, C. Zhou, Yanzi Zhu\nVenue: International Conference on Rebooting Computing\nTldr: None",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: ed92c3948a9195c9e265dc4315f7f629c40b7a2d\nTitle: Estimability study on the age of toddlers\u2019 gait development based on gait parameters\nYear: 2023\nAbstract: None\nAuthors: Chisa Tsuyuki, Haruna Hiraga, M. Sudo, T. Ueda, Kanako Seo, Masayuki Minatozaki, Yuko Fukuda, Yasuyuki Okuda, Hiroyuki Iwasaki, H. Naito, Dajiang Lu\nVenue: Scientific Reports\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The age of gait development, or the level of gait development with age as its indicator, can be estimated from several gait parameters related to gait development and its estimability is investigated.'}",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: f864734103cbbe9d46025abf4b41ec4737b5f08d\nTitle: Editorial: Emerging talents in comparative immunology: 2022\nYear: 2023\nAbstract: (LPS)\nAuthors: Yanjing Liu, Xin-Jiang Lu, Chris Hauton, Guanjun Yang, Jing Chen\nVenue: Frontiers in Immunology\nTldr: {'model': 'tldr@v2.0.0', 'text': None}",
  "Faculty Name: lu jiang\nMetadata:\nPaperid: fa20570f630ebcf53a6d386464c29aa4140b710d\nTitle: Hydraulic-Pump Fault-Diagnosis Method Based on Mean Spectrogram Bar Graph of Voiceprint and ResNet-50 Model Transfer\nYear: 2023\nAbstract: The vibration signal of a pump is often used for analysis in the study of hydraulic-pump fault diagnosis methods. In this study, for the analysis, sound signals were used, which can be used to acquire data in a non-contact manner to expand the use scenarios of hydraulic-pump fault-diagnosis methods. First, the original data are denoised using complete ensemble empirical mode decomposition with adaptive noise and the minimum redundancy maximum relevance algorithm. Second, the noise-reduced data are plotted as mean spectrogram bar graphs, and the datasets are divided. Third, the training set graphs are input into the ResNet-50 network to train the base model for fault diagnosis. Fourth, all the layers of the base model are frozen, except for the fully connected and softmax layers, and the support set graphs are used to train the base model through transfer learning. Finally, a fault diagnosis model is obtained.",
  "Fourth, all the layers of the base model are frozen, except for the fully connected and softmax layers, and the support set graphs are used to train the base model through transfer learning. Finally, a fault diagnosis model is obtained. The model is tested using data from two test pumps, resulting in accuracies of 86.1% and 90.8% and providing evidence for the effectiveness of the proposed method for diagnosing faults in hydraulic plunger pumps.\nAuthors: Peiyao Zhang, Wanlu Jiang, Yunfei Zheng, Shuqing Zhang, Sheng Zhang, Siyuan Liu\nVenue: Journal of Marine Science and Engineering\nTldr: None",
  "List of 2023 Open Access papers by lu jiang are:\nThe response linearity of energy measurement up to TeV in the DAMPE experiment\nDirect measurement of Ne-Mg-Si nuclei in cosmic rays with DAMPE\nDArk Matter Particle Explorer: 7 years in Space\nA PCA-based Method for Electron-Proton Discrimination of the DAMPE Experiment\nMeasurements of the boron-to-carbon and boron-to-oxygen flux ratios in cosmic rays with DAMPE\nA phosphoglycerate mutase 1 allosteric inhibitor overcomes drug resistance to EGFR-targeted therapy via disrupting IL-6/JAK2/STAT3 signaling pathway in lung adenocarcinoma.\nPGAM1 Inhibition Promotes HCC Ferroptosis and Synergizes with Anti\u2010PD\u20101 Immunotherapy\nEnterococcus faecalis promotes the progression of colorectal cancer via its metabolite: biliverdin\nHCC prediction models in chronic hepatitis B patients receiving entecavir or tenofovir: a systematic review and meta-analysis\nChanging incidence of hepatitis B and persistent infection risk in adults: a population-based follow-up study from 2011 in China\nThe efficacy and safety of asleep and awake subthalamic deep brain",
  "prediction models in chronic hepatitis B patients receiving entecavir or tenofovir: a systematic review and meta-analysis\nChanging incidence of hepatitis B and persistent infection risk in adults: a population-based follow-up study from 2011 in China\nThe efficacy and safety of asleep and awake subthalamic deep brain stimulation for Parkinson\u2019s disease patients: A 1-year follow-up\nEffects of STN\u2010DBS surgery on cerebral glucose metabolism and distribution of DAT in Parkinson's disease\nMulti-Omics Unravels Metabolic Alterations in the Ileal Mucosa of Neonatal Piglets Receiving Total Parenteral Nutrition\nAnalysis of Individual Cosmic-Ray Proton and Helium Fluxes towards PeV Energies with DAMPE\nDecreased Expression of KLF4 Leading to Functional Deficit in Pediatric Patients with Intestinal Failure and Potential Therapeutic Strategy Using Decanoic Acid\nCarbon Flux with DAMPE Using Machine Learning Methods\nLactobacillus johnsonii Attenuates Liver Steatosis and Bile Acid Dysregulation in Parenteral Nutrition-Fed Rats\nProbing hadronic cross sections in the TeV - PeV regime with DAMPE through machine learning techniques\nMeasurement of Heavy Nulei beyond Iron in Cosmic Rays with",
  "johnsonii Attenuates Liver Steatosis and Bile Acid Dysregulation in Parenteral Nutrition-Fed Rats\nProbing hadronic cross sections in the TeV - PeV regime with DAMPE through machine learning techniques\nMeasurement of Heavy Nulei beyond Iron in Cosmic Rays with the DAMPE Experiment\nCosmic Ray Carbon and Oxygen Flux Measurements with the DAMPE Experiment\nStudy of hadronic cross-sections with cosmic ray Carbon from GeV to TeV by the DAMPE experiment\nLatest results on searching for fractionally charged particles with the DAMPE experiment\nAnalysis of cosmic lithium,",
  "Rays with the DAMPE Experiment\nCosmic Ray Carbon and Oxygen Flux Measurements with the DAMPE Experiment\nStudy of hadronic cross-sections with cosmic ray Carbon from GeV to TeV by the DAMPE experiment\nLatest results on searching for fractionally charged particles with the DAMPE experiment\nAnalysis of cosmic lithium, beryllium and boron with the DAMPE mission\nMedian mandibular flexure\u2014the unique physiological phenomenon of the mandible and its clinical significance in implant restoration\nBAC Transgenic Expression of Human TREM2-R47H Remodels Amyloid Plaques but Unable to Reprogram Plaque-associated Microglial Reactivity in 5xFAD Mice\nTMEM241 is a UDP-N-acetylglucosamine transporter required for M6P modification of NPC2 and cholesterol transport\nReduced electron relaxation time of perovskite films via g-C3N4 quantum dot doping for high-performance perovskite solar cells\nHow to drive corporate responsible innovation?",
  "A dual perspective from internal and external drivers of environmental protection enterprises\nInchworm\u2010Like Soft Robot with Multimodal Locomotion Using an Acrylic Stick\u2010Constrained Dielectric Elastomer Actuator\nParadoxical Induction of ALOX15/15B by Cortisol in Human Amnion Fibroblasts: Implications for Inflammatory Responses of the Fetal Membranes at Parturition\nRecent progresses on the gamma-ray observations of DAMPE\nGRB 200829A: External-shock Origin of the Very Early Prompt Emission?\nMeasurement of the p+He energy spectrum with the DAMPE space mission\nHydraulic-Pump Fault-Diagnosis Method Based on Mean Spectrogram Bar Graph of Voiceprint and ResNet-50 Model Transfer\nCombining Spatiotemporally Global and Local Interpolations Improves Modeling of Annual Land Surface Temperature Cycles\nGlobal mapping of urban thermal anisotropy reveals substantial potential biases for remotely sensed urban climates.",
  "Impact of Varicella Immunization and Public Health and Social Measures on Varicella Incidence: Insights from Surveillance Data in Shanghai, 2013\u20132022\nCoverage and impact of influenza vaccination among children in Minhang District, China, 2013\u20132020\nAssociations of Morphological Changes in Skeletal Muscles of Preschool Children in China Following Physical Activity\nQualitative study of the association between psychosocial health and physical activity/sleep quality in toddlers\nEstimability study on the age of toddlers\u2019 gait development based on gait parameters\nAdvances in gene therapy hold promise for treating hereditary hearing loss.",
  "Research on integrated coastal zone management from past to the future: a bibliometric analysis\nLow-Light Image Enhancement via Structure Modeling and Guidance\nEdge Preserving Implicit Surface Representation of Point Clouds\nAccuracy of narrow band imaging for detecting the malignant transformation of oral potentially malignant disorders: A systematic review and meta-analysis\nUpdates on immunological mechanistic insights and targeting of the oral lichen planus microenvironment\nCD8+ tissue-resident memory T cells induce oral lichen planus erosion via cytokine network\nSingle-cell immune profiling reveals immune responses in oral lichen planus\nAuditing Gender Presentation Differences in Text-to-Image Models\n\u201cEasier or Harder, Depending on Who the Hearing Person Is\u201d: Codesigning Videoconferencing Tools for Small Groups with Mixed Hearing Status\nEfficient conversion of biomass waste to N/O co-doped hierarchical porous carbon for high performance supercapacitors\nEditorial: Emerging talents in comparative immunology: 2022",
  "Faculty Name: maarten sap\nMetadata:\nPaperid: 14ddefae2be4b5bb50b9fcb4a085e45fbecb5c5c\nTitle: Modeling Empathic Similarity in Personal Narratives\nYear: 2023\nAbstract: The most meaningful connections between people are often fostered through expression of shared vulnerability and emotional experiences in personal narratives. We introduce a new task of identifying similarity in personal stories based on empathic resonance, i.e., the extent to which two people empathize with each others' experiences, as opposed to raw semantic or lexical similarity, as has predominantly been studied in NLP. Using insights from social psychology, we craft a framework that operationalizes empathic similarity in terms of three key features of stories: main events, emotional trajectories, and overall morals or takeaways. We create EmpathicStories, a dataset of 1,500 personal stories annotated with our empathic similarity features, and 2,000 pairs of stories annotated with empathic similarity scores. Using our dataset, we fine-tune a model to compute empathic similarity of story pairs, and show that this outperforms semantic similarity models on automated correlation and retrieval metrics.",
  "Using our dataset, we fine-tune a model to compute empathic similarity of story pairs, and show that this outperforms semantic similarity models on automated correlation and retrieval metrics. Through a user study with 150 participants, we also assess the effect our model has on retrieving stories that users empathize with, compared to naive semantic similarity-based retrieval, and find that participants empathized significantly more with stories retrieved by our model. Our work has strong implications for the use of empathy-aware models to foster human connection and empathy between people.\nAuthors: Jocelyn Shen, Maarten Sap, Pedro Colon-Hernandez, Hae Won Park, C. Breazeal\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': \"A new task of identifying similarity in personal stories based on empathic resonance is introduced, i.e., the extent to which two people empathize with each others' experiences, as opposed to raw semantic or lexical similarity, as has predominantly been studied in NLP.\"}",
  "Faculty Name: maarten sap\nMetadata:\nPaperid: 185ace5661963e2e1eb998e739e4110272a6bb43\nTitle: COBRA Frames: Contextual Reasoning about Effects and Harms of Offensive Statements\nYear: 2023\nAbstract: Warning: This paper contains content that may be offensive or upsetting. Understanding the harms and offensiveness of statements requires reasoning about the social and situational context in which statements are made. For example, the utterance\"your English is very good\"may implicitly signal an insult when uttered by a white man to a non-white colleague, but uttered by an ESL teacher to their student would be interpreted as a genuine compliment. Such contextual factors have been largely ignored by previous approaches to toxic language detection. We introduce COBRA frames, the first context-aware formalism for explaining the intents, reactions, and harms of offensive or biased statements grounded in their social and situational context. We create COBRACORPUS, a dataset of 33k potentially offensive statements paired with machine-generated contexts and free-text explanations of offensiveness, implied biases, speaker intents, and listener reactions.",
  "We create COBRACORPUS, a dataset of 33k potentially offensive statements paired with machine-generated contexts and free-text explanations of offensiveness, implied biases, speaker intents, and listener reactions. To study the contextual dynamics of offensiveness, we train models to generate COBRA explanations, with and without access to the context. We find that explanations by context-agnostic models are significantly worse than by context-aware ones, especially in situations where the context inverts the statement's offensiveness (29% accuracy drop). Our work highlights the importance and feasibility of contextualized NLP by modeling social factors.",
  "We find that explanations by context-agnostic models are significantly worse than by context-aware ones, especially in situations where the context inverts the statement's offensiveness (29% accuracy drop). Our work highlights the importance and feasibility of contextualized NLP by modeling social factors.\nAuthors: Xuhui Zhou, Haojie Zhu, Akhila Yerukola, Thomas Davidson, Jena D. Hwang, Swabha Swayamdipta, Maarten Sap\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'COBRA frames are introduced, the first context-aware formalism for explaining the intents, reactions, and harms of offensive or biased statements grounded in their social and situational context, and the importance and feasibility of contextualized NLP by modeling social factors are highlighted.'}",
  "Faculty Name: maarten sap\nMetadata:\nPaperid: 27553f8bd9cbee90f6e65b9cdecadff0e7cc55ee\nTitle: Riveter: Measuring Power and Social Dynamics Between Entities\nYear: 2023\nAbstract: Riveter provides a complete easy-to-use pipeline for analyzing verb connotations associated with entities in text corpora. We prepopulate the package with connotation frames of sentiment, power, and agency, which have demonstrated usefulness for capturing social phenomena, such as gender bias, in a broad range of corpora. For decades, lexical frameworks have been foundational tools in computational social science, digital humanities, and natural language processing, facilitating multifaceted analysis of text corpora. But working with verb-centric lexica specifically requires natural language processing skills, reducing their accessibility to other researchers. By organizing the language processing pipeline, providing complete lexicon scores and visualizations for all entities in a corpus, and providing functionality for users to target specific research questions, Riveter greatly improves the accessibility of verb lexica and can facilitate a broad range of future research.",
  "By organizing the language processing pipeline, providing complete lexicon scores and visualizations for all entities in a corpus, and providing functionality for users to target specific research questions, Riveter greatly improves the accessibility of verb lexica and can facilitate a broad range of future research.\nAuthors: Maria Antoniak, Anjalie Field, Jimin Mun, Melanie Walsh, Lauren F. Klein, Maarten Sap\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Riveter greatly improves the accessibility of verb lexica and can facilitate a broad range of future research by organizing the language processing pipeline, providing complete lexicon scores and visualizations for all entities in a corpus, and providing functionality for users to target specific research questions.'}",
  "Faculty Name: maarten sap\nMetadata:\nPaperid: 57d65e85c62aef04dfb2a48380e415fbb790e5ee\nTitle: Don't Take This Out of Context!: On the Need for Contextual Models and Evaluations for Stylistic Rewriting\nYear: 2023\nAbstract: None\nAuthors: Akhila Yerukola, Xuhui Zhou, Elizabeth Clark, Maarten Sap\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: None",
  "Faculty Name: maarten sap\nMetadata:\nPaperid: 85a5ffc509fa50c96b415e09ae87fb6e5f435b37\nTitle: BiasX: \"Thinking Slow\" in Toxic Content Moderation with Explanations of Implied Social Biases\nYear: 2023\nAbstract: Toxicity annotators and content moderators often default to mental shortcuts when making decisions. This can lead to subtle toxicity being missed, and seemingly toxic but harmless content being over-detected. We introduce BiasX, a framework that enhances content moderation setups with free-text explanations of statements' implied social biases, and explore its effectiveness through a large-scale crowdsourced user study. We show that indeed, participants substantially benefit from explanations for correctly identifying subtly (non-)toxic content. The quality of explanations is critical: imperfect machine-generated explanations (+2.4% on hard toxic examples) help less compared to expert-written human explanations (+7.2%). Our results showcase the promise of using free-text explanations to encourage more thoughtful toxicity moderation.",
  "The quality of explanations is critical: imperfect machine-generated explanations (+2.4% on hard toxic examples) help less compared to expert-written human explanations (+7.2%). Our results showcase the promise of using free-text explanations to encourage more thoughtful toxicity moderation.\nAuthors: Yiming Zhang, Sravani Nanduri, Liwei Jiang, Tongshuang Wu, Maarten Sap\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': \"BiasX, a framework that enhances content moderation setups with free-text explanations of statements' implied social biases, is introduced and it is shown that indeed, participants substantially benefit from explanations for correctly identifying subtly (non-)toxic content.\"}",
  "Faculty Name: maarten sap\nMetadata:\nPaperid: 9d2dc57903e99f33b9cf727c3903718751d82663\nTitle: Improving Language Models with Advantage-based Offline Policy Gradients\nYear: 2023\nAbstract: Language Models (LMs) achieve substantial language capabilities when finetuned using Reinforcement Learning with Human Feedback (RLHF). However, RLHF is an unstable and data-hungry process that continually requires new high-quality LM-generated data for finetuning. We introduce Advantage-Leftover Lunch RL (A-LoL), a new class of offline policy gradient algorithms that enable RL training on any pre-existing data. By assuming the entire LM output sequence as a single action, A-LoL allows incorporating sequence-level classifiers or human-designed scoring functions as rewards. Subsequently, by using LM's internal sequence-level value estimate, A-LoL filters negative advantage (low-quality) data points during training, making it resilient to noise. Overall, A-LoL is an easy-to-implement LM training recipe that is sample-efficient and stable.",
  "Subsequently, by using LM's internal sequence-level value estimate, A-LoL filters negative advantage (low-quality) data points during training, making it resilient to noise. Overall, A-LoL is an easy-to-implement LM training recipe that is sample-efficient and stable. We demonstrate the effectiveness of A-LoL and its variants with a set of four different language generation tasks. We compare against both online RL (PPO) and recent preference-based (DPO, PRO) and reward-based (GOLD) offline RL baselines. On the commonly-used RLHF benchmark, Helpful and Harmless Assistant (HHA), LMs trained with A-LoL methods achieve the highest diversity while also being rated more safe and helpful than baselines according to humans. Additionally, in the remaining three tasks, A-LoL could optimize multiple distinct reward functions even when using noisy or suboptimal training data. We also release our experimental code.",
  "Additionally, in the remaining three tasks, A-LoL could optimize multiple distinct reward functions even when using noisy or suboptimal training data. We also release our experimental code. https://github.com/abaheti95/LoL-RL\nAuthors: Ashutosh Baheti, Ximing Lu, Faeze Brahman, Ronan Le Bras, Maarten Sap, Mark O. Riedl\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Advantage-Leftover Lunch RL (A-LoL), a new class of offline policy gradient algorithms that enable RL training on any pre-existing data that assumes the entire LM output sequence as a single action, and allows incorporating sequence-level classifiers or human-designed scoring functions as rewards.'}",
  "Faculty Name: maarten sap\nMetadata:\nPaperid: a5731b32060909bfc8848fa5f7e1e14ca3b53240\nTitle: From Dogwhistles to Bullhorns: Unveiling Coded Rhetoric with Language Models\nYear: 2023\nAbstract: Dogwhistles are coded expressions that simultaneously convey one meaning to a broad audience and a second, often hateful or provocative, meaning to a narrow in-group; they are deployed to evade both political repercussions and algorithmic content moderation. For example, the word \u201ccosmopolitan\u201d in a sentence such as \u201cwe need to end the cosmopolitan experiment\u201d can mean \u201cworldly\u201d to many but also secretly mean \u201cJewish\u201d to a select few. We present the first large-scale computational investigation of dogwhistles. We develop a typology of dogwhistles, curate the largest-to-date glossary of over 300 dogwhistles with rich contextual information and examples, and analyze their usage in historical U.S. politicians\u2019 speeches.",
  "We present the first large-scale computational investigation of dogwhistles. We develop a typology of dogwhistles, curate the largest-to-date glossary of over 300 dogwhistles with rich contextual information and examples, and analyze their usage in historical U.S. politicians\u2019 speeches. We then assess whether a large language model (GPT-3) can identify dogwhistles and their meanings, and find that GPT-3\u2019s performance varies widely across types of dogwhistles and targeted groups. Finally, we show that harmful content containing dogwhistles avoids toxicity detection, highlighting online risks presented by such coded language. This work sheds light on the theoretical and applied importance of dogwhistles in both NLP and computational social science, and provides resources to facilitate future research in modeling dogwhistles and mitigating their online harms.\nAuthors: Julia Mendelsohn, Ronan Le Bras, Yejin Choi, Maarten Sap\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: None",
  "Faculty Name: maarten sap\nMetadata:\nPaperid: a66ff335f5934fe7503a99d3eb3abed493994df1\nTitle: NLPositionality: Characterizing Design Biases of Datasets and Models\nYear: 2023\nAbstract: Design biases in NLP systems, such as performance differences for different populations, often stem from their creator\u2019s positionality, i.e., views and lived experiences shaped by identity and background. Despite the prevalence and risks of design biases, they are hard to quantify because researcher, system, and dataset positionality is often unobserved. We introduce NLPositionality, a framework for characterizing design biases and quantifying the positionality of NLP datasets and models. Our framework continuously collects annotations from a diverse pool of volunteer participants on LabintheWild, and statistically quantifies alignment with dataset labels and model predictions. We apply NLPositionality to existing datasets and models for two tasks\u2014social acceptability and hate speech detection.",
  "Our framework continuously collects annotations from a diverse pool of volunteer participants on LabintheWild, and statistically quantifies alignment with dataset labels and model predictions. We apply NLPositionality to existing datasets and models for two tasks\u2014social acceptability and hate speech detection. To date, we have collected 16,299 annotations in over a year for 600 instances from 1,096 annotators across 87 countries.We find that datasets and models align predominantly with Western, White, college-educated, and younger populations. Additionally, certain groups, such as non-binary people and non-native English speakers, are further marginalized by datasets and models as they rank least in alignment across all tasks. Finally, we draw from prior literature to discuss how researchers can examine their own positionality and that of their datasets and models, opening the door for more inclusive NLP systems.",
  "Finally, we draw from prior literature to discuss how researchers can examine their own positionality and that of their datasets and models, opening the door for more inclusive NLP systems.\nAuthors: Sebastin Santy, Jenny T Liang, Ronan Le Bras, Katharina Reinecke, Maarten Sap\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'NLPositionality, a framework for characterizing design biases and quantifying the positionality of NLP datasets and models, is introduced and it is found that dataset and models align predominantly with Western, White, college-educated, and younger populations.'}",
  "Faculty Name: maarten sap\nMetadata:\nPaperid: a89c30ceca55783a1b2ff843eb6a4793e4a54b66\nTitle: Don't Take This Out of Context! On the Need for Contextual Models and Evaluations for Stylistic Rewriting\nYear: 2023\nAbstract: Most existing stylistic text rewriting methods and evaluation metrics operate on a sentence level, but ignoring the broader context of the text can lead to preferring generic, ambiguous, and incoherent rewrites. In this paper, we investigate integrating the preceding textual context into both the $\\textit{rewriting}$ and $\\textit{evaluation}$ stages of stylistic text rewriting, and introduce a new composite contextual evaluation metric $\\texttt{CtxSimFit}$ that combines similarity to the original sentence with contextual cohesiveness. We comparatively evaluate non-contextual and contextual rewrites in formality, toxicity, and sentiment transfer tasks. Our experiments show that humans significantly prefer contextual rewrites as more fitting and natural over non-contextual ones, yet existing sentence-level automatic metrics (e.g., ROUGE, SBERT) correlate poorly with human preferences ($\\rho$=0--0.3).",
  "Our experiments show that humans significantly prefer contextual rewrites as more fitting and natural over non-contextual ones, yet existing sentence-level automatic metrics (e.g., ROUGE, SBERT) correlate poorly with human preferences ($\\rho$=0--0.3). In contrast, human preferences are much better reflected by both our novel $\\texttt{CtxSimFit}$ ($\\rho$=0.7--0.9) as well as proposed context-infused versions of common metrics ($\\rho$=0.4--0.7). Overall, our findings highlight the importance of integrating context into the generation and especially the evaluation stages of stylistic text rewriting.\nAuthors: Akhila Yerukola, Xuhui Zhou, Maarten Sap\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A new composite contextual evaluation metric is introduced that combines similarity to the original sentence with contextual cohesiveness and highlights the importance of integrating context into the generation and especially the evaluation stages of stylistic text rewriting.'}",
  "Faculty Name: maarten sap\nMetadata:\nPaperid: c2850c897a179c07a25023029306600e0ea82f75\nTitle: Queer In AI: A Case Study in Community-Led Participatory AI\nYear: 2023\nAbstract: Queerness and queer people face an uncertain future in the face of ever more widely deployed and invasive artificial intelligence (AI). These technologies have caused numerous harms to queer people, including privacy violations, censoring and downranking queer content, exposing queer people and spaces to harassment by making them hypervisible, deadnaming and outing queer people. More broadly, they have violated core tenets of queerness by classifying and controlling queer identities. In response to this, the queer community in AI has organized Queer in AI, a global, decentralized, volunteer-run grassroots organization that employs intersectional and community-led participatory design to build an inclusive and equitable AI future. In this paper, we present Queer in AI as a case study for community-led participatory design in AI. We examine how participatory design and intersectional tenets started and shaped this community\u2019s programs over the years.",
  "In this paper, we present Queer in AI as a case study for community-led participatory design in AI. We examine how participatory design and intersectional tenets started and shaped this community\u2019s programs over the years. We discuss different challenges that emerged in the process, look at ways this organization has fallen short of operationalizing participatory and intersectional principles, and then assess the organization\u2019s impact. Queer in AI provides important lessons and insights for practitioners and theorists of participatory methods broadly through its rejection of hierarchy in favor of decentralization, success at building aid and programs by and for the queer community, and effort to change actors and institutions outside of the queer community. Finally, we theorize how communities like Queer in AI contribute to the participatory design in AI more broadly by fostering cultures of participation in AI, welcoming and empowering marginalized participants, critiquing poor or exploitative participatory practices, and bringing participation to institutions outside of individual research projects. Queer in AI\u2019s work serves as a case study of grassroots activism and participatory methods within AI, demonstrating the potential of community-led participatory methods and intersectional praxis, while also providing challenges, case studies, and nuanced insights to researchers developing and using participatory methods.",
  "Queer in AI\u2019s work serves as a case study of grassroots activism and participatory methods within AI, demonstrating the potential of community-led participatory methods and intersectional praxis, while also providing challenges, case studies, and nuanced insights to researchers developing and using participatory methods.\nAuthors: AI OrganizersOfQueerin, Anaelia Ovalle, Arjun Subramonian, Ashwin Singh, C. Voelcker, Danica J. Sutherland, Davide Locatelli, Eva Breznik, Filip Klubicka, Hang Yuan, J. Hetvi, Huan Zhang, Jaidev Shriram, Kruno Lehman, Luca Soldaini, Maarten Sap, M. Deisenroth, Maria Leonor Pacheco, Maria Ryskina, Martin Mundt, M. Agarwal, Nyx McLean, Pan Xu, Pranav A, Raj Korpan, Ruchira Ray, Sarah Mathew, Sarthak Arora, S. T. John, Tanvi Anand, Vishakha Agrawal, William Agnew, Yanan Long, Zijie J. Wang, Zeerak Talat, Avijit Ghosh, N.",
  "Ruchira Ray, Sarah Mathew, Sarthak Arora, S. T. John, Tanvi Anand, Vishakha Agrawal, William Agnew, Yanan Long, Zijie J. Wang, Zeerak Talat, Avijit Ghosh, N. Dennler, Michael Noseworthy, Sharvani Jha, Emi Baylor, Aditya Joshi, Natalia Y. Bilenko, Andrew McNamara, Raphael Gontijo-Lopes, Alex Markham, Evyn D\u01d2ng, J. Kay, Manu Saraswat, Nikhil Vytla, Luke Stark\nVenue: Conference on Fairness, Accountability and Transparency\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper examines how participatory design and intersectional tenets started and shaped this community\u2019s programs over the years, and discusses different challenges that emerged in the process, and looks at ways this organization has fallen short of operationalizing participatory and intersectionsal principles.'}",
  "Faculty Name: maarten sap\nMetadata:\nPaperid: d655f652d02251b45db43181c5e3c73dfc59cd51\nTitle: Value Kaleidoscope: Engaging AI with Pluralistic Human Values, Rights, and Duties\nYear: 2023\nAbstract: Human values are crucial to human decision-making. Value pluralism is the view that multiple correct values may be held in tension with one another (e.g., when considering lying to a friend to protect their feelings, how does one balance honesty with friendship?). As statistical learners, AI systems fit to averages by default, washing out these potentially irreducible value conflicts. To improve AI systems to better reflect value pluralism, the first-order challenge is to explore the extent to which AI systems can model pluralistic human values, rights, and duties as well as their interaction. We introduce ValuePrism, a large-scale dataset of 218k values, rights, and duties connected to 31k human-written situations. ValuePrism's contextualized values are generated by GPT-4 and deemed high-quality by human annotators 91% of the time.",
  "We introduce ValuePrism, a large-scale dataset of 218k values, rights, and duties connected to 31k human-written situations. ValuePrism's contextualized values are generated by GPT-4 and deemed high-quality by human annotators 91% of the time. We conduct a large-scale study with annotators across diverse social and demographic backgrounds to try to understand whose values are represented. With ValuePrism, we build Kaleido, an open, light-weight, and structured language-based multi-task model that generates, explains, and assesses the relevance and valence (i.e., support or oppose) of human values, rights, and duties within a specific context. Humans prefer the sets of values output by our system over the teacher GPT-4, finding them more accurate and with broader coverage. In addition, we demonstrate that Kaleido can help explain variability in human decision-making by outputting contrasting values. Finally, we show that Kaleido's representations transfer to other philosophical frameworks and datasets, confirming the benefit of an explicit, modular, and interpretable approach to value pluralism.",
  "In addition, we demonstrate that Kaleido can help explain variability in human decision-making by outputting contrasting values. Finally, we show that Kaleido's representations transfer to other philosophical frameworks and datasets, confirming the benefit of an explicit, modular, and interpretable approach to value pluralism. We hope that our work will serve as a step to making more explicit the implicit values behind human decision-making and to steering AI systems to make decisions that are more in accordance with them.\nAuthors: Taylor Sorensen, Liwei Jiang, Jena D. Hwang, Sydney Levine, Valentina Pyatkin, Peter West, Nouha Dziri, Ximing Lu, Kavel Rao, Chandra Bhagavatula, Maarten Sap, J. Tasioulas, Yejin Choi\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Kaleido is built, an open, light-weight, and structured language-based multi-task model that generates, explains, and assesses the relevance and valence of human values, rights, and duties within a specific context and demonstrates that Kaleido can help explain variability in human decision-making by outputting contrasting values.'}",
  "Faculty Name: maarten sap\nMetadata:\nPaperid: ddcd2bcc809bd0c2755a4a9487473d61ac327c50\nTitle: Clever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in Large Language Models\nYear: 2023\nAbstract: The escalating debate on AI's capabilities warrants developing reliable metrics to assess machine\"intelligence\". Recently, many anecdotal examples were used to suggest that newer large language models (LLMs) like ChatGPT and GPT-4 exhibit Neural Theory-of-Mind (N-ToM); however, prior work reached conflicting conclusions regarding those abilities. We investigate the extent of LLMs' N-ToM through an extensive evaluation on 6 tasks and find that while LLMs exhibit certain N-ToM abilities, this behavior is far from being robust. We further examine the factors impacting performance on N-ToM tasks and discover that LLMs struggle with adversarial examples, indicating reliance on shallow heuristics rather than robust ToM abilities. We caution against drawing conclusions from anecdotal examples, limited benchmark testing, and using human-designed psychological tests to evaluate models.",
  "We further examine the factors impacting performance on N-ToM tasks and discover that LLMs struggle with adversarial examples, indicating reliance on shallow heuristics rather than robust ToM abilities. We caution against drawing conclusions from anecdotal examples, limited benchmark testing, and using human-designed psychological tests to evaluate models.\nAuthors: Natalie Shapira, Mosh Levy, S. Alavi, Xuhui Zhou, Yejin Choi, Yoav Goldberg, Maarten Sap, Vered Shwartz\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is found that while LLMs exhibit certain N-ToM abilities, this behavior is far from being robust, indicating reliance on shallow heuristics rather than robust ToM abilities.'}",
  "Faculty Name: maarten sap\nMetadata:\nPaperid: ea0585ed23e25d5f8682eb91f20c6ddbeb6a27b4\nTitle: Towards Countering Essentialism through Social Bias Reasoning\nYear: 2023\nAbstract: Essentialist beliefs (i.e., believing that members of the same group are fundamentally alike) play a central role in social stereotypes and can lead to harm when left unchallenged. In our work, we conduct exploratory studies into the task of countering essentialist beliefs (e.g., ``liberals are stupid''). Drawing on prior work from psychology and NLP, we construct five types of counterstatements and conduct human studies on the effectiveness of these different strategies. Our studies also investigate the role in choosing a counterstatement of the level of explicitness with which an essentialist belief is conveyed. We find that statements that broaden the scope of a stereotype (e.g., to other groups, as in ``conservatives can also be stupid'') are the most popular countering strategy.",
  "We find that statements that broaden the scope of a stereotype (e.g., to other groups, as in ``conservatives can also be stupid'') are the most popular countering strategy. We conclude with a discussion of challenges and open questions for future work in this area (e.g., improving factuality, studying community-specific variation) and we emphasize the importance of work at the intersection of NLP and psychology.\nAuthors: Emily Allaway, Nina Taneja, S. Leslie, Maarten Sap\nVenue: arXiv.org\nTldr: None",
  "List of 2023 Open Access papers by maarten sap are:\nModeling Empathic Similarity in Personal Narratives\nCOBRA Frames: Contextual Reasoning about Effects and Harms of Offensive Statements\nRiveter: Measuring Power and Social Dynamics Between Entities\nDon't Take This Out of Context!: On the Need for Contextual Models and Evaluations for Stylistic Rewriting\nBiasX: \"Thinking Slow\" in Toxic Content Moderation with Explanations of Implied Social Biases\nImproving Language Models with Advantage-based Offline Policy Gradients\nFrom Dogwhistles to Bullhorns: Unveiling Coded Rhetoric with Language Models\nNLPositionality: Characterizing Design Biases of Datasets and Models\nDon't Take This Out of Context! On the Need for Contextual Models and Evaluations for Stylistic Rewriting\nQueer In AI: A Case Study in Community-Led Participatory AI\nValue Kaleidoscope: Engaging AI with Pluralistic Human Values, Rights, and Duties\nClever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in Large Language Models\nTowards Countering Essentialism through Social Bias Reasoning",
  "Title: Brian MacWhinney -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Brian MacWhinney, Affiliated Faculty at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Affiliated Faculty\" name=\"categories-1\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Brian MacWhinney - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Brian MacWhinney, Affiliated Faculty at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Brian\"/>\n<meta content=\"Lastname\" property=\"profile:MacWhinney\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/macwhinney-brian.",
  "cmu.edu//people/faculty/macwhinney-brian.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nBrian \n                        MacWhinney\nProfessor (On Leave), Psychology\nLanguage Technologies Institute\nContact\n254M \u2014Baker Hall\nmacw(through)cmu.edu\n412-268-7205\nPsychology\n\nLinks:\nhttps://www.cmu.edu/dietrich/psychology/",
  "Faculty Name: madhavi ganapathiraju\nMetadata:\nPaperid: de52a2f746c5cf145ee2af3a978ee1942eec1a57\nTitle: Editorial: Systems biology, women in science 2021/22: translational systems biology and in silico trials\nYear: 2023\nAbstract: None\nAuthors: Jane A. Leopold, M. Ganapathiraju, N. Yanamala\nVenue: Frontiers in Systems Biology\nTldr: None",
  "List of 2023 Open Access papers by madhavi ganapathiraju are:\nEditorial: Systems biology, women in science 2021/22: translational systems biology and in silico trials",
  "Faculty Name: malihe alikhani\nMetadata:\nPaperid: 2386c6a7c40b5129960f2eb3c6be27db65b04c1f\nTitle: Learning to Generate Equitable Text in Dialogue from Biased Training Data\nYear: 2023\nAbstract: The ingrained principles of fairness in a dialogue system\u2019s decision-making process and generated responses are crucial for user engagement, satisfaction, and task achievement. Absence of equitable and inclusive principles can hinder the formation of common ground, which in turn negatively impacts the overall performance of the system. For example, misusing pronouns in a user interaction may cause ambiguity about the intended subject. Yet, there is no comprehensive study of equitable text generation in dialogue. Aptly, in this work, we use theories of computational learning to study this problem. We provide formal definitions of equity in text generation, and further, prove formal connections between learning human-likeness and learning equity: algorithms for improving equity ultimately reduce to algorithms for improving human-likeness (on augmented data).",
  "We provide formal definitions of equity in text generation, and further, prove formal connections between learning human-likeness and learning equity: algorithms for improving equity ultimately reduce to algorithms for improving human-likeness (on augmented data). With this insight, we also formulate reasonable conditions under which text generation algorithms can learn to generate equitable text without any modifications to the biased training data on which they learn. To exemplify our theory in practice, we look at a group of algorithms for the GuessWhat?! visual dialogue game and, using this example, test our theory empirically. Our theory accurately predicts relative-performance of multiple algorithms in generating equitable text as measured by both human and automated evaluation.\nAuthors: Anthony Sicilia, Malihe Alikhani\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work provides formal definitions of equity in text generation, and proves formal connections between learning human-likeness and learning equity: algorithms for improving equity ultimately reduce to algorithms forimproving human- likeness (on augmented data).'}",
  "Faculty Name: malihe alikhani\nMetadata:\nPaperid: 2605bc92935ca67829e9542030be0e44ae81c22e\nTitle: Learning Multimodal Cues of Children\u2019s Uncertainty\nYear: 2023\nAbstract: Understanding uncertainty plays a critical role in achieving common ground (Clark et al., 1983). This is especially important for multimodal AI systems that collaborate with users to solve a problem or guide the user through a challenging concept. In this work, for the first time, we present a dataset annotated in collaboration with developmental and cognitive psychologists for the purpose of studying nonverbal cues of uncertainty. We then present an analysis of the data, studying different roles of uncertainty and its relationship with task difficulty and performance. Lastly, we present a multimodal machine learning model that can predict uncertainty given a real-time video clip of a participant, which we find improves upon a baseline multimodal transformer model. This work informs research on cognitive coordination between human-human and human-AI and has broad implications for gesture understanding and generation. The anonymized version of our data and code will be publicly available upon the completion of the required consent forms and data sheets.",
  "This work informs research on cognitive coordination between human-human and human-AI and has broad implications for gesture understanding and generation. The anonymized version of our data and code will be publicly available upon the completion of the required consent forms and data sheets.\nAuthors: Qi Cheng, Mert Inan, Rahma Mbarki, Grace Grmek, Theresa Choi, Yiming Sun, Kimele Persaud, Jenny Wang, Malihe Alikhani\nVenue: SIGDIAL Conferences\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A multimodal machine learning model that can predict uncertainty given a real-time video clip of a participant is presented, which improves upon a baseline multimodAL transformer model and has broad implications for gesture understanding and generation.'}",
  "Faculty Name: malihe alikhani\nMetadata:\nPaperid: 604cc00ff6a4d57d97856b49be4df89452cf30a8\nTitle: Findings of the Second WMT Shared Task on Sign Language Translation (WMT-SLT23)\nYear: 2023\nAbstract: This paper presents the results of the Second WMT Shared Task on Sign Language Translation (WMT-SLT23; https://www.wmt-slt.com/). This shared task is concerned with automatic translation between signed and spoken languages. The task is unusual in the sense that it requires processing visual information (such as video frames or human pose estimation) beyond the well-known paradigm of text-to-text machine translation (MT). The task offers four tracks involving the following languages: Swiss German Sign Language (DSGS), French Sign Language of Switzerland (LSF-CH), Italian Sign Language of Switzerland (LIS-CH), German, French and Italian. Four teams (including one working on a baseline submission) participated in this second edition of the task, all submitting to the DSGS-to-German track.",
  "Four teams (including one working on a baseline submission) participated in this second edition of the task, all submitting to the DSGS-to-German track. Besides a system ranking and system papers describing state-of-the-art techniques, this shared task makes the following scientific contributions: novel corpora and reproducible baseline systems. Finally, the task also resulted in publicly available sets of system outputs and more human evaluation scores for sign language translation.",
  "Besides a system ranking and system papers describing state-of-the-art techniques, this shared task makes the following scientific contributions: novel corpora and reproducible baseline systems. Finally, the task also resulted in publicly available sets of system outputs and more human evaluation scores for sign language translation.\nAuthors: Mathias M\u00fcller, Malihe Alikhani, Eleftherios Avramidis, Richard Bowden, Annelies Braffort, Necati Cihan Camg\u00f6z, Sarah Ebling, Cristina Espa\u00f1a-Bonet, Anne G\u00f6hring, Roman Grundkiewicz, Mert Inan, Zifan Jiang, Oscar Koller, Amit Moryossef, Annette Rios, D. Shterionov, Sandra Sidler-Miserez, Katja Tissi, Davy Van Landuyt\nVenue: Conference on Machine Translation\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper presents the results of the Second WMT Shared Task on Sign Language Translation, concerned with automatic translation between signed and spoken languages, which resulted in publicly available sets of system outputs and more human evaluation scores for sign language translation.'}",
  "Faculty Name: malihe alikhani\nMetadata:\nPaperid: 78ee30f94bfa9c08306cd2f5bf92e98240aa692d\nTitle: Multilingual Content Moderation: A Case Study on Reddit\nYear: 2023\nAbstract: Content moderation is the process of flagging content based on pre-defined platform rules. There has been a growing need for AI moderators to safeguard users as well as protect the mental health of human moderators from traumatic content. While prior works have focused on identifying hateful/offensive language, they are not adequate for meeting the challenges of content moderation since 1) moderation decisions are based on violation of rules, which subsumes detection of offensive speech, and 2) such rules often differ across communities which entails an adaptive solution. We propose to study the challenges of content moderation by introducing a multilingual dataset of 1.8 Million Reddit comments spanning 56 subreddits in English, German, Spanish and French1. We perform extensive experimental analysis to highlight the underlying challenges and suggest related research problems such as cross-lingual transfer, learning under label noise (human biases), transfer of moderation models, and predicting the violated rule.",
  "We perform extensive experimental analysis to highlight the underlying challenges and suggest related research problems such as cross-lingual transfer, learning under label noise (human biases), transfer of moderation models, and predicting the violated rule. Our dataset and analysis can help better prepare for the challenges and opportunities of auto moderation.\nAuthors: Meng Ye, Karan Sikka, Katherine Atwell, Sabit Hassan, Ajay Divakaran, Malihe Alikhani\nVenue: Conference of the European Chapter of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes to study the challenges of content moderation by introducing a multilingual dataset of 1.8 Million Reddit comments spanning 56 subreddits in English, German, Spanish and French and performs extensive experimental analysis to highlight the underlying challenges and suggest related research problems.'}",
  "Faculty Name: malihe alikhani\nMetadata:\nPaperid: e2be92ff1ae2abdc05c1929d6d02623c58f37097\nTitle: Image\u2013text coherence and its implications for multimodal AI\nYear: 2023\nAbstract: Human communication often combines imagery and text into integrated presentations, especially online. In this paper, we show how image\u2013text coherence relations can be used to model the pragmatics of image\u2013text presentations in AI systems. In contrast to alternative frameworks that characterize image\u2013text presentations in terms of the priority, relevance, or overlap of information across modalities, coherence theory postulates that each unit of a discourse stands in specific pragmatic relations to other parts of the discourse, with each relation involving its own information goals and inferential connections. Text accompanying an image may, for example, characterize what's visible in the image, explain how the image was obtained, offer the author's appraisal of or reaction to the depicted situation, and so forth. The advantage of coherence theory is that it provides a simple, robust, and effective abstraction of communicative goals for practical applications.",
  "The advantage of coherence theory is that it provides a simple, robust, and effective abstraction of communicative goals for practical applications. To argue this, we review case studies describing coherence in image\u2013text data sets, predicting coherence from few-shot annotations, and coherence models of image\u2013text tasks such as caption generation and caption evaluation.\nAuthors: Malihe Alikhani, Baber Khalid, Matthew Stone\nVenue: Frontiers in Artificial Intelligence\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper shows how image\u2013text coherence relations can be used to model the pragmatics of image-text presentations in AI systems, and reviews case studies describing coherence in image\u2013 Text data sets, predicting coherence from few-shot annotations, and coherence models of image\u2013 text tasks such as caption generation and caption evaluation.'}",
  "Faculty Name: malihe alikhani\nMetadata:\nPaperid: ee866d0dd47351542e4924f14203a767dd03194a\nTitle: A corpus of Persian literary text\nYear: 2023\nAbstract: None\nAuthors: Shahab Raji, Malihe Alikhani, Gerard de Melo, Matthew Stone\nVenue: Language Resources and Evaluation\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The corpus, the tools, and experiments described in this paper can be used not only for digital humanities studies of Persian literature but also for processing Persian texts in general, as well as in other broader cross-linguistic applications.'}",
  "Faculty Name: malihe alikhani\nMetadata:\nPaperid: f19180afd6cae7c241fa461eed122e4c04a14217\nTitle: D-CALM: A Dynamic Clustering-based Active Learning Approach for Mitigating Bias\nYear: 2023\nAbstract: Despite recent advancements, NLP models continue to be vulnerable to bias. This bias often originates from the uneven distribution of real-world data and can propagate through the annotation process. Escalated integration of these models in our lives calls for methods to mitigate bias without overbearing annotation costs. While active learning (AL) has shown promise in training models with a small amount of annotated data, AL's reliance on the model's behavior for selective sampling can lead to an accumulation of unwanted bias rather than bias mitigation. However, infusing clustering with AL can overcome the bias issue of both AL and traditional annotation methods while exploiting AL's annotation efficiency. In this paper, we propose a novel adaptive clustering-based active learning algorithm, D-CALM, that dynamically adjusts clustering and annotation efforts in response to an estimated classifier error-rate.",
  "However, infusing clustering with AL can overcome the bias issue of both AL and traditional annotation methods while exploiting AL's annotation efficiency. In this paper, we propose a novel adaptive clustering-based active learning algorithm, D-CALM, that dynamically adjusts clustering and annotation efforts in response to an estimated classifier error-rate. Experiments on eight datasets for a diverse set of text classification tasks, including emotion, hatespeech, dialog act, and book type detection, demonstrate that our proposed algorithm significantly outperforms baseline AL approaches with both pretrained transformers and traditional Support Vector Machines. D-CALM showcases robustness against different measures of information gain and, as evident from our analysis of label and error distribution, can significantly reduce unwanted model bias.\nAuthors: Sabit Hassan, Malihe Alikhani\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A novel adaptive clustering-based active learning algorithm that dynamically adjusts clustering and annotation efforts in response to an estimated classifier error-rate, D-CALM, which showcases robustness against different measures of information gain and can significantly reduce unwanted model bias.'}",
  "List of 2023 Open Access papers by malihe alikhani are:\nLearning to Generate Equitable Text in Dialogue from Biased Training Data\nLearning Multimodal Cues of Children\u2019s Uncertainty\nFindings of the Second WMT Shared Task on Sign Language Translation (WMT-SLT23)\nMultilingual Content Moderation: A Case Study on Reddit\nImage\u2013text coherence and its implications for multimodal AI\nA corpus of Persian literary text\nD-CALM: A Dynamic Clustering-based Active Learning Approach for Mitigating Bias",
  "Faculty Name: matt gormley\nMetadata:\nPaperid: d6ae4c0679bdceb029f652efd2a854ac5ade772f\nTitle: It\u2019s MBR All the Way Down: Modern Generation Techniques Through the Lens of Minimum Bayes Risk\nYear: 2023\nAbstract: Minimum Bayes Risk (MBR) decoding is a method for choosing the outputs of a machine learning system based not on the output with the highest probability, but the output with the lowest risk (expected error) among multiple candidates. It is a simple but powerful method: for an additional cost at inference time, MBR provides reliable several-point improvements across metrics for a wide variety of tasks without any additional data or training. Despite this, MBR is not frequently applied in NLP works, and knowledge of the method itself is limited. We first provide an introduction to the method and the recent literature. We show that several recent methods that do not reference MBR can be written as special cases of MBR; this reformulation provides additional theoretical justification for the performance of these methods, explaining some results that were previously only empirical.",
  "We first provide an introduction to the method and the recent literature. We show that several recent methods that do not reference MBR can be written as special cases of MBR; this reformulation provides additional theoretical justification for the performance of these methods, explaining some results that were previously only empirical. We provide theoretical and empirical results about the effectiveness of various MBR variants and make concrete recommendations for the application of MBR in NLP models, including future directions in this area.\nAuthors: Amanda Bertsch, Alex Xie, Graham Neubig, Matthew R. Gormley\nVenue: BIGPICTURE\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is shown that several recent methods that do not reference MBR can be written as special cases of MBR; this reformulation provides additional theoretical justification for the performance of these methods, explaining some results that were previously only empirical.'}",
  "Faculty Name: matt gormley\nMetadata:\nPaperid: dbc368bc8b49347dd27679894524fa62f88492c9\nTitle: Unlimiformer: Long-Range Transformers with Unlimited Length Input\nYear: 2023\nAbstract: Since the proposal of transformers, these models have been limited to bounded input lengths, because of their need to attend to every token in the input. In this work, we propose Unlimiformer: a general approach that wraps any existing pretrained encoder-decoder transformer, and offloads the cross-attention computation to a single k-nearest-neighbor (kNN) index, while the returned kNN distances are the attention dot-product scores. This kNN index can be kept on either the GPU or CPU memory and queried in sub-linear time; this way, we can index practically unlimited input sequences, while every attention head in every decoder layer retrieves its top-k keys, instead of attending to every key. We evaluate Unlimiformer on several long-document and book-summarization benchmarks, showing that it can process even 500k token-long inputs from the BookSum dataset, without any input truncation at test time.",
  "We evaluate Unlimiformer on several long-document and book-summarization benchmarks, showing that it can process even 500k token-long inputs from the BookSum dataset, without any input truncation at test time. We demonstrate that Unlimiformer improves pretrained models such as BART and Longformer by extending them to unlimited inputs without additional learned weights and without modifying their code. We make our code and models publicly available at https://github.com/abertsch72/unlimiformer .\nAuthors: Amanda Bertsch, Uri Alon, Graham Neubig, Matthew R. Gormley\nVenue: Neural Information Processing Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes Unlimiformer: a general approach that wraps any existing pretrained encoder-decoder transformer, and offloads the cross-attention computation to a single k-nearest-neighbor (kNN) index, while the returned kNN distances are the attention dot-product scores.'}",
  "Faculty Name: matt gormley\nMetadata:\nPaperid: e80f1b4c254a5c135f5f3416ba3a863f8ec4e06c\nTitle: MDACE: MIMIC Documents Annotated with Code Evidence\nYear: 2023\nAbstract: We introduce a dataset for evidence/rationale extraction on an extreme multi-label classification task over long medical documents. One such task is Computer-Assisted Coding (CAC) which has improved significantly in recent years, thanks to advances in machine learning technologies. Yet simply predicting a set of final codes for a patient encounter is insufficient as CAC systems are required to provide supporting textual evidence to justify the billing codes. A model able to produce accurate and reliable supporting evidence for each code would be a tremendous benefit. However, a human annotated code evidence corpus is extremely difficult to create because it requires specialized knowledge. In this paper, we introduce MDACE, the first publicly available code evidence dataset, which is built on a subset of the MIMIC-III clinical records.",
  "However, a human annotated code evidence corpus is extremely difficult to create because it requires specialized knowledge. In this paper, we introduce MDACE, the first publicly available code evidence dataset, which is built on a subset of the MIMIC-III clinical records. The dataset \u2013 annotated by professional medical coders \u2013 consists of 302 Inpatient charts with 3,934 evidence spans and 52 Profee charts with 5,563 evidence spans. We implemented several evidence extraction methods based on the EffectiveCAN model (Liu et al., 2021) to establish baseline performance on this dataset. MDACE can be used to evaluate code evidence extraction methods for CAC systems, as well as the accuracy and interpretability of deep learning models for multi-label classification. We believe that the release of MDACE will greatly improve the understanding and application of deep learning technologies for medical coding and document classification.",
  "MDACE can be used to evaluate code evidence extraction methods for CAC systems, as well as the accuracy and interpretability of deep learning models for multi-label classification. We believe that the release of MDACE will greatly improve the understanding and application of deep learning technologies for medical coding and document classification.\nAuthors: Hua Cheng, Rana Jafari, April Russell, Russell Klopfer, Edmond Lu, Benjamin Striner, Matthew R. Gormley\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'MDACE is introduced, the first publicly available code evidence dataset, which is built on a subset of the MIMIC-III clinical records and can be used to evaluate code evidence extraction methods for CAC systems, as well as the accuracy and interpretability of deep learning models for multi-label classification.'}",
  "Faculty Name: matt gormley\nMetadata:\nPaperid: ebb3d299213bae89b5d302cc3dfc36573ec83956\nTitle: SummQA at MEDIQA-Chat 2023: In-Context Learning with GPT-4 for Medical Summarization\nYear: 2023\nAbstract: Medical dialogue summarization is challenging due to the unstructured nature of medical conversations, the use of medical terminologyin gold summaries, and the need to identify key information across multiple symptom sets. We present a novel system for the Dialogue2Note Medical Summarization tasks in the MEDIQA 2023 Shared Task. Our approach for sectionwise summarization (Task A) is a two-stage process of selecting semantically similar dialogues and using the top-k similar dialogues as in-context examples for GPT-4. For full-note summarization (Task B), we use a similar solution with k=1.",
  "Our approach for sectionwise summarization (Task A) is a two-stage process of selecting semantically similar dialogues and using the top-k similar dialogues as in-context examples for GPT-4. For full-note summarization (Task B), we use a similar solution with k=1. We achieved 3rd place in Task A (2nd among all teams), 4th place in Task B Division Wise Summarization (2nd among all teams), 15th place in Task A Section Header Classification (9th among all teams), and 8th place among all teams in Task B. Our results highlight the effectiveness of few-shot prompting for this task, though we also identify several weaknesses of prompting-based approaches. We compare GPT-4 performance with several finetuned baselines. We find that GPT-4 summaries are more abstractive and shorter. We make our code publicly available.",
  "We compare GPT-4 performance with several finetuned baselines. We find that GPT-4 summaries are more abstractive and shorter. We make our code publicly available.\nAuthors: Yash Mathur, Sanketh Rangreji, Raghav Kapoor, Medha Palavalli, Amanda Bertsch, Matthew R. Gormley\nVenue: Clinical Natural Language Processing Workshop\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work presents a novel system for the Dialogue2Note Medical Summarization tasks in the MEDIQA 2023 Shared Task, and highlights the effectiveness of few-shot prompting for this task, though it also identifies several weaknesses of prompting-based approaches.'}",
  "List of 2023 Open Access papers by matt gormley are:\nIt\u2019s MBR All the Way Down: Modern Generation Techniques Through the Lens of Minimum Bayes Risk\nUnlimiformer: Long-Range Transformers with Unlimited Length Input\nMDACE: MIMIC Documents Annotated with Code Evidence\nSummQA at MEDIQA-Chat 2023: In-Context Learning with GPT-4 for Medical Summarization",
  "Faculty Name: matthias grabmair\nMetadata:\nPaperid: 1109a51ff68d8c7a09d651d706028e9e380f2af8\nTitle: Joint Span Segmentation and Rhetorical Role Labeling with Data Augmentation for Legal Documents\nYear: 2023\nAbstract: Segmentation and Rhetorical Role Labeling of legal judgements play a crucial role in retrieval and adjacent tasks, including case summarization, semantic search, argument mining etc. Previous approaches have formulated this task either as independent classification or sequence labeling of sentences. In this work, we reformulate the task at span level as identifying spans of multiple consecutive sentences that share the same rhetorical role label to be assigned via classification. We employ semi-Markov Conditional Random Fields (CRF) to jointly learn span segmentation and span label assignment. We further explore three data augmentation strategies to mitigate the data scarcity in the specialized domain of law where individual documents tend to be very long and annotation cost is high. Our experiments demonstrate improvement of span-level prediction metrics with a semi-Markov CRF model over a CRF baseline. This benefit is contingent on the presence of multi sentence spans in the document.",
  "Our experiments demonstrate improvement of span-level prediction metrics with a semi-Markov CRF model over a CRF baseline. This benefit is contingent on the presence of multi sentence spans in the document.\nAuthors: Santosh T.Y.S.S, Philipp Bock, Matthias Grabmair\nVenue: European Conference on Information Retrieval\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work reformulates the task at span level as identifying spans of multiple consecutive sentences that share the same rhetorical role label to be assigned via classification, and employs semi-Markov Conditional Random Fields (CRF) to jointly learn span segmentation and span label assignment.'}",
  "Faculty Name: matthias grabmair\nMetadata:\nPaperid: 5315883bd39a4e4af6332e344bb32d29613b3c97\nTitle: Zero-shot Transfer of Article-aware Legal Outcome Classification for European Court of Human Rights Cases\nYear: 2023\nAbstract: In this paper, we cast Legal Judgment Prediction on European Court of Human Rights cases into an article-aware classification task, where the case outcome is classified from a combined input of case facts and convention articles. This configuration facilitates the model learning some legal reasoning ability in mapping article text to specific case fact text. It also provides an opportunity to evaluate the model\u2019s ability to generalize to zero-shot settings when asked to classify the case outcome with respect to articles not seen during training. We devise zero-shot experiments and apply domain adaptation methods based on domain discrimination and Wasserstein distance. Our results demonstrate that the article-aware architecture outperforms straightforward fact classification. We also find that domain adaptation methods improve zero-shot transfer performance, with article relatedness and encoder pre-training influencing the effect.",
  "We devise zero-shot experiments and apply domain adaptation methods based on domain discrimination and Wasserstein distance. Our results demonstrate that the article-aware architecture outperforms straightforward fact classification. We also find that domain adaptation methods improve zero-shot transfer performance, with article relatedness and encoder pre-training influencing the effect.\nAuthors: Santosh T.Y.S.S, O. Ichim, Matthias Grabmair\nVenue: Findings\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper casts Legal Judgment Prediction on European Court of Human Rights cases into an article-aware classification task, where the case outcome is classified from a combined input of case facts and convention articles, and finds that domain adaptation methods improve zero-shot transfer performance.'}",
  "Faculty Name: matthias grabmair\nMetadata:\nPaperid: 6f11b0542cd8abc51d979e474bbf77676d001859\nTitle: Pervasive Computational Law\nYear: 2023\nAbstract: None\nAuthors: Clement Guitton, Aurelia Tam\u00f3-Larrieux, Simon Mayer, Kevin D. Ashley, Matthias Grabmair, Galileo Sartor, Giovanni Sartor, G. van Dijck\nVenue: IEEE pervasive computing\nTldr: None",
  "Faculty Name: matthias grabmair\nMetadata:\nPaperid: ff28f812113a7082f7d285ed3bf6dcbed49d0320\nTitle: Leveraging Task Dependency and Contrastive Learning for Case Outcome Classification on European Court of Human Rights Cases\nYear: 2023\nAbstract: We report on an experiment in case outcome classification on European Court of Human Rights cases where our model first learns to identify the convention articles allegedly violated by the state from case facts descriptions, and subsequently uses that information to classify whether the court finds a violation of those articles. We assess the dependency between these two tasks at the feature and outcome level. Furthermore, we leverage a hierarchical contrastive loss to pull together article-specific representations of cases at the higher level, leading to distinctive article clusters. The cases in each article cluster are further pulled closer based on their outcome, leading to sub-clusters of cases with similar outcomes. Our experiment results demonstrate that, given a static pre-trained encoder, our models produce a small but consistent improvement in classification performance over single-task and joint models without contrastive loss.",
  "The cases in each article cluster are further pulled closer based on their outcome, leading to sub-clusters of cases with similar outcomes. Our experiment results demonstrate that, given a static pre-trained encoder, our models produce a small but consistent improvement in classification performance over single-task and joint models without contrastive loss.\nAuthors: Santosh T.Y.S.S, Santosh T.Y.S.S, Phillip Kemper, Matthias Grabmair\nVenue: Conference of the European Chapter of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': None}",
  "List of 2023 Open Access papers by matthias grabmair are:\nPervasive Computational Law\nJoint Span Segmentation and Rhetorical Role Labeling with Data Augmentation for Legal Documents\nZero-shot Transfer of Article-aware Legal Outcome Classification for European Court of Human Rights Cases\nLeveraging Task Dependency and Contrastive Learning for Case Outcome Classification on European Court of Human Rights Cases",
  "Title: Michael Mauldin -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Michael Mauldin, Adjunct Faculty at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Adjunct Faculty\" name=\"categories-1\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Michael Mauldin - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Michael Mauldin, Adjunct Faculty at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Michael\"/>\n<meta content=\"Lastname\" property=\"profile:Mauldin\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/mauldin-michael.",
  "cmu.edu//people/faculty/mauldin-michael.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nMichael \n                        Mauldin\nAdjunct Research Computer Scientist, Language Technologies Institute\nInventor, Lycos, Inc. Early Internet Search Engine\nContact\nfuzzy(through)lazytoad.com\nPersonal Website\n\nLinks:\nhttps://lazytoad.com/lti/",
  "Title: Florian Metze -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio page for Florian Metze\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Adjunct Faculty\" name=\"categories-1\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Florian Metze - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio page for Florian Metze\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Florian\"/>\n<meta content=\"Lastname\" property=\"profile:Metze\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/metze-florian.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.",
  "cmu.edu//people/faculty/metze-florian.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nFlorian \n                        Metze\nAdjunct Professor, Language Technologies Institute\nContact\nfmetze(through)andrew.cmu.edu\nAddress\n5000 Forbes Avenue\nPittsburgh, PA 15213\n\nLinks:",
  "List of 2023 Open Access papers by michael mauldin are:",
  "List of 2023 Open Access papers by michael shamos are:",
  "Title: Teruko Mitamura -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Teruko Mitamura, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Core Faculty\" name=\"categories-1\"/>\n<meta content=\"Information Extraction, Summarization and Question Answering;Information Retrieval, Text Mining and Analytics;Language Technologies for Education;Natural Language Processing and Computational Linguistics\" name=\"categories-2\"/>\n<meta content=\"Yes\" name=\"show-categories-2\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Teruko Mitamura - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Teruko Mitamura,",
  "Faculty Member at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Teruko\"/>\n<meta content=\"Lastname\" property=\"profile:Mitamura\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/mitamura-teruko.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nTeruko \n                        Mitamura\nResearch Professor, Language Technologies Institute\nContact\n6711 \u2014Gates & Hillman Centers\nteruko(through)cs.cmu.edu\n412-268-6596\nResearch Area\nInformation Extraction, Summarization and Question Answering, Information Retrieval, Text Mining and Analytics, Language Technologies for Education, Natural Language Processing and Computational Linguistics\nPersonal Website\n\nLinks:\nhttp://www.cs.cmu.edu/~teruko/",
  "Title: Tom MItchell -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Tom Mitchell, Affiliated Faculty at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Affiliated Faculty\" name=\"categories-1\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Tom MItchell - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Tom Mitchell, Affiliated Faculty at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Tom\"/>\n<meta content=\"Lastname\" property=\"profile:Mitchell\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/mitchell-tom.",
  "cmu.edu//people/faculty/mitchell-tom.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nTom \n                        Mitchell\nE. Fredkin University Professor, Machine Learning\nLanguage Technologies Institute\nContact\n8211 \u2014Gates & Hillman Centers\nmitchell(through)andrew.cmu.edu\n412-268-2611\nResearch\nI am interested in many areas of computer science, but especially in how to construct computers that learn from experience.\u00a0 At the heart of the problem of machine learning is the question of how to automatically formulate general hypotheses given a collection of very specific training examples. My research has addressed a number of approaches to this question, including statistical approaches that find regularities over large numbers of training examples, and analytical approaches that generalize from very few examples and rely instead on prior knowledge and reasoning.\nMuch of my current research focuses around two projects:\nMachine learning approaches to analyzing human brain activity.",
  "My research has addressed a number of approaches to this question, including statistical approaches that find regularities over large numbers of training examples, and analytical approaches that generalize from very few examples and rely instead on prior knowledge and reasoning.\nMuch of my current research focuses around two projects:\nMachine learning approaches to analyzing human brain activity.\nThis project uses functional Magnetic Resonance Imaging (fMRI) to capture three-dimensional images of human brain activity at a spatial resolution of 1mm, once per second.\u00a0 This is a wonderful set of data for studying the operation of the human brain, and because it is relatively new, there is a great need for new algorithms to analyze the data.\u00a0 Recently we have demonstrated that it is possible to train machine learning algorithms to decode mental states of human subjects (e.g., to determine whether the word a person is examining is a noun or a verb) based on their observed fMRI brain activity.\u00a0 I am interested in developing new algorithms that will help discover the spatial-temporal patterns of activity associated with a variety of brain processes, and that will help us better understand the working of the human brain.",
  "I am interested in developing new algorithms that will help discover the spatial-temporal patterns of activity associated with a variety of brain processes, and that will help us better understand the working of the human brain.\u00a0 We have access to the CMU-University of Pittsburgh\u00a0 Brain Imaging Research Center, to design and collect data for our own experiments.This project raises interesting machine learning questions such as how to train classifiers in extremely high dimensional, noisy data, and how to learn temporal models that characterize the evolution of hidden cognitive states while humans perform tasks such as reading and answering questions.\nIntelligent workstation assistants that learn to help their users.\nThis is part of a large multi-researcher project to build enduring, personalized, learning assistants for users of computer workstations (like us!).\u00a0 We are working toward a software agent that can understand the user's email, calendar, text files, and actions, and that can learn the user's interests, habits, and tasks, in order to help in a wide range of activities.\u00a0 My specific interest lies in how to make the agent learn.",
  "We are working toward a software agent that can understand the user's email, calendar, text files, and actions, and that can learn the user's interests, habits, and tasks, in order to help in a wide range of activities.\u00a0 My specific interest lies in how to make the agent learn.\u00a0 For example, I am currently interested in the question of how the agent can learn to automatically extract information from text emails and files, and how it can learn what threads of activities the user is involved in, when, with whom, about what, etc.\u00a0 This project raises many interesting machine learning questions about learning from labeled and unlabeled data, about learning and statistical language processing, and about cummulative learning over long periods of time.\nMachine Learning Department\nPersonal Website\n\nLinks:\nhttps://www.ml.cmu.edu/\nhttp://www.cs.cmu.edu/~tom/",
  "Faculty Name: mona diab\nMetadata:\nPaperid: 0a94fbb5e1c93513523f00e75d672ef4553861f9\nTitle: Can Large Language Models Infer Causation from Correlation?\nYear: 2023\nAbstract: Causal inference is one of the hallmarks of human intelligence. While the field of CausalNLP has attracted much interest in the recent years, existing causal inference datasets in NLP primarily rely on discovering causality from empirical knowledge (e.g., commonsense knowledge). In this work, we propose the first benchmark dataset to test the pure causal inference skills of large language models (LLMs). Specifically, we formulate a novel task Corr2Cause, which takes a set of correlational statements and determines the causal relationship between the variables. We curate a large-scale dataset of more than 200K samples, on which we evaluate seventeen existing LLMs. Through our experiments, we identify a key shortcoming of LLMs in terms of their causal inference skills, and show that these models achieve almost close to random performance on the task.",
  "We curate a large-scale dataset of more than 200K samples, on which we evaluate seventeen existing LLMs. Through our experiments, we identify a key shortcoming of LLMs in terms of their causal inference skills, and show that these models achieve almost close to random performance on the task. This shortcoming is somewhat mitigated when we try to re-purpose LLMs for this skill via finetuning, but we find that these models still fail to generalize -- they can only perform causal inference in in-distribution settings when variable names and textual expressions used in the queries are similar to those in the training set, but fail in out-of-distribution settings generated by perturbing these queries. Corr2Cause is a challenging task for LLMs, and would be helpful in guiding future research on improving LLMs' pure reasoning skills and generalizability. Our data is at https://huggingface.co/datasets/causalnlp/corr2cause. Our code is at https://github.com/causalNLP/corr2cause.",
  "Our data is at https://huggingface.co/datasets/causalnlp/corr2cause. Our code is at https://github.com/causalNLP/corr2cause.\nAuthors: Zhijing Jin, Jiarui Liu, Zhiheng Lyu, Spencer Poff, Mrinmaya Sachan, Rada Mihalcea, Mona T. Diab, B. Sch\u00f6lkopf\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes the first benchmark dataset to test the pure causal inference skills of large language models (LLMs), and formulates a novel task Corr2Cause, which takes a set of correlational statements and determines the causal relationship between the variables.'}",
  "Faculty Name: mona diab\nMetadata:\nPaperid: 11ff985b42649154d87015b8a4c2cf07abf82fef\nTitle: A bleeding bite: crotalinae snake envonamation\nYear: 2023\nAbstract: None\nAuthors: M. Osman, M. A. Diab, B. Mohanakrishnan, M. Elmahi, A. Islam\nVenue: American Journal of the Medical Sciences\nTldr: None",
  "Faculty Name: mona diab\nMetadata:\nPaperid: 27b69c63d3ca627e64da78b8e5ef0c49b2840ea6\nTitle: Comparison of the structures and topologies of plasma extracted circulating nuclear and mitochondrial cell-free DNA\nYear: 2023\nAbstract: Introduction: The function, origin and structural features of circulating nuclear DNA (cir-nDNA) and mitochondrial DNA (cir-mtDNA) are poorly known, even though they have been investigated in numerous clinical studies, and are involved in a number of routine clinical applications. Based on our previous report disproving the conventional plasma isolation used for cirDNA analysis, this work enables a direct topological comparison of the circulating structures associated with nuclear DNA and mitochondrial cell-free DNA. Materials and methods: We used a Q-PCR and low-pass whole genome sequencing (LP-WGS) combination approach of cir-nDNA and cir-mtDNA, extracted using a procedure that eliminates platelet activation during the plasma isolation process to prevent mitochondria release in the extracellular milieu. Various physical procedures, such as filtration and differential centrifugation, were employed to infer their circulating structures.",
  "Various physical procedures, such as filtration and differential centrifugation, were employed to infer their circulating structures. Results: DSP-S cir-mtDNA mean size profiles distributed on a slightly shorter range than SSP-S. SSP-S detected 40-fold more low-sized cir-mtDNA fragments (<90 bp/nt) and three-fold less long-sized fragments (>200 bp/nt) than DSP-S. The ratio of the fragment number below 90 bp over the fragment number above 200 bp was very homogenous among both DSP-S and SSP-S profiles, being 134-fold lower with DSP-S than with SSP-S. Cir-mtDNA and cir-nDNA DSP-S and SSP-S mean size profiles of healthy individuals ranged in different intervals with periodic sub-peaks only detectable with cir-nDNA. The very low amount of cir-mtDNA fragments of short size observed suggested that most of the cir-mtDNA is poorly fragmented and appearing longer than \u223c1,000 bp, the readout limit of this LP-WGS method.",
  "The very low amount of cir-mtDNA fragments of short size observed suggested that most of the cir-mtDNA is poorly fragmented and appearing longer than \u223c1,000 bp, the readout limit of this LP-WGS method. Data suggested that cir-nDNA is, among DNA extracted in plasma, associated with \u223c8.6% of large structures (apoptotic bodies, large extracellular vesicles (EVs), cell debris\u2026), \u223c27.7% in chromatin and small EVs and \u223c63.7% mainly in oligo- and mono-nucleosomes. By contrast, cir-mtDNA appeared to be preponderantly (75.7%) associated with extracellular mitochondria, either in its free form or with large EVs; to a lesser extent, it was also associated with other structures: small EVs (\u223c18.4%), and exosomes or protein complexes (\u223c5.9%). Conclusion: This is the first study to directly compare the structural features of cir-nDNA and cir-mtDNA.",
  "Conclusion: This is the first study to directly compare the structural features of cir-nDNA and cir-mtDNA. The significant differences revealed between both are due to the DNA topological structure contained in the nucleus (chromatin) and in the mitochondria (plasmid) that determine their biological stability in blood. Although cir-nDNA and cir-mtDNA are principally associated with mono-nucleosomes and cell-free mitochondria, our study highlights the diversity of the circulating structures associated with cell-free DNA. They consequently have different pharmacokinetics as well as physiological functions. Thus, any accurate evaluation of their biological or diagnostic individual properties must relies on appropriate pre-analytics, and optimally on the isolation or enrichment of one category of their cirDNA associated structures.",
  "They consequently have different pharmacokinetics as well as physiological functions. Thus, any accurate evaluation of their biological or diagnostic individual properties must relies on appropriate pre-analytics, and optimally on the isolation or enrichment of one category of their cirDNA associated structures.\nAuthors: E. Pisareva, Benoit Roch, Cynthia Sanchez, B. Pastor, Alexia Mirandola, M. Diab\u2010Assaf, T. Mazard, C. Pr\u00e9vostel, Zahra Al Amir Dache, Alain R. Thierry\nVenue: Frontiers in Genetics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This is the first study to directly compare the structural features of cir-nDNA and cir-mtDNA, and highlights the diversity of the circulating structures associated with cell-free DNA.'}",
  "Faculty Name: mona diab\nMetadata:\nPaperid: 3503a4c6163197136bbd880c9db514e8c01b6936\nTitle: Cytomegalovirus at the crossroads of immunosenescence and oncogenesis\nYear: 2023\nAbstract: Human cytomegalovirus (HCMV), whose genome is around 235 kb, is a ubiquitous human herpesvirus that infects between 40% and 95% of the population. Though HCMV infection is commonly asymptomatic and leads to subtle clinical symptoms, it can promote robust immune responses and establish lifelong latency. In addition, in immunocompromised hosts, including individuals with acquired immunodeficiency syndrome (AIDS), transplant recipients, and developing fetuses it can lead to severe diseases. Immunosenescence, well-defined as the alterations in the immune system, is linked mainly to aging and has been recently gathering considerable attention.",
  "Immunosenescence, well-defined as the alterations in the immune system, is linked mainly to aging and has been recently gathering considerable attention. Senescence was characterized by an elevated inflammation and hence considered a powerful contributor to \u201cinflammaging\u201d that is measured mainly by tumor necrosis factor-\u03b1 (TNF-\u03b1), interleukin-6 (IL-6), and C-reactive protein (CRP) levels as well as latent viral infections, for instance, cytomegalovirus (CMV). Inflammaging resulted in a senescence-associated secretory phenotype (SASP). HCMV is markedly associated with accelerated aging of the immune system as well as several age-associated diseases that accumulate and subsequently deteriorate the immune responses, thus have been linked to mortality, declined vaccine efficacy, serious diseases, and tumors in the elderly. HCMV triggers or exacerbates immunosenescence; on the other hand, the weakened immune responses and inflammaging favor viral reactivation and highlight the role of HCMV in aging as well as viral-associated tumors. HCMV reactivation resulting in sequential lytic and latent viral cycles could contribute to HCMV genomic variability.",
  "HCMV reactivation resulting in sequential lytic and latent viral cycles could contribute to HCMV genomic variability. Besides the oncomodulatory role and transforming capacities of HCMV, the immune-privileged tumor microenvironment has been considered the main element in tumor progression and aggressiveness. Therefore, the interplay between HCMV, immunosenescence, and cancer will aid in discovering new therapeutic approaches that target HCMV and act as immune response boosters mainly to fight cancers of poor prognosis, particularly in the elderly population.\nAuthors: Fidaa Bouezzedine, Ranim El Baba, S. Morot-Bizot, M. Diab\u2010Assaf, G. Herbein\nVenue: Exploration of Immunology\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The interplay between HCMV, immunosenescence, and cancer will aid in discovering new therapeutic approaches that target H CMV and act as immune response boosters mainly to fight cancers of poor prognosis, particularly in the elderly population.'}",
  "Faculty Name: mona diab\nMetadata:\nPaperid: 4286d07449447f3bfffc1eeb2ee0de9b00dfadfd\nTitle: ALERT: Adapt Language Models to Reasoning Tasks\nYear: 2023\nAbstract: None\nAuthors: Ping Yu, Tianlu Wang, O. Yu. Golovneva, Badr AlKhamissi, Siddharth Verma, Zhijing Jin, Gargi Ghosh, Mona T. Diab, Asli Celikyilmaz\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The extensive empirical analysis shows that language models learn more reasoning skills such as textual entailment, abductive reasoning, and analogical reasoning during the finetuning stage compared to pretraining stage, but also finds that when language models are finetuned they tend to overfit to the prompt template, which hurts the robustness of models causing generalization problems.'}",
  "Faculty Name: mona diab\nMetadata:\nPaperid: 45f7ab2dd1bd86703f3fc0f713d35851ae15b038\nTitle: Author Correction: Arabic natural language processing for Qur\u2019anic research: a systematic review\nYear: 2023\nAbstract: None\nAuthors: M. Bashir, Aqil M. Azmi, H. Nawaz, W. Zaghouani, Mona T. Diab, Ala I. Al-Fuqaha, Junaid Qadir\nVenue: Artificial Intelligence Review\nTldr: None",
  "Faculty Name: mona diab\nMetadata:\nPaperid: 4674d83e0c54a9a7b6833121cc2f40cd21f2579c\nTitle: PAMR1 negatively impacts cell proliferation and migration of Human Colon Cancer HT29 Cell Line\nYear: 2023\nAbstract: Colorectal cancer (CRC) is becoming one of the most prevalent cancers worldwide. Among cancers, it ranks the third place in terms of incidence and the second in terms of mortality. Even though immunological test allows fast and easy diagnostic method, there is no specific and reliable methods for early detection of CRC. Despite different treatments, high risk of re-occurrence is associated with advanced and metastatic CRC stages. An exhaustive knowledge on specific biomarkers or molecular actors involved in CRC could help to eradicate tumors or limit cancer recurrence. In this study, we focused on PAMR1 (Peptidase Domain Containing Associated with Muscle Regeneration 1), which is already considered as a tumor suppressor in breast and cervical cancers.",
  "In this study, we focused on PAMR1 (Peptidase Domain Containing Associated with Muscle Regeneration 1), which is already considered as a tumor suppressor in breast and cervical cancers. In silico analysis of RNASeq data showed that PAMR1 was significantly downregulated in CRC tissues compared to their adjacent normal ones, as well as in cervical cancer. Our analysis showed that this downregulation, probably due to promoter hypermethylation, such as in breast cancer tissues, appeared in the four cancer stages as early as the first stage. In consistency with in silico analyses, the expression of PAMR1 was found to be lower at the transcript and protein levels in CRC tissue samples compared to normal ones, as well as in different CRC cell lines (HCT116, HT29, and SW620) compared to normal colon cell line (CCD841CoN).",
  "To understand the role of PAMR1 in CRC cancer, recombinant purified PAMR1 or concentrated secretome from CHO overexpressing PAMR1 were used to exogenously treat CRC cell lines with a focus on HT-29 cells as well as Hela cervical cancer cell line known to be sensitive to PAMR1. Transient or stable transfections were also performed to determine the impact of PAMR1 overexpression in HT29 and/or HeLa cells. In this study, we finally showed that presence of PAMR1 could reduce both cell proliferation and cell migration with a positive correlation between these biological effects and PAMR1\u2019s quantity. This implies that PAMR1 expresses anti-proliferative and anti-migrative effects in CRC. Further studies to be done in order to confirm the tumor suppressive role of PAMR1 in CRC.",
  "This implies that PAMR1 expresses anti-proliferative and anti-migrative effects in CRC. Further studies to be done in order to confirm the tumor suppressive role of PAMR1 in CRC.\nAuthors: Layla Haymour, A. Chaunavel, Mona Diab Assaf, A. Maftah, S\u00e9bastien Legardinier\nVenue: bioRxiv\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is shown that presence of PAMR1 could reduce both cell proliferation and cell migration with a positive correlation between these biological effects and PAMr1\u2019s quantity, which implies that PamR1 expresses anti-proliferative and anti-migrative effects in CRC.'}",
  "Faculty Name: mona diab\nMetadata:\nPaperid: 4bb86a709eb9f47242f8b7f93e9a9c24bdb74870\nTitle: Aspalathus linearis (Rooibos) Targets Adipocytes and Obesity-Associated Inflammation\nYear: 2023\nAbstract: Excess weight and obesity are the fifth leading cause of death globally, and sustained efforts from health professionals and researchers are required to mitigate this pandemic-scale problem. Polyphenols and flavonoids found in Aspalathus linearis\u2014a plant widely consumed as Rooibos tea\u2014are increasingly being investigated for their positive effects on various health issues including inflammation. The aim of our study was to examine the effect of Rooibos extract on obesity and the associated low-grade chronic inflammatory state by testing antioxidant activity, cytokine secretions, macrophage polarization and the differentiation of human adipocytes through the development of adipospheroids. Rooibos extract significantly decreased ROS production and the secretion of pro-inflammatory cytokines (IFN-\u03b3, IL-12, IL-2 and IL-17a) in human leukocytes.",
  "Rooibos extract significantly decreased ROS production and the secretion of pro-inflammatory cytokines (IFN-\u03b3, IL-12, IL-2 and IL-17a) in human leukocytes. Additionally, Rooibos extract down-regulated LPS-induced macrophage M1 polarization, shown by a significant decrease in the expression of pro-inflammatory cytokines: TNF\u03b1, IL-8, IL-6, IL-1\u03b2 and CXCL10. In addition, Rooibos inhibited intracellular lipid accumulation and reduced adipogenesis by decreasing the expression of PPAR\u03b3, Ap2 and HSL in adipospheroids. A significant decrease in leptin expression was noted and this, more interestingly, was accompanied by a significant increase in adiponectin expression. Using a co-culture system between macrophages and adipocytes, Rooibos extract significantly decreased the expression of all studied pro-inflammatory cytokines and particularly leptin, and increased adiponectin expression. Thus, adding Rooibos tea to the daily diet is likely to prevent the development of obesity associated with chronic low-level inflammation.",
  "Thus, adding Rooibos tea to the daily diet is likely to prevent the development of obesity associated with chronic low-level inflammation.\nAuthors: Rawan Nehme, A. Chervet, C. Decombat, L. Longechamp, A. Rossary, Rebecca Boutin, A. Rousset, F. S\u00e9n\u00e9joux, Caroline Vachias, C. Auxenfans, D. Fraisse, Jean-Baptiste Guyon, E. Filaire, J. Berthon, M. Diab\u2010Assaf, L. Delort, F. Caldefie-Ch\u00e9zet\nVenue: Nutrients\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Rooibos extract significantly decreased the expression of all studied pro-inflammatory cytokines and particularly leptin, and increased adiponectin expression, likely to prevent the development of obesity associated with chronic low-level inflammation.'}",
  "Faculty Name: mona diab\nMetadata:\nPaperid: 5e2f8088647e357bb6440d271ed1fcc4d5ed7e7c\nTitle: Care4Lang at MEDIQA-Chat 2023: Fine-tuning Language Models for Classifying and Summarizing Clinical Dialogues\nYear: 2023\nAbstract: Summarizing medical conversations is one of the tasks proposed by MEDIQA-Chat to promote research on automatic clinical note generation from doctor-patient conversations. In this paper, we present our submission to this task using fine-tuned language models, including T5, BART and BioGPT models. The fine-tuned models are evaluated using ensemble metrics including ROUGE, BERTScore andBLEURT. Among the fine-tuned models, Flan-T5 achieved the highest aggregated score for dialogue summarization.",
  "The fine-tuned models are evaluated using ensemble metrics including ROUGE, BERTScore andBLEURT. Among the fine-tuned models, Flan-T5 achieved the highest aggregated score for dialogue summarization.\nAuthors: Amal AlQahtani, R. Salama, Mona T. Diab, Abdou Youssef\nVenue: Clinical Natural Language Processing Workshop\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper presents their submission to this task using fine-tuned language models, including T5, BART and BioGPT models, and finds Flan-T5 achieved the highest aggregated score for dialogue summarization.'}",
  "Faculty Name: mona diab\nMetadata:\nPaperid: 81513416b80f753166e224b34b599e9385980a97\nTitle: Emerging Therapeutic Approaches to Target the Dark Side of Senescent Cells: New Hopes to Treat Aging as a Disease and to Delay Age-Related Pathologies\nYear: 2023\nAbstract: Life expectancy has drastically increased over the last few decades worldwide, with important social and medical burdens and costs. To stay healthy longer and to avoid chronic disease have become essential issues. Organismal aging is a complex process that involves progressive destruction of tissue functionality and loss of regenerative capacity. One of the most important aging hallmarks is cellular senescence, which is a stable state of cell cycle arrest that occurs in response to cumulated cell stresses and damages. Cellular senescence is a physiological mechanism that has both beneficial and detrimental consequences. Senescence limits tumorigenesis, lifelong tissue damage, and is involved in different biological processes, such as morphogenesis, regeneration, and wound healing.",
  "Cellular senescence is a physiological mechanism that has both beneficial and detrimental consequences. Senescence limits tumorigenesis, lifelong tissue damage, and is involved in different biological processes, such as morphogenesis, regeneration, and wound healing. However, in the elderly, senescent cells increasingly accumulate in several organs and secrete a combination of senescence associated factors, contributing to the development of various age-related diseases, including cancer. Several studies have revealed major molecular pathways controlling the senescent phenotype, as well as the ones regulating its interactions with the immune system. Attenuating the senescence-associated secretory phenotype (SASP) or eliminating senescent cells have emerged as attractive strategies aiming to reverse or delay the onset of aging diseases. Here, we review current senotherapies designed to suppress the deleterious effect of SASP by senomorphics or to selectively kill senescent cells by \u201csenolytics\u201d or by immune system-based approaches. These recent investigations are promising as radical new controls of aging pathologies and associated multimorbidities.",
  "These recent investigations are promising as radical new controls of aging pathologies and associated multimorbidities.\nAuthors: Roula Khalil, M. Diab\u2010Assaf, J. Lema\u00eetre\nVenue: Cells\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Current senotherapies designed to suppress the deleterious effect of SASP by senomorphics or to selectively kill senescent cells by \u201csenolytics\u201d or by immune system-based approaches are reviewed.'}",
  "Faculty Name: mona diab\nMetadata:\nPaperid: 99bfe503743c5ec8e16e50ab8438159cdb533a89\nTitle: The Troubling Emergence of Hallucination in Large Language Models - An Extensive Definition, Quantification, and Prescriptive Remediations\nYear: 2023\nAbstract: The recent advancements in Large Language Models (LLMs) have garnered widespread acclaim for their remarkable emerging capabilities. However, the issue of hallucination has parallelly emerged as a by-product, posing significant concerns. While some recent endeavors have been made to identify and mitigate different types of hallucination, there has been a limited emphasis on the nuanced categorization of hallucination and associated mitigation methods. To address this gap, we offer a fine-grained discourse on profiling hallucination based on its degree, orientation, and category, along with offering strategies for alleviation. As such, we define two overarching orientations of hallucination: (i) factual mirage (FM) and (ii) silver lining (SL).",
  "As such, we define two overarching orientations of hallucination: (i) factual mirage (FM) and (ii) silver lining (SL). To provide a more comprehensive understanding, both orientations are further sub-categorized into intrinsic and extrinsic, with three degrees of severity - (i) mild, (ii) moderate, and (iii) alarming. We also meticulously categorize hallucination into six types: (i) acronym ambiguity, (ii) numeric nuisance, (iii) generated golem, (iv) virtual voice, (v) geographic erratum, and (vi) time wrap. Furthermore, we curate HallucInation eLiciTation (HILT), a publicly available dataset comprising of 75,000 samples generated using 15 contemporary LLMs along with human annotations for the aforementioned categories. Finally, to establish a method for quantifying and to offer a comparative spectrum that allows us to evaluate and rank LLMs based on their vulnerability to producing hallucinations, we propose Hallucination Vulnerability Index (HVI). We firmly believe that HVI holds significant value as a tool for the wider NLP community, with the potential to serve as a rubric in AI-related policy-making.",
  "We firmly believe that HVI holds significant value as a tool for the wider NLP community, with the potential to serve as a rubric in AI-related policy-making. In conclusion, we propose two solution strategies for mitigating hallucinations.\nAuthors: Vipula Rawte, Swagata Chakraborty, Agnibh Pathak, Anubhav Sarkar, S.M. Towhidul Islam Tonmoy, Islam Tonmoy, Aman Chadha, Amit P. Sheth, Amitava Das, Paris, A. Sridhar, Erik Visser, Improved, Jianlin Su, Yu Lu, Shengfeng Pan, Ahmed Murtadha, Bo Wen, Yunfeng Liu, Roformer, Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, Tatsunori Hashimoto, Stanford, Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth\u00e9e Lacroix, Baptiste Rozi\u00e8re, Naman Goyal, Eric Hambro,",
  "Percy Liang, Tatsunori Hashimoto, Stanford, Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timoth\u00e9e Lacroix, Baptiste Rozi\u00e8re, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, R\u00e9mi Louf, Morgan Funtow-icz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, Susan Zhang, Stephen Roller, Mikel Artetxe, Moya Chen, Shuohui Chen, Christopher De-wan, Mona T. Diab, Xi Xian Li, Todor Victoria Lin, Myle Ott, Kurt Shuster, Punit Daniel Simig, Singh Koura, Anjali Sridhar, Tianlu Wang,",
  "Moya Chen, Shuohui Chen, Christopher De-wan, Mona T. Diab, Xi Xian Li, Todor Victoria Lin, Myle Ott, Kurt Shuster, Punit Daniel Simig, Singh Koura, Anjali Sridhar, Tianlu Wang, Luke Zettlemoyer. 2022, Daniel M. Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B. Brown, Alec Radford, Dario Amodei, Paul F. Chris-tiano\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work defines two overarching orientations of hallucination and proposes two solution strategies for mitigating hallucinations, and firmly believes that HVI holds significant value as a tool for the wider NLP community, with the potential to serve as a rubric in AI-related policy-making.'}",
  "Faculty Name: mona diab\nMetadata:\nPaperid: bcfbcbbe128ee74e39cb8698e5dfd6047b690487\nTitle: Crosstalk of Inflammatory Cytokines within the Breast Tumor Microenvironment\nYear: 2023\nAbstract: Several immune and immunocompetent cells, including dendritic cells, macrophages, adipocytes, natural killer cells, T cells, and B cells, are significantly correlated with the complex discipline of oncology. Cytotoxic innate and adaptive immune cells can block tumor proliferation, and others can prevent the immune system from rejecting malignant cells and provide a favorable environment for tumor progression. These cells communicate with the microenvironment through cytokines, a chemical messenger, in an endocrine, paracrine, or autocrine manner. These cytokines play an important role in health and disease, particularly in host immune responses to infection and inflammation.",
  "These cells communicate with the microenvironment through cytokines, a chemical messenger, in an endocrine, paracrine, or autocrine manner. These cytokines play an important role in health and disease, particularly in host immune responses to infection and inflammation. They include chemokines, interleukins (ILs), adipokines, interferons, colony-stimulating factors (CSFs), and tumor necrosis factor (TNF), which are produced by a wide range of cells, including immune cells, such as macrophages, B-cells, T-cells, and mast cells, as well as endothelial cells, fibroblasts, a variety of stromal cells, and some cancer cells. Cytokines play a crucial role in cancer and cancer-related inflammation, with direct and indirect effects on tumor antagonistic or tumor promoting functions. They have been extensively researched as immunostimulatory mediators to promote the generation, migration and recruitment of immune cells that contribute to an effective antitumor immune response or pro-tumor microenvironment.",
  "They have been extensively researched as immunostimulatory mediators to promote the generation, migration and recruitment of immune cells that contribute to an effective antitumor immune response or pro-tumor microenvironment. Thus, in many cancers such as breast cancer, cytokines including leptin, IL-1B, IL-6, IL-8, IL-23, IL-17, and IL-10 stimulate while others including IL-2, IL-12, and IFN-\u03b3, inhibit cancer proliferation and/or invasion and enhance the body\u2019s anti-tumor defense. Indeed, the multifactorial functions of cytokines in tumorigenesis will advance our understanding of cytokine crosstalk pathways in the tumor microenvironment, such as JAK/STAT, PI3K, AKT, Rac, MAPK, NF-\u03baB, JunB, cFos, and mTOR, which are involved in angiogenesis, cancer proliferation and metastasis. Accordingly, targeting and blocking tumor-promoting cytokines or activating and amplifying tumor-inhibiting cytokines are considered cancer-directed therapies.",
  "Accordingly, targeting and blocking tumor-promoting cytokines or activating and amplifying tumor-inhibiting cytokines are considered cancer-directed therapies. Here, we focus on the role of the inflammatory cytokine system in pro- and anti-tumor immune responses, discuss cytokine pathways involved in immune responses to cancer and some anti-cancer therapeutic applications.\nAuthors: Ola Habanjar, R. Bingula, C. Decombat, M. Diab\u2010Assaf, F. Caldefie-Ch\u00e9zet, L. Delort\nVenue: International Journal of Molecular Sciences\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The role of the inflammatory cytokine system in pro- and anti-tumor immune responses is focused on, and cytokine pathways involved in immune responses to cancer and some anti-cancer therapeutic applications are discussed.'}",
  "Faculty Name: mona diab\nMetadata:\nPaperid: c218cd1772999517b137bbbc9872c4f67e540b7f\nTitle: OPT-R: Exploring the Role of Explanations in Finetuning and Prompting for Reasoning Skills of Large Language Models\nYear: 2023\nAbstract: We conduct a thorough investigation into the reasoning capabilities of Large Language Models (LLMs), focusing specifically on the Open Pretrained Transformers (OPT) models as a representative of such models. Our study entails finetuning three different sizes of OPT on a carefully curated reasoning corpus, resulting in two sets of finetuned models: OPT-R, finetuned without explanations, and OPT-RE, finetuned with explanations. We then evaluate all models on 57 out-of-domain tasks drawn from the Super-NaturalInstructions benchmark, covering 26 distinct reasoning skills, utilizing three prompting techniques. Through a comprehensive grid of 27 configurations and 6,156 test evaluations, we investigate the dimensions of finetuning, prompting, and scale to understand the role of explanations on different reasoning skills.",
  "Through a comprehensive grid of 27 configurations and 6,156 test evaluations, we investigate the dimensions of finetuning, prompting, and scale to understand the role of explanations on different reasoning skills. Our findings reveal that having explanations in the fewshot exemplar has no significant impact on the model\u2019s performance when the model is finetuned, while positively affecting the non-finetuned counterpart. Moreover, we observe a slight yet consistent increase in classification accuracy as we incorporate explanations during prompting and finetuning, respectively. Finally, we offer insights on which reasoning skills benefit the most from incorporating explanations during finetuning and prompting, such as Numerical (+20.4%) and Analogical (+13.9%) reasoning, as well as skills that exhibit negligible or negative effects.",
  "Finally, we offer insights on which reasoning skills benefit the most from incorporating explanations during finetuning and prompting, such as Numerical (+20.4%) and Analogical (+13.9%) reasoning, as well as skills that exhibit negligible or negative effects.\nAuthors: Badr AlKhamissi, Siddharth Verma, Ping Yu, Zhijing Jin, Asli Celikyilmaz, Mona T. Diab\nVenue: NLRSE\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is revealed that having explanations in the fewshot exemplar has no significant impact on the model\u2019s performance when the model is finetuned, while positively affecting the non-finetuned counterpart, and a slight yet consistent increase in classification accuracy as the authors incorporate explanations during prompting and finetuning.'}",
  "Faculty Name: mona diab\nMetadata:\nPaperid: c5849f406e8263806a84e1a407ec0e0fe131bd5c\nTitle: Evaluating Multilingual Speech Translation under Realistic Conditions with Resegmentation and Terminology\nYear: 2023\nAbstract: We present the ACL 60/60 evaluation sets for multilingual translation of ACL 2022 technical presentations into 10 target languages. This dataset enables further research into multilingual speech translation under realistic recording conditions with unsegmented audio and domain-specific terminology, applying NLP tools to text and speech in the technical domain, and evaluating and improving model robustness to diverse speaker demographics.\nAuthors: Elizabeth Salesky, Kareem Darwish, Mohamed Al-Badrashiny, Mona T. Diab, J. Niehues\nVenue: International Workshop on Spoken Language Translation\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This dataset enables further research into multilingual speech translation under realistic recording conditions with unsegmented audio and domain-specific terminology, applying NLP tools to text and speech in the technical domain, and evaluating and improving model robustness to diverse speaker demographics.'}",
  "Faculty Name: mona diab\nMetadata:\nPaperid: e818b74b7415fb43deeb80c1a33ffd5be76abed4\nTitle: A Combination of Ruthenium Complexes and Photosensitizers to Treat Colorectal Cancer\nYear: 2023\nAbstract: Treatment regimens are regularly evolving alongside novel therapies and drugs. Such evolution is necessary to circumvent resistance mechanisms and to give patients the best possible health care. When dealing with cancer, most regimens involve multiple treatments (surgery, radiation therapy, chemotherapy, immunotherapy, etc.). The purpose of this study was to associate in a single compound metal-based drugs and photosensitizers to combine chemotherapy and photodynamic therapy. Two arene\u2013ruthenium tetrapyridylporphyrin compounds (2H-TPyP-arene-Ru and Zn-TPyP-arene-Ru) have been synthesized and evaluated on two colorectal cancer cell lines (HCT116 and HT-29). Their cytotoxicity and phototoxicity have been evaluated. In addition, the anticancer mechanism and the cell death process mediated by the two compounds were studied.",
  "Their cytotoxicity and phototoxicity have been evaluated. In addition, the anticancer mechanism and the cell death process mediated by the two compounds were studied. The results showed that the two arene\u2013ruthenium photosensitizer-containing complexes have a strong phototoxic effect after photoactivation. The 2H-TPyP-arene-Ru complex induced outstanding cytotoxicity when compared to the Zn-TPyP-arene-Ru analogue. Moreover, under light, these two arene\u2013ruthenium photosensitizers induce an apoptotic process in human colorectal cancer cell lines.\nAuthors: Jacquie Massoud, A. Pinon, M. Gallardo-Villagr\u00e1n, L. Paulus, Catherine Ouk, Claire Carrion, Sayed Antoun, Mona Diab-Assaf, Bruno Therrien, B. Liagre\nVenue: Inorganics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Results showed that the two arene\u2013ruthenium photosensitizer-containing complexes have a strong phototoxic effect after photoactivation, and induce an apoptotic process in human colorectal cancer cell lines.'}",
  "Faculty Name: mona diab\nMetadata:\nPaperid: f727f928e7e179307d8d4a1da2387393f2bd7915\nTitle: Methods for Measuring, Updating, and Visualizing Factual Beliefs in Language Models\nYear: 2023\nAbstract: Language models can memorize a considerable amount of factual information during pretraining that can be elicited through prompting or finetuning models on tasks like question answering. In this paper, we discuss approaches to measuring model factual beliefs, updating incorrect factual beliefs in models, and visualizing graphical relationships between factual beliefs. Our main contributions include: (1) new metrics for evaluating belief-updating methods focusing on the logical consistency of beliefs, (2) a training objective for Sequential, Local, and Generalizing updates (SLAG) that improves the performance of existing hypernetwork approaches, and (3) the introduction of the belief graph, a new form of visualization for language models that shows relationships between stored model beliefs. Our experiments suggest that models show only limited consistency between factual beliefs, but update methods can both fix incorrect model beliefs and greatly improve their consistency.",
  "Our experiments suggest that models show only limited consistency between factual beliefs, but update methods can both fix incorrect model beliefs and greatly improve their consistency. Although off-the-shelf optimizers are surprisingly strong belief-updating baselines, our learned optimizers can outperform them in more difficult settings than have been considered in past work.\nAuthors: Peter Hase, Mona T. Diab, Asli Celikyilmaz, Xian Li, Zornitsa Kozareva, Veselin Stoyanov, Mohit Bansal, Srini Iyer\nVenue: Conference of the European Chapter of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The experiments suggest that models show only limited consistency between factual beliefs, but update methods can both fix incorrect model beliefs and greatly improve their consistency, and off-the-shelf optimizers can outperform them in more difficult settings than have been considered in past work.'}",
  "List of 2023 Open Access papers by mona diab are:\nCan Large Language Models Infer Causation from Correlation?\nALERT: Adapt Language Models to Reasoning Tasks\nCare4Lang at MEDIQA-Chat 2023: Fine-tuning Language Models for Classifying and Summarizing Clinical Dialogues\nThe Troubling Emergence of Hallucination in Large Language Models - An Extensive Definition, Quantification, and Prescriptive Remediations\nOPT-R: Exploring the Role of Explanations in Finetuning and Prompting for Reasoning Skills of Large Language Models\nMethods for Measuring, Updating,",
  "Quantification, and Prescriptive Remediations\nOPT-R: Exploring the Role of Explanations in Finetuning and Prompting for Reasoning Skills of Large Language Models\nMethods for Measuring, Updating, and Visualizing Factual Beliefs in Language Models\nComparison of the structures and topologies of plasma extracted circulating nuclear and mitochondrial cell-free DNA\nCytomegalovirus at the crossroads of immunosenescence and oncogenesis\nAspalathus linearis (Rooibos) Targets Adipocytes and Obesity-Associated Inflammation\nEmerging Therapeutic Approaches to Target the Dark Side of Senescent Cells: New Hopes to Treat Aging as a Disease and to Delay Age-Related Pathologies\nCrosstalk of Inflammatory Cytokines within the Breast Tumor Microenvironment\nAuthor Correction: Arabic natural language processing for Qur\u2019anic research: a systematic review\nEvaluating Multilingual Speech Translation under Realistic Conditions with Resegmentation and Terminology\nA bleeding bite: crotalinae snake envonamation\nPAMR1 negatively impacts cell proliferation and migration of Human Colon Cancer HT29 Cell Line\nA Combination of Ruthenium Complexes and Photosensitizers to Treat Colorectal Cancer",
  "List of 2023 Open Access papers by monika woszczyna are:",
  "Faculty Name: morency louis philippe\nMetadata:\nPaperid: 0a425c0d87c674b142104a07e17c5084b3ad28ca\nTitle: Quantifying & Modeling Feature Interactions: An Information Decomposition Framework\nYear: 2023\nAbstract: The recent explosion of interest in multimodal applications has resulted in a wide selection of datasets and methods for representing and integrating information from different signals. Despite these empirical advances, there remain fundamental research questions: how can we quantify the nature of interactions that exist among input features? Subsequently, how can we capture these interactions using suitable data-driven methods? To answer this question, we propose an information-theoretic approach to quantify the degree of redundancy , uniqueness , and synergy across input features, which we term the PID statistics of a multimodal distribution. Using 2 newly proposed estimators that scale to high-dimensional distributions, we demonstrate their usefulness in quantifying the interactions within multimodal datasets, the nature of interactions captured by multimodal models, and principled approaches for model selection. We conduct extensive experiments on both synthetic datasets where the PID statistics are known and on large-scale multimodal benchmarks where PID estimation was previously impossible.",
  "We conduct extensive experiments on both synthetic datasets where the PID statistics are known and on large-scale multimodal benchmarks where PID estimation was previously impossible. Finally, to demonstrate the real-world applicability of our approach, we present three case studies in pathology, mood prediction, and robotic perception where our framework accurately recommends strong multimodal models for each application.\nAuthors: P. Liang, Yun Cheng, Xiang Fan, Chun Kai Ling, Suzanne Nie, Richard J. Chen, Zihao Deng, Faisal Mahmood, R. Salakhutdinov, Louis-Philippe Morency\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes an information-theoretic approach to quantify the degree of redundancy, uniqueness, and synergy across input features, which is term the PID statistics of a multimodal distribution.'}",
  "Faculty Name: morency louis philippe\nMetadata:\nPaperid: 114eafdb14145f002d503f259d768d67dae87479\nTitle: Reconstructing the neurodynamics of face perception during real world vision in humans using intracranial EEG recordings\nYear: 2023\nAbstract: None\nAuthors: Arish Alreja, Michael J. Ward, J. A. Colan, Qianli Ma, R. M. Richardson, Louis-Philippe Morency, A. Ghuman\nVenue: Journal of Vision\nTldr: None",
  "Faculty Name: morency louis philippe\nMetadata:\nPaperid: 40fb36ee67fdde99b196b4d1772de114aa821698\nTitle: MultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning\nYear: 2023\nAbstract: Learning multimodal representations involves integrating information from multiple heterogeneous sources of data. In order to accelerate progress towards understudied modalities and tasks while ensuring real-world robustness, we release MultiZoo, a public toolkit consisting of standardized implementations of>20 core multimodal algorithms and MultiBench, a large-scale benchmark spanning 15 datasets, 10 modalities, 20 prediction tasks, and 6 research areas. Together, these provide an automated end-to-end machine learning pipeline that simplifies and standardizes data loading, experimental setup, and model evaluation. To enable holistic evaluation, we offer a comprehensive methodology to assess (1) generalization, (2) time and space complexity, and (3) modality robustness. MultiBench paves the way towards a better understanding of the capabilities and limitations of multimodal models, while ensuring ease of use, accessibility, and reproducibility.",
  "MultiBench paves the way towards a better understanding of the capabilities and limitations of multimodal models, while ensuring ease of use, accessibility, and reproducibility. Our toolkits are publicly available, will be regularly updated, and welcome inputs from the community.\nAuthors: P. Liang, Yiwei Lyu, Xiang Fan, Arav Agarwal, Yun Cheng, Louis-Philippe Morency, R. Salakhutdinov\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'MultiZoo is released, a public toolkit consisting of standardized implementations of>20 core multimodal algorithms and MultiBench, a large-scale benchmark spanning 15 datasets, 10 modalities, 20 prediction tasks, and 6 research areas that provide an automated end-to-end machine learning pipeline that simplifies and standardizes data loading, experimental setup, and model evaluation.'}",
  "Faculty Name: morency louis philippe\nMetadata:\nPaperid: 47a4ac301820c3ea7da4efb8e2466cc6468ad631\nTitle: SenteCon: Leveraging Lexicons to Learn Human-Interpretable Language Representations\nYear: 2023\nAbstract: Although deep language representations have become the dominant form of language featurization in recent years, in many settings it is important to understand a model's decision-making process. This necessitates not only an interpretable model but also interpretable features. In particular, language must be featurized in a way that is interpretable while still characterizing the original text well. We present SenteCon, a method for introducing human interpretability in deep language representations. Given a passage of text, SenteCon encodes the text as a layer of interpretable categories in which each dimension corresponds to the relevance of a specific category. Our empirical evaluations indicate that encoding language with SenteCon provides high-level interpretability at little to no cost to predictive performance on downstream tasks.",
  "Given a passage of text, SenteCon encodes the text as a layer of interpretable categories in which each dimension corresponds to the relevance of a specific category. Our empirical evaluations indicate that encoding language with SenteCon provides high-level interpretability at little to no cost to predictive performance on downstream tasks. Moreover, we find that SenteCon outperforms existing interpretable language representations with respect to both its downstream performance and its agreement with human characterizations of the text.\nAuthors: Victoria Lin, Louis-Philippe Morency\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work presents SenteCon, a method for introducing human interpretability in deep language representations that outperforms existing interpretable language representations with respect to both its downstream performance and its agreement with human characterizations of the text.'}",
  "Faculty Name: morency louis philippe\nMetadata:\nPaperid: 64703e760f662b1c0f647931bb63fe57e5ba91e4\nTitle: Neural Mixed Effects for Nonlinear Personalized Predictions\nYear: 2023\nAbstract: Personalized prediction is a machine learning approach that predicts a person\u2019s future observations based on their past labeled observations and is typically used for sequential tasks, e.g., to predict daily mood ratings. When making personalized predictions, a model can combine two types of trends: (a) trends shared across people, i.e., person-generic trends, such as being happier on weekends, and (b) unique trends for each person, i.e., person-specific trends, such as a stressful weekly meeting. Mixed effect models are popular statistical models to study both trends by combining person-generic and person-specific parameters. Though linear mixed effect models are gaining popularity in machine learning by integrating them with neural networks, these integrations are currently limited to linear person-specific parameters: ruling out nonlinear person-specific trends. In this paper, we propose Neural Mixed Effect (NME) models to optimize nonlinear person-specific parameters anywhere in a neural network in a scalable manner1.",
  "In this paper, we propose Neural Mixed Effect (NME) models to optimize nonlinear person-specific parameters anywhere in a neural network in a scalable manner1. NME combines the efficiency of neural network optimization with nonlinear mixed effects modeling. Empirically, we observe that NME improves performance across six unimodal and multimodal datasets, including a smartphone dataset to predict daily mood and a mother-adolescent dataset to predict affective state sequences where half the mothers experience symptoms of depression. Furthermore, we evaluate NME for two model architectures, including for neural conditional random fields (CRF) to predict affective state sequences where the CRF learns nonlinear person-specific temporal transitions between affective states. Analysis of these person-specific transitions on the mother-adolescent dataset shows interpretable trends related to the mother\u2019s depression symptoms.",
  "Analysis of these person-specific transitions on the mother-adolescent dataset shows interpretable trends related to the mother\u2019s depression symptoms.\nAuthors: T. W\u00f6rtwein, Nicholas Allen, Lisa B. Sheeber, R. Auerbach, J. Cohn, Louis-Philippe Morency\nVenue: International Conference on Multimodal Interaction\nTldr: {'model': 'tldr@v2.0.0', 'text': 'NME combines the efficiency of neural network optimization with nonlinear mixed effects modeling and improves performance across six unimodal and multimodal datasets, including a smartphone dataset to predict daily mood and a mother-adolescent datasets to predict affective state sequences where half the mothers experience symptoms of depression.'}",
  "Faculty Name: morency louis philippe\nMetadata:\nPaperid: 6838c43e702a3f995967ba2e3edd5f65ff5f5511\nTitle: SHAP-based Prediction of Mother's History of Depression to Understand the Influence on Child Behavior\nYear: 2023\nAbstract: Depression strongly impacts parents\u2019 behavior. Does parents\u2019 depression strongly affect the behavior of their children as well? To investigate this question, we compared dyadic interactions between 73 depressed and 75 non-depressed mothers and their adolescent child. Families were of low income and 84% were white. Child behavior was measured from audio-video recordings using manual annotation of verbal and nonverbal behavior by expert coders and by multimodal computational measures of facial expression, face and head dynamics, prosody, speech behavior, and linguistics. For both sets of measures, we used Support Vector Machines. For computational measures, we investigated the relative contribution of single versus multiple modalities using a novel approach to SHapley Additive exPlanations (SHAP). Computational measures outperformed manual ratings by human experts. Among individual computational measures, prosody was the most informative.",
  "For computational measures, we investigated the relative contribution of single versus multiple modalities using a novel approach to SHapley Additive exPlanations (SHAP). Computational measures outperformed manual ratings by human experts. Among individual computational measures, prosody was the most informative. SHAP reduction resulted in a four-fold decrease in the number of features and highest performance (77% accuracy; positive and negative agreements at 75% and 76%, respectively). These findings suggest that maternal depression strongly impacts the behavior of adolescent children; differences are most revealed in prosody; multimodal features together with SHAP reduction are most powerful.\nAuthors: Maneesh Bilalpur, Saurabh Hinduja, Laura Cariola, Lisa B. Sheeber, Nicholas B Allen, Louis-Philippe Morency, Jeffrey F. Cohn\nVenue: International Conference on Multimodal Interaction\nTldr: None",
  "Faculty Name: morency louis philippe\nMetadata:\nPaperid: 7dab13685363176edc5cc7882d0890811d2cb584\nTitle: Counterfactual Augmentation for Multimodal Learning Under Presentation Bias\nYear: 2023\nAbstract: In real-world machine learning systems, labels are often derived from user behaviors that the system wishes to encourage. Over time, new models must be trained as new training examples and features become available. However, feedback loops between users and models can bias future user behavior, inducing a presentation bias in the labels that compromises the ability to train new models. In this paper, we propose counterfactual augmentation, a novel causal method for correcting presentation bias using generated counterfactual labels. Our empirical evaluations demonstrate that counterfactual augmentation yields better downstream performance compared to both uncorrected models and existing bias-correction methods. Model analyses further indicate that the generated counterfactuals align closely with true counterfactuals in an oracle setting.",
  "Our empirical evaluations demonstrate that counterfactual augmentation yields better downstream performance compared to both uncorrected models and existing bias-correction methods. Model analyses further indicate that the generated counterfactuals align closely with true counterfactuals in an oracle setting.\nAuthors: Victoria Lin, Louis-Philippe Morency, D. Dimitriadis, Srinagesh Sharma\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Empirical evaluations demonstrate that counterfactual augmentation yields better downstream performance compared to both uncorrected models and existing bias-correction methods, and model analyses indicate that the generatedcounterfactuals align closely with true counterfactUALs in an oracle setting.'}",
  "Faculty Name: morency louis philippe\nMetadata:\nPaperid: 8d0c37eee7162f33178979b4183f0211e2dcae0d\nTitle: Difference-Masking: Choosing What to Mask in Continued Pretraining\nYear: 2023\nAbstract: The self-supervised objective of masking-and-predicting has led to promising performance gains on a variety of downstream tasks. However, while most approaches randomly mask tokens, there is strong intuition that deciding what to mask can substantially improve learning outcomes. We investigate this in continued pretraining setting in which pretrained models continue to pretrain on domain-specific data before performing some downstream task. We introduce Difference-Masking, a masking strategy that automatically chooses what to mask during continued pretraining by considering what makes a task domain different from the pretraining domain. Empirically, we find that Difference-Masking outperforms baselines on continued pretraining settings across four diverse language-only and multimodal video tasks.",
  "Empirically, we find that Difference-Masking outperforms baselines on continued pretraining settings across four diverse language-only and multimodal video tasks.\nAuthors: Alex Wilf, Syeda Nahida Akter, Leena Mathur, P. Liang, Sheryl Mathew, Mengrou Shou, Eric Nyberg, Louis-Philippe Morency\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Difference-Masking is introduced, a masking strategy that automatically chooses what to mask during continued pretraining by considering what makes a task domain different from the pretraining domain.'}",
  "Faculty Name: morency louis philippe\nMetadata:\nPaperid: 8d53c510928ad1164aebea4d9477812ed1893be2\nTitle: Expanding the Role of Affective Phenomena in Multimodal Interaction Research\nYear: 2023\nAbstract: In recent decades, the field of affective computing has made substantial progress in advancing the ability of AI systems to recognize and express affective phenomena, such as affect and emotions, during human-human and human-machine interactions. This paper describes our examination of research at the intersection of multimodal interaction and affective computing, with the objective of observing trends and identifying understudied areas. We examined over 16,000 papers from selected conferences in multimodal interaction, affective computing, and natural language processing: ACM International Conference on Multimodal Interaction, AAAC International Conference on Affective Computing and Intelligent Interaction, Annual Meeting of the Association for Computational Linguistics, and Conference on Empirical Methods in Natural Language Processing. We identified 910 affect-related papers and present our analysis of the role of affective phenomena in these papers.",
  "We identified 910 affect-related papers and present our analysis of the role of affective phenomena in these papers. We find that this body of research has primarily focused on enabling machines to recognize or express affect and emotion; there has been limited research on how affect and emotion predictions might, in turn, be used by AI systems to enhance machine understanding of human social behaviors and cognitive states. Based on our analysis, we discuss directions to expand the role of affective phenomena in multimodal interaction research.\nAuthors: Leena Mathur, Maja J Matari'c, Louis-Philippe Morency\nVenue: International Conference on Multimodal Interaction\nTldr: {'model': 'tldr@v2.0.0', 'text': 'An examination of research at the intersection of multimodal interaction and affective computing, with the objective of observing trends and identifying understudied areas, finds that this body of research has primarily focused on enabling machines to recognize or express affect and emotion.'}",
  "Faculty Name: morency louis philippe\nMetadata:\nPaperid: 90b09bdb1bd78875ee8d8d324a568a36955e4765\nTitle: Multimodal Fusion Interactions: A Study of Human and Automatic Quantification\nYear: 2023\nAbstract: In order to perform multimodal fusion of heterogeneous signals, we need to understand their interactions: how each modality individually provides information useful for a task and how this information changes in the presence of other modalities. In this paper, we perform a comparative study of how humans annotate two categorizations of multimodal interactions: (1) partial labels, where different annotators annotate the label given the first, second, and both modalities, and (2) counterfactual labels, where the same annotator annotates the label given the first modality before asking them to explicitly reason about how their answer changes when given the second.",
  "We further propose an alternative taxonomy based on (3) information decomposition, where annotators annotate the degrees of redundancy: the extent to which modalities individually and together give the same predictions, uniqueness: the extent to which one modality enables a prediction that the other does not, and synergy: the extent to which both modalities enable one to make a prediction that one would not otherwise make using individual modalities. Through experiments and annotations, we highlight several opportunities and limitations of each approach and propose a method to automatically convert annotations of partial and counterfactual labels to information decomposition, yielding an accurate and efficient method for quantifying multimodal interactions.\nAuthors: P. Liang, Yun Cheng, R. Salakhutdinov, Louis-Philippe Morency\nVenue: International Conference on Multimodal Interaction\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A comparative study of how humans annotate two categorizations of multimodal interactions is performed and a method to automatically convert annotations of partial and counterfactual labels to information decomposition is proposed, yielding an accurate and efficient method for quantifying multimodals interactions.'}",
  "Faculty Name: morency louis philippe\nMetadata:\nPaperid: a988c09b7e76e86a93edcbf3f284dd028b0fb406\nTitle: Multimodal Learning Without Labeled Multimodal Data: Guarantees and Applications\nYear: 2023\nAbstract: In many machine learning systems that jointly learn from multiple modalities, a core research question is to understand the nature of multimodal interactions: the emergence of new task-relevant information during learning from both modalities that was not present in either alone. We study this challenge of interaction quantification in a semi-supervised setting with only labeled unimodal data and naturally co-occurring multimodal data (e.g., unlabeled images and captions, video and corresponding audio) but when labeling them is time-consuming. Using a precise information-theoretic definition of interactions, our key contributions are the derivations of lower and upper bounds to quantify the amount of multimodal interactions in this semi-supervised setting. We propose two lower bounds based on the amount of shared information between modalities and the disagreement between separately trained unimodal classifiers, and derive an upper bound through connections to approximate algorithms for min-entropy couplings.",
  "We propose two lower bounds based on the amount of shared information between modalities and the disagreement between separately trained unimodal classifiers, and derive an upper bound through connections to approximate algorithms for min-entropy couplings. We validate these estimated bounds and show how they accurately track true interactions. Finally, two semi-supervised multimodal applications are explored based on these theoretical results: (1) analyzing the relationship between multimodal performance and estimated interactions, and (2) self-supervised learning that embraces disagreement between modalities beyond agreement as is typically done.\nAuthors: P. Liang, Chun Kai Ling, Yun Cheng, A. Obolenskiy, Yudong Liu, Rohan Pandey, Alex Wilf, Louis-Philippe Morency, R. Salakhutdinov\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes two lower bounds based on the amount of shared information between modalities and the disagreement between separately trained unimodal classifiers, and derive an upper bound through connections to approximate algorithms for min-entropy couplings and validate these estimated bounds and show how they accurately track true interactions.'}",
  "Faculty Name: morency louis philippe\nMetadata:\nPaperid: bd94ea913fcf8698f2257f87a17755b46a420458\nTitle: Representation Learning for Interpersonal and Multimodal Behavior Dynamics: A Multiview Extension of Latent Change Score Models\nYear: 2023\nAbstract: Characterizing the dynamics of behavior across multiple modalities and individuals is a vital component of computational behavior analysis. This is especially important in certain applications, such as psychotherapy, where individualized tracking of behavior patterns can provide valuable information about the patient\u2019s mental state. Conventional methods that rely on aggregate statistics and correlational metrics may not always suffice, as they are often unable to capture causal relationships or evaluate the true probability of identified patterns. To address these challenges, we present a novel approach to learning multimodal and interpersonal representations of behavior dynamics during one-on-one interaction. Our approach is enabled by the introduction of a multiview extension of latent change score models, which facilitates the concurrent capture of both inter-modal and interpersonal behavior dynamics and the identification of directional relationships between them. A core advantage of our approach is its high level of interpretability while simultaneously achieving strong predictive performance.",
  "Our approach is enabled by the introduction of a multiview extension of latent change score models, which facilitates the concurrent capture of both inter-modal and interpersonal behavior dynamics and the identification of directional relationships between them. A core advantage of our approach is its high level of interpretability while simultaneously achieving strong predictive performance. We evaluate our approach within the domain of therapist-client interactions, with the objective of gaining a deeper understanding about the collaborative relationship between the two, a crucial element of the therapeutic process. Our results demonstrate improved performance over conventional approaches that rely upon summary statistics or correlational metrics. Furthermore, since our multiview approach includes the explicit modeling of uncertainty, it naturally lends itself to integration with probabilistic classifiers, such as Gaussian process models. We demonstrate that this integration leads to even further improved performance, all the while maintaining highly interpretable qualities. Our analysis provides compelling motivation for further exploration of stochastic systems within computational models of behavior.",
  "We demonstrate that this integration leads to even further improved performance, all the while maintaining highly interpretable qualities. Our analysis provides compelling motivation for further exploration of stochastic systems within computational models of behavior.\nAuthors: A. Vail, J. Girard, Lauren M. Bylsma, Jay Fournier, Holly A. Swartz, Jeffrey F. Cohn, Louis-Philippe Morency\nVenue: International Conference on Multimodal Interaction\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work presents a novel approach to learning multimodal and interpersonal representations of behavior dynamics during one-on-one interaction enabled by the introduction of a multiview extension of latent change score models that demonstrates improved performance over conventional approaches that rely upon summary statistics or correlational metrics.'}",
  "Faculty Name: morency louis philippe\nMetadata:\nPaperid: d01cc51c0d06583b809833a5f7ce71101d278528\nTitle: MultiViz: Towards User-Centric Visualizations and Interpretations of Multimodal Models\nYear: 2023\nAbstract: The nature of human and computer interactions are inherently multimodal, which has led to substantial interest in building interpretable, interactive, and reliable multimodal interfaces. However, modern multimodal models and interfaces are typically black-box neural networks, which makes it challenging to understand their internal mechanics. How can we visualize their internal workings in order to empower stakeholders to visualize model behavior, perform model debugging, and promote trust in these models? Our paper proposes MultiViz, a method for analyzing the behavior of multimodal models via 4 stages: (1) unimodal importance, (2) cross-modal interactions, (3) multimodal representations and (4) multimodal prediction. MultiViz includes modular visualization tools for each stage before combining outputs from all stages through an interactive and human-in-the-loop API.",
  "MultiViz includes modular visualization tools for each stage before combining outputs from all stages through an interactive and human-in-the-loop API. Through user studies with 21 participants on 8 trained models across 6 real-world tasks, we show that the complementary stages in MultiViz together enable users to (1) simulate model predictions, (2) assign interpretable concepts to features, (3) perform error analysis on model misclassifications, and (4) use insights from error analysis to debug models. MultiViz is publicly available at https://github.com/pliang279/MultiViz, will be regularly updated with new visualization tools and metrics, and welcomes input from the community1.",
  "MultiViz is publicly available at https://github.com/pliang279/MultiViz, will be regularly updated with new visualization tools and metrics, and welcomes input from the community1.\nAuthors: P. Liang, Yiwei Lyu, Gunjan Chhablani, Nihal Jain, Zihao Deng, Xingbo Wang, Louis-Philippe Morency, R. Salakhutdinov\nVenue: CHI Extended Abstracts\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is shown that the complementary stages in MultiViz together enable users to simulate model predictions, assign interpretable concepts to features, perform error analysis on model misclassifications, and use insights from error analysis to debug models.'}",
  "Faculty Name: morency louis philippe\nMetadata:\nPaperid: dcb4f2b9b0e6da0d629878d1ad0469aee3df2020\nTitle: Understanding Masked Autoencoders via Hierarchical Latent Variable Models\nYear: 2023\nAbstract: Masked autoencoder (MAE), a simple and effective self-supervised learning framework based on the reconstruction of masked image regions, has recently achieved prominent success in a variety of vision tasks. Despite the emergence of intriguing empirical observations on MAE, a theoretically principled understanding is still lacking. In this work, we formally characterize and justify existing empirical in-sights and provide theoretical guarantees of MAE. We formulate the underlying data-generating process as a hierarchical latent variable model, and show that under reasonable assumptions, MAE provably identifies a set of latent variables in the hierarchical model, explaining why MAE can extract high-level information from pixels. Further, we show how key hyperparameters in MAE (the masking ratio and the patch size) determine which true latent variables to be recovered, therefore influencing the level of semantic information in the representation.",
  "Further, we show how key hyperparameters in MAE (the masking ratio and the patch size) determine which true latent variables to be recovered, therefore influencing the level of semantic information in the representation. Specifically, extremely large or small masking ratios inevitably lead to low-level representations. Our theory offers coherent explanations of existing empirical observations and provides insights for potential empirical improvements and fundamental limitations of the masked-reconstruction paradigm. We conduct extensive experiments to validate our theoretical insights.\nAuthors: Lingjing Kong, Martin Q. Ma, Guan-Hong Chen, E. Xing, Yuejie Chi, Louis-Philippe Morency, Kun Zhang\nVenue: Computer Vision and Pattern Recognition\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work formally characterize and justify existing empirical in-sights and provide theoretical guarantees of MAE, and formulate the underlying data-generating process as a hierarchical latent variable model, and shows that under reasonable assumptions, MAE provably identifies a set of latent variables in the hierarchical model.'}",
  "Faculty Name: morency louis philippe\nMetadata:\nPaperid: e1b2a35a000ca296c32284b323c7e36a28fe0693\nTitle: Factorized Contrastive Learning: Going Beyond Multi-view Redundancy\nYear: 2023\nAbstract: In a wide range of multimodal tasks, contrastive learning has become a particularly appealing approach since it can successfully learn representations from abundant unlabeled data with only pairing information (e.g., image-caption or video-audio pairs). Underpinning these approaches is the assumption of multi-view redundancy - that shared information between modalities is necessary and sufficient for downstream tasks. However, in many real-world settings, task-relevant information is also contained in modality-unique regions: information that is only present in one modality but still relevant to the task. How can we learn self-supervised multimodal representations to capture both shared and unique information relevant to downstream tasks? This paper proposes FactorCL, a new multimodal representation learning method to go beyond multi-view redundancy.",
  "How can we learn self-supervised multimodal representations to capture both shared and unique information relevant to downstream tasks? This paper proposes FactorCL, a new multimodal representation learning method to go beyond multi-view redundancy. FactorCL is built from three new contributions: (1) factorizing task-relevant information into shared and unique representations, (2) capturing task-relevant information via maximizing MI lower bounds and removing task-irrelevant information via minimizing MI upper bounds, and (3) multimodal data augmentations to approximate task relevance without labels. On large-scale real-world datasets, FactorCL captures both shared and unique information and achieves state-of-the-art results on six benchmarks\nAuthors: P. Liang, Zihao Deng, Martin Q. Ma, James Y. Zou, Louis-Philippe Morency, R. Salakhutdinov\nVenue: Neural Information Processing Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'FactorCL is a new multimodal representation learning method to go beyond multi-view redundancy and captures both shared and unique information and achieves state-of-the-art results on six benchmarks.'}",
  "Faculty Name: morency louis philippe\nMetadata:\nPaperid: f891e9eeedbf20cdc54429ffcc0402a10f48494e\nTitle: Language Models Get a Gender Makeover: Mitigating Gender Bias with Few-Shot Data Interventions\nYear: 2023\nAbstract: Societal biases present in pre-trained large language models are a critical issue as these models have been shown to propagate biases in countless downstream applications, rendering them unfair towards specific groups of people. Since large-scale retraining of these models from scratch is both time and compute-expensive, a variety of approaches have been previously proposed that de-bias a pre-trained model. While the majority of current state-of-the-art debiasing methods focus on changes to the training regime, in this paper, we propose data intervention strategies as a powerful yet simple technique to reduce gender bias in pre-trained models. Specifically, we empirically show that by fine-tuning a pre-trained model on only 10 debiased (intervened) training examples, the tendency to favor any gender is significantly reduced.",
  "Specifically, we empirically show that by fine-tuning a pre-trained model on only 10 debiased (intervened) training examples, the tendency to favor any gender is significantly reduced. Since our proposed method only needs a few training examples, we argue that our few-shot de-biasing approach is highly feasible and practical. Through extensive experimentation, we show that our de-biasing technique performs better than competitive state-of-the-art baselines with minimal loss in language modeling ability.\nAuthors: Himanshu Thakur, Atishay Jain, Praneetha Vaddamanu, P. Liang, Louis-Philippe Morency\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper empirically shows that by fine-tuning a pre-trained model on only 10 debiased (intervened) training examples, the tendency to favor any gender is significantly reduced, and argues that the few-shot de-biasing approach is highly feasible and practical.'}",
  "List of 2023 Open Access papers by morency louis philippe are:\nQuantifying & Modeling Feature Interactions: An Information Decomposition Framework\nReconstructing the neurodynamics of face perception during real world vision in humans using intracranial EEG recordings\nMultiZoo & MultiBench: A Standardized Toolkit for Multimodal Deep Learning\nSenteCon: Leveraging Lexicons to Learn Human-Interpretable Language Representations\nNeural Mixed Effects for Nonlinear Personalized Predictions\nSHAP-based Prediction of Mother's History of Depression to Understand the Influence on Child Behavior\nCounterfactual Augmentation for Multimodal Learning Under Presentation Bias\nDifference-Masking: Choosing What to Mask in Continued Pretraining\nExpanding the Role of Affective Phenomena in Multimodal Interaction Research\nMultimodal Fusion Interactions: A Study of Human and Automatic Quantification\nMultimodal Learning Without Labeled Multimodal Data: Guarantees and Applications\nRepresentation Learning for Interpersonal and Multimodal Behavior Dynamics: A Multiview Extension of Latent Change Score Models\nMultiViz: Towards User-Centric Visualizations and Interpretations of Multimodal Models\nUnderstanding Masked Autoencoders via Hierarchical Latent Variable",
  "Data: Guarantees and Applications\nRepresentation Learning for Interpersonal and Multimodal Behavior Dynamics: A Multiview Extension of Latent Change Score Models\nMultiViz: Towards User-Centric Visualizations and Interpretations of Multimodal Models\nUnderstanding Masked Autoencoders via Hierarchical Latent Variable Models\nFactorized Contrastive Learning: Going Beyond Multi-view Redundancy\nLanguage Models Get a Gender Makeover: Mitigating Gender Bias with Few-Shot Data Interventions",
  "Title: Louis-Philippe Morency -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Louis-Philippe Morency, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Core Faculty\" name=\"categories-1\"/>\n<meta content=\"Machine Learning;Multimodal Computing and Interaction;Spoken Interfaces and Dialogue Processing\" name=\"categories-2\"/>\n<meta content=\"Yes\" name=\"show-categories-2\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Louis-Philippe Morency - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Louis-Philippe Morency,",
  "Faculty Member at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Louis-Philippe \"/>\n<meta content=\"Lastname\" property=\"profile:Morency\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/morency-louis-philippe.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nLouis-Philippe  \n                        Morency\nLeonardo Associate Professor of Computer Science (On Leave), Language Technologies Institute\nContact\n5411 \u2014Gates & Hillman Centers\nmorency(through)cs.cmu.edu\n412-268-5508\nResearch Area\nMachine Learning, Multimodal Computing and Interaction, Spoken Interfaces and Dialogue Processing\nResearch\nMy research interest lies at the intersection of machine learning, computer vision, computational linguistics and signal processing \u2014 building the computational foundations to enable computers with the abilities to analyze,",
  "Multimodal Computing and Interaction, Spoken Interfaces and Dialogue Processing\nResearch\nMy research interest lies at the intersection of machine learning, computer vision, computational linguistics and signal processing \u2014 building the computational foundations to enable computers with the abilities to analyze, recognize and predict subtle human communicative behaviors during social interactions. Human face-to-face communication is a little like a dance: participants continuously adjust their behaviors based on their interlocutor\u2019s speech, gestures and facial expressions during social interaction. The actual sophistication of human communication comes to the fore when we try to create computers that can understand and participate, however crudely, in this type of social interaction.",
  "The actual sophistication of human communication comes to the fore when we try to create computers that can understand and participate, however crudely, in this type of social interaction.\nHuman Communication Dynamics\nI formalize this new research endeavor with a human communication dynamics framework, addressing four key computational challenges:\nbehavioral dynamics\nto model the appearance and temporal variations of individual communicative behaviors and their effects on perceived meanings;\nmultimodal dynamics\nto model the interdependence between different communicative channels including visual gestures and expressions, language, and acoustic signals;\ninterpersonal dynamics\nto model the social and conversational influence between participants during dyadic or small-group interactions (i.e., micro-level);\nand\nsocietal dynamics\nto model the cultural and behavioral changes in a larger groups (i.e., meso-level) or in different societies (i.e, macro-level).\nMultimodal Machine Learning\nCentral to this research effort is the introduction of new probabilistic models that can learn temporal and fine-grained dependencies across behaviors, modalities and interlocutors. These energy-based probabilistic models must address core computational issues with human communication dynamics, including hierarchical and nonlinear feature representation, multiview learning and potential over fitting on smaller training sets.",
  "These energy-based probabilistic models must address core computational issues with human communication dynamics, including hierarchical and nonlinear feature representation, multiview learning and potential over fitting on smaller training sets. For example, I created a family of latent probabilistic models (HCRF, LDCRF, CCNF, etc.) designed to automatically learn the hidden dynamics present in human verbal and nonverbal communication.\nHealth Behavior Informatics\nThis research has many applications in education (learning analytics), business (negotiation, interpersonal skills training) and social multimedia (opinion mining, social influence). One area I am particularly excited about is the development of new decision support tools for healthcare applications. For example, how can we quantify, analyze and summarize patient verbal and nonverbal behaviors during psychotherapy? This information could not only help clinicians between therapy sessions but also facilitate collaboration with other medical team members by providing objective behavior measures for the patient\u2019s medical record.\nPersonal Website\n\nLinks:\nhttp://www.cs.cmu.edu/~morency/",
  "Title: David Mortensen -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of David Mortensen, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Core Faculty\" name=\"categories-1\"/>\n<meta content=\"Corpus Annotation and Resources;Natural Language Processing and Computational Linguistics\" name=\"categories-2\"/>\n<meta content=\"Yes\" name=\"show-categories-2\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"David Mortensen - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of David Mortensen, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:David\"/>\n<meta content=\"Lastname\" property=\"profile:Mortensen\"/>\n<meta content=\"http://lti.cmu.",
  "Faculty Member at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:David\"/>\n<meta content=\"Lastname\" property=\"profile:Mortensen\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/mortensen-david.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nDavid \n                        Mortensen\nAssistant Research Professor, Language Technologies Institute\nContact\n5707 \u2014Gates & Hillman Centers\ndmortens(through)cs.cmu.edu\n412-268-2894\nResearch Area\nCorpus Annotation and Resources, Natural Language Processing and Computational Linguistics\nEducation\nMaster of Science in Intelligent Information Systems\nPersonal Website\n\nLinks:\nhttps://www.cs.cmu.edu/~dmortens/",
  "Title: Jack Mostow -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Jack Mostow, Affiliated Faculty at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Affiliated Faculty\" name=\"categories-1\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Jack Mostow - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Jack Mostow, Affiliated Faculty at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Jack\"/>\n<meta content=\"Lastname\" property=\"profile:Mostow\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/mostow-jack.",
  "cmu.edu//people/faculty/mostow-jack.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nJack \n                        Mostow\nResearch Professor Emeritus, Robotics Institute\nLanguage Technologies Institute\nContact\n3113 \u2014Newell-Simon Hall\nmostow(through)cs.cmu.edu\n412-268-1330\nRobotics Institute\nPersonal Website\n\nLinks:\nhttps://www.ri.cmu.edu/\nhttp://www.cs.cmu.edu/~mostow/",
  "Title: Graham Neubig -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Graham Neubig, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Core Faculty\" name=\"categories-1\"/>\n<meta content=\"Machine Learning;Machine Translation;Natural Language Processing and Computational Linguistics;Spoken Interfaces and Dialogue Processing\" name=\"categories-2\"/>\n<meta content=\"Yes\" name=\"show-categories-2\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Graham Neubig - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Graham Neubig,",
  "Faculty Member at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Graham\"/>\n<meta content=\"Lastname\" property=\"profile:Neubig\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/neubig-graham.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nGraham \n                        Neubig\nAssociate Professor, Language Technologies Institute\nContact\n5409 \u2014Gates & Hillman Centers\ngneubig(through)cs.cmu.edu\nResearch Area\nMachine Learning, Machine Translation, Natural Language Processing and Computational Linguistics, Spoken Interfaces and Dialogue Processing\nEducation\nMaster of Science in Intelligent Information Systems\nResearch\nMy research is concerned with language and its role in human communication.",
  "cmu.edu\nResearch Area\nMachine Learning, Machine Translation, Natural Language Processing and Computational Linguistics, Spoken Interfaces and Dialogue Processing\nEducation\nMaster of Science in Intelligent Information Systems\nResearch\nMy research is concerned with language and its role in human communication. In particular, my long-term research goal is to break down barriers in human-human or human-machine communication through the development of natural language processing (NLP) technologies. This includes the development of technology for machine translation, which helps break down barriers in communication for people who speak different languages, and natural language understanding, which helps computers understand and respond to human language. Within this overall goal of breaking down barriers to human communication, I have focused on several aspects of language that both make it interesting as a scientific subject, and hold potential for the construction of practical systems.\nAdvances in core NLP technology: Human language is complex and nuanced, and handling this complexity in a computational way requires sophisticated algorithms or learning techniques, the development of which is far from a solved problem. The first major area of my work focuses on advances in core NLP technology, which improve the accuracy with which we can analyze, translate, generate, or reply to textual inputs.",
  "The first major area of my work focuses on advances in core NLP technology, which improve the accuracy with which we can analyze, translate, generate, or reply to textual inputs.\nModels of language associated with other modalities: Human language does not exist in a vacuum, and is often associated with context from the world around it. The second thread of my research focuses on models of natural language associated with other modalities, tackling the problems, and exploiting the fascinating possibilities presented by having text associated with other types of information. Specifically, I have worked extensively with speech, and am also interested in associations between natural and formal languages such as source code.\nLearning from naturally occurring data: Language data exists in abundance, particularly due to the advent of the internet, and it is possible to acquire extremely large amounts of this data for scientific or engineering purposes. A third thread of my research focuses on learning NLP models from naturally occurring data through the use of unsupervised, semi-supervised, or active learning, which allows us to exploit this data to improve models while reducing the necessity for costly manual annotation.\nPersonal Website\n\nLinks:\nhttp://www.phontron.com/",
  "Faculty Name: norman sadeh\nMetadata:\nPaperid: 3625207ac4fcdf8aa091a589dd6efc996062e3fb\nTitle: Purpose in the Machine: Do Traffic Simulators Produce Distributionally Equivalent Outcomes for Reinforcement Learning Applications?\nYear: 2023\nAbstract: Traffic simulators are used to generate data for learning in intelligent transportation systems (ITSs). A key question is to what extent their modelling assumptions affect the capabilities of ITSs to adapt to various scenarios when deployed in the real world. This work focuses on two simulators commonly used to train reinforcement learning (RL) agents for traffic applications, CityFlow and SUMO. A controlled virtual experiment varying driver behavior and simulation scale finds evidence against distributional equivalence in RL-relevant measures from these simulators, with the root mean squared error and KL divergence being significantly greater than 0 for all assessed measures. While granular real-world validation generally remains infeasible, these findings suggest that traffic simulators are not a deus ex machina for RL training: understanding the impacts of inter-simulator differences is necessary to train and deploy RL-based ITSs.",
  "While granular real-world validation generally remains infeasible, these findings suggest that traffic simulators are not a deus ex machina for RL training: understanding the impacts of inter-simulator differences is necessary to train and deploy RL-based ITSs.\nAuthors: Rex Chen, K. Carley, Fei Fang, Norman M. Sadeh\nVenue: Online World Conference on Soft Computing in Industrial Applications\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work focuses on two simulators commonly used to train reinforcement learning agents for traffic applications, CityFlow and SUMO, and finds evidence against distributional equivalence in RL-relevant measures from these simulators.'}",
  "Faculty Name: norman sadeh\nMetadata:\nPaperid: 3c6d1884d5f15577b76356a3f1e7da6ffba6e2bd\nTitle: Do Privacy Labels Answer Users' Privacy Questions?\nYear: 2023\nAbstract: \u2014Inspired by earlier academic research, iOS app privacy labels and the recent Google Play data safety labels have been introduced as a way to systematically present users with concise summaries of an app\u2019s data practices. Yet, little research has been conducted to determine how well today\u2019s mobile app privacy labels address people\u2019s actual privacy concerns or questions. We analyze a crowd-sourced corpus of privacy questions collected from mobile app users to determine to what extent these mobile app labels actually address users\u2019 privacy concerns and questions. While there are differences between iOS labels and Google Play labels, our results indicate that an important percentage of people\u2019s privacy questions are not answered or only partially addressed in today\u2019s labels.",
  "While there are differences between iOS labels and Google Play labels, our results indicate that an important percentage of people\u2019s privacy questions are not answered or only partially addressed in today\u2019s labels. Findings from this work not only shed light on the additional fields that would need to be included in mobile app privacy labels but can also help inform refinements to existing labels to better address users\u2019 typical privacy questions\nAuthors: Shikun Zhang, N. Sadeh\nVenue: Proceedings 2023 Symposium on Usable Security\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A crowd-sourced corpus of privacy questions collected from mobile app users is analyzed to determine to what extent these mobile app labels actually address users\u2019 privacy concerns and questions.'}",
  "Faculty Name: norman sadeh\nMetadata:\nPaperid: 3f165dae2310a5d8aa7294ffdc45573a51c957b8\nTitle: Exploring Smart Commercial Building Occupants\u2019 Perceptions and Notification Preferences of Internet of Things Data Collection in the United States\nYear: 2023\nAbstract: Data collection through the Internet of Things (IoT) devices, or smart devices, in commercial buildings enables possibilities for increased convenience and energy efficiency. However, such benefits face a large perceptual challenge when being implemented in practice, due to the different ways occupants working in the buildings understand and trust in the data collection. The semi-public, pervasive, and multi-modal nature of data collection in smart buildings points to the need to study occupants\u2019 understanding of data collection and notification preferences. We conduct an online study with 492 participants in the US who report working in smart commercial buildings regarding: 1) awareness and perception of data collection in smart commercial buildings, 2) privacy notification preferences, and 3) potential factors for privacy notification preferences.",
  "We conduct an online study with 492 participants in the US who report working in smart commercial buildings regarding: 1) awareness and perception of data collection in smart commercial buildings, 2) privacy notification preferences, and 3) potential factors for privacy notification preferences. We find that around half of the participants are not fully aware of the data collection and use practices of IoT even though they notice the presence of IoT devices and sensors. We also discover many misunderstandings around different data practices. The majority of participants want to be notified of data practices in smart buildings, and they prefer push notifications to passive ones such as websites or physical signs. Surprisingly, mobile app notification, despite being a popular channel for smart homes, is the least preferred method for smart commercial buildings.\nAuthors: Tu Le, Alan Wang, Yaxing Yao, Yuanyuan Feng, Arsalan Heydarian, N. Sadeh, Yuan Tian\nVenue: European Symposium on Security and Privacy\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is found that around half of the participants are not fully aware of the data collection and use practices of IoT even though they notice the presence of IoT devices and sensors.'}",
  "Faculty Name: norman sadeh\nMetadata:\nPaperid: 88efd1663016c4170674c8f30067e7096b172598\nTitle: Comparing Privacy Label Disclosures of Apps Published in both the App Store and Google Play Stores\nYear: 2023\nAbstract: Apple and Android introduced privacy labels in 2020 and 2022 respectively as a way of providing consumers with succinct summaries of mobile apps\u2019 more salient data practices. A number of apps are published in both stores, offering us the opportunity to compare their privacy label disclosures in the two app stores. This paper compares the data practices privacy labels are intended to capture in each store. It then proceeds to analyze the disclosures of 822 apps published in both app stores, focusing on possible discrepancies. This analysis reveals that privacy label disclosures of what is ostensibly the same mobile app can be quite different. We discuss the different possible reasons behind these differences, including the possibility that these discrepancies might be indicative of potential privacy compliance issues.",
  "This analysis reveals that privacy label disclosures of what is ostensibly the same mobile app can be quite different. We discuss the different possible reasons behind these differences, including the possibility that these discrepancies might be indicative of potential privacy compliance issues. In particular, focusing on data collection disclosures of five different data types (location, contact info, sensitive info, identifiers, and health & fitness) we find discrepancies between iOS and Google Play privacy label disclosures in 66.5% of the mobile apps we analyze.\nAuthors: David Rodriguez, Akshatha Jain, J. D. \u00c1lamo, N. Sadeh\nVenue: 2023 IEEE European Symposium on Security and Privacy Workshops (EuroS&PW)\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is revealed that privacy label disclosures of what is ostensibly the same mobile app can be quite different, including the possibility that these discrepancies might be indicative of potential privacy compliance issues.'}",
  "Faculty Name: norman sadeh\nMetadata:\nPaperid: 8f93ba514aee5e56d9d888f07e6625f8b3a40fcc\nTitle: Understanding How to Inform Blind and Low-Vision Users about Data Privacy through Privacy Question Answering Assistants\nYear: 2023\nAbstract: Understanding and managing data privacy in the digital world can be challenging for sighted users, let alone blind and low-vision (BLV) users. There is limited research on how BLV users, who have special accessibility needs, navigate data privacy, and how potential privacy tools could assist them. We conducted an in-depth qualitative study with 21 US BLV participants to understand their data privacy risk perception and mitigation, as well as their information behaviors related to data privacy. We also explored BLV users' attitudes towards potential privacy question answering (Q&A) assistants that enable them to better navigate data privacy information. We found that BLV users face heightened security and privacy risks, but their risk mitigation is often insufficient. They do not necessarily seek data privacy information but clearly recognize the benefits of a potential privacy Q&A assistant.",
  "We found that BLV users face heightened security and privacy risks, but their risk mitigation is often insufficient. They do not necessarily seek data privacy information but clearly recognize the benefits of a potential privacy Q&A assistant. They also expect privacy Q&A assistants to possess cross-platform compatibility, support multi-modality, and demonstrate robust functionality. Our study sheds light on BLV users' expectations when it comes to usability, accessibility, trust and equity issues regarding digital data privacy.\nAuthors: Yuanyuan Feng, Abhilasha Ravichander, Yaxing Yao, Shikun Zhang, Rex Chen, Shomir Wilson, Norman M. Sadeh\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is found that BLV users face heightened security and privacy risks, but their risk mitigation is often insufficient, and they expect privacy Q&A assistants to possess cross-platform compatibility, support multi-modality, and demonstrate robust functionality.'}",
  "Faculty Name: norman sadeh\nMetadata:\nPaperid: d07e77f0477c3568d64086ef4d50ea1fcff63b8c\nTitle: ATLAS: Automatically Detecting Discrepancies Between Privacy Policies and Privacy Labels\nYear: 2023\nAbstract: Privacy policies are long, complex documents that end-users seldom read. Privacy labels aim to ameliorate these issues by providing succinct summaries of salient data practices. In December 2020, Apple began requiring that app developers submit privacy labels describing their apps\u2019 data practices. Yet, research suggests that app developers often struggle to do so. In this paper, we automatically identify possible discrepancies between mobile app privacy policies and their privacy labels. Such discrepancies could be indicators of potential privacy compliance issues. We introduce the Automated Privacy Label Analysis System (ATLAS). ATLAS includes three components: a pipeline to systematically retrieve iOS App Store listings and privacy policies; an ensemble-based classifier capable of predicting privacy labels from the text of privacy policies with 91.3% accuracy using state-of-the-art NLP techniques; and a discrepancy analysis mechanism that enables a large-scale privacy analysis of the iOS App Store.",
  "Our system has enabled us to analyze 354,725 iOS apps. We find several interesting trends. For example, only 40.3% of apps in the App Store provide easily accessible privacy policies, and only 29.6% of apps provide both accessible privacy policies and privacy labels. Among apps that provide both, 88.0% have at least one possible discrepancy between the text of their privacy policy and their privacy label, which could be indicative of a potential compliance issue. We find that, on average, apps have 5.32 such potential compliance issues. We hope that ATLAS will help app developers, researchers, regulators, and mobile app stores alike. For example, app developers could use our classifier to check for discrepancies between their privacy policies and privacy labels, and regulators could use our system to help review apps at scale for potential compliance issues.",
  "We hope that ATLAS will help app developers, researchers, regulators, and mobile app stores alike. For example, app developers could use our classifier to check for discrepancies between their privacy policies and privacy labels, and regulators could use our system to help review apps at scale for potential compliance issues.\nAuthors: Akshatha Jain, David Rodr\u00edguez Torrado, J. D. \u00c1lamo, N. Sadeh\nVenue: 2023 IEEE European Symposium on Security and Privacy Workshops (EuroS&PW)\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper automatically identifies possible discrepancies between mobile app privacy policies and their privacy labels, and finds that, on average, apps have 5.32 potential compliance issues.'}",
  "List of 2023 Open Access papers by norman sadeh are:\nDo Privacy Labels Answer Users' Privacy Questions?\nExploring Smart Commercial Building Occupants\u2019 Perceptions and Notification Preferences of Internet of Things Data Collection in the United States\nComparing Privacy Label Disclosures of Apps Published in both the App Store and Google Play Stores\nATLAS: Automatically Detecting Discrepancies Between Privacy Policies and Privacy Labels\nPurpose in the Machine: Do Traffic Simulators Produce Distributionally Equivalent Outcomes for Reinforcement Learning Applications?\nUnderstanding How to Inform Blind and Low-Vision Users about Data Privacy through Privacy Question Answering Assistants",
  "Title: Eric Nyberg -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Eric Nyberg, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Core Faculty\" name=\"categories-1\"/>\n<meta content=\"Information Extraction, Summarization and Question Answering;Information Retrieval, Text Mining and Analytics;Language Technologies for Education\" name=\"categories-2\"/>\n<meta content=\"Yes\" name=\"show-categories-2\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Eric Nyberg - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Eric Nyberg,",
  "Faculty Member at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Eric\"/>\n<meta content=\"Lastname\" property=\"profile:Nyberg\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/nyberg-eric.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nEric \n                        Nyberg\nProfessor, Language Technologies Institute\nContact\n6715 \u2014Gates & Hillman Centers\nehn(through)cs.cmu.edu\n412-268-7281\nResearch Area\nInformation Extraction, Summarization and Question Answering, Information Retrieval, Text Mining and Analytics, Language Technologies for Education\nPersonal Website\n\nLinks:\nhttp://www.cs.cmu.edu/~ehn/",
  "Title: Kemal Oflazer -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Kemal Oflazer, Affiliated Faculty at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Core Faculty\" name=\"categories-1\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Kemal Oflazer - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Kemal Oflazer, Affiliated Faculty at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Kemal\"/>\n<meta content=\"Lastname\" property=\"profile:Oflazer\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/oflazer-kemal.",
  "cmu.edu//people/faculty/oflazer-kemal.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nKemal \n                        Oflazer\nTeaching Professor, Language Technologies Institute\nComputer Science Department\nContact\n1009 \u2014Carnegie Mellon - Qatar Campus\nko(through)qatar.cmu.edu\nComputer Science - Qatar\nPersonal Website\n\nLinks:\nhttps://www.qatar.cmu.edu/academics-research/academics/computer-science/#/?feed=news&category=49&limit=3&featuredCategory=49&page=1\nhttps://www.andrew.cmu.edu/user/ko/",
  "Faculty Name: raj reddy\nMetadata:\nPaperid: 0e175e5836fcf16795dd7b9399e0754cce698602\nTitle: Integrative Multi-omic Profiling of Two Human Decedents Receiving Pig Heart Xenografts Reveals Strong Perturbations in Early Immune-Cell and Cellular Metabolism Responses\nYear: 2023\nAbstract: Background Recent advances in xenotransplantation in living and decedent humans using pig xenografts have laid promising groundwork towards future emergency use and first in human trials. Major obstacles remain though, including a lack of knowledge of the genetic incompatibilities between pig donors and human recipients which may led to harmful immune responses against the xenograft or dysregulation of normal physiology. In 2022 two pig heart xenografts were transplanted into two brain-dead human decedents with a minimized immunosuppression regime, primarily to evaluate onset of hyper-acute antibody mediated rejection and sustained xenograft function over 3 days.",
  "In 2022 two pig heart xenografts were transplanted into two brain-dead human decedents with a minimized immunosuppression regime, primarily to evaluate onset of hyper-acute antibody mediated rejection and sustained xenograft function over 3 days. Methods We performed multi-omic profiling to assess the dynamic interactions between the pig and human genomes in the first two pig heart-xenografts transplants into human decedents. To assess global and specific biological changes that may correlate with immune-related outcomes and xenograft function, we generated transcriptomic, lipidomic, proteomic and metabolomics datasets, across blood and tissue samples collected every 6 hours over the 3-day procedures. Results Single-cell datasets in the 3-day pig xenograft-decedent models show dynamic immune activation processes. We observe specific scRNA-seq, snRNA-seq and geospatial transcriptomic changes of early immune-activation leading to pronounced downstream T-cell activity and hallmarks of early antibody mediated rejection (AbMR) and/or ischemia reperfusion injury (IRI) in the first xenograft recipient.",
  "We observe specific scRNA-seq, snRNA-seq and geospatial transcriptomic changes of early immune-activation leading to pronounced downstream T-cell activity and hallmarks of early antibody mediated rejection (AbMR) and/or ischemia reperfusion injury (IRI) in the first xenograft recipient. Using longitudinal multiomic integrative analyses from blood in addition to antigen presentation pathway enrichment, we also observe in the first xeno-heart recipient significant cellular metabolism and liver damage pathway changes that correlate with profound physiological dysfunction whereas, these signals are not present in the other xenograft recipient. Conclusions Single-cell and multiomics approaches reveal fundamental insights into early molecular immune responses indicative of IRI and/or early AbMR in the first human decedent, which was not evident in the conventional histological evaluations.\nAuthors: Eloi Schmauch, B. Piening, Bo Xia, Chenchen Zhu, J. Stern, Wei-Meng Zhang, A. Dowdell, Bao-Li Loza, Maede Mohebnasab, L. Gragert, K. Khalil, Brendan R. Camellato, M. F. de Oliveira, D. O\u2019Brien, E. Weldon, Xiangping Lin,",
  "A. Dowdell, Bao-Li Loza, Maede Mohebnasab, L. Gragert, K. Khalil, Brendan R. Camellato, M. F. de Oliveira, D. O\u2019Brien, E. Weldon, Xiangping Lin, Hui Gao, L. Kagermazova, Jacqueline I. Kim, A. Loupy, A. Heguy, S. Taylor, Florrie Zhu, Sarah Gao, Divya Gandla, K. Reddy, A. Chang, Basil Michael, Lihua Jiang, Ruiqi Jian, N. Narula, S. Linna-Kuosmanen, Minna Kaikkonen-M\u00e4\u00e4tt\u00e4, M. Lorber, M. Kellis, V. Tatapudi, D. Ayares, A. Griesemer, M. Mangiola, H. Pass, M. Snyder, Robert A. Montgomery, J. Boeke, B. Keating\nVenue: bioRxiv\nTldr: {'model': 'tldr@v2.0.0',",
  "D. Ayares, A. Griesemer, M. Mangiola, H. Pass, M. Snyder, Robert A. Montgomery, J. Boeke, B. Keating\nVenue: bioRxiv\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Single-cell and multiomics approaches reveal fundamental insights into early molecular immune responses indicative of IRI and/or early AbMR in the first human decedent, which was not evident in the conventional histological evaluations.'}",
  "Faculty Name: raj reddy\nMetadata:\nPaperid: 2af3849abf77fbc5bf35de75cbd0edcbf2f14244\nTitle: Anti Inflammatory activity of AgNps synthesized using flower formulation (Rosa andJasminum\nYear: 2023\nAbstract: Introduction: In recent years, there has been a resurgence in the use of traditional medicinal herbs, and as a result, \npharmaceutical companies are investing heavily in developing natural medications derived from plants. Nanoparticles act \nin a number of potential ways and fields. Chemical synthesis of nanoparticles is no longer advantageous compared to \nplant-based synthesis. The current study uses a green method to create silver nanoparticles (AgNPs) utilizing flower \nextract.\nMaterials and methods: The anti-inflammatory activity for gel was tested by the following convention proposed by \nMuzushima and Kabayashi with specific alterations. 0.05 mL of Rosa and jasminum jel of various fixations.\nResult: Using rosa and jasminum extract in the manufacture of silver nanoparticles, the nanoparticles showed remarkable \nantioxidant and anti-inflammatory activity.",
  "0.05 mL of Rosa and jasminum jel of various fixations.\nResult: Using rosa and jasminum extract in the manufacture of silver nanoparticles, the nanoparticles showed remarkable \nantioxidant and anti-inflammatory activity. It was discovered that the cytotoxic effect was less harmful, demonstrating \nbiocompatibility. Rosa jasminum extract of AgNps showed good anti-inflammatory efficacy in the EA and BSA assays.\nConclusion: From our study we concluded that Silver nanoparticles were created using rosa and jasminum extract, and \nthe nanoparticles displayed impressive anti-inflammatory.\nAuthors: R. Bharath, A. Arthanari, S. Rajeshkumar\nVenue: Journal of Complementary Medicine Research\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Using rosa and jasminum extract in the manufacture of silver nanoparticles, the nanoparticles showed remarkable antioxidant and anti-inflammatory activity, and the cytotoxic effect was less harmful, demonstrating biocompatibility.'}",
  "Faculty Name: raj reddy\nMetadata:\nPaperid: 405a3700dabfc2e6e024a35dbca6af5ee20b67f2\nTitle: Jigsaw: A step toward co-operative learning among medical and nursing students\nYear: 2023\nAbstract: Background and Aim: To shift the paradigm from passive tutor driven tutorials to more responsible active learning by the students, a co operative teaching learning method could be a good alternative. The Jigsaw approach, a model of co operative learning, focuses on learning in groups with fellow learner co operation and reassures team work. Thus, this study was aimed at assessing the effectiveness of jigsaw strategy in comparison to tutorials in enhancing cognitive skills among the medical students in microbiology. Materials and Methods: A cross sectional study was carried out at microbiology department for 50 consenting MBBS students of professional year II and 50 consenting B.Sc nursing students of 2nd years. Students were randomly divided into two batches: Aand B of 25 students each. They were prepared for either a jigsaw (Experimental) or tutorial (Control) a week prior on predecided topics. The same groups were crossed over for another topic.",
  "Students were randomly divided into two batches: Aand B of 25 students each. They were prepared for either a jigsaw (Experimental) or tutorial (Control) a week prior on predecided topics. The same groups were crossed over for another topic. Students' performance was assessed by pretest, posttest, academic achievement level, and retention test by prevalidated multiple choice questionnaires. The student perception on TL methods was evaluated by using learning experience questionnaires. Results: Posttest scores of both groups were found to be significant at the level of P < 0.05. Among medical students, mean of posttest scores in the jigsaw is more than tutorial (12.4 v/s 9.7, crossover 13.3 v/s 11.2) and in nursing students (11.7 v/s 8.2, crossover 11.6 v/s 9.9). Mean retention tests scores and absolute achievement level were high in jigsaw groups. The students preferred jigsaw over the tutorial.",
  "Mean retention tests scores and absolute achievement level were high in jigsaw groups. The students preferred jigsaw over the tutorial. Conclusion: Jigsaw strategy is a robust instructional tool, well perceived by the students to enhance cognitive skills as inferred by the results and can be tailored to the needs of varied topics across different disciplines.\nAuthors: Vinod Kumar C S, S. Kalasuramath, S. Reddy, R. Reddy\nVenue: Archives of Medicine and Health Sciences\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Jigsaw strategy is a robust instructional tool, well perceived by the students to enhance cognitive skills as inferred by the results and can be tailored to the needs of varied topics across different disciplines.'}",
  "Faculty Name: raj reddy\nMetadata:\nPaperid: beedd5ec0316af0fa27dbd13c9d57d191bbcdacf\nTitle: Performance Evaluation and Cyberattack Mitigation in a Blockchain-Enabled Peer-to-Peer Energy Trading Framework\nYear: 2023\nAbstract: With the electric power grid experiencing a rapid shift to the smart grid paradigm over a deregulated energy market, Internet of Things (IoT)-based solutions are gaining prominence, and innovative peer-to-peer (P2P) energy trading at a micro level is being deployed. Such advancement, however, leaves traditional security models vulnerable and paves the path for blockchain, a distributed ledger technology (DLT), with its decentralized, open, and transparency characteristics as a viable alternative. However, due to deregulation in energy trading markets, most of the prototype resilience regarding cybersecurity attack, performance and scalability of transaction broadcasting, and its direct impact on overall performances and attacks are required to be supported, which becomes a performance bottleneck with existing blockchain solutions such as Hyperledger, Ethereum, and so on.",
  "However, due to deregulation in energy trading markets, most of the prototype resilience regarding cybersecurity attack, performance and scalability of transaction broadcasting, and its direct impact on overall performances and attacks are required to be supported, which becomes a performance bottleneck with existing blockchain solutions such as Hyperledger, Ethereum, and so on. In this paper, we design a novel permissioned Corda framework for P2P energy trading peers that not only mitigates a new class of cyberattacks, i.e., delay trading (or discard), but also disseminates the transactions in a optimized propagation time, resulting in a fair transaction distribution. Sharing transactions in a permissioned R3 Corda blockchain framework is handled by the Advanced Message Queuing Protocol (AMQP) and transport layer security (TLS). The unique contribution of this paper lies in the use of an optimized CPU and JVM heap memory scenario analysis with P2P metric in addition to a far more realistic multihosted testbed for the performance analysis. The average latencies measured are 22 ms and 51 ms for sending and receiving messages. We compare the throughput by varying different types of flow such as energy request, request + pay, transfer, multiple notary, sender, receiver, and single notary.",
  "The average latencies measured are 22 ms and 51 ms for sending and receiving messages. We compare the throughput by varying different types of flow such as energy request, request + pay, transfer, multiple notary, sender, receiver, and single notary. In the proposed framework, request is an energy asset that is based on payment state and contract in the P2P energy trading module, so in request flow, only one node with no notary appears on the vault of the node.Energy request + pay flow interaction deals with two nodes, such as producer and consumer, to deal with request and transfer of asset ownership with the help of a notary. Request + repeated pay flow request, on node A and repeatedly transfers a fraction of energy asset state to another node, B, through a notary.",
  "Request + repeated pay flow request, on node A and repeatedly transfers a fraction of energy asset state to another node, B, through a notary.\nAuthors: N. Pradhan, A. Singh, S. Sudha, K. H. K. Reddy, D. S. Roy\nVenue: Italian National Conference on Sensors\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A novel permissioned Corda framework for P2P energy trading peers that not only mitigates a new class of cyberattacks, i.e., delay trading (or discard), but also disseminates the transactions in a optimized propagation time, resulting in a fair transaction distribution.'}",
  "Faculty Name: raj reddy\nMetadata:\nPaperid: e48f14c82a52ed7b594799b2a51e7f2a703e17d1\nTitle: The Evolving Profile of Idiosyncratic Drug Induced liver Injury.\nYear: 2023\nAbstract: None\nAuthors: R. Fontana, E. Bjornsson, K. Reddy, R. Andrade\nVenue: Clinical Gastroenterology and Hepatology\nTldr: {'model': 'tldr@v2.0.0', 'text': 'DILI patients with an elevated INR or mental status changes should be considered for N-acetylcysteine therapy and urgent liver transplant evaluation, and selected patients with moderate to severe DRESS or autoimmune features on liver biopsy may benefit from short-term corticosteroids.'}",
  "List of 2023 Open Access papers by raj reddy are:\nJigsaw: A step toward co-operative learning among medical and nursing students\nIntegrative Multi-omic Profiling of Two Human Decedents Receiving Pig Heart Xenografts Reveals Strong Perturbations in Early Immune-Cell and Cellular Metabolism Responses\nThe Evolving Profile of Idiosyncratic Drug Induced liver Injury.\nPerformance Evaluation and Cyberattack Mitigation in a Blockchain-Enabled Peer-to-Peer Energy Trading Framework\nAnti Inflammatory activity of AgNps synthesized using flower formulation (Rosa andJasminum",
  "Title: Bhiksha Raj -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Bhiksha Raj, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Core Faculty\" name=\"categories-1\"/>\n<meta content=\"Machine Learning;Multimodal Computing and Interaction;Privacy and Security;Speech Processing;Spoken Interfaces and Dialogue Processing\" name=\"categories-2\"/>\n<meta content=\"Yes\" name=\"show-categories-2\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Bhiksha Raj - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Bhiksha Raj,",
  "Faculty Member at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Bhiksha\"/>\n<meta content=\"Lastname\" property=\"profile:Raj\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/raj-bhiksha.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nBhiksha \n                        Raj\nProfessor, Language Technologies Institute\nContact\n6705 \u2014Gates & Hillman Centers\nbhiksha(through)cs.cmu.edu\n412-268-9826\nResearch Area\nMachine Learning, Multimodal Computing and Interaction, Privacy and Security, Speech Processing, Spoken Interfaces and Dialogue Processing\nPersonal Website\n\nLinks:\nhttp://mlsp.cs.cmu.edu/people/bhiksha/index.php",
  "List of 2023 Open Access papers by ralf brown are:",
  "List of 2023 Open Access papers by ravi starzl are:",
  "Title: Raj Reddy -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Raj Reddy, Affiliated Faculty at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Affiliated Faculty\" name=\"categories-1\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Raj Reddy - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Raj Reddy, Affiliated Faculty at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Raj\"/>\n<meta content=\"Lastname\" property=\"profile:Reddy\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/reddy-raj.",
  "cmu.edu//people/faculty/reddy-raj.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nRaj \n                        Reddy\nMoza Bint Nasser University Professor, Robotics Institute\nLanguage Technologies Institute\nContact\n5327 \u2014Wean Hall\nrr0s(through)andrew.cmu.edu\n412-268-2597\nResearch\nDr. Reddy's research interests include the study of human-computer interaction and artificial intelligence. His current research projects include spoken language systems; gigabit networks; universal digital libraries; and distance learning on demand.\nRobotics Institute\nPersonal Website\n\nLinks:\nhttps://www.ri.cmu.edu/\nhttp://www.rr.cs.cmu.edu/",
  "Faculty Name: richard stern\nMetadata:\nPaperid: 1782bb8c2eb9fd97a7e07ba464a49f263ca6170c\nTitle: Age validation of Black Rockfish, Copper Rockfish, and Cabezon using secondary ion mass spectrometry (SIMS) to elucidate seasonal patterns in otolith stable oxygen isotopes\nYear: 2023\nAbstract: None\nAuthors: M. Terwilliger, L. Rasmuson, R. Stern\nVenue: Environmental Biology of Fishes\nTldr: None",
  "Faculty Name: richard stern\nMetadata:\nPaperid: 1c3b832b704a691ffec5f1be43ac70934ba8a5a5\nTitle: Author Correction: Age of the magma chamber and its physicochemical state under Elbrus Greater Caucasus, Russia using zircon petrochronology and modeling insights\nYear: 2023\nAbstract: None\nAuthors: I. Bindeman, O. Melnik, M. Guillong, I. Utkin, J\u00f6ren-Frederik Wotzlaw, A. Schmitt, R. Stern\nVenue: Scientific Reports\nTldr: None",
  "Faculty Name: richard stern\nMetadata:\nPaperid: 1d5edd14887d19f783b929ea8cd23ec02aaec1e7\nTitle: Discovery of a giant 3.3\u20133.1 Ga terrane in the Rae craton, Canada: Implications for the timing and extent of ancient continental growth\nYear: 2023\nAbstract: We report the discovery of one of the largest ancient (>3.0 Ga) crustal terranes on Earth. Granitoids with crystallization ages >3.0 Ga and/or Sm-Nd depleted mantle model ages \u22653.2 Ga define a ~1000 \u00d7 100 km belt on the western margin of the Rae craton, Canada, referred to herein as the Perry River terrane (PRT). Zircon U-Pb-Hf-O isotope and whole-rock geochemical data from granitoids show that the PRT is a predominantly juvenile 3.3\u20133.2 Ga terrane that was partially reworked by more evolved ca. 3.1 Ga magmatism. These findings call for a reassessment of the timing and extent of ancient continental growth on Earth.",
  "3.1 Ga magmatism. These findings call for a reassessment of the timing and extent of ancient continental growth on Earth. A global compilation of zircon Hf isotope data from 3.6 to 3.0 Ga igneous rocks reveals clusters of relatively juvenile (initial \u03b5Hf \u22122 to +3) rocks at ca. 3.31 and ca. 3.23 Ga, which include samples from the PRT and 13 other terranes worldwide. Other global zircon data sets also document age peaks between 3.3 and 3.2 Ga, and a cluster of broadly chondritic initial \u03b5Hf values around 3.2 Ga. The 3.3\u20133.2 Ga period may therefore have been a time of enhanced net continental growth on Earth, and the PRT is one of the largest terranes preserved from that time. Furthermore, zircon Hf isotope data from 3.3\u20133.1 Ga PRT granitoids and 3.5\u20133.0 Ga igneous rocks worldwide yield little evidence for parent magmas that interacted with or derived from pre\u20133.6 Ga continental material.",
  "Furthermore, zircon Hf isotope data from 3.3\u20133.1 Ga PRT granitoids and 3.5\u20133.0 Ga igneous rocks worldwide yield little evidence for parent magmas that interacted with or derived from pre\u20133.6 Ga continental material. Contrary to some continental-growth models, this latter observation suggests that the volume of continental crust established by 3.6 Ga was relatively small.\nAuthors: B. Neil, Daniel B. Tersmette, T. Chacko, L. Heaman, B. Kjarsgaard, E. Martel, R. Creaser, D. Pearson, R. Stern, S. A. Dufrane, Yan Luo\nVenue: Geology\nTldr: None",
  "Faculty Name: richard stern\nMetadata:\nPaperid: 42a2c532f30f4144919211a7098d26f7de7bae00\nTitle: Diamonds reveal subducted slab harzburgite in the lower mantle\nYear: 2023\nAbstract: Characterizing compositional heterogeneity in Earth\u2019s lower mantle is critical to understanding its dynamics. Three low-nitrogen diamonds from Koffiefontein (South Africa), containing inclusion assemblages of ferropericlase \u00b1 orthopyroxene \u00b1 magnesite, constrain diamond formation in an Mg-rich lower-mantle environment. Ferropericlase inclusions have Mg# 82.7\u201388.5 and orthopyroxene inclusions (retrogressed bridgmanite) have Mg# 95.0\u201395.1 and mantle-like \u03b418O of +5.6\u2030 \u00b1 0.2\u2030. Magnesite included in one diamond implicates carbonated fluids in diamond formation. High Mg# and low Ca, Al, and Na of the assemblage indicate a melt-depleted meta-harzburgitic environment, in contrast to more fertile compositions expected for primitive lower mantle.",
  "Magnesite included in one diamond implicates carbonated fluids in diamond formation. High Mg# and low Ca, Al, and Na of the assemblage indicate a melt-depleted meta-harzburgitic environment, in contrast to more fertile compositions expected for primitive lower mantle. Extremely low Ca in orthopyroxene inclusions may reflect a combination of melt depletion and low equilibration temperatures at the time of trapping. Inclusion compositions implicate subducted oceanic slab meta-harzburgite as the host for diamond growth. Mantle-like \u03b418O of the orthopyroxene inclusions indicates unaltered oceanic lithosphere. Similar melt-depleted characteristics in lower-mantle inclusion assemblages worldwide support that meta-harzburgite is the dominant host of lower-mantle diamonds.\nAuthors: N. A. Meyer, T. Stachel, D. Pearson, R. Stern, J. Harris, M. Walter\nVenue: Geology\nTldr: None",
  "Faculty Name: richard stern\nMetadata:\nPaperid: 42f863b48ae99f2b38f449af85ced160ced1fd38\nTitle: Age of the magma chamber and its physicochemical state under Elbrus Greater Caucasus, Russia using zircon petrochronology and modeling insights\nYear: 2023\nAbstract: None\nAuthors: I. Bindeman, O. Melnik, M. Guillong, I. Utkin, J. Wotzlaw, A. Schmitt, R. Stern\nVenue: Scientific Reports\nTldr: None",
  "Faculty Name: richard stern\nMetadata:\nPaperid: 6a224b87c49f8e957dfd7df618fa2f2da74c20e1\nTitle: Sulfate recycling at subduction zones indicated by sulfur isotope systematics of Mesozoic ultramafic island arc cumulates in the North American Cordillera\nYear: 2023\nAbstract: None\nAuthors: D. Milidragovic, J. Nott, D. Spence, D. Schumann, J. Scoates, G. Nixon, R. Stern\nVenue: Earth and Planetary Science Letters\nTldr: None",
  "Faculty Name: richard stern\nMetadata:\nPaperid: 715faa00f2b68fae6a3ee635708eccfcdf558060\nTitle: Automatic Detection of Dyspnea in Real Human\u2013Robot Interaction Scenarios\nYear: 2023\nAbstract: A respiratory distress estimation technique for telephony previously proposed by the authors is adapted and evaluated in real static and dynamic HRI scenarios. The system is evaluated with a telephone dataset re-recorded using the robotic platform designed and implemented for this study. In addition, the original telephone training data are modified using an environmental model that incorporates natural robot-generated and external noise sources and reverberant effects using room impulse responses (RIRs). The results indicate that the average accuracy and AUC are just 0.4% less than those obtained with matched training/testing conditions with simulated data. Quite surprisingly, there is not much difference in accuracy and AUC between static and dynamic HRI conditions. Moreover, the beamforming methods delay-and-sum and MVDR lead to average improvement in accuracy and AUC equal to 8% and 2%, respectively, when applied to training and testing data.",
  "Quite surprisingly, there is not much difference in accuracy and AUC between static and dynamic HRI conditions. Moreover, the beamforming methods delay-and-sum and MVDR lead to average improvement in accuracy and AUC equal to 8% and 2%, respectively, when applied to training and testing data. Regarding the complementarity of time-dependent and time-independent features, the combination of both types of classifiers provides the best joint accuracy and AUC score.\nAuthors: Eduardo Alvarado, Nicol\u00e1s Gr\u00e1geda, Alejandro Luzanto, R. Mah\u00fa, J. Wuth, Laura Mendoza, Richard M. Stern, N. B. Yoma\nVenue: Italian National Conference on Sensors\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A respiratory distress estimation technique for telephony previously proposed by the authors is adapted and evaluated in real static and dynamic HRI scenarios and the combination of both types of classifiers provides the best joint accuracy and AUC score.'}",
  "Faculty Name: richard stern\nMetadata:\nPaperid: 8b49ebfc2b436c8b064ecf5b1eb3c5a12fc8d4b8\nTitle: Unsupervised Voice Type Discrimination Score Adaptation Using X-Vector Clusters\nYear: 2023\nAbstract: Voice type discrimination (VTD) is the task of automatically detecting speech produced in the same room as a recording device (\"live speech\") among other speech and non-speech noises, such as traffic noises or radio broadcasts (\"distractor audio\"). Existing work has described methods for performing the VTD task. This paper presents a method for adapting the output of these existing methods in an unsupervised manner via x-vector clustering and correlation. This adaptation method can be applied to the output of any VTD algorithm, requires no additional training data, and has been shown to yield a relative decrease in decision cost function (DCF) score of up to 47% on a standardized database collected for the task.",
  "This adaptation method can be applied to the output of any VTD algorithm, requires no additional training data, and has been shown to yield a relative decrease in decision cost function (DCF) score of up to 47% on a standardized database collected for the task.\nAuthors: Mark Lindsey, Tyler Vuong, R. Stern\nVenue: IEEE International Conference on Acoustics, Speech, and Signal Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This adaptation method can be applied to the output of any VTD algorithm, requires no additional training data, and has been shown to yield a relative decrease in decision cost function (DCF) score of up to 47% on a standardized database collected for the task.'}",
  "Faculty Name: richard stern\nMetadata:\nPaperid: a1fa5a0b9b49159d196a80a6c8408dde0beb5c23\nTitle: Water in omphacite and garnet from unmetasomatised xenolithic eclogite: T-X-fO2 controls, and implications for conductivity and the deep H2O cycle\nYear: 2023\nAbstract: None\nAuthors: Sonja Aulbach, Roland Stalder, Malcolm Massuyeau, Richard A. Stern, D. Ionov, Larry Heaman, Andrey Korsakov\nVenue: Goldschmidt2023 abstracts\nTldr: None",
  "Faculty Name: richard stern\nMetadata:\nPaperid: cac3431a30d7a1d3479d25510aadb30182f88b5c\nTitle: Online Active Learning For Sound Event Detection\nYear: 2023\nAbstract: Data collection and annotation is a laborious, time-consuming prerequisite for supervised machine learning tasks. Online Active Learning (OAL) is a paradigm that addresses this issue by simultaneously minimizing the amount of annotation required to train a classifier and adapting to changes in the data over the duration of the data collection process. Prior work has indicated that fluctuating class distributions and data drift are still common problems for OAL. This work presents new loss functions that address these challenges when OAL is applied to Sound Event Detection (SED). Experimental results from the SONYC dataset and two Voice-Type Discrimination (VTD) corpora indicate that OAL can reduce the time and effort required to train SED classifiers by a factor of 5 for SONYC, and that the new methods presented here successfully resolve issues present in existing OAL methods.",
  "Experimental results from the SONYC dataset and two Voice-Type Discrimination (VTD) corpora indicate that OAL can reduce the time and effort required to train SED classifiers by a factor of 5 for SONYC, and that the new methods presented here successfully resolve issues present in existing OAL methods.\nAuthors: Mark Lindsey, Ankit Shah, Francis Kubala, R. M. Stern\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Experimental results from the SonyC dataset and two Voice-Type Discrimination corpora indicate that OAL can reduce the time and effort required to train SED classifiers by a factor of 5 for SONYC, and that the new methods presented here successfully resolve issues present in existing OAL methods.'}",
  "Faculty Name: richard stern\nMetadata:\nPaperid: d2cbb6d653a83f1bee6a0a971e8ce38f83d2a74c\nTitle: Zircon within chromitite requires revision of the tectonic history of the Eoarchean Itsaq Gneiss complex, Greenland\nYear: 2023\nAbstract: None\nAuthors: H. Sawada, T. Morishita, A. Vezinet, R. Stern, K. Tani, I. Nishio, Kanta Takahashi, D. Graham Pearson, K. Szilas\nVenue: Geoscience Frontiers\nTldr: None",
  "Faculty Name: richard stern\nMetadata:\nPaperid: da10328c6412b39f0f4cf73bf18b3f464299fd23\nTitle: Fibrous calcite veins record stepwise, asymmetric opening and episodic hydrocarbon expulsion from organic-rich shales\nYear: 2023\nAbstract: Episodic fluid expulsion through fractures is widely expected during hydrocarbon generation, yet direct evidence for this process is lacking in the case of organic-rich shales. We investigated the formation of antitaxial, bed-parallel fibrous calcite veins hosted in organic-rich shales of the Eocene Dongying Depression, Bohai Bay Basin, China. Our results from detailed, in situ geochemical traverses show that while some symmetric veins exhibit broadly synchronous and steady-state opening, other asymmetric veins consist of two geochemically distinct generations of calcite to either side of the median zone, suggesting asymmetric and asynchronous growth in two discrete episodes during hydrocarbon expulsion. Thus, we argue that each asymmetric vein recording two stages of opening implies that hydrocarbons were expelled from shales episodically.",
  "Thus, we argue that each asymmetric vein recording two stages of opening implies that hydrocarbons were expelled from shales episodically.\nAuthors: Miao Wang, Yong Chen, R. Stern, Ashley Went, Yaoqi Zhou, G. Song, Tengfei Zhou, M. Steele\u2010MacInnis\nVenue: Geology\nTldr: None",
  "Faculty Name: richard stern\nMetadata:\nPaperid: ee5388bdff1c2afa23477606118406d205eb394a\nTitle: Water in Omphacite and Garnet From Pristine Xenolithic Eclogite: T\u2010X\u2010fO2 Controls, Retentivity, and Implications for Electrical Conductivity and Deep H2O Recycling\nYear: 2023\nAbstract: Kimberlite\u2010borne eclogite xenoliths having Precambrian oceanic crustal protoliths and entrained from \u2265100 km depth can retain pristine geochemical features despite extended residence in the cratonic lithospheric mantle, making them valuable archives of deep chemical cycling including that of water. We determined, by Fourier Transform Infrared Spectroscopy, structural OH contents in clinopyroxene and garnet from 15 unmetasomatized eclogite xenoliths.",
  "We determined, by Fourier Transform Infrared Spectroscopy, structural OH contents in clinopyroxene and garnet from 15 unmetasomatized eclogite xenoliths. Calculated total c(H2O) is 100\u2013510 wt.ppm for clinopyroxene and below detection (\u223c2 wt.ppm) to 200 wt.ppm for garnet, while garnet \u03b418O, determined by Secondary Ion Mass Spectrometry, ranges from +5.0\u2030 to +7.3\u2030, (similar to high\u2010 and low\u2010temperature seawater\u2010altered oceanic crust). Estimated electrical conductivity in pristine eclogites increases with temperature (i.e., depth for conductive geotherms), while clinopyroxene\u2010garnet H2O partition coefficients decrease with increasing temperature and garnet grossular component (i.e., Ca#), similar to other incompatible components. Various considerations suggest the retention of primary H2O in the samples, likely occurring in km\u2010sized pods of coarse\u2010grained eclogite. High Al2O3 in clinopyroxene as omphacite component, stabilized during high\u2010pressure metamorphism, facilitates H2O uptake.",
  "Various considerations suggest the retention of primary H2O in the samples, likely occurring in km\u2010sized pods of coarse\u2010grained eclogite. High Al2O3 in clinopyroxene as omphacite component, stabilized during high\u2010pressure metamorphism, facilitates H2O uptake. Therefore, the high bulk c(H2O) estimated for samples with plagioclase\u2010rich, deep crustal protoliths (median 290 wt.ppm) may indicate an interaction with fluids expelled at depth from serpentinites. The c(H2O) of ancient and modern subducted bulk oceanic crust (\u223c220\u2013240 wt.ppm) are similar, suggesting constant mantle ingassing since at least 3 Ga ago. This places constraints on factors, such as mantle temperatures, that determine the efficiency of deep water cycling.\nAuthors: Sonja Aulbach, Roland Stalder, Malcolm Massuyeau, Richard A. Stern, D. Ionov, Andrey Korsakov\nVenue: Geochemistry Geophysics Geosystems\nTldr: None",
  "List of 2023 Open Access papers by richard stern are:\nAutomatic Detection of Dyspnea in Real Human\u2013Robot Interaction Scenarios\nUnsupervised Voice Type Discrimination Score Adaptation Using X-Vector Clusters\nAge validation of Black Rockfish, Copper Rockfish, and Cabezon using secondary ion mass spectrometry (SIMS) to elucidate seasonal patterns in otolith stable oxygen isotopes\nAuthor Correction: Age of the magma chamber and its physicochemical state under Elbrus Greater Caucasus, Russia using zircon petrochronology and modeling insights\nDiscovery of a giant 3.3\u20133.1 Ga terrane in the Rae craton, Canada: Implications for the timing and extent of ancient continental growth\nDiamonds reveal subducted slab harzburgite in the lower mantle\nAge of the magma chamber and its physicochemical state under Elbrus Greater Caucasus,",
  "3\u20133.1 Ga terrane in the Rae craton, Canada: Implications for the timing and extent of ancient continental growth\nDiamonds reveal subducted slab harzburgite in the lower mantle\nAge of the magma chamber and its physicochemical state under Elbrus Greater Caucasus, Russia using zircon petrochronology and modeling insights\nSulfate recycling at subduction zones indicated by sulfur isotope systematics of Mesozoic ultramafic island arc cumulates in the North American Cordillera\nZircon within chromitite requires revision of the tectonic history of the Eoarchean Itsaq Gneiss complex, Greenland\nFibrous calcite veins record stepwise, asymmetric opening and episodic hydrocarbon expulsion from organic-rich shales\nWater in omphacite and garnet from unmetasomatised xenolithic eclogite: T-X-fO2 controls, and implications for conductivity and the deep H2O cycle\nWater in Omphacite and Garnet From Pristine Xenolithic Eclogite: T\u2010X\u2010fO2 Controls, Retentivity, and Implications for Electrical Conductivity and Deep H2O Recycling\nOnline Active Learning For Sound Event Detection",
  "Faculty Name: rita singh\nMetadata:\nPaperid: 1de2dcb5de694920f50f000a3795eb0ca54d57ab\nTitle: LoFT: Local Proxy Fine-tuning For Improving Transferability Of Adversarial Attacks Against Large Language Model\nYear: 2023\nAbstract: It has been shown that Large Language Model (LLM) alignments can be circumvented by appending specially crafted attack suffixes with harmful queries to elicit harmful responses. To conduct attacks against private target models whose characterization is unknown, public models can be used as proxies to fashion the attack, with successful attacks being transferred from public proxies to private target models. The success rate of attack depends on how closely the proxy model approximates the private model. We hypothesize that for attacks to be transferrable, it is sufficient if the proxy can approximate the target model in the neighborhood of the harmful query. Therefore, in this paper, we propose \\emph{Local Fine-Tuning (LoFT)}, \\textit{i.e.}, fine-tuning proxy models on similar queries that lie in the lexico-semantic neighborhood of harmful queries to decrease the divergence between the proxy and target models.",
  "Therefore, in this paper, we propose \\emph{Local Fine-Tuning (LoFT)}, \\textit{i.e.}, fine-tuning proxy models on similar queries that lie in the lexico-semantic neighborhood of harmful queries to decrease the divergence between the proxy and target models. First, we demonstrate three approaches to prompt private target models to obtain similar queries given harmful queries. Next, we obtain data for local fine-tuning by eliciting responses from target models for the generated similar queries. Then, we optimize attack suffixes to generate attack prompts and evaluate the impact of our local fine-tuning on the attack's success rate. Experiments show that local fine-tuning of proxy models improves attack transferability and increases attack success rate by $39\\%$, $7\\%$, and $0.5\\%$ (absolute) on target models ChatGPT, GPT-4, and Claude respectively.",
  "Experiments show that local fine-tuning of proxy models improves attack transferability and increases attack success rate by $39\\%$, $7\\%$, and $0.5\\%$ (absolute) on target models ChatGPT, GPT-4, and Claude respectively.\nAuthors: Muhammad Ahmed Shah, Roshan Sharma, Hira Dhamyal, R. Olivier, Ankit Shah, Dareen Alharthi, Hazim T Bukhari, Massa Baali, Soham Deshmukh, Michael Kuhlmann, Bhiksha Raj, Rita Singh\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Local fine-tuning of proxy models improves attack transferability and increases attack success rate by $39, $7, and $0.5$ (absolute) on target models ChatGPT, GPT-4, and Claude respectively.'}",
  "Faculty Name: rita singh\nMetadata:\nPaperid: 255bad49d29202e2d255926ab0983c125dcce835\nTitle: Evaluating Speech Synthesis by Training Recognizers on Synthetic Speech\nYear: 2023\nAbstract: Modern speech synthesis systems have improved significantly, with synthetic speech being indistinguishable from real speech. However, efficient and holistic evaluation of synthetic speech still remains a significant challenge. Human evaluation using Mean Opinion Score (MOS) is ideal, but inefficient due to high costs. Therefore, researchers have developed auxiliary automatic metrics like Word Error Rate (WER) to measure intelligibility. Prior works focus on evaluating synthetic speech based on pre-trained speech recognition models, however, this can be limiting since this approach primarily measures speech intelligibility. In this paper, we propose an evaluation technique involving the training of an ASR model on synthetic speech and assessing its performance on real speech. Our main assumption is that by training the ASR model on the synthetic speech, the WER on real speech reflects the similarity between distributions, a broader assessment of synthetic speech quality beyond intelligibility.",
  "Our main assumption is that by training the ASR model on the synthetic speech, the WER on real speech reflects the similarity between distributions, a broader assessment of synthetic speech quality beyond intelligibility. Our proposed metric demonstrates a strong correlation with both MOS naturalness and MOS intelligibility when compared to SpeechLMScore and MOSNet on three recent Text-to-Speech (TTS) systems: MQTTS, StyleTTS, and YourTTS.\nAuthors: Dareen Alharthi, Roshan Sharma, Hira Dhamyal, Soumi Maiti, Bhiksha Raj, Rita Singh\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper proposes an evaluation technique involving the training of an ASR model on synthetic speech and assessing its performance on real speech, and demonstrates a strong correlation with both MOS naturalness and MOS intelligibility when compared to SpeechLMScore and MosNet on three recent Text-to-Speech systems.'}",
  "Faculty Name: rita singh\nMetadata:\nPaperid: 2a8f592c31d8de9906183b081095b9842025f792\nTitle: Rethinking Audiovisual Segmentation with Semantic Quantization and Decomposition\nYear: 2023\nAbstract: Audiovisual segmentation (AVS) is a challenging task that aims to segment visual objects in videos based on their associated acoustic cues. With multiple sound sources involved, establishing robust correspondences between audio and visual contents poses unique challenges due to its (1) intricate entanglement across sound sources and (2) frequent shift among sound events. Assuming sound events occur independently, the multi-source semantic space (which encompasses all possible semantic categories) can be represented as the Cartesian product of single-source sub-spaces. This motivates us to decompose the multi-source audio semantics into single-source semantics, enabling more effective interaction with visual content. Specifically, we propose a semantic decomposition method based on product quantization, where the multi-source semantics can be decomposed and represented by several quantized single-source semantics.",
  "This motivates us to decompose the multi-source audio semantics into single-source semantics, enabling more effective interaction with visual content. Specifically, we propose a semantic decomposition method based on product quantization, where the multi-source semantics can be decomposed and represented by several quantized single-source semantics. Furthermore, we introduce a global-to-local quantization mechanism, which distills knowledge from stable global (clip-level) features into local (frame-level) ones, to handle the constant shift of audio semantics. Extensive experiments demonstrate that semantically quantized and decomposed audio representation significantly improves AVS performance, e.g., +21.2% mIoU on the most challenging AVS-Semantic benchmark.\nAuthors: Xiang Li, Jinglu Wang, Xiaohao Xu, Xiulian Peng, Rita Singh, Yan Lu, Bhiksha Raj\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes a semantic decomposition method based on product quantization, where the multi-source semantics can be decomposed and represented by several quantized single-source semantics, enabling more effective interaction with visual content.'}",
  "Faculty Name: rita singh\nMetadata:\nPaperid: 37e8e07d3ecfa43a1e64d48202c73f597e6f9fee\nTitle: Towards Noise-Tolerant Speech-Referring Video Object Segmentation: Bridging Speech and Text\nYear: 2023\nAbstract: None\nAuthors: Xiang Li, Jinglu Wang, Xiaohao Xu, Muqiao Yang, Fan Yang, Yizhou Zhao, Rita Singh, Bhiksha Raj\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: None",
  "Faculty Name: rita singh\nMetadata:\nPaperid: 3bd320ddb25886417ae90011b00f13f5d558097b\nTitle: BASS: Block-wise Adaptation for Speech Summarization\nYear: 2023\nAbstract: End-to-end speech summarization has been shown to improve performance over cascade baselines. However, such models are difficult to train on very large inputs (dozens of minutes or hours) owing to compute restrictions and are hence trained with truncated model inputs. Truncation leads to poorer models, and a solution to this problem rests in block-wise modeling, i.e., processing a portion of the input frames at a time. In this paper, we develop a method that allows one to train summarization models on very long sequences in an incremental manner. Speech summarization is realized as a streaming process, where hypothesis summaries are updated every block based on new acoustic information. We devise and test strategies to pass semantic context across the blocks. Experiments on the How2 dataset demonstrate that the proposed block-wise training method improves by 3 points absolute on ROUGE-L over a truncated input baseline.",
  "We devise and test strategies to pass semantic context across the blocks. Experiments on the How2 dataset demonstrate that the proposed block-wise training method improves by 3 points absolute on ROUGE-L over a truncated input baseline.\nAuthors: Roshan Sharma, Kenneth Zheng, Siddhant Arora, Shinji Watanabe, Rita Singh, B. Raj\nVenue: Interspeech\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper develops a method that allows one to train summarization models on very long sequences in an incremental manner and devise and test strategies to pass semantic context across the blocks.'}",
  "Faculty Name: rita singh\nMetadata:\nPaperid: 45b7d6e09d11e496e941481056177cf0164b5278\nTitle: GPT-Sentinel: Distinguishing Human and ChatGPT Generated Content\nYear: 2023\nAbstract: This paper presents a novel approach for detecting ChatGPT-generated vs. human-written text using language models. To this end, we first collected and released a pre-processed dataset named OpenGPTText, which consists of rephrased content generated using ChatGPT. We then designed, implemented, and trained two different models for text classification, using Robustly Optimized BERT Pretraining Approach (RoBERTa) and Text-to-Text Transfer Transformer (T5), respectively. Our models achieved remarkable results, with an accuracy of over 97% on the test dataset, as evaluated through various metrics. Furthermore, we conducted an interpretability study to showcase our model's ability to extract and differentiate key features between human-written and ChatGPT-generated text. Our findings provide important insights into the effective use of language models to detect generated text.",
  "Furthermore, we conducted an interpretability study to showcase our model's ability to extract and differentiate key features between human-written and ChatGPT-generated text. Our findings provide important insights into the effective use of language models to detect generated text.\nAuthors: Yutian Chen, Hao Kang, Vivian Zhai, Liang Li, Rita Singh, B. Ramakrishnan\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper designed, implemented, and trained two different models for text classification, using Robustly Optimized BERT Pretraining Approach (RoBERTa) and Text-to-Text Transfer Transformer (T5), respectively, and achieved remarkable results, with an accuracy of over 97% on the test dataset.'}",
  "Faculty Name: rita singh\nMetadata:\nPaperid: 47b70ad4c09a3195d24f926279afd5f35badbe86\nTitle: Comparison of freeze-thaw and sonication cycle-based methods for extracting AMR-associated metabolites from Staphylococcus aureus\nYear: 2023\nAbstract: Emerging antimicrobial resistance (AMR) among Gram-positive pathogens, specifically in Staphylococcus aureus (S. aureus), is becoming a leading public health concern demanding effective therapeutics. Metabolite modulation can improve the efficacy of existing antibiotics and facilitate the development of effective therapeutics. However, it remained unexplored for drug-resistant S. aureus (gentamicin and methicillin-resistant), primarily due to the dearth of optimal metabolite extraction protocols including a protocol for AMR-associated metabolites. Therefore, in this investigation, we have compared the performance of the two most widely used methods, i.e., freeze-thaw cycle (FTC) and sonication cycle (SC), alone and in combination (FTC\u2009+\u2009SC), and identified the optimal method for this purpose.",
  "Therefore, in this investigation, we have compared the performance of the two most widely used methods, i.e., freeze-thaw cycle (FTC) and sonication cycle (SC), alone and in combination (FTC\u2009+\u2009SC), and identified the optimal method for this purpose. A total of 116, 119, and 99 metabolites were identified using the FTC, SC, and FTC\u2009+\u2009SC methods, respectively, leading to the identification of 163 metabolites cumulatively. Out of 163, 69 metabolites were found to be associated with AMR in published literature consisting of the highest number of metabolites identified by FTC (57) followed by SC (54) and FTC\u2009+\u2009SC (40). Thus, the performances of FTC and SC methods were comparable with no additional benefits of combining both. Moreover, each method showed biasness toward specific metabolite(s) or class of metabolites, suggesting that the choice of metabolite extraction method shall be decided based on the metabolites of interest in the investigation.",
  "Thus, the performances of FTC and SC methods were comparable with no additional benefits of combining both. Moreover, each method showed biasness toward specific metabolite(s) or class of metabolites, suggesting that the choice of metabolite extraction method shall be decided based on the metabolites of interest in the investigation.\nAuthors: Rita Singh, Lovnish Thakur, Anil Kumar, Sevaram Singh, S Kumar, M. Kumar, Yashwant Kumar, Niraj Kumar\nVenue: Frontiers in Microbiology\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The performances of FTC and SC methods were comparable with no additional benefits of combining both, and each method showed biasness toward specific metabolite(s) or class of metabolites, suggesting that the choice of metabolite extraction method shall be decided based on the metabolites of interest in the investigation.'}",
  "Faculty Name: rita singh\nMetadata:\nPaperid: 49e173279a64a1e6b849cbfcd002cf3f0dbb1948\nTitle: Plant-Avian Frugivory in the Urban Ecosystem of Delhi\nYear: 2023\nAbstract: Plant-frugivore interactions are important ecological processes that play a vital role in maintaining the dynamics of the ecosystem. Birds are very important frugivores and very little is known about the plant-avian interaction matrix in the urban ecosystems of India. The present study endeavours to understand and document the plant\u2013avian frugivory interactions in the human-dominated green spaces which is a mosaic of selectively planted exotic and native tree species in Delhi. A total of thirty avian frugivore species were recorded feeding on twenty-two focal tree species using phyto-centric approach. Characteristic traits of fruits like fruit diameter, colour and type and their interacting avian species were studied based on their fruit handling behaviour. The highest number of avian frugivore species were observed on native Ficus tree species in urban Delhi ecosystem, thereby providing evident proof of being an important food resource for avian disperser communities.",
  "The highest number of avian frugivore species were observed on native Ficus tree species in urban Delhi ecosystem, thereby providing evident proof of being an important food resource for avian disperser communities. The study suggests to introduce more native fig tree species in the city plantations to enhance and sustain the avian diversity in the novel fragmented urban ecosystems.\nAuthors: Divya, Rita Singh, Sanjay Keshari Das\nVenue: Ecology, environment & conservation\nTldr: None",
  "Faculty Name: rita singh\nMetadata:\nPaperid: 5a3307b2e64bbcaff1202e261b8a83f7d03418a8\nTitle: Rethinking Voice-Face Correlation: A Geometry View\nYear: 2023\nAbstract: Previous works on voice-face matching and voice-guided face synthesis demonstrate strong correlations between voice and face, but mainly rely on coarse semantic cues such as gender, age, and emotion. In this paper, we aim to investigate the capability of reconstructing the 3D facial shape from voice from a geometry perspective without any semantic information. We propose a voice-anthropometric measurement (AM)-face paradigm, which identifies predictable facial AMs from the voice and uses them to guide 3D face reconstruction. By leveraging AMs as a proxy to link the voice and face geometry, we can eliminate the influence of unpredictable AMs and make the face geometry tractable. Our approach is evaluated on our proposed dataset with ground-truth 3D face scans and corresponding voice recordings, and we find significant correlations between voice and specific parts of the face geometry, such as the nasal cavity and cranium.",
  "Our approach is evaluated on our proposed dataset with ground-truth 3D face scans and corresponding voice recordings, and we find significant correlations between voice and specific parts of the face geometry, such as the nasal cavity and cranium. Our work offers a new perspective on voice-face correlation and can serve as a good empirical study for anthropometry science.\nAuthors: Xiang Li, Yandong Wen, Muqiao Yang, Jinglu Wang, Rita Singh, B. Raj\nVenue: ACM Multimedia\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes a voice-anthropometric measurement (AM)-face paradigm, which identifies predictable facial AMs from the voice and uses them to guide 3D face reconstruction and finds significant correlations between voice and specific parts of the face geometry, such as the nasal cavity and cranium.'}",
  "Faculty Name: rita singh\nMetadata:\nPaperid: 63a4150c9ad87c003de43b32828c8ceec6bb4468\nTitle: A Gene-Based Algorithm for Identifying Factors That May Affect a Speaker\u2019s Voice\nYear: 2023\nAbstract: Over the past decades, many machine-learning- and artificial-intelligence-based technologies have been created to deduce biometric or bio-relevant parameters of speakers from their voice. These voice profiling technologies have targeted a wide range of parameters, from diseases to environmental factors, based largely on the fact that they are known to influence voice. Recently, some have also explored the prediction of parameters whose influence on voice is not easily observable through data-opportunistic biomarker discovery techniques. However, given the enormous range of factors that can possibly influence voice, more informed methods for selecting those that may be potentially deducible from voice are needed. To this end, this paper proposes a simple path-finding algorithm that attempts to find links between vocal characteristics and perturbing factors using cytogenetic and genomic data. The links represent reasonable selection criteria for use by computational by profiling technologies only, and are not intended to establish any unknown biological facts.",
  "To this end, this paper proposes a simple path-finding algorithm that attempts to find links between vocal characteristics and perturbing factors using cytogenetic and genomic data. The links represent reasonable selection criteria for use by computational by profiling technologies only, and are not intended to establish any unknown biological facts. The proposed algorithm is validated using a simple example from medical literature\u2014that of the clinically observed effects of specific chromosomal microdeletion syndromes on the vocal characteristics of affected people. In this example, the algorithm attempts to link the genes involved in these syndromes to a single example gene (FOXP2) that is known to play a broad role in voice production. We show that in cases where strong links are exposed, vocal characteristics of the patients are indeed reported to be correspondingly affected. Validation experiments and subsequent analyses confirm that the methodology could be potentially useful in predicting the existence of vocal signatures in na\u00efve cases where their existence has not been otherwise observed.",
  "We show that in cases where strong links are exposed, vocal characteristics of the patients are indeed reported to be correspondingly affected. Validation experiments and subsequent analyses confirm that the methodology could be potentially useful in predicting the existence of vocal signatures in na\u00efve cases where their existence has not been otherwise observed.\nAuthors: Rita Singh\nVenue: Entropy\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A simple path-finding algorithm that attempts to find links between vocal characteristics and perturbing factors using cytogenetic and genomic data and shows that in cases where strong links are exposed, vocal characteristics of the patients are indeed reported to be correspondingly affected.'}",
  "Faculty Name: rita singh\nMetadata:\nPaperid: 721b39472c801124b5e3102edffe9d6f0754e1c2\nTitle: Deriving Vocal Fold Oscillation Information from Recorded Voice Signals Using Models of Phonation\nYear: 2023\nAbstract: During phonation, the vocal folds exhibit a self-sustained oscillatory motion, which is influenced by the physical properties of the speaker\u2019s vocal folds and driven by the balance of bio-mechanical and aerodynamic forces across the glottis. Subtle changes in the speaker\u2019s physical state can affect voice production and alter these oscillatory patterns. Measuring these can be valuable in developing computational tools that analyze voice to infer the speaker\u2019s state. Traditionally, vocal fold oscillations (VFOs) are measured directly using physical devices in clinical settings. In this paper, we propose a novel analysis-by-synthesis approach that allows us to infer the VFOs directly from recorded speech signals on an individualized, speaker-by-speaker basis.",
  "Traditionally, vocal fold oscillations (VFOs) are measured directly using physical devices in clinical settings. In this paper, we propose a novel analysis-by-synthesis approach that allows us to infer the VFOs directly from recorded speech signals on an individualized, speaker-by-speaker basis. The approach, called the ADLES-VFT algorithm, is proposed in the context of a joint model that combines a phonation model (with a glottal flow waveform as the output) and a vocal tract acoustic wave propagation model such that the output of the joint model is an estimated waveform. The ADLES-VFT algorithm is a forward-backward algorithm which minimizes the error between the recorded waveform and the output of this joint model to estimate its parameters. Once estimated, these parameter values are used in conjunction with a phonation model to obtain its solutions. Since the parameters correlate with the physical properties of the vocal folds of the speaker, model solutions obtained using them represent the individualized VFOs for each speaker. The approach is flexible and can be applied to various phonation models. In addition to presenting the methodology, we show how the VFOs can be quantified from a dynamical systems perspective for classification purposes.",
  "The approach is flexible and can be applied to various phonation models. In addition to presenting the methodology, we show how the VFOs can be quantified from a dynamical systems perspective for classification purposes. Mathematical derivations are provided in an appendix for better readability.\nAuthors: Wayne Zhao, Rita Singh\nVenue: Entropy\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A novel analysis-by-synthesis approach that allows us to infer the VFOs directly from recorded speech signals on an individualized, speaker- by-speaker basis is proposed and it is shown how the V FOs can be quantified from a dynamical systems perspective for classification purposes.'}",
  "Faculty Name: rita singh\nMetadata:\nPaperid: 7a25aa397ae2a7f82df87a936ce6ff7f03b7ac4c\nTitle: Token Prediction as Implicit Classification to Identify LLM-Generated Text\nYear: 2023\nAbstract: This paper introduces a novel approach for identifying the possible large language models (LLMs) involved in text generation. Instead of adding an additional classification layer to a base LM, we reframe the classification task as a next-token prediction task and directly fine-tune the base LM to perform it. We utilize the Text-to-Text Transfer Transformer (T5) model as the backbone for our experiments. We compared our approach to the more direct approach of utilizing hidden states for classification. Evaluation shows the exceptional performance of our method in the text classification task, highlighting its simplicity and efficiency. Furthermore, interpretability studies on the features extracted by our model reveal its ability to differentiate distinctive writing styles among various LLMs even in the absence of an explicit classifier.",
  "Evaluation shows the exceptional performance of our method in the text classification task, highlighting its simplicity and efficiency. Furthermore, interpretability studies on the features extracted by our model reveal its ability to differentiate distinctive writing styles among various LLMs even in the absence of an explicit classifier. We also collected a dataset named OpenLLMText, containing approximately 340k text samples from human and LLMs, including GPT3.5, PaLM, LLaMA, and GPT2.\nAuthors: Yutian Chen, Hao Kang, Vivian Zhai, Liangze Li, Rita Singh, Bhiksha Raj\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Evaluation shows the exceptional performance of the method in the text classification task, highlighting its simplicity and efficiency, and interpretability studies on the features extracted by the model reveal its ability to differentiate distinctive writing styles among various LLMs even in the absence of an explicit classifier.'}",
  "Faculty Name: rita singh\nMetadata:\nPaperid: 7ce9a6ad52408b9ab0113d0ae9b413585fe2accc\nTitle: Effect of myo-inositol and di-chiro inositol plus vitamin D supplementation during pregnancy on prevention of gestational diabetes: a multi-centric, prospective, randomized, double-blind clinical trial\nYear: 2023\nAbstract: Background: Aim of study was to evaluate the impact of myoinositol and D-chiro inositol plus vitamin D supplementation on the prevention of gestational diabetes mellitus (GDM) in pregnant women.\nMethods: In the multi-centric, prospective, randomised, double-blind clinical trial, either vitamin D alone (group I) or myoinositol and D-chiro inositol plus Vitamin D (group II) were administered to pregnant women from 12 weeks of gestation. The administration was continued until delivery to primigravids who were normoglycemic at 12 weeks of gestation and consented. From October 2018 to December 2019.",
  "The administration was continued until delivery to primigravids who were normoglycemic at 12 weeks of gestation and consented. From October 2018 to December 2019. A total of 1250 women were enrolled, and randomly allocated to either of the groups: 630 women in Group I and 620 in Group II. The allocation was blinded. The primary outcome was the rate of GDM as assessed by oral glucose tolerance test (OGTT) recommended by diabetes in pregnancy Study Group India (DIPSI), International Federation of Gynecology and Obstetrics (FIGO) and the Government of India, at first antenatal visit followed by at weeks 24 to 28 in both the groups.\nResults: The rate of GDM was found more in group I as compared to group II treated with myoinositol and D-chiro Inositol plus vitamin D, but the difference was not statistically significant (5.08% in group I and 3.22% in group II).",
  "Results: The rate of GDM was found more in group I as compared to group II treated with myoinositol and D-chiro Inositol plus vitamin D, but the difference was not statistically significant (5.08% in group I and 3.22% in group II).\nConclusions: In conclusion, an improved trend has been noticed in the reduction of the rate of GDM with myoinositol and D-chiro inositol plus vitamin D as compared to vitamin D alone. Myoinositol and D-chiro inositol plus vitamin D supplementation may be a good option for pregnant women to prevent the GDM occurrence especially in women having positive risk factors for GDM.",
  "Myoinositol and D-chiro inositol plus vitamin D supplementation may be a good option for pregnant women to prevent the GDM occurrence especially in women having positive risk factors for GDM.\n\u00a0\nAuthors: H. Divakar, Sheetal S Joshi, V. Thobbi, Shobha Bembalgi, S. Gupte, V. Bhat, Rita Singh, Poorni Narayanan, Bhagyashri Kulkarni, Prachi Ahire, D. V., I. Manyonda\nVenue: International Journal of Reproduction Contraception Obstetrics and Gynecology\nTldr: {'model': 'tldr@v2.0.0', 'text': 'An improved trend has been noticed in the reduction of the rate of GDM with myoinositol and D-chiro inositol plus vitamin D as compared to vitamin D alone, which may be a good option for pregnant women to prevent the GDM occurrence.'}",
  "Faculty Name: rita singh\nMetadata:\nPaperid: 7de69ba0381aa265803b79ccaedf247d266d19ab\nTitle: Utilization of the Whole Cowpea Pod and Barley Husk in The Production of Nutritionally Enriched Composite Flour\nYear: 2023\nAbstract: Background: Cowpea is a climbing annual crop from Fabaceae family which is grown for its edible seeds and pods. Cowpea is rich in various nutrients such as fibre, protein, iron, potassium and is low in fat and calories. It has been observed that non-Communicable diseases are increasing at a rapid rate in India as well as globally. The need of the hour is to control the rate of diseases through modification in dietary practices. This study has focused on formulation of whole cowpea pod enriched composite flour by including more fibre and various nutrients in the diet. Methods: In the study, composite flour using whole cowpea pod flour, barley husk flour and whole wheat flour was developed. The nutritional characteristics of composite flour and barley husk were analyzed. Storage study with two different packaging materials was also done.",
  "Methods: In the study, composite flour using whole cowpea pod flour, barley husk flour and whole wheat flour was developed. The nutritional characteristics of composite flour and barley husk were analyzed. Storage study with two different packaging materials was also done. Result: The composite flour was found to have good nutritional properties as it contained valuable amount of protein, energy and crude fibre. It was also found that the flour had higher content of iron, magnesium and calcium while barley husk had higher content of manganese. Laminated aluminium pouches found to be more suitable for use as a packaging material.\n\nAuthors: Urvashi, Anuradha Dutta, R. Raghuvanshi, Y. Singh, Nivedita, S. Tilara, D. Joshi\nVenue: Asian Journal of Dairy and Food Research\nTldr: None",
  "Faculty Name: rita singh\nMetadata:\nPaperid: 8665c864d71df1e918d2010778fc06712f4e5550\nTitle: Imprecise Label Learning: A Unified Framework for Learning with Various Imprecise Label Configurations\nYear: 2023\nAbstract: Learning with reduced labeling standards, such as noisy label, partial label, and multiple label candidates, which we generically refer to as \\textit{imprecise} labels, is a commonplace challenge in machine learning tasks. Previous methods tend to propose specific designs for every emerging imprecise label configuration, which is usually unsustainable when multiple configurations of imprecision coexist. In this paper, we introduce imprecise label learning (ILL), a framework for the unification of learning with various imprecise label configurations. ILL leverages expectation-maximization (EM) for modeling the imprecise label information, treating the precise labels as latent variables.Instead of approximating the correct labels for training, it considers the entire distribution of all possible labeling entailed by the imprecise information.",
  "ILL leverages expectation-maximization (EM) for modeling the imprecise label information, treating the precise labels as latent variables.Instead of approximating the correct labels for training, it considers the entire distribution of all possible labeling entailed by the imprecise information. We demonstrate that ILL can seamlessly adapt to partial label learning, semi-supervised learning, noisy label learning, and, more importantly, a mixture of these settings. Notably, ILL surpasses the existing specified techniques for handling imprecise labels, marking the first unified framework with robust and effective performance across various challenging settings. We hope our work will inspire further research on this topic, unleashing the full potential of ILL in wider scenarios where precise labels are expensive and complicated to obtain.",
  "We hope our work will inspire further research on this topic, unleashing the full potential of ILL in wider scenarios where precise labels are expensive and complicated to obtain.\nAuthors: Hao Chen, Ankit Shah, Jindong Wang, R. Tao, Yidong Wang, Xingxu Xie, Masashi Sugiyama, Rita Singh, B. Raj\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Imprecise label learning (ILL) is introduced, a framework for the unification of learning with various imprecise label configurations, marking the first unified framework with robust and effective performance across various challenging settings.'}",
  "Faculty Name: rita singh\nMetadata:\nPaperid: 8aac453851c7b6178e2aea7c4d53f070380c25e2\nTitle: APPLIED ASPECT OF SATVAVAJAYA CHIKITSA\nYear: 2023\nAbstract: The human being is a tripod having three pillars, Satva (mind), Atma (soul) and Sharira (body). Here, Satva is a connecting link between Atma and Sharira, which is otherwise called Manas. It has an immense influence on the health and ill health of the individual. \u2018Prasanna\u2019 Manah is a sign of a healthy life. \nIn Ayurvedic contexts, Chikitsa is classified into two parts based on resources (Vyapashraya Bheden): 1. Daivvyapashray Chikitsa 2. Yuktivyapashray Chikitsa.",
  "In Ayurvedic contexts, Chikitsa is classified into two parts based on resources (Vyapashraya Bheden): 1. Daivvyapashray Chikitsa 2. Yuktivyapashray Chikitsa. Daivvyapashray Chikitsa refers to Mantra, Ausadhi, Mani, Mangala, Bali, Upahara, Home, Niyam, Prayashchita, Upvasa, Swastyayanapatha, Pranipata, Gamana etc. Yuktivyapashrya Chikitsa refers to Samsodhana (Vamanadi) and Upshamana (Pachanadi). In another context, Acharya Charak and Acharya Vagbhat explained Trividham Ausdham as; 1. Daivvyapashray Chikitsa, 2. Yuktivyapashrya Chikitsa 3. Satvavajaya Chikitsa.",
  "Daivvyapashray Chikitsa, 2. Yuktivyapashrya Chikitsa 3. Satvavajaya Chikitsa. Their Satvavajaya Chikitsa further explained, \"Aiming to control the mind or is a method of restraining the mind from unwholesome objects.\u201d Satvavajaya Chikitsa is that typical Ayurvedic approach that prevents the impaired Dhi, Dhriti and Smriti and brings them back to a normal state. Hence, it plays a significant role in maintaining a harmonious state between these three factors, ultimately leading to a happy and healthy state of the individual.\nAuthors: Rita Singh, C. B. Singjh, Yogesh Kumar, Ajay Kumar, Shailendra Singh\nVenue: International Ayurvedic Medical Journal\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Satvavajaya Chikitsa is that typical Ayurvedic approach that prevents the impaired Dhi, Dhriti and Smriti, and brings them back to a normal state.'}",
  "Faculty Name: rita singh\nMetadata:\nPaperid: a6e3a10a6286967413e3406374bbeea533640030\nTitle: The Hidden Dance of Phonemes and Visage: Unveiling the Enigmatic Link between Phonemes and Facial Features\nYear: 2023\nAbstract: This work unveils the enigmatic link between phonemes and facial features. Traditional studies on voice-face correlations typically involve using a long period of voice input, including generating face images from voices and reconstructing 3D face meshes from voices. However, in situations like voice-based crimes, the available voice evidence may be short and limited. Additionally, from a physiological perspective, each segment of speech -- phoneme -- corresponds to different types of airflow and movements in the face. Therefore, it is advantageous to discover the hidden link between phonemes and face attributes. In this paper, we propose an analysis pipeline to help us explore the voice-face relationship in a fine-grained manner, i.e., phonemes v.s. facial anthropometric measurements (AM). We build an estimator for each phoneme-AM pair and evaluate the correlation through hypothesis testing.",
  "In this paper, we propose an analysis pipeline to help us explore the voice-face relationship in a fine-grained manner, i.e., phonemes v.s. facial anthropometric measurements (AM). We build an estimator for each phoneme-AM pair and evaluate the correlation through hypothesis testing. Our results indicate that AMs are more predictable from vowels compared to consonants, particularly with plosives. Additionally, we observe that if a specific AM exhibits more movement during phoneme pronunciation, it is more predictable. Our findings support those in physiology regarding correlation and lay the groundwork for future research on speech-face multimodal learning.\nAuthors: Liao Qu, X. Zou, Xiang Li, Yandong Wen, Rita Singh, B. Raj\nVenue: Interspeech\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes an analysis pipeline to help explore the voice-face relationship in a fine-grained manner, i.s. phonemes v. facial anthropometric measurements (AM), and indicates that AMs are more predictable from vowels compared to consonants, particularly with plosives.'}",
  "Faculty Name: rita singh\nMetadata:\nPaperid: ad22af138fa1d1490cda0301abf8159a7c30c5a2\nTitle: Pengi: An Audio Language Model for Audio Tasks\nYear: 2023\nAbstract: In the domain of audio processing, Transfer Learning has facilitated the rise of Self-Supervised Learning and Zero-Shot Learning techniques. These approaches have led to the development of versatile models capable of tackling a wide array of tasks, while delivering state-of-the-art performance. However, current models inherently lack the capacity to produce the requisite language for open-ended tasks, such as Audio Captioning or Audio Question&Answering. We introduce Pengi, a novel Audio Language Model that leverages Transfer Learning by framing all audio tasks as text-generation tasks. It takes as input, an audio recording, and text, and generates free-form text as output. The input audio is represented as a sequence of continuous embeddings by an audio encoder. A text encoder does the same for the corresponding text input. Both sequences are combined as a prefix to prompt a pre-trained frozen language model.",
  "The input audio is represented as a sequence of continuous embeddings by an audio encoder. A text encoder does the same for the corresponding text input. Both sequences are combined as a prefix to prompt a pre-trained frozen language model. The unified architecture of Pengi enables open-ended tasks and close-ended tasks without any additional fine-tuning or task-specific extensions. When evaluated on 22 downstream tasks, our approach yields state-of-the-art performance in several of them. Our results show that connecting language models with audio models is a major step towards general-purpose audio understanding\nAuthors: Soham Deshmukh, Benjamin Elizalde, Rita Singh, Huaming Wang\nVenue: Neural Information Processing Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Pengi is introduced, a novel Audio Language Model that leverages Transfer Learning by framing all audio tasks as text-generation tasks, and shows that connecting language models with audio models is a major step towards general-purpose audio understanding.'}",
  "Faculty Name: rita singh\nMetadata:\nPaperid: b5d8e7e1e1543cf39b84cd894a6a899e086e058b\nTitle: Mean Platelet Volume in Type 2 Diabetes: Correlation with Poor Glycaemic Control\nYear: 2023\nAbstract: Background: Diabetes is a global pandemic. Mean platelet volume (MPV) is an indicator of increased platelet activity, which is considered to play a role in the development of vascular complications in diabetes. Platelet volume is strongly and independently related with glycaemic control in Type 2 diabetes (T2D).\n\nAim: To study the MPV in patients with T2D, and its correlation with HbA1c, duration of T2D, and microvascular complications.\n\nMethodology: This was a cross-sectional, observational study conducted at the Department of Medicine, Gandhi Medical College, Bhopal, India, during a period of 18 months on 300 patients with T2D. Blood glucose, HbA1c, MPV, fundoscopy, and 24-hour urine protein were done.",
  "Blood glucose, HbA1c, MPV, fundoscopy, and 24-hour urine protein were done. Data were represented as mean+/-standard deviation and statistical analysis was done using SPSS software (IBM, Armonk, New York, USA).\n\nResults: The mean age of patients was 56.64\u00b18.69 years, with 52% of the patients being females. Of these patients, 18.3% had HbA1c between 6.5\u20138.0%, 51.7% between 8.1\u201310.0% and the rest above 10.0%. A total of 51% of the patients had diabetes for 6\u201310 years of duration and 30% for more than 10 years. Patients with higher HbA1c level and prolonged duration of diabetes had higher MPV (p<0.001). Patients with advanced diabetic retinopathy changes and nephropathy also had higher MPV (p<0.05).",
  "Patients with higher HbA1c level and prolonged duration of diabetes had higher MPV (p<0.001). Patients with advanced diabetic retinopathy changes and nephropathy also had higher MPV (p<0.05).\n\nConclusion: Measurement of MPV in patients with T2D can be a useful and easily available prognostic marker, and hence assist clinicians to anticipate the occurrence of microvascular complications associated with the disease, especially in resource-poor settings, and reduce the burden of cost for the patient.\nAuthors: Avarna Agarwal, Anita Arya, R. Saxena, Simmi Dube\nVenue: EMJ Diabetes\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Measurement of MPV in patients with T2D can be a useful and easily available prognostic marker, and hence assist clinicians to anticipate the occurrence of microvascular complications associated with the disease, especially in resource-poor settings, and reduce the burden of cost for the patient.'}",
  "Faculty Name: rita singh\nMetadata:\nPaperid: b7e2074934985b6112b6bce8c3680b14e621fdfe\nTitle: Importance of negative sampling in weak label learning\nYear: 2023\nAbstract: Weak-label learning is a challenging task that requires learning from data\"bags\"containing positive and negative instances, but only the bag labels are known. The pool of negative instances is usually larger than positive instances, thus making selecting the most informative negative instance critical for performance. Such a selection strategy for negative instances from each bag is an open problem that has not been well studied for weak-label learning. In this paper, we study several sampling strategies that can measure the usefulness of negative instances for weak-label learning and select them accordingly. We test our method on CIFAR-10 and AudioSet datasets and show that it improves the weak-label classification performance and reduces the computational cost compared to random sampling methods. Our work reveals that negative instances are not all equally irrelevant, and selecting them wisely can benefit weak-label learning.",
  "We test our method on CIFAR-10 and AudioSet datasets and show that it improves the weak-label classification performance and reduces the computational cost compared to random sampling methods. Our work reveals that negative instances are not all equally irrelevant, and selecting them wisely can benefit weak-label learning.\nAuthors: Ankit Shah, Fuyu Tang, Zelin Ye, Rita Singh, Bhiksha Raj\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work reveals that negative instances are not all equally irrelevant, and selecting them wisely can benefit weak-label learning, and reduces the computational cost compared to random sampling methods.'}",
  "Faculty Name: rita singh\nMetadata:\nPaperid: d77d82c224bf953cf67cb94e1c65b69497859fbb\nTitle: Implementing International Federation of Gynecology and Obstetrics Nutrition Checklist for Pregnant Women: Opportunities and Challenges in Low- and Middle-income Countries\nYear: 2023\nAbstract: None\nAuthors: Rita Singh, Richa Mishra, Sheetal S Joshi, H. Divakar, Gubbi Venkatasubbaiah Divakar, Bhagyashri Kulkarni, Poorni Narayanan\nVenue: Journal of South Asian Federation of Obstetrics and Gynaecology\nTldr: None",
  "Faculty Name: rita singh\nMetadata:\nPaperid: d7911ff6f80bd9f053ef8d304f15791f510f5cda\nTitle: Completing Visual Objects via Bridging Generation and Segmentation\nYear: 2023\nAbstract: This paper presents a novel approach to object completion, with the primary goal of reconstructing a complete object from its partially visible components. Our method, named MaskComp, delineates the completion process through iterative stages of generation and segmentation. In each iteration, the object mask is provided as an additional condition to boost image generation, and, in return, the generated images can lead to a more accurate mask by fusing the segmentation of images. We demonstrate that the combination of one generation and one segmentation stage effectively functions as a mask denoiser. Through alternation between the generation and segmentation stages, the partial object mask is progressively refined, providing precise shape guidance and yielding superior object completion results. Our experiments demonstrate the superiority of MaskComp over existing approaches, e.g., ControlNet and Stable Diffusion, establishing it as an effective solution for object completion.",
  "Through alternation between the generation and segmentation stages, the partial object mask is progressively refined, providing precise shape guidance and yielding superior object completion results. Our experiments demonstrate the superiority of MaskComp over existing approaches, e.g., ControlNet and Stable Diffusion, establishing it as an effective solution for object completion.\nAuthors: Xiang Li, Yinpeng Chen, Chung-Ching Lin, Rita Singh, Bhiksha Raj, Zicheng Liu\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The method, named MaskComp, delineates the completion process through iterative stages of generation and segmentation, and demonstrates that the combination of one generation and one segmentation stage effectively functions as a mask denoiser.'}",
  "Faculty Name: rita singh\nMetadata:\nPaperid: e2572e0adacfb116b19b25691e7f6b3749490a88\nTitle: Training Audio Captioning Models without Audio\nYear: 2023\nAbstract: Automated Audio Captioning (AAC) is the task of generating natural language descriptions given an audio stream. A typical AAC system requires manually curated training data of audio segments and corresponding text caption annotations. The creation of these audio-caption pairs is costly, resulting in general data scarcity for the task. In this work, we address this major limitation and propose an approach to train AAC systems using only text. Our approach leverages the multimodal space of contrastively trained audio-text models, such as CLAP. During training, a decoder generates captions conditioned on the pretrained CLAP text encoder. During inference, the text encoder is replaced with the pretrained CLAP audio encoder. To bridge the modality gap between text and audio embeddings, we propose the use of noise injection or a learnable adapter, during training.",
  "During training, a decoder generates captions conditioned on the pretrained CLAP text encoder. During inference, the text encoder is replaced with the pretrained CLAP audio encoder. To bridge the modality gap between text and audio embeddings, we propose the use of noise injection or a learnable adapter, during training. We find that the proposed text-only framework performs competitively with state-of-the-art models trained with paired audio, showing that efficient text-to-audio transfer is possible. Finally, we showcase both stylized audio captioning and caption enrichment while training without audio or human-created text captions.\nAuthors: Soham Deshmukh, Benjamin Elizalde, Dimitra Emmanouilidou, Bhiksha Raj, Rita Singh, Huaming Wang\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes an approach to train AAC systems using only text, and finds that the proposed text-only framework performs competitively with state-of-the-art models trained with paired audio, showing that efficient text-to-audio transfer is possible.'}",
  "Faculty Name: rita singh\nMetadata:\nPaperid: f5b88ca9d74e8ddc679adcd07a292bd8481062fa\nTitle: Prompting Audios Using Acoustic Properties For Emotion Representation\nYear: 2023\nAbstract: Emotions lie on a continuum, but current models treat emotions as a finite valued discrete variable. This representation does not capture the diversity in the expression of emotion. To better represent emotions we propose the use of natural language descriptions (or prompts). In this work, we address the challenge of automatically generating these prompts and training a model to better learn emotion representations from audio and prompt pairs. We use acoustic properties that are correlated to emotion like pitch, intensity, speech rate, and articulation rate to automatically generate prompts i.e. 'acoustic prompts'. We use a contrastive learning objective to map speech to their respective acoustic prompts. We evaluate our model on Emotion Audio Retrieval and Speech Emotion Recognition. Our results show that the acoustic prompts significantly improve the model's performance in EAR, in various Precision@K metrics. In SER, we observe a 3.8% relative accuracy improvement on the Ravdess dataset.",
  "We evaluate our model on Emotion Audio Retrieval and Speech Emotion Recognition. Our results show that the acoustic prompts significantly improve the model's performance in EAR, in various Precision@K metrics. In SER, we observe a 3.8% relative accuracy improvement on the Ravdess dataset.\nAuthors: Hira Dhamyal, Benjamin Elizalde, Soham Deshmukh, Huaming Wang, Bhiksha Raj, Rita Singh\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work addresses the challenge of automatically generating prompts and training a model to better learn emotion representations from audio and prompt pairs by using acoustic properties that are correlated to emotion like pitch, intensity, speech rate, and articulation rate to automatically generate prompts.'}",
  "Faculty Name: rita singh\nMetadata:\nPaperid: f969f059b01be02f9995396b6cc397959b574635\nTitle: Pairwise Similarity Learning is SimPLE\nYear: 2023\nAbstract: In this paper, we focus on a general yet important learning problem, pairwise similarity learning (PSL). PSL subsumes a wide range of important applications, such as open-set face recognition, speaker verification, image retrieval and person re-identification. The goal of PSL is to learn a pairwise similarity function assigning a higher similarity score to positive pairs (i.e., a pair of samples with the same label) than to negative pairs (i.e., a pair of samples with different label). We start by identifying a key desideratum for PSL, and then discuss how existing methods can achieve this desideratum. We then propose a surprisingly simple proxy-free method, called SimPLE, which requires neither feature/proxy normalization nor angular margin and yet is able to generalize well in open-set recognition. We apply the proposed method to three challenging PSL tasks: open-set face recognition, image retrieval and speaker verification.",
  "We then propose a surprisingly simple proxy-free method, called SimPLE, which requires neither feature/proxy normalization nor angular margin and yet is able to generalize well in open-set recognition. We apply the proposed method to three challenging PSL tasks: open-set face recognition, image retrieval and speaker verification. Comprehensive experimental results on large-scale benchmarks show that our method performs significantly better than current state-of-the-art methods. Our project page is available at simple.is.tue.mpg.de.\nAuthors: Yandong Wen, Weiyang Liu, Yao Feng, Bhiksha Raj, Rita Singh, Adrian Weller, Michael J. Black, Bernhard Sch\u00f6lkopf\nVenue: IEEE International Conference on Computer Vision\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work identifies a key desideratum for PSL, and proposes a surprisingly simple proxy-free method, called SimPLE, which requires neither feature/proxy normalization nor angular margin and yet is able to generalize well in open-set recognition.'}",
  "Faculty Name: rita singh\nMetadata:\nPaperid: fcddb888f01eae5c5530b2d1533d6064f207ea2b\nTitle: Gonadotropin Receptor Cross-Talk and Altered Functions in Gonadal and Non-Gonadal Tissues\nYear: 2023\nAbstract: Reproduction depends on the responses of gonadotropins through their specific receptors. The gonadotropin family has three members; Follicle Stimulating Hormone (FSH), Luteinizing Hormone (LH), and Human Chorionic Gonadotropin (hCG). These glycoprotein hormones comprise two subunits, an identical \u03b1-subunit and a hormone-specific-\u03b2 subunit. Their cognate receptors (FSHR and LHCGR) are two adrenergic receptor-like family A/rhodopsin-like G-Protein Coupled Receptors (GPCRs) with structurally distinct ligand binding domains. The hCG binds to LHCGR but has a longer half-life and higher affinity to LHCGR.",
  "The hCG binds to LHCGR but has a longer half-life and higher affinity to LHCGR. The expression of FSHR and LHCGR is observed in both gonadal and nongonadal cells. In this review, we will be emphasizing the differential expression of gonadotropin receptors in different cells of the human body, their specific responses through cross-talk, and how a defect in the expression and activity of FSHR and LHCGR may alter the responses of FSH and LH/hCG leading to diseases like PCOS, cancer and metabolic disorders.\nAuthors: Rita Singh, Anjali Pathak\nVenue: Journal of Endocrinology & Reproduction\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This review will be emphasizing the differential expression of gonadotropin receptors in different cells of the human body, their specific responses through cross-talk, and how a defect in the expression and activity of FSHR and LHCGR may alter the responses of F SH and LH/hCG leading to diseases like PCOS, cancer and metabolic disorders.'}",
  "List of 2023 Open Access papers by rita singh are:\nImplementing International Federation of Gynecology and Obstetrics Nutrition Checklist for Pregnant Women: Opportunities and Challenges in Low- and Middle-income Countries\nMean Platelet Volume in Type 2 Diabetes: Correlation with Poor Glycaemic Control\nBASS: Block-wise Adaptation for Speech Summarization\nRethinking Voice-Face Correlation: A Geometry View\nA Gene-Based Algorithm for Identifying Factors That May Affect a Speaker\u2019s Voice\nDeriving Vocal Fold Oscillation Information from Recorded Voice Signals Using Models of Phonation\nImprecise Label Learning: A Unified Framework for Learning with Various Imprecise Label Configurations\nThe Hidden Dance of Phonemes and Visage: Unveiling the Enigmatic Link between Phonemes and Facial Features\nPengi: An Audio Language Model for Audio Tasks\nGPT-Sentinel: Distinguishing Human and ChatGPT Generated Content\nToken Prediction as Implicit Classification to Identify LLM-Generated Text\nEffect of myo-inositol and di-chiro inositol plus vitamin D supplementation during pregnancy on prevention of gestational diabetes: a multi-centric, prospective, randomized,",
  "prospective, randomized, double-blind clinical trial\nPlant-Avian Frugivory in the Urban Ecosystem of Delhi\nLoFT: Local Proxy Fine-tuning For Improving Transferability Of Adversarial Attacks Against Large Language Model\nEvaluating Speech Synthesis by Training Recognizers on Synthetic Speech\nRethinking Audiovisual Segmentation with Semantic Quantization and Decomposition\nTowards Noise-Tolerant Speech-Referring Video Object Segmentation: Bridging Speech and Text\nImportance of negative sampling in weak label learning\nCompleting Visual Objects via Bridging Generation and Segmentation\nTraining Audio Captioning Models without Audio\nPrompting Audios Using Acoustic Properties For Emotion Representation\nPairwise Similarity Learning is SimPLE\nGonadotropin Receptor Cross-Talk and Altered Functions in Gonadal and Non-Gonadal Tissues\nComparison of freeze-thaw and sonication cycle-based methods for extracting AMR-associated metabolites from Staphylococcus aureus\nAPPLIED ASPECT OF SATVAVAJAYA CHIKITSA\nUtilization of the Whole Cowpea Pod and Barley Husk in The Production of Nutritionally Enriched Composite Flour",
  "Faculty Name: robert frederking\nMetadata:\nPaperid: 42f711ca3491d4bf33b35683944d9b8f5bc1c558\nTitle: Reconstructing ice force-displacement development in structural assessments of freshwater, polycrystalline ice impacts\nYear: 2023\nAbstract: None\nAuthors: Ekaterina Kim, K. H\u00f8yland, R. Frederking\nVenue: International Journal of Impact Engineering\nTldr: None",
  "List of 2023 Open Access papers by robert frederking are:\nReconstructing ice force-displacement development in structural assessments of freshwater, polycrystalline ice impacts",
  "Faculty Name: roni rosenfeld\nMetadata:\nPaperid: 11b798422679ebd291e0eb62d97aace5cc0bd290\nTitle: Evaluation of FluSight influenza forecasting in the 2021\u201322 and 2022\u201323 seasons with a new target laboratory-confirmed influenza hospitalizations\nYear: 2023\nAbstract: Accurate forecasts can enable more effective public health responses during seasonal influenza epidemics. Forecasting teams were asked to provide national and jurisdiction-specific probabilistic predictions of weekly confirmed influenza hospital admissions for one through four weeks ahead for the 2021-22 and 2022-23 influenza seasons. Across both seasons, 26 teams submitted forecasts, with the submitting teams varying between seasons. Forecast skill was evaluated using the Weighted Interval Score (WIS), relative WIS, and coverage. Six out of 23 models outperformed the baseline model across forecast weeks and locations in 2021-22 and 12 out of 18 models in 2022-23.",
  "Forecast skill was evaluated using the Weighted Interval Score (WIS), relative WIS, and coverage. Six out of 23 models outperformed the baseline model across forecast weeks and locations in 2021-22 and 12 out of 18 models in 2022-23. Averaging across all forecast targets, the FluSight ensemble was the 2nd most accurate model measured by WIS in 2021-22 and the 5th most accurate in the 2022-23 season. Forecast skill and 95% coverage for the FluSight ensemble and most component models degraded over longer forecast horizons and during periods of rapid change. Current influenza forecasting efforts help inform situational awareness, but research is needed to address limitations, including decreased performance during periods of changing epidemic dynamics.\nAuthors: Sarabeth M. Mathis, Alexander E. Webber, Tom\u00e1s M Le\u00f3n, Erin L Murray, Monica Sun, L. A. White, L. Brooks, Alden Green, Addison J. Hu, Daniel J McDonald, Roni Rosenfeld, Dmitry Shemetov, R. Tibshirani, S. Kandula, Sen Pei, Jeffrey Shaman, R. Yaari, T.",
  "Monica Sun, L. A. White, L. Brooks, Alden Green, Addison J. Hu, Daniel J McDonald, Roni Rosenfeld, Dmitry Shemetov, R. Tibshirani, S. Kandula, Sen Pei, Jeffrey Shaman, R. Yaari, T. Yamana, Pulak Agarwal, Srikar Balusu, Gautham Gururajan, Harshavardhan Kamarthi, B. A. Prakash, Rishi Raman, Alexander Rodr\u00edguez, Zhiyuan Zhao, Akilan Meiyappan, Shalina Omar, P. Baccam, H. Gurung, S. Stage, B. Suchoski, M. Ajelli, A. G. Kummer, M. Litvinova, Paulo C. Ventura, Spencer Wadsworth, Jarad Niemi, Erica Carcelen, Alison Hill, Sung-Mok Jung, J. Lemaitre, J. Lessler, Sara L. Loo, Clif McKee, Koji Sato, Clair Smith, S. Truelove, Thomas McAndrew, Wenxuan Ye, Nikos Bosse, W. Hlavacek,",
  "Sung-Mok Jung, J. Lemaitre, J. Lessler, Sara L. Loo, Clif McKee, Koji Sato, Clair Smith, S. Truelove, Thomas McAndrew, Wenxuan Ye, Nikos Bosse, W. Hlavacek, Yen Ting Lin, A. Mallela, Ye Chen, Shelby Lamm, Jaechoul Lee, Richard G Posner, A. Perofsky, C\u00e9cile Viboud, Leonardo Clemente, Fred S Lu, Austin G Meyer, Mauricio Santillana, Matteo Chinazzi, Jessica T. Davis, K. Mu, A. Pastore y Piontti, A. Vespignani, X. Xiong, M. Ben-Nun, P. Riley, J. Turtle, Chis Hulme-Lowe, Shakeel Jessa, V. Nagraj, Stephen D. Turner, Desiree Williams, Avranil Basu, John M Drake, S. Fox, G. Gibson, Ehsan Suez, E. Thommes, Monica G. Cojocaru, E. Cramer, Aaron Gerding, A. Stark, E. Ray, Nick Reich,",
  "Turner, Desiree Williams, Avranil Basu, John M Drake, S. Fox, G. Gibson, Ehsan Suez, E. Thommes, Monica G. Cojocaru, E. Cramer, Aaron Gerding, A. Stark, E. Ray, Nick Reich, Li Shandross, N. Wattanachit, Yijin Wang, Martha W Zorn, Majd Al Aawar, A. Srivastava, L. A. Meyers, A. Adiga, Benjamin Hurt, Gursharn Kaur, Bryan L Lewis, M. Marathe, S. Venkatramanan, P. Butler, Andrew Farabow, N. Muralidhar, Naren Ramakrishnan, Carrie Reed, M. Biggerstaff, R. Borchering\nVenue: medRxiv\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Averaging across all forecast targets,",
  "N. Muralidhar, Naren Ramakrishnan, Carrie Reed, M. Biggerstaff, R. Borchering\nVenue: medRxiv\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Averaging across all forecast targets, the FluSight ensemble was the 2nd most accurate model measured by WIS in 2021-22 and the 5th most accurate in the 2022-23 season and most component models degraded over longer forecast horizons and during periods of rapid change.'}",
  "Faculty Name: roni rosenfeld\nMetadata:\nPaperid: 61c7e06e7d6760ecf2f5d20f86711287d131d8ea\nTitle: Computationally Assisted Quality Control for Public Health Data Streams\nYear: 2023\nAbstract: Irregularities in public health data streams (like COVID-19 Cases) hamper data-driven decision-making for public health stakeholders. A real-time, computer-generated list of the most important, outlying data points from thousands of public health data streams could assist an expert reviewer in identifying these irregularities. However, existing outlier detection frameworks perform poorly on this task because they do not account for the data volume or for the statistical properties of public health streams. Accordingly, we developed FlaSH (Flagging Streams in public Health), a practical outlier detection framework for public health data users that uses simple, scalable models to capture these statistical properties explicitly. In an experiment where human experts evaluate FlaSH and existing methods (including deep learning approaches), FlaSH scales to the data volume of this task, matches or exceeds these other methods in mean accuracy, and identifies the outlier points that users empirically rate as more helpful.",
  "In an experiment where human experts evaluate FlaSH and existing methods (including deep learning approaches), FlaSH scales to the data volume of this task, matches or exceeds these other methods in mean accuracy, and identifies the outlier points that users empirically rate as more helpful. Based on these results, FlaSH has been deployed on data streams used by public health stakeholders.\nAuthors: Ananya Joshi, Kathryn Mazaitis, Roni Rosenfeld, Bryan Wilder\nVenue: International Joint Conference on Artificial Intelligence\nTldr: {'model': 'tldr@v2.0.0', 'text': 'FlaSH (Flagging Streams in public Health), a practical outlier detection framework for public health data users that uses simple, scalable models to capture these statistical properties explicitly, has been deployed on data streams used by public health stakeholders.'}",
  "Faculty Name: roni rosenfeld\nMetadata:\nPaperid: d486295e298f682b2f98e21106af659d88d396a5\nTitle: Correcting for heterogeneity in real-time epidemiological indicators\nYear: 2023\nAbstract: Auxiliary data sources have become increasingly important in epidemiological surveillance, as they are often available at a finer spatial and temporal resolution, larger coverage, and lower latency than traditional surveillance signals. We describe the problem of spatial and temporal heterogeneity in these signals derived from these data sources, where spatial and/or temporal biases are present. We present a method to use a ``guiding'' signal to correct for these biases and produce a more reliable signal that can be used for modeling and forecasting. The method assumes that the heterogeneity can be approximated by a low-rank matrix and that the temporal heterogeneity is smooth over time. We also present a hyperparameter selection algorithm to choose the parameters representing the matrix rank and degree of temporal smoothness of the corrections. In the absence of ground truth, we use maps and plots to argue that this method does indeed reduce heterogeneity.",
  "We also present a hyperparameter selection algorithm to choose the parameters representing the matrix rank and degree of temporal smoothness of the corrections. In the absence of ground truth, we use maps and plots to argue that this method does indeed reduce heterogeneity. Reducing heterogeneity from auxiliary data sources greatly increases their utility in modeling and forecasting epidemics.\nAuthors: Aaron M. Rumack, Roni Rosenfeld, F. W. Townes\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': \"This work presents a method to use a ``guiding'' signal to correct for spatial and temporal biases and produce a more reliable signal that can be used for modeling and forecasting.\"}",
  "Faculty Name: roni rosenfeld\nMetadata:\nPaperid: efdcd232e525fa10f784ebf51e49b5c83cc67354\nTitle: Federated Epidemic Surveillance\nYear: 2023\nAbstract: The surveillance of a pandemic is a challenging task, especially when crucial data is distributed and stakeholders cannot or are unwilling to share. To overcome this obstacle, federated methodologies should be developed to incorporate less sensitive evidence that entities are willing to provide. This study aims to explore the feasibility of pushing hypothesis tests behind each custodian's firewall and then meta-analysis to combine the results, and to determine the optimal approach for reconstructing the hypothesis test and optimizing the inference. We propose a hypothesis testing framework to identify a surge in the indicators and conduct power analyses and experiments on real and semi-synthetic data to showcase the properties of our proposed hypothesis test and suggest suitable methods for combining $p$-values. Our findings highlight the potential of using $p$-value combination as a federated methodology for pandemic surveillance and provide valuable insights into integrating available data sources.",
  "Our findings highlight the potential of using $p$-value combination as a federated methodology for pandemic surveillance and provide valuable insights into integrating available data sources.\nAuthors: Ruiqi Lyu, Bryan Wilder, R. Rosenfeld\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': \"This study aims to explore the feasibility of pushing hypothesis tests behind each custodian's firewall and then meta-analysis to combine the results, and to determine the optimal approach for reconstructing the hypothesis test and optimizing the inference.\"}",
  "List of 2023 Open Access papers by roni rosenfeld are:\nFederated Epidemic Surveillance\nEvaluation of FluSight influenza forecasting in the 2021\u201322 and 2022\u201323 seasons with a new target laboratory-confirmed influenza hospitalizations\nComputationally Assisted Quality Control for Public Health Data Streams\nCorrecting for heterogeneity in real-time epidemiological indicators",
  "Title: Roni Rosenfeld -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Roni Rosenfeld, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Computational Epidemiology;Dialogue Systems for the Developing World\" name=\"categories-2\"/>\n<meta content=\"Yes\" name=\"show-categories-2\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Roni Rosenfeld - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Roni Rosenfeld, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Roni\"/>\n<meta content=\"Lastname\" property=\"profile:Rosenfeld\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/rosenfeld-roni.",
  "cmu.edu//people/faculty/rosenfeld-roni.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nRoni \n                        Rosenfeld\nProfessor, Language Technologies Institute\nHead, Machine Learning\nContact\n8002 \u2014Gates & Hillman Centers\nroni.rosenfeld(through)cs.cmu.edu\n412-268-7678\nResearch Area\nComputational Epidemiology, Dialogue Systems for the Developing World\nResearch\nMy research interests lie in two areas: forecasting epidemics, and information and communication technologies for development (ICT4D).\nForecasting Epidemics\nDELPHI\nThe long term vision of our DELPHI research group is to make epidemiological forecasting as universally accepted and useful as weather forecasting. While this will likely take several decades, in the shorter term we've selected high-value epidemiological forecasting targets like influenza and dengue that we can work with.",
  "While this will likely take several decades, in the shorter term we've selected high-value epidemiological forecasting targets like influenza and dengue that we can work with. We've created forecasting methods for them, established metrics for measuring and tracking forecasting accuracy, estimated our forecasting limits for each target, and identified new data sources to support that forecasting goal. We are part of the multi-university MIDAS research group.\nMachine Learning for Social Good\nML4SG\nMachine Learning for Social Good (ML4SG) is an undertaking of Carnegie Mellon University\u2019s School of Computer Science to enhance SCS\u2019s research and education in applying machine learning to problems of societal impact.\nInformation and Communication Technologies for Development\nICT4D\nWe work in a subfield of this research area, in what we've termed spoken language technologies for development (SLT4D). As part of this work, we're finding ways to use spoken language technologies \u2014 like automatic speech recognition, speech synthesis and human-machine dialog systems \u2014 to aid socio-economic development around the world.\nOur current project, Polly, uses a telephone-based viral entertainment service to reach low-literacy people in Pakistan and India. Polly familiarizes individuals with speech interfaces and introduces them to development-related services.",
  "Our current project, Polly, uses a telephone-based viral entertainment service to reach low-literacy people in Pakistan and India. Polly familiarizes individuals with speech interfaces and introduces them to development-related services. First deployed in Lahore in May 2012, Polly reached more than 165,000 users all over Pakistan and fielded more than 2.5 million calls in eight months. In 2013 we launched Polly in Bangalore, India, and it spread virally to West Bengal, New Delhi and other areas of India. As of March 2015, we are collaborating with the US embassy in Conakry to deploy Polly in Guinea, where we hope to achieve person-to-person spreading of approved public health messages about Ebola in many languages. A previous project, HealthLine, investigated using a telephone-based automated dialog system for access to healthcare information by low-literate community health workers in Pakistan.\nMachine Learning Department\nPersonal Website\n\nLinks:\nhttps://delphi.midas.cs.cmu.edu/\nhttps://www.cmu.edu/scs/ml4sg/\nhttp://www.cs.cmu.edu/~Polly/\nhttps://www.ml.cmu.edu/\nhttp://www.cs.cmu.edu/~roni/",
  "Title: Carolyn Ros\u00e9 -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Carolyn Ros\u00e9, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Core Faculty\" name=\"categories-1\"/>\n<meta content=\"Computer-Supported Collaborative Learning/MOOCs;Information Retrieval, Text Mining and Analytics;Language Technologies for Education;Natural Language Processing and Computational Linguistics\" name=\"categories-2\"/>\n<meta content=\"Yes\" name=\"show-categories-2\"/>\n<meta content=\"Alumni;Faculty\" name=\"global-categories\"/>\n<meta content=\"Carolyn Ros\u00e9 - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Carolyn Ros\u00e9,",
  "Faculty\" name=\"global-categories\"/>\n<meta content=\"Carolyn Ros\u00e9 - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Carolyn Ros\u00e9, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Carolyn\"/>\n<meta content=\"Lastname\" property=\"profile:Ros\u00e9\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/ros\u00e9-carolyn.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nCarolyn \n                        Ros\u00e9\nProfessor, Language Technologies Institute\nHuman-Computer Interaction Institute\nContact\n5415 \u2014Gates & Hillman Centers\ncprose(through)cs.cmu.edu\n412-268-7130\nResearch Area\nComputer-Supported Collaborative Learning/MOOCs, Information Retrieval, Text Mining and Analytics, Language Technologies for Education,",
  "cmu.edu\n412-268-7130\nResearch Area\nComputer-Supported Collaborative Learning/MOOCs, Information Retrieval, Text Mining and Analytics, Language Technologies for Education, Natural Language Processing and Computational Linguistics\nEducation\nPh.D. in Language and Information Technology\n1997\nEmployer Upon Graduation:\nFaculty, LTI CMU\nResearch\nMy research focuses on better understanding the social and pragmatic nature of conversation, and using this understanding to build computational systems that improve the efficacy of conversation both between people, and between people and computers. In order to pursue these goals, I invoke approaches from computational discourse analysis and text mining, conversational agents, and computer-supported collaborative learning. I ground my research in the fields of language technologies and human-computer interaction, and am fortunate to work closely with students and post-docs from the LTI\u00a0and the\nHuman-Computer Interaction Institute\n, as well as to direct my own lab,\nTELEDIA\n. My group\u2019s highly interdisciplinary work, published in 160 peer-reviewed publications, is represented in the top venues in five fields: language technologies, learning sciences, cognitive science, educational technology and human-computer interaction.",
  "My group\u2019s highly interdisciplinary work, published in 160 peer-reviewed publications, is represented in the top venues in five fields: language technologies, learning sciences, cognitive science, educational technology and human-computer interaction.\nAn exciting direction of my group's work is spearheading a satellite working group to support social interaction for learning in MOOCs with EdX called\nDANCE\n. My research toward this end has birthed and substantially contributed to the growth of two thriving interrelated research areas: automated analysis of collaborative learning processes and dynamic support for collaborative learning. Both areas use intelligent conversational agents to support collaborative learning in a context-sensitive way.\nAll of my work draws insight from rich theoretical models from sociolinguistics and discourse analysis, and pares them down to precise operationalizations that capture the most important essence for achieving impact. I always start by investigating how conversation works and formalizing this understanding in models that are precise enough to be reproducible and that demonstrate explanatory power in connection with outcomes with real-world value. The next step is to adapt, extend and apply machine learning and text mining technologies that leverage this deep understanding to build computational models capable of automatically applying these constructs to naturally occurring language interactions.",
  "The next step is to adapt, extend and apply machine learning and text mining technologies that leverage this deep understanding to build computational models capable of automatically applying these constructs to naturally occurring language interactions. Finally, with the technology to automatically monitor naturalistic language communication in place, we can build interventions with real-world benefits.\nThis approach leads to three aspects included in each project:\nBasic research on discourse analysis\nto identify conversational constructs that predict important group outcomes such as learning, knowledge transfer or motivation.\nBasic research on text classification technology\nfor automated analysis of conversational constructs identified under research on discourse analysis, as well as tools to enable other researchers to do the same.\nBasic research on conversational agent technology and summarization\nthat eases development of interventions triggered by automatic analyses from basic research on text classification that either enables human facilitators to offer support, directly provide feedback to groups or influence group participation in positive ways.\nHuman-Computer Interaction Institute\nPersonal Website\n\nLinks:\nhttp://www.hcii.cmu.edu/\nhttp://www.cs.cmu.edu/~cprose/MyGroup.html\nhttp://www.cs.cmu.edu/~cprose/DANCE.html\nhttps://hcii.cmu.edu/\nhttp://www.cs.cmu.edu/~cprose/",
  "Title: Alexander Rudnicky -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Alexander Rudnicky, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Core Faculty\" name=\"categories-1\"/>\n<meta content=\"Multimodal Computing and Interaction;Speech Processing;Spoken Interfaces and Dialogue Processing\" name=\"categories-2\"/>\n<meta content=\"Yes\" name=\"show-categories-2\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Alexander Rudnicky - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Alexander Rudnicky,",
  "Faculty Member at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Alexander\"/>\n<meta content=\"Lastname\" property=\"profile:Rudnicky\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/rudnicky-alexander.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nAlexander \n                        Rudnicky\nResearch Professor Emeritus, Language Technologies Institute\nContact\n6511 \u2014Gates & Hillman Centers\nalex.rudnicky(through)cs.cmu.edu\n412-268-2622\nResearch Area\nMultimodal Computing and Interaction, Speech Processing, Spoken Interfaces and Dialogue Processing\nResearch\nMy research centers on interactive systems that use speech. I am currently interested in the following problems:\nImplicit Learning\n: Human-computer interaction generates information that the system could use to modify its behavior.",
  "Speech Processing, Spoken Interfaces and Dialogue Processing\nResearch\nMy research centers on interactive systems that use speech. I am currently interested in the following problems:\nImplicit Learning\n: Human-computer interaction generates information that the system could use to modify its behavior. For example, a speech recognition error that is repaired leaves information about a misclassification that could be used to improve subsequent accuracy. Exploiting such situations (and in fact contriving to create them) can provide a rich set of experiences that drive self-improving systems\nAutomatic detection and recovery from error\n: Humans easily detect and recover from breakdowns in communication. Automatic systems are less successful at this, however we can use features of recognition, understanding and dialog to predict the likelihood of misunderstanding at a given point in an interaction, and then apply heuristic strategies for guiding the conversation back onto track.\nA theory of language design for speech-based interactive systems\n: Speech-mode communication predisposes the user to make certain word choices and to exhibit certain grammatical preferences. An understanding of the principles that underlie these preferences (and how these can be influenced by the system's language) leads to better language design for interactive systems.",
  "An understanding of the principles that underlie these preferences (and how these can be influenced by the system's language) leads to better language design for interactive systems.\nThe role of speech in the computer interface\n: Speech is an effective means of communication, but it is not always suitable for all types of interaction. Ideally we can analyze an interface in terms of the task(s) it will be used for, the costs of specific interactions and the value perceived by the user. To date we've studied models based on time, system error and task structure. These models turn out to be useful for simple systems and appear to be extensible to more complex systems.\u00a0Many of these issues are being explored in the context of working systems, for example a language interface for a team of humans and robots working together (Treasure Hunt) or a information access for conferences (ConQuest) or for scheduling court time (Let\u2019s Play).\nPersonal Website\n\nLinks:\nhttp://www.cs.cmu.edu/~air/",
  "Title: Norman Sadeh -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Norman Sadeh, Affiliated Faculty at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Affiliated Faculty\" name=\"categories-1\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Norman Sadeh - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Norman Sadeh, Affiliated Faculty at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Norman\"/>\n<meta content=\"Lastname\" property=\"profile:Sadeh\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/sadeh-norman.",
  "cmu.edu//people/faculty/sadeh-norman.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nNorman \n                        Sadeh\nProfessor, Software and Societal Systems\nCo-Director of MSIT, Privacy Engineering Program\nContact\nns1i(through)andrew.cmu.edu\nSoftware and Societal Systems\nPrivacy Engineering Program\nPersonal Website\n\nLinks:\nhttps://s3d.cmu.edu/\nhttps://privacy.cs.cmu.edu/\nhttps://www.normsadeh.org/",
  "Title: Maarten Sap -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Maarten Sap, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Core Faculty\" name=\"categories-1\"/>\n<meta content=\"Computational Social Science;Conversational AI;Discourse and Pragmatics;Fairness and Ethics in Language Technology\" name=\"categories-2\"/>\n<meta content=\"Yes\" name=\"show-categories-2\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Maarten Sap - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Maarten Sap,",
  "Faculty Member at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Maarten\"/>\n<meta content=\"Lastname\" property=\"profile:Sap\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/sap-maarten.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nMaarten \n                        Sap\nAssistant Professor, Language Technologies Institute\nContact\n6713 \u2014Gates & Hillman Centers\nmsap2(through)andrew.cmu.edu\nResearch Area\nComputational Social Science, Conversational AI, Discourse and Pragmatics, Fairness and Ethics in Language Technology\nPersonal Website\n\nLinks:\nhttp://maartensap.com/",
  "Title: Thomas Schaaf -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Thomas Schaaf, Adjunct Faculty at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Adjunct Faculty\" name=\"categories-1\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Thomas Schaaf - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Thomas Schaaf, Adjunct Faculty at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Thomas\"/>\n<meta content=\"Lastname\" property=\"profile:Schaaf\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/schaaf-thomas.",
  "cmu.edu//people/faculty/schaaf-thomas.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nThomas \n                        Schaaf\nPrincipal Research Scientist, 3M | M*Modal\nContact\nfuzzy(through)lazytoad.com\n\nLinks:",
  "Faculty Name: scott fahlman\nMetadata:\nPaperid: 13922d438c437cea443b6c4747c54a29a8bdd742\nTitle: Score: A Rule Engine for the Scone Knowledge Base System\nYear: 2023\nAbstract: We present Score, a rule engine designed and implemented for the Scone knowledge base system. Scone is a knowledge base system designed for storing and manipulating rich representations of general knowledge in symbolic form. It represents knowledge in the form of nodes and links in a network structure, and it can perform basic inference about the relationships between different elements efficiently. On its own, Scone acts as a sort of\"smart memory\"that can interface with other software systems. One area of improvement for Scone is how useful it can be in supplying knowledge to an intelligent agent that can use the knowledge to perform actions and update the knowledge base with its observations. We augment the Scone system with a production rule engine that automatically performs simple inference based on existing and newly-added structures in Scone's knowledge base, potentially improving the capabilities of any planning systems built on top of Scone.",
  "We augment the Scone system with a production rule engine that automatically performs simple inference based on existing and newly-added structures in Scone's knowledge base, potentially improving the capabilities of any planning systems built on top of Scone. Production rule systems consist of\"if-then\"production rules that try to match their predicates to existing knowledge and fire their actions when their predicates are satisfied. We propose two kinds of production rules, if-added and if-needed rules, that differ in how they are checked and fired to cover multiple use cases. We then implement methods to efficiently check and fire these rules in a large knowledge base. The new rule engine is not meant to be a complex stand-alone planner, so we discuss how it fits into the context of Scone and future work on planning systems.\nAuthors: Jeffrey Chen, S. Fahlman\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': \"The Scone system is augmented with a production rule engine that automatically performs simple inference based on existing and newly-added structures in Scone's knowledge base, potentially improving the capabilities of any planning systems built on top of Scone.\"}",
  "List of 2023 Open Access papers by scott fahlman are:\nScore: A Rule Engine for the Scone Knowledge Base System",
  "Faculty Name: sean welleck\nMetadata:\nPaperid: 3aaf6a2cbad5850ad81ab5c163599cb3d523436f\nTitle: Self-Refine: Iterative Refinement with Self-Feedback\nYear: 2023\nAbstract: Like humans, large language models (LLMs) do not always generate the best output on their first try. Motivated by how humans refine their written text, we introduce Self-Refine, an approach for improving initial outputs from LLMs through iterative feedback and refinement. The main idea is to generate an initial output using an LLMs; then, the same LLMs provides feedback for its output and uses it to refine itself, iteratively. Self-Refine does not require any supervised training data, additional training, or reinforcement learning, and instead uses a single LLM as the generator, refiner, and feedback provider. We evaluate Self-Refine across 7 diverse tasks, ranging from dialog response generation to mathematical reasoning, using state-of-the-art (GPT-3.5, ChatGPT, and GPT-4) LLMs.",
  "We evaluate Self-Refine across 7 diverse tasks, ranging from dialog response generation to mathematical reasoning, using state-of-the-art (GPT-3.5, ChatGPT, and GPT-4) LLMs. Across all evaluated tasks, outputs generated with Self-Refine are preferred by humans and automatic metrics over those generated with the same LLM using conventional one-step generation, improving by ~20% absolute on average in task performance. Our work demonstrates that even state-of-the-art LLMs like GPT-4 can be further improved at test time using our simple, standalone approach.",
  "Our work demonstrates that even state-of-the-art LLMs like GPT-4 can be further improved at test time using our simple, standalone approach.\nAuthors: Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, S. Welleck, Bodhisattwa Prasad Majumder, Shashank Gupta, A. Yazdanbakhsh, Peter Clark\nVenue: Neural Information Processing Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Self-Refine is introduced, an approach for improving initial outputs from LLMs through iterative feedback and refinement that demonstrates that even state-of-the-art LLMs like GPT-4 can be further improved at test time using this simple, standalone approach.'}",
  "Faculty Name: sean welleck\nMetadata:\nPaperid: ca991e0283a1c30a46eb585d9eb499fc0ec8ecc2\nTitle: Inference-Time Policy Adapters (IPA): Tailoring Extreme-Scale LMs without Fine-tuning\nYear: 2023\nAbstract: While extreme-scale language models have demonstrated exceptional performance on a variety of language tasks, the degree of control over these language models through pure prompting can often be limited. Directly fine-tuning such language models can be effective for tailoring them, but it can be either extremely costly (e.g., GPT-3) or not even feasible for the broader community (e.g., GPT-4). We propose Inference-time Policy Adapters (IPA), which efficiently tailors a language model such as GPT-3 without fine-tuning it. IPA guides a large base model during decoding time through a lightweight policy adapter trained to optimize an arbitrary user objective with reinforcement learning. On five challenging text generation tasks, such as toxicity reduction and lexically constrained generation, IPA consistently brings significant improvements over off-the-shelf language models. It outperforms competitive baseline methods, sometimes even including expensive fine-tuning.",
  "On five challenging text generation tasks, such as toxicity reduction and lexically constrained generation, IPA consistently brings significant improvements over off-the-shelf language models. It outperforms competitive baseline methods, sometimes even including expensive fine-tuning. In particular, tailoring GPT-2 with IPA can outperform GPT-3, while tailoring GPT-3 with IPA brings a major performance boost over GPT-3 (and sometimes even over GPT-4). Our promising results highlight the potential of IPA as a lightweight alternative to tailoring extreme-scale language models.",
  "Our promising results highlight the potential of IPA as a lightweight alternative to tailoring extreme-scale language models.\nAuthors: Ximing Lu, Faeze Brahman, Peter West, Jaehun Jang, Khyathi Raghavi Chandu, Abhilasha Ravichander, Lianhui Qin, Prithviraj Ammanabrolu, Liwei Jiang, Sahana Ramnath, Nouha Dziri, Jillian R. Fisher, Bill Yuchen Lin, Skyler Hallinan, Xiang Ren, S. Welleck, Yejin Choi\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Inference-time Policy Adapters (IPA) is proposed, which efficiently tailors a language model such as GPT-3 without fine-tuning it, and consistently brings significant improvements over off-the-shelf language models.'}",
  "List of 2023 Open Access papers by sean welleck are:\nSelf-Refine: Iterative Refinement with Self-Feedback\nInference-Time Policy Adapters (IPA): Tailoring Extreme-Scale LMs without Fine-tuning",
  "Title: Michael Shamos -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Michael Shamos, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Core Faculty\" name=\"categories-1\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Michael Shamos - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Michael Shamos, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Michael\"/>\n<meta content=\"Lastname\" property=\"profile:Shamos\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/shamos-michael.",
  "cmu.edu//people/faculty/shamos-michael.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nMichael \n                        Shamos\nDistinguished Career Professor, Language Technologies Institute\nInstitute for Software Research\nContact\n6707 \u2014Gates & Hillman Centers\nshamos(through)cs.cmu.edu\n412-268-8193\nInstitute for Software Research\nPersonal Website\n\nLinks:\nhttps://www.cs.cmu.edu/~brassmars/\nhttp://www.cs.cmu.edu/~jbigham/",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 00542e510058b11d1faf612de9b45fa0d4d3f4e5\nTitle: Saturation time of exposure interval for cross-neutralization response to SARS-CoV-2: Implications for vaccine dose interval\nYear: 2023\nAbstract: None\nAuthors: Sho Miyamoto, Y. Kuroda, T. Kanno, A. Ueno, N. Shiwa-Sudo, N. Iwata-Yoshikawa, Yusuke Sakai, N. Nagata, T. Arashiro, A. Ainai, Saya Moriyama, N. Kishida, Shinji Watanabe, K. Nojima, Y. Seki, T. Mizukami, H. Hasegawa, H. Ebihara, S. Fukushi, Yoshimasa Takahashi, Maeda Ken, Tadaki Suzuki\nVenue: iScience\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The results highlight the importance of vaccine dosage intervals of 4 months or longer,",
  "S. Fukushi, Yoshimasa Takahashi, Maeda Ken, Tadaki Suzuki\nVenue: iScience\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The results highlight the importance of vaccine dosage intervals of 4 months or longer, regardless of the antigenicity of the exposed antigen, to maximize the breadth of serum cross-neutralization covering SARS-CoV-2 Omicron lineages.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 01a819f7155bb87c32f1e4c13d9439c080e6aa97\nTitle: Joint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning\nYear: 2023\nAbstract: Multilingual self-supervised learning (SSL) has often lagged behind state-of-the-art (SOTA) methods due to the expenses and complexity required to handle many languages. This further harms the reproducibility of SSL, which is already limited to few research groups due to its resource usage. We show that more powerful techniques can actually lead to more efficient pre-training, opening SSL to more research groups. We propose WavLabLM, which extends WavLM\u2019s joint prediction and denoising to 40k hours of data across 136 languages. To build WavLabLM, we devise a novel multi-stage pre-training method, designed to address the language imbalance of multilingual data. WavLabLM achieves comparable performance to XLS-R on ML-SUPERB with less than $10 \\%$ of the training data, making SSL realizable with academic compute.",
  "WavLabLM achieves comparable performance to XLS-R on ML-SUPERB with less than $10 \\%$ of the training data, making SSL realizable with academic compute. We show that further efficiency can be achieved with a vanilla HuBERT Base model, which can maintain $94 \\%$ of XLS-R\u2019s performance with only $3 \\%$ of the data, 4 GPUs, and limited trials. We open-source all code and models in ESPnet.\nAuthors: William Chen, Jiatong Shi, Brian Yan, Dan Berrebbi, Wangyou Zhang, Yifan Peng, Xuankai Chang, Soumi Maiti, Shinji Watanabe\nVenue: Automatic Speech Recognition & Understanding\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes WavLabLM, which extends WavLM\u2019s joint prediction and denoising to 40k hours of data across 136 languages, and devise a novel multi-stage pre-training method, designed to address the language imbalance of multilingual data.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 0534fd0ed04acaa60f820b730bf3c4816767fa43\nTitle: Tensor decomposition for minimization of E2E SLU model toward on-device processing\nYear: 2023\nAbstract: Spoken Language Understanding (SLU) is a critical speech recognition application and is often deployed on edge devices. Consequently, on-device processing plays a significant role in the practical implementation of SLU. This paper focuses on the end-to-end (E2E) SLU model due to its small latency property, unlike a cascade system, and aims to minimize the computational cost. We reduce the model size by applying tensor decomposition to the Conformer and E-Branchformer architectures used in our E2E SLU models. We propose to apply singular value decomposition to linear layers and the Tucker decomposition to convolution layers, respectively. We also compare COMP/PARFAC decomposition and Tensor-Train decomposition to the Tucker decomposition. Since the E2E model is represented by a single neural network, our tensor decomposition can flexibly control the number of parameters without changing feature dimensions.",
  "We also compare COMP/PARFAC decomposition and Tensor-Train decomposition to the Tucker decomposition. Since the E2E model is represented by a single neural network, our tensor decomposition can flexibly control the number of parameters without changing feature dimensions. On the STOP dataset, we achieved 70.9% exact match accuracy under the tight constraint of only 15 million parameters.\nAuthors: Yosuke Kashiwagi, Siddhant Arora, Hayato Futami, Jessica Huynh, Shih-Lun Wu, Yifan Peng, Brian Yan, E. Tsunoo, Shinji Watanabe\nVenue: Interspeech\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper aims to minimize the computational cost of the end-to-end (E2E) SLU model due to its small latency property, unlike a cascade system, and reduces the model size by applying tensor decomposition to the Conformer and E-Branchformer architectures used in the E2E SLU models.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 06353e1b7e7c8dc701ac76dcd4db5061b24468c9\nTitle: Decoder-only Architecture for Speech Recognition with CTC Prompts and Text Data Augmentation\nYear: 2023\nAbstract: Collecting audio-text pairs is expensive; however, it is much easier to access text-only data. Unless using shallow fusion, end-to-end automatic speech recognition (ASR) models require architecture modifications or additional training schemes to use text-only data. Inspired by recent advances in decoder-only language models (LMs), such as GPT-3 and PaLM adopted for speech-processing tasks, we propose using a decoder-only architecture for ASR with simple text augmentation. To provide audio information, encoder features compressed by CTC prediction are used as prompts for the decoder, which can be regarded as refining CTC prediction using the decoder-only model. Because the decoder architecture is the same as an autoregressive LM, it is simple to enhance the model by leveraging external text data with LM training.",
  "Because the decoder architecture is the same as an autoregressive LM, it is simple to enhance the model by leveraging external text data with LM training. An experimental comparison using LibriSpeech and Switchboard shows that our proposed models with text augmentation training reduced word error rates from ordinary CTC by 0.3% and 1.4% on LibriSpeech test-clean and testother set, respectively, and 2.9% and 5.0% on Switchboard and CallHome. The proposed model had advantage on computational efficiency compared with conventional encoder-decoder ASR models with a similar parameter setup, and outperformed them on the LibriSpeech 100h and Switchboard training scenarios.",
  "The proposed model had advantage on computational efficiency compared with conventional encoder-decoder ASR models with a similar parameter setup, and outperformed them on the LibriSpeech 100h and Switchboard training scenarios.\nAuthors: E. Tsunoo, Hayato Futami, Yosuke Kashiwagi, Siddhant Arora, Shinji Watanabe\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes using a decoder-only architecture for ASR with simple text augmentation training that had advantage on computational efficiency compared with conventional encoder-decoder ASR models with a similar parameter setup, and outperformed them on the LibriSpeech 100h and Switchboard training scenarios.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 083cf10c0cbf75dd5755a6a2cd971f39e7da75c2\nTitle: UniverSLU: Universal Spoken Language Understanding for Diverse Classification and Sequence Generation Tasks with a Single Network\nYear: 2023\nAbstract: Recent studies have demonstrated promising outcomes by employing large language models with multi-tasking capabilities. They utilize prompts to guide the model's behavior and surpass performance of task-specific models. Motivated by this, we ask: can we build a single model that jointly perform various spoken language understanding (SLU) tasks? To address this, we utilize pre-trained automatic speech recognition (ASR) models and employ various task and dataset specifiers as discrete prompts. We demonstrate efficacy of our single multi-task learning (MTL) model\"UniverSLU\"for 12 different speech classification and sequence generation tasks across 17 datasets and 9 languages. Results show that UniverSLU achieves competitive performance and even surpasses task-specific models.",
  "We demonstrate efficacy of our single multi-task learning (MTL) model\"UniverSLU\"for 12 different speech classification and sequence generation tasks across 17 datasets and 9 languages. Results show that UniverSLU achieves competitive performance and even surpasses task-specific models. We also conduct preliminary investigations into enabling human-interpretable natural phrases instead of task specifiers as discrete prompts and test the model's generalization capabilities to new paraphrases.\nAuthors: Siddhant Arora, Hayato Futami, Jee-weon Jung, Yifan Peng, Roshan Sharma, Yosuke Kashiwagi, E. Tsunoo, Shinji Watanabe\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work utilizes pre-trained automatic speech recognition (ASR) models and employs various task and dataset specifiers as discrete prompts to build a single model that jointly perform various spoken language understanding (SLU) tasks.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 090b284b2f8fc93ac3e7a92fc9f91bf4965ba75c\nTitle: ML-SUPERB: Multilingual Speech Universal PERformance Benchmark\nYear: 2023\nAbstract: Speech processing Universal PERformance Benchmark (SUPERB) is a leaderboard to benchmark the performance of Self-Supervised Learning (SSL) models on various speech processing tasks. However, SUPERB largely considers English speech in its evaluation. This paper presents multilingual SUPERB (ML-SUPERB), covering 143 languages (ranging from high-resource to endangered), and considering both automatic speech recognition and language identification. Following the concept of SUPERB, ML-SUPERB utilizes frozen SSL features and employs a simple framework for multilingual tasks by learning a shallow downstream model. Similar to the SUPERB benchmark, we find speech SSL models can significantly improve performance compared to FBANK features. Furthermore, we find that multilingual models do not always perform better than their monolingual counterparts. We will release ML-SUPERB as a challenge with organized datasets and reproducible training scripts for future multilingual representation research.",
  "Furthermore, we find that multilingual models do not always perform better than their monolingual counterparts. We will release ML-SUPERB as a challenge with organized datasets and reproducible training scripts for future multilingual representation research.\nAuthors: Jiatong Shi, Dan Berrebbi, William Chen, Ho-Lam Chung, En-Pei Hu, Wei Huang, Xuankai Chang, Shang-Wen Li, Abdel-rahman Mohamed, Hung-yi Lee, Shinji Watanabe\nVenue: Interspeech\nTldr: {'model': 'tldr@v2.0.0', 'text': None}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 0b234f749c6aebf5b1ec61fa0b2ac0d348ad08ed\nTitle: TorchAudio 2.1: Advancing Speech Recognition, Self-Supervised Learning, and Audio Processing Components for Pytorch\nYear: 2023\nAbstract: TorchAudio is an open-source audio and speech processing library built for PyTorch. It aims to accelerate the research and development of audio and speech technologies by providing well-designed, easy-to-use, and performant PyTorch components. Its contributors routinely engage with users to understand their needs and fulfill them by developing impactful features. Here, we survey TorchAudio\u2019s development principles and contents and highlight key features we include in its latest version (2.1): self-supervised learning pre-trained pipelines and training recipes, high-performance CTC decoders, speech recognition models and training recipes, advanced media I/O capabilities, and tools for performing forced alignment, multi-channel speech enhancement, and reference-less speech assessment. For a selection of these features, through empirical studies, we demonstrate their efficacy and show that they achieve competitive or state-of-the-art performance.",
  "For a selection of these features, through empirical studies, we demonstrate their efficacy and show that they achieve competitive or state-of-the-art performance.\nAuthors: Jeff Hwang, Moto Hira, Caroline Chen, Xiaohui Zhang, Zhaoheng Ni, Guangzhi Sun, Pingchuan Ma, Ruizhe Huang, Vineel Pratap, Yuekai Zhang, Anurag Kumar, Chin-Yun Yu, Chuang Zhu, Chunxi Liu, Jacob Kahn, M. Ravanelli, Peng Sun, Shinji Watanabe, Yangyang Shi, Yumeng Tao, Robin Scheibler, Samuele Cornell, Sean Kim, Stavros Petridis\nVenue: Automatic Speech Recognition & Understanding\nTldr: {'model': 'tldr@v2.0.0', 'text': 'TorchAudio\u2019s development principles and contents are surveyed and key features included in its latest version (2.1) are highlighted: self-supervised learning pre-trained pipelines and training recipes, high-performance CTC decoders, speech recognition models and training recipes, advanced media I/O capabilities, and tools for performing forced alignment, multi-channel speech enhancement, and reference-less speech assessment.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 0c7018db4a00df1792a7b3de3cb0b48aa19ca041\nTitle: Integrating Pretrained ASR and LM to Perform Sequence Generation for Spoken Language Understanding\nYear: 2023\nAbstract: There has been an increased interest in the integration of pretrained speech recognition (ASR) and language models (LM) into the SLU framework. However, prior methods often struggle with a vocabulary mismatch between pretrained models, and LM cannot be directly utilized as they diverge from its NLU formulation. In this study, we propose a three-pass end-to-end (E2E) SLU system that effectively integrates ASR and LM subnetworks into the SLU formulation for sequence generation tasks. In the first pass, our architecture predicts ASR transcripts using the ASR subnetwork. This is followed by the LM subnetwork, which makes an initial SLU prediction. Finally, in the third pass, the deliberation subnetwork conditions on representations from the ASR and LM subnetworks to make the final prediction.",
  "This is followed by the LM subnetwork, which makes an initial SLU prediction. Finally, in the third pass, the deliberation subnetwork conditions on representations from the ASR and LM subnetworks to make the final prediction. Our proposed three-pass SLU system shows improved performance over cascaded and E2E SLU models on two benchmark SLU datasets, SLURP and SLUE, especially on acoustically challenging utterances.\nAuthors: Siddhant Arora, Hayato Futami, Yosuke Kashiwagi, E. Tsunoo, Brian Yan, Shinji Watanabe\nVenue: Interspeech\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This study proposes a three-pass end-to-end (E2E) SLU system that effectively integrates ASR and LM subnetworks into the SLU formulation for sequence generation tasks and shows improved performance over cascaded and E2E SLU models on two benchmark SLU datasets, SLURP and SLUE.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 1028bf42a4c792acefd3be9da45e58f2b1620fe3\nTitle: Structured Pruning of Self-Supervised Pre-Trained Models for Speech Recognition and Understanding\nYear: 2023\nAbstract: Self-supervised speech representation learning (SSL) has shown to be effective in various downstream tasks, but SSL models are usually large and slow. Model compression techniques such as pruning aim to reduce the model size and computation without degradation in accuracy. Prior studies focus on the pruning of Transformers; however, speech models not only utilize a stack of Transformer blocks, but also combine a frontend network based on multiple convolutional layers for low-level feature representation learning. This frontend has a small size but a heavy computational cost. In this work, we propose three task-specific structured pruning methods to deal with such heterogeneous networks. Experiments on LibriSpeech and SLURP show that the proposed method is more accurate than the original wav2vec2-base with 10% to 30% less computation, and is able to reduce the computation by 40% to 50% without any degradation.",
  "Experiments on LibriSpeech and SLURP show that the proposed method is more accurate than the original wav2vec2-base with 10% to 30% less computation, and is able to reduce the computation by 40% to 50% without any degradation.\nAuthors: Yifan Peng, Kwangyoun Kim, Felix Wu, Prashant Sridhar, Shinji Watanabe\nVenue: IEEE International Conference on Acoustics, Speech, and Signal Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes three task-specific structured pruning methods to deal with heterogeneous speech models that not only utilize a stack of Transformer blocks, but also combine a frontend network based on multiple convolutional layers for low-level feature representation learning.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 10e8dc07ea256c6a88d7043cf135417402ed38f4\nTitle: Prompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot Task Generalization\nYear: 2023\nAbstract: We investigate the emergent abilities of the recently proposed web-scale speech model Whisper, by adapting it to unseen tasks with prompt engineering. We selected three tasks: audio-visual speech recognition (AVSR), code-switched speech recognition (CS-ASR), and speech translation (ST) on unseen language pairs. We design task-specific prompts, by either leveraging another large-scale model, or simply manipulating the special tokens in the default prompts. Experiments show that compared to the default prompts, our proposed prompts improve performance by 10% to 45% on the three zero-shot tasks, and even outperform SotA supervised models on some datasets. In addition, our experiments reveal many interesting properties of Whisper, including its robustness to prompts, bias on accents, and the multilingual understanding in its latent space.",
  "In addition, our experiments reveal many interesting properties of Whisper, including its robustness to prompts, bias on accents, and the multilingual understanding in its latent space. Code is available at https://github.com/jasonppy/PromptingWhisper\nAuthors: Puyuan Peng, Brian Yan, Shinji Watanabe, David F. Harwath\nVenue: Interspeech\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work investigates the emergent abilities of the recently proposed web-scale speech model Whisper, by adapting it to unseen tasks with prompt engineering, and designs task-specific prompts that improve performance on the three zero-shot tasks and even outperform SotA supervised models on some datasets.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 14f5fd91d75bc10d9fff53dfe7ee73484fc4273b\nTitle: A Comparative Study on E-Branchformer vs Conformer in Speech Recognition, Translation, and Understanding Tasks\nYear: 2023\nAbstract: Conformer, a convolution-augmented Transformer variant, has become the de facto encoder architecture for speech processing due to its superior performance in various tasks, including automatic speech recognition (ASR), speech translation (ST) and spoken language understanding (SLU). Recently, a new encoder called E-Branchformer has outperformed Conformer in the LibriSpeech ASR benchmark, making it promising for more general speech applications. This work compares E-Branchformer and Conformer through extensive experiments using different types of end-to-end sequence-to-sequence models. Results demonstrate that E-Branchformer achieves comparable or better performance than Conformer in almost all evaluation sets across 15 ASR, 2 ST, and 3 SLU benchmarks, while being more stable during training. We will release our training configurations and pre-trained models for reproducibility, which can benefit the speech community.",
  "We will release our training configurations and pre-trained models for reproducibility, which can benefit the speech community.\nAuthors: Yifan Peng, Kwangyoun Kim, Felix Wu, Brian Yan, Siddhant Arora, William Chen, Jiyang Tang, Suwon Shon, Prashant Sridhar, Shinji Watanabe\nVenue: Interspeech\nTldr: {'model': 'tldr@v2.0.0', 'text': 'E-Branchformer achieves comparable or better performance than Conformer in almost all evaluation sets across 15 ASR, 2 ST, and 3 SLU benchmarks, while being more stable during training.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 16fbcf340648b302ad8d4e6ed34c7ab5ad346db9\nTitle: Efficient Sequence Transduction by Jointly Predicting Tokens and Durations\nYear: 2023\nAbstract: This paper introduces a novel Token-and-Duration Transducer (TDT) architecture for sequence-to-sequence tasks. TDT extends conventional RNN-Transducer architectures by jointly predicting both a token and its duration, i.e. the number of input frames covered by the emitted token. This is achieved by using a joint network with two outputs which are independently normalized to generate distributions over tokens and durations. During inference, TDT models can skip input frames guided by the predicted duration output, which makes them significantly faster than conventional Transducers which process the encoder output frame by frame. TDT models achieve both better accuracy and significantly faster inference than conventional Transducers on different sequence transduction tasks. TDT models for Speech Recognition achieve better accuracy and up to 2.82X faster inference than conventional Transducers.",
  "TDT models achieve both better accuracy and significantly faster inference than conventional Transducers on different sequence transduction tasks. TDT models for Speech Recognition achieve better accuracy and up to 2.82X faster inference than conventional Transducers. TDT models for Speech Translation achieve an absolute gain of over 1 BLEU on the MUST-C test compared with conventional Transducers, and its inference is 2.27X faster. In Speech Intent Classification and Slot Filling tasks, TDT models improve the intent accuracy by up to over 1% (absolute) over conventional Transducers, while running up to 1.28X faster. Our implementation of the TDT model will be open-sourced with the NeMo (https://github.com/NVIDIA/NeMo) toolkit.\nAuthors: Hainan Xu, Fei Jia, Somshubra Majumdar, Hengguan Huang, Shinji Watanabe, Boris Ginsburg\nVenue: International Conference on Machine Learning\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A novel Token-and-Duration Transducer architecture for sequence-to-sequence tasks by jointly predicting both a token and its duration, i.e.",
  "the number of input frames covered by the emitted token.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 1ac784bfd7c64b35d4914b80d7974038e3dd092a\nTitle: Effect of medium-chain triglycerides supplements and walking on health-related quality of life in sedentary, healthy middle-aged, and older adults with low BMIs: a randomized, double-blind, placebo-controlled, parallel-group trial\nYear: 2023\nAbstract: Introduction To extend individuals\u2019 healthy life expectancies, the improvement of subjective health and quality of life (QOL) has been increasingly prioritized, alongside the improvement of their physical functioning. Reports have indicated that intake of medium-chain triglycerides (MCTs) benefits the physical health of older individuals requiring nursing care, and athletes, and healthy individuals. But there are few studies investigating the effects of MCTs on subjective health and QOL. The present study sought to evaluate the combined effects of 12-week MCTs supplements and moderate-intensity walking exercise on the subjective health and QOL of middle-aged and older adults aged 60\u201374 with low BMIs (< 24\u2009kg/m2) and who had no exercise habits.",
  "The present study sought to evaluate the combined effects of 12-week MCTs supplements and moderate-intensity walking exercise on the subjective health and QOL of middle-aged and older adults aged 60\u201374 with low BMIs (< 24\u2009kg/m2) and who had no exercise habits. Methods A placebo-controlled, double-blind, parallel-group trial was conducted. Three MCTs supplement groups with different doses and fatty acid compositions were compared with a control group. The study used the SF-36v2 questionnaire to assess subjective health and health-related QOL (HRQOL). Results The result showed significant improvements in the scores on subscales of the physical QOL, such as Physical functioning and General health, and summary scores on the mental QOL, compared to the control. Conclusion It is estimated that the combination of continuous intake of MCTs and walking exercise may affect HRQOL and improve subjective physical and mental health in sedentary, healthy, middle-aged and older adults. Clinical trial registration https://rctportal.niph.go.jp/s/detail/um?trial_id=UMIN000046861, UMIN000046861.",
  "Clinical trial registration https://rctportal.niph.go.jp/s/detail/um?trial_id=UMIN000046861, UMIN000046861.\nAuthors: Haruna Ishikawa, Keiichi Kojima, Shinji Watanabe, N. Nosaka, Tatsushi Mutoh\nVenue: Frontiers in Nutrition\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is estimated that the combination of continuous intake of MCTs and walking exercise may affect HRQOL and improve subjective physical and mental health in sedentary, healthy, middle-aged and older adults.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 1dc2d0f43df7f7a7847817203411357eca79a5b3\nTitle: Reducing Barriers to Self-Supervised Learning: HuBERT Pre-training with Academic Compute\nYear: 2023\nAbstract: Self-supervised learning (SSL) has led to great strides in speech processing. However, the resources needed to train these models has become prohibitively large as they continue to scale. Currently, only a few groups with substantial resources are capable of creating SSL models, which harms reproducibility. In this work, we optimize HuBERT SSL to fit in academic constraints. We reproduce HuBERT independently from the original implementation, with no performance loss. Our code and training optimizations make SSL feasible with only 8 GPUs, instead of the 32 used in the original work. We also explore a semi-supervised route, using an ASR model to skip the first pre-training iteration. Within one iteration of pre-training, our models improve over HuBERT on several tasks. Furthermore, our HuBERT Large variant requires only 8 GPUs, achieving similar performance to the original trained on 128.",
  "Within one iteration of pre-training, our models improve over HuBERT on several tasks. Furthermore, our HuBERT Large variant requires only 8 GPUs, achieving similar performance to the original trained on 128. As our contribution to the community, all models, configurations, and code are made open-source in ESPnet.\nAuthors: William Chen, Xuankai Chang, Yifan Peng, Zhaoheng Ni, Soumi Maiti, Shinji Watanabe\nVenue: Interspeech\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work optimizing HuBERT SSL to fit in academic constraints, and reproducibility, and explores a semi-supervised route, using an ASR model to skip the first pre-training iteration.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 2126b5497eb51926d0baac655a1e0f88f0d1ec00\nTitle: Antiviral efficacy against and replicative fitness of an XBB.1.9.1 clinical isolate\nYear: 2023\nAbstract: None\nAuthors: R. Uraki, Mutsumi Ito, Maki Kiso, S. Yamayoshi, K. Iwatsuki-Horimoto, Yuko Sakai-Tagawa, Masaki Imai, M. Koga, Shinya Yamamoto, E. Adachi, Makoto Saito, T. Tsutsumi, Amato Otani, S. Fukushi, Shinji Watanabe, Tadaki Suzuki, Tetsuhiro Kikuchi, H. Yotsuyanagi, Maeda Ken, Yoshihiro Kawaoka\nVenue: iScience\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The results suggest that XBB.1.9.2.1 and X BB.1-CoV-2 have similar antigenicity and replicative ability,",
  "Yoshihiro Kawaoka\nVenue: iScience\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The results suggest that XBB.1.9.2.1 and X BB.1-CoV-2 have similar antigenicity and replicative ability, and that the currently available COVID-19 antivirals remain effective against XBB, even at the highest concentration used.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 2567a34501c1b258c102a07e737b87e556af0809\nTitle: Speech Summarization of Long Spoken Document: Improving Memory Efficiency of Speech/Text Encoders\nYear: 2023\nAbstract: Speech summarization requires processing several minute-long speech sequences to allow exploiting the whole context of a spoken document. A conventional approach is a cascade of automatic speech recognition (ASR) and text summarization (TS). However, the cascade systems are sensitive to ASR errors. Moreover, the cascade system cannot be optimized for input speech and utilize para-linguistic information. Recently, there has been an increased interest in end-to-end (E2E) approaches optimized to output summaries directly from speech. Such systems can thus mitigate the ASR errors of cascade approaches. However, E2E speech summarization requires massive computational resources because it needs to encode long speech sequences.",
  "Recently, there has been an increased interest in end-to-end (E2E) approaches optimized to output summaries directly from speech. Such systems can thus mitigate the ASR errors of cascade approaches. However, E2E speech summarization requires massive computational resources because it needs to encode long speech sequences. We propose a speech summarization system that enables E2E summarization from 100 seconds, which is the limit of the conventional method, to up to 10 minutes (i.e., the duration of typical instructional videos on YouTube). However, the modeling capability of this model for minute-long speech sequences is weaker than the conventional approach. We thus exploit auxiliary text information from ASR transcriptions to improve the modeling capabilities. The resultant system consists of a dual speech/text encoder decoder-based summarization system. We perform experiments on the How2 dataset showing the proposed system improved METEOR scores by up to 2.7 points by fully exploiting the long spoken documents.",
  "The resultant system consists of a dual speech/text encoder decoder-based summarization system. We perform experiments on the How2 dataset showing the proposed system improved METEOR scores by up to 2.7 points by fully exploiting the long spoken documents.\nAuthors: Takatomo Kano, A. Ogawa, Marc Delcroix, Roshan Sharma, Kohei Matsuura, Shinji Watanabe\nVenue: IEEE International Conference on Acoustics, Speech, and Signal Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes a speech summarization system that enables E2E summarization from 100 seconds, which is the limit of the conventional method, to up to 10 minutes (i.e., the duration of typical instructional videos on YouTube), and exploits auxiliary text information from ASR transcriptions to improve the modeling capabilities.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 25b28a08a75ad0e6c8ed27f48c59199fba15fcbd\nTitle: FindAdaptNet: Find and Insert Adapters by Learned Layer Importance\nYear: 2023\nAbstract: Adapters are lightweight bottleneck modules introduced to assist pre-trained self-supervised learning (SSL) models to be customized to new tasks. However, searching the appropriate layers to insert adapters on large models has become difficult due to the large number of possible layers and thus a vast search space (2N possibilities for N layers). In this paper, we propose a technique that achieves automatic insertion of adapters for downstream automatic speech recognition (ASR) and spoken language understanding (SLU) tasks. Our approach is based on two-stage training. First, we train our model for a specific downstream task with additional shallow learnable layers and weight parameters to obtain the weighted summation over the output of each layer in SSL. This training method is established by the SUPERB baseline [1]. This first-stage training determines the most important layers given their respective weights.",
  "This training method is established by the SUPERB baseline [1]. This first-stage training determines the most important layers given their respective weights. In the second stage, we proceed to insert adapters to the most important layers, retaining both performance and neural architecture search efficiency. On the CommonVoice dataset[2] we obtain 20.6% absolute improvement in Word Error Rate (WER) on the Welsh language against the conventional method, which inserts the adapter modules into the highest layers without search. In the SLURP SLU task, our method yields 4.0% intent accuracy improvement against the same conventional baseline.\nAuthors: Junwei Huang, Karthik Ganesan, Soumi Maiti, Young Min Kim, Xuankai Chang, Paul Liang, Shinji Watanabe\nVenue: IEEE International Conference on Acoustics, Speech, and Signal Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper proposes a technique that achieves automatic insertion of adapters for downstream automatic speech recognition (ASR) and spoken language understanding (SLU) tasks, based on two-stage training based on a weighted summation over the output of each layer in SSL.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 25c399a231364f4a77d1dc4b59927585e63f5f11\nTitle: UNSSOR: Unsupervised Neural Speech Separation by Leveraging Over-determined Training Mixtures\nYear: 2023\nAbstract: In reverberant conditions with multiple concurrent speakers, each microphone acquires a mixture signal of multiple speakers at a different location. In over-determined conditions where the microphones out-number speakers, we can narrow down the solutions to speaker images and realize unsupervised speech separation by leveraging each mixture signal as a constraint (i.e., the estimated speaker images at a microphone should add up to the mixture). Equipped with this insight, we propose UNSSOR, an algorithm for $\\textbf{u}$nsupervised $\\textbf{n}$eural $\\textbf{s}$peech $\\textbf{s}$eparation by leveraging $\\textbf{o}$ver-determined training mixtu$\\textbf{r}$es.",
  "At each training step, we feed an input mixture to a deep neural network (DNN) to produce an intermediate estimate for each speaker, linearly filter the estimates, and optimize a loss so that, at each microphone, the filtered estimates of all the speakers can add up to the mixture to satisfy the above constraint. We show that this loss can promote unsupervised separation of speakers. The linear filters are computed in each sub-band based on the mixture and DNN estimates through the forward convolutive prediction (FCP) algorithm. To address the frequency permutation problem incurred by using sub-band FCP, a loss term based on minimizing intra-source magnitude scattering is proposed. Although UNSSOR requires over-determined training mixtures, we can train DNNs to achieve under-determined separation (e.g., unsupervised monaural speech separation). Evaluation results on two-speaker separation in reverberant conditions show the effectiveness and potential of UNSSOR.",
  "Although UNSSOR requires over-determined training mixtures, we can train DNNs to achieve under-determined separation (e.g., unsupervised monaural speech separation). Evaluation results on two-speaker separation in reverberant conditions show the effectiveness and potential of UNSSOR.\nAuthors: Zhong-Qiu Wang, Shinji Watanabe\nVenue: Neural Information Processing Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Evaluation results on two-speaker separation in reverberant conditions show the effectiveness and potential of UNSSOR, an algorithm for over-determined training mixtures that can promote unsupervised separation of speakers.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 2f9860ab7979516fe2d4b503bb4b0bcdbd045bf2\nTitle: Antigenic drift and subtype interference shape A(H3N2) epidemic dynamics in the United States\nYear: 2023\nAbstract: Influenza viruses continually evolve new antigenic variants, through mutations in epitopes of their major surface proteins, hemagglutinin (HA) and neuraminidase (NA). Antigenic drift potentiates the reinfection of previously infected individuals, but the contribution of this process to variability in annual epidemics is not well understood. Here we link influenza A(H3N2) virus evolution to regional epidemic dynamics in the United States during 1997-2019. We integrate phenotypic measures of HA antigenic drift and sequence-based measures of HA and NA fitness to infer antigenic and genetic distances between viruses circulating in successive seasons.",
  "Here we link influenza A(H3N2) virus evolution to regional epidemic dynamics in the United States during 1997-2019. We integrate phenotypic measures of HA antigenic drift and sequence-based measures of HA and NA fitness to infer antigenic and genetic distances between viruses circulating in successive seasons. We estimate the magnitude, severity, timing, transmission rate, age-specific patterns, and subtype dominance of each regional outbreak and find that genetic distance based on broad sets of epitope sites is the strongest evolutionary predictor of A(H3N2) virus epidemiology. Increased HA and NA epitope distance between seasons correlates with larger, more intense epidemics, higher transmission, greater A(H3N2) subtype dominance, and a greater proportion of cases in adults relative to children, consistent with increased population susceptibility. Based on random forest models, A(H1N1) incidence impacts A(H3N2) epidemics to a greater extent than viral evolution, suggesting that subtype interference is a major driver of influenza A virus infection dynamics, presumably via heterosubtypic cross-immunity.",
  "Based on random forest models, A(H1N1) incidence impacts A(H3N2) epidemics to a greater extent than viral evolution, suggesting that subtype interference is a major driver of influenza A virus infection dynamics, presumably via heterosubtypic cross-immunity.\nAuthors: A. Perofsky, John Huddleston, Chelsea Hansen, John R. Barnes, Thomas Rowe, Xiyan Xu, Rebecca J. Kondor, D. Wentworth, Nicola S. Lewis, L. Whittaker, B. Ermetal, Ruth Harvey, Monica Galiano, R. S. Daniels, John W McCauley, Seiichiro Fujisaki, Kazuya Nakamura, Noriko Kishida, Shinji Watanabe, Hideki Hasegawa, Sheena G. Sullivan, Ian G. Barr, Kanta Subbarao, F. Krammer, Trevor Bedford, C\u00e9cile Viboud\nVenue: medRxiv\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Increased HA and NA epitope distance between seasons correlates with larger, more intense epidemics, higher transmission, greater A(H3N2) subtype dominance, and a greater proportion of cases in adults relative to children, consistent with increased population susceptibility.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 331af9b7193e563b021e8e6892e7cb3030decd38\nTitle: Segment-Level Vectorized Beam Search Based on Partially Autoregressive Inference\nYear: 2023\nAbstract: Attention-based encoder-decoder models with autoregressive (AR) decoding have proven to be the dominant approach for automatic speech recognition (ASR) due to their superior accuracy. However, they often suffer from slow inference. This is primarily attributed to the incremental calculation of the decoder. This work proposes a partially AR framework, which employs segment-level vectorized beam search for improving the inference speed of an ASR model based on the hybrid connectionist temporal classification (CTC) attention-based architecture. It first generates an initial hypothesis using greedy CTC decoding, identifying low-confidence tokens based on their output probabilities. We then utilize the decoder to perform segment-level vectorized beam search on these tokens, re-predicting in parallel with minimal decoder calculations. Experimental results show that our method is 12 to 13 times faster in inference on the LibriSpeech corpus over AR decoding whilst preserving high accuracy.",
  "We then utilize the decoder to perform segment-level vectorized beam search on these tokens, re-predicting in parallel with minimal decoder calculations. Experimental results show that our method is 12 to 13 times faster in inference on the LibriSpeech corpus over AR decoding whilst preserving high accuracy.\nAuthors: Masao Someki, N. Eng, Yosuke Higuchi, Shinji Watanabe\nVenue: Automatic Speech Recognition & Understanding\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A partially AR framework, which employs segment-level vectorized beam search for improving the inference speed of an ASR model based on the hybrid connectionist temporal classification (CTC) attention-based architecture, which is 12 to 13 times faster in inference on the LibriSpeech corpus over AR decoding whilst preserving high accuracy.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 3b93dd5f2d2512a4b58f6c776af59f74a90764a5\nTitle: Unsupervised Data Selection for TTS: Using Arabic Broadcast News as a Case Study\nYear: 2023\nAbstract: .\nAuthors: Massa Baali, Tomoki Hayashi, Hamdy Mubarak, Soumi Maiti, Shinji Watanabe, W. El-Hajj, Ahmed Ali\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': None}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 3bd320ddb25886417ae90011b00f13f5d558097b\nTitle: BASS: Block-wise Adaptation for Speech Summarization\nYear: 2023\nAbstract: End-to-end speech summarization has been shown to improve performance over cascade baselines. However, such models are difficult to train on very large inputs (dozens of minutes or hours) owing to compute restrictions and are hence trained with truncated model inputs. Truncation leads to poorer models, and a solution to this problem rests in block-wise modeling, i.e., processing a portion of the input frames at a time. In this paper, we develop a method that allows one to train summarization models on very long sequences in an incremental manner. Speech summarization is realized as a streaming process, where hypothesis summaries are updated every block based on new acoustic information. We devise and test strategies to pass semantic context across the blocks. Experiments on the How2 dataset demonstrate that the proposed block-wise training method improves by 3 points absolute on ROUGE-L over a truncated input baseline.",
  "We devise and test strategies to pass semantic context across the blocks. Experiments on the How2 dataset demonstrate that the proposed block-wise training method improves by 3 points absolute on ROUGE-L over a truncated input baseline.\nAuthors: Roshan Sharma, Kenneth Zheng, Siddhant Arora, Shinji Watanabe, Rita Singh, B. Raj\nVenue: Interspeech\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper develops a method that allows one to train summarization models on very long sequences in an incremental manner and devise and test strategies to pass semantic context across the blocks.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 3c01b59cd923192913bb96849a892c5732c40d3d\nTitle: CMU\u2019s IWSLT 2023 Simultaneous Speech Translation System\nYear: 2023\nAbstract: This paper describes CMU\u2019s submission to the IWSLT 2023 simultaneous speech translation shared task for translating English speech to both German text and speech in a streaming fashion. We first build offline speech-to-text (ST) models using the joint CTC/attention framework. These models also use WavLM front-end features and mBART decoder initialization. We adapt our offline ST models for simultaneous speech-to-text translation (SST) by 1) incrementally encoding chunks of input speech, re-computing encoder states for each new chunk and 2) incrementally decoding output text, pruning beam search hypotheses to 1-best after processing each chunk. We then build text-to-speech (TTS) models using the VITS framework and achieve simultaneous speech-to-speech translation (SS2ST) by cascading our SST and TTS models.",
  "We then build text-to-speech (TTS) models using the VITS framework and achieve simultaneous speech-to-speech translation (SS2ST) by cascading our SST and TTS models.\nAuthors: Brian Yan, Jiatong Shi, Soumi Maiti, William Chen, Xinjian Li, Yifan Peng, Siddhant Arora, Shinji Watanabe\nVenue: International Workshop on Spoken Language Translation\nTldr: {'model': 'tldr@v2.0.0', 'text': 'CMU\u2019s submission to the IWSLT 2023 simultaneous speech translation shared task for translating English speech to both German text and speech in a streaming fashion is described.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 3fb0c9a82c0d9c01448b37600efefb780e5362fe\nTitle: Crystalline electric field and magnetic anisotropy in Dy-based icosahedral quasicrystal and approximant\nYear: 2023\nAbstract: The lack of the theory of the crystalline electric field (CEF) in rare-earth based quasicrystal (QC) and approximant crystal (AC) has prevented us from understanding the electronic states. Recent success of the formulation of the CEF theory on the basis of the point charge model has made it possible to analyze the CEF microscopically. Here, by applying this formulation to the QC Au-SM-Dy (SM=Si, Ge, Al, and Ga) and AC, we theoretically analyze the CEF. In the Dy$^{3+}$ ion with $4f^9$ configuration, the CEF Hamiltonian is diagonalized by the basis set for the total angular momentum $J=15/2$.",
  "In the Dy$^{3+}$ ion with $4f^9$ configuration, the CEF Hamiltonian is diagonalized by the basis set for the total angular momentum $J=15/2$. The ratio of the valences of the screened ligand ions $\\alpha=Z_{\\rm SM}/Z_{\\rm Au}$ plays an important role in characterizing the CEF ground state. For $0\\le\\alpha<0.30$, the magnetic easy axis for the CEF ground state is shown to be perpendicular to the mirror plane. On the other hand, for $\\alpha>0.30$, the magnetic easy axis is shown to be lying in the mirror plane and as $\\alpha$ increases, the easy axis rotates to the clockwise direction in the mirror plane at the Dy site and tends to approach the pseudo 5 fold axis. Possible relevance of these results to experiments is discussed.\nAuthors: S. Watanabe, T. Iwasaki\nVenue: Physical review B\nTldr: None",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 47ba7df38e24da9bad9266d2b58abbb2b70db6e5\nTitle: Exploration of Efficient End-to-End ASR using Discretized Input from Self-Supervised Learning\nYear: 2023\nAbstract: Self-supervised learning (SSL) of speech has shown impressive results in speech-related tasks, particularly in automatic speech recognition (ASR). While most methods employ the output of intermediate layers of the SSL model as real-valued features for downstream tasks, there is potential in exploring alternative approaches that use discretized token sequences. This approach offers benefits such as lower storage requirements and the ability to apply techniques from natural language processing. In this paper, we propose a new protocol that utilizes discretized token sequences in ASR tasks, which includes de-duplication and sub-word modeling to enhance the input sequence. It reduces computational cost by decreasing the length of the sequence. Our experiments on the LibriSpeech dataset demonstrate that our proposed protocol performs competitively with conventional ASR systems using continuous input features, while reducing computational and storage costs.",
  "It reduces computational cost by decreasing the length of the sequence. Our experiments on the LibriSpeech dataset demonstrate that our proposed protocol performs competitively with conventional ASR systems using continuous input features, while reducing computational and storage costs.\nAuthors: Xuankai Chang, Brian Yan, Yuya Fujita, Takashi Maekaku, Shinji Watanabe\nVenue: Interspeech\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper proposes a new protocol that utilizes discretized token sequences in ASR tasks, which includes de-duplication and sub-word modeling to enhance the input sequence and reduces computational cost by decreasing the length of the sequence.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 48c6318dbcf9908cabe0023b8817566f34d0b466\nTitle: I3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition\nYear: 2023\nAbstract: Transformer-based end-to-end speech recognition has achieved great success. However, the large footprint and computational overhead make it difficult to deploy these models in some real-world applications. Model compression techniques can reduce the model size and speed up inference, but the compressed model has a fixed architecture which might be suboptimal. We propose a novel Transformer encoder with Input-Dependent Dynamic Depth (I3D) to achieve strong performance-efficiency trade-offs. With a similar number of layers at inference time, I3D-based models outperform the vanilla Transformer and the static pruned model via iterative layer pruning. We also present interesting analysis on the gate probabilities and the input-dependency, which helps us better understand deep encoders.",
  "With a similar number of layers at inference time, I3D-based models outperform the vanilla Transformer and the static pruned model via iterative layer pruning. We also present interesting analysis on the gate probabilities and the input-dependency, which helps us better understand deep encoders.\nAuthors: Yifan Peng, Jaesong Lee, Shinji Watanabe\nVenue: IEEE International Conference on Acoustics, Speech, and Signal Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A novel Transformer encoder with Input-Dependent Dynamic Depth (I3D) to achieve strong performance-efficiency trade-offs and interesting analysis on the gate probabilities and the input-dependency, which helps to better understand deep encoders.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 4b8d3ede673ddeab9dfb5184da6b748d7a526754\nTitle: A Vector Quantized Approach for Text to Speech Synthesis on Real-World Spontaneous Speech\nYear: 2023\nAbstract: Recent Text-to-Speech (TTS) systems trained on reading or acted corpora have achieved near human-level naturalness. The diversity of human speech, however, often goes beyond the coverage of these corpora. We believe the ability to handle such diversity is crucial for AI systems to achieve human-level communication. Our work explores the use of more abundant real-world data for building speech synthesizers. We train TTS systems using real-world speech from YouTube and podcasts. We observe the mismatch between training and inference alignments in mel-spectrogram based autoregressive models, leading to unintelligible synthesis, and demonstrate that learned discrete codes within multiple code groups effectively resolves this issue. We introduce our MQTTS system whose architecture is designed for multiple code generation and monotonic alignment, along with the use of a clean silence prompt to improve synthesis quality.",
  "We introduce our MQTTS system whose architecture is designed for multiple code generation and monotonic alignment, along with the use of a clean silence prompt to improve synthesis quality. We conduct ablation analyses to identify the efficacy of our methods. We show that MQTTS outperforms existing TTS systems in several objective and subjective measures.\nAuthors: Li-Wei Chen, Shinji Watanabe, Alexander I. Rudnicky\nVenue: AAAI Conference on Artificial Intelligence\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work introduces the MQTTS system, a Text-to-Speech system whose architecture is designed for multiple code generation and monotonic alignment, along with the use of a clean silence prompt to improve synthesis quality, and shows that MqTTS outperforms existing TTS systems in several objective and subjective measures.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 4c6bb748e22e2e599faf8fd30821ee03053579b7\nTitle: A Randomized, Double-Blind, Controlled Trial Assessing If Medium-Chain Triglycerides in Combination with Moderate-Intensity Exercise Increase Muscle Strength in Healthy Middle-Aged and Older Adults\nYear: 2023\nAbstract: An adequate nutritional intake is recommended for the prevention of physical frailty and sarcopenia. In particular, medium-chain fatty acids (MCFAs) are reportedly important for muscle strength in nursing home residents. However, the effects of MCFAs on healthy adults at risk for frailty remain unknown. Hence, a randomized, placebo-controlled study was conducted to investigate the effects of 12 weeks of medium-chain triglycerides (MCTs) intake and walking on muscle mass and function in healthy, sedentary, middle-aged and older adults with a low body mass index. Three MCT intake groups with different amounts of octanoic and decanoic acid intake were compared with a control group.",
  "Three MCT intake groups with different amounts of octanoic and decanoic acid intake were compared with a control group. After 12 weeks, knee extension strength increased in all groups, with the increases in all MCT intake groups being significantly higher than those in the control group (p < 0.05). Grip strength significantly increased from baseline in the MCT 6 g/day intake group (p < 0.05). The combination of aerobic exercise and MCT intake may be effective in preventing decline in muscle strength and promoting increase in muscle strength as they can improve muscle energy production, thereby contributing to the maintenance of good health for middle-aged and older adults at high risk for frailty and sarcopenia.",
  "The combination of aerobic exercise and MCT intake may be effective in preventing decline in muscle strength and promoting increase in muscle strength as they can improve muscle energy production, thereby contributing to the maintenance of good health for middle-aged and older adults at high risk for frailty and sarcopenia.\nAuthors: K. Kojima, Haruna Ishikawa, Shinji Watanabe, N. Nosaka, Tatsushi Mutoh\nVenue: Nutrients\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The combination of aerobic exercise and MCT intake may be effective in preventing decline in muscle strength and promoting increase in Muscle strength as they can improve muscle energy production, thereby contributing to the maintenance of good health for middle-aged and older adults at high risk for frailty and sarcopenia.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 4d35540aaf993c8fa7e1fa5fc6a990f1eb830263\nTitle: A New Benchmark of Aphasia Speech Recognition and Detection Based on E-Branchformer and Multi-task Learning\nYear: 2023\nAbstract: Aphasia is a language disorder that affects the speaking ability of millions of patients. This paper presents a new benchmark for Aphasia speech recognition and detection tasks using state-of-the-art speech recognition techniques with the AphsiaBank dataset. Specifically, we introduce two multi-task learning methods based on the CTC/Attention architecture to perform both tasks simultaneously. Our system achieves state-of-the-art speaker-level detection accuracy (97.3%), and a relative WER reduction of 11% for moderate Aphasia patients. In addition, we demonstrate the generalizability of our approach by applying it to another disordered speech database, the DementiaBank Pitt corpus. We will make our all-in-one recipes and pre-trained model publicly available to facilitate reproducibility. Our standardized data preprocessing pipeline and open-source recipes enable researchers to compare results directly, promoting progress in disordered speech processing.",
  "We will make our all-in-one recipes and pre-trained model publicly available to facilitate reproducibility. Our standardized data preprocessing pipeline and open-source recipes enable researchers to compare results directly, promoting progress in disordered speech processing.\nAuthors: Jiyang Tang, William Chen, Xuankai Chang, Shinji Watanabe, B. MacWhinney\nVenue: Interspeech\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A new benchmark for Aphasia speech recognition and detection tasks using state-of-the-art speech recognition techniques with the AphsiaBank dataset is presented and two multi-task learning methods based on the CTC/Attention architecture are introduced to perform both tasks simultaneously.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 52d2c8d36c4ace01d8c440a44e1a7fdea04ec482\nTitle: Antiviral Susceptibilities of Distinct Lineages of Influenza C and D Viruses\nYear: 2023\nAbstract: The emergence and spread of antiviral-resistant influenza viruses are of great concern. To minimize the public health risk, it is important to monitor antiviral susceptibilities of influenza viruses. Analyses of the antiviral susceptibilities of influenza A and B viruses have been conducted globally; however, those of influenza C and D viruses are limited. Here, we determined the susceptibilities of influenza C viruses representing all six lineages (C/Taylor, C/Yamagata, C/Sao Paulo, C/Aichi, C/Kanagawa, and C/Mississippi) and influenza D viruses representing four lineages (D/OK, D/660, D/Yama2016, and D/Yama2019) to RNA polymerase inhibitors (baloxavir and favipiravir) by using a focus reduction assay.",
  "All viruses tested were susceptible to both drugs. We then performed a genetic analysis to check for amino acid substitutions associated with baloxavir and favipiravir resistance and found that none of the viruses tested possessed these substitutions. Use of the focus reduction assay with the genotypic assay has proven valuable for monitoring the antiviral susceptibilities of influenza C and D viruses as well as influenza A and B viruses. Antiviral susceptibility monitoring of all influenza virus types should continue in order to assess the public health risks posed by these viruses.\nAuthors: E. Takashita, S. Murakami, Y. Matsuzaki, Seiichiro Fujisaki, H. Morita, Shiho Nagata, Misa Katayama, K. Mizuta, H. Nishimura, Shinji Watanabe, T. Horimoto, H. Hasegawa\nVenue: Viruses\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Use of the focus reduction assay with the genotypic assay has proven valuable for monitoring the antiviral susceptibilities of influenza C and D viruses as well as influenza A and B viruses.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 611f9ee6eef0936462cd78f371798d0699951c59\nTitle: Paaploss: A Phonetic-Aligned Acoustic Parameter Loss for Speech Enhancement\nYear: 2023\nAbstract: Despite rapid advancement in recent years, current speech enhancement models often produce speech that differs in perceptual quality from real clean speech. We propose a learning objective that formalizes differences in perceptual quality, by using domain knowledge of acoustic-phonetics. We identify temporal acoustic parameters \u2013 such as spectral tilt, spectral flux, shimmer, etc. \u2013 that are non-differentiable, and we develop a neural network estimator that can accurately predict their time-series values across an utterance. We also model phoneme-specific weights for each feature, as the acoustic parameters are known to show different behavior in different phonemes. We can add this criterion as an auxiliary loss to any model that produces speech, to optimize speech outputs to match the values of clean speech in these features. Experimentally we show that it improves speech enhancement workflows in both time-domain and time-frequency domain, as measured by standard evaluation metrics.",
  "We can add this criterion as an auxiliary loss to any model that produces speech, to optimize speech outputs to match the values of clean speech in these features. Experimentally we show that it improves speech enhancement workflows in both time-domain and time-frequency domain, as measured by standard evaluation metrics. We also provide an analysis of phoneme-dependent improvement on acoustic parameters, demonstrating the additional interpretability that our method provides. This analysis can suggest which features are currently the bottleneck for improvement.\nAuthors: Muqiao Yang, Joseph Konan, David Bick, YUNYANG ZENG, Shuo Han, Anurag Kumar, Shinji Watanabe, B. Raj\nVenue: IEEE International Conference on Acoustics, Speech, and Signal Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A learning objective is proposed that formalizes differences in perceptual quality, by using domain knowledge of acoustic-phonetics, and a neural network estimator is developed that can accurately predict their time-series values across an utterance.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 659be1ff350634f50cc066d258ee6a45e697e552\nTitle: SigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing\nYear: 2023\nAbstract: In our submission to the SIGMORPHON 2023 Shared Task on interlinear glossing (IGT), we explore approaches to data augmentation and modeling across seven low-resource languages. For data augmentation, we explore two approaches: creating artificial data from the provided training data and utilizing existing IGT resources in other languages. On the modeling side, we test an enhanced version of the provided token classification baseline as well as a pretrained multilingual seq2seq model. Additionally, we apply post-correction using a dictionary for Gitksan, the language with the smallest amount of data. We find that our token classification models are the best performing, with the highest word-level accuracy for Arapaho and highest morpheme-level accuracy for Gitksan out of all submissions. We also show that data augmentation is an effective strategy, though applying artificial data pretraining has very different effects across both models tested.",
  "We find that our token classification models are the best performing, with the highest word-level accuracy for Arapaho and highest morpheme-level accuracy for Gitksan out of all submissions. We also show that data augmentation is an effective strategy, though applying artificial data pretraining has very different effects across both models tested.\nAuthors: Taiqi He, Lindia Tjuatja, Nathaniel R. Robinson, Shinji Watanabe, David R. Mortensen, Graham Neubig, L. Levin\nVenue: Special Interest Group on Computational Morphology and Phonology Workshop\nTldr: {'model': 'tldr@v2.0.0', 'text': 'In this submission to the SIGMORPHON 2023 Shared Task on interlinear glossing (IGT), approaches to data augmentation and modeling across seven low-resource languages are explored and token classification models are found to be the best performing.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 6c2b800cd03ad064922c8596a18d784ce25d47ac\nTitle: Integration of Frame- and Label-synchronous Beam Search for Streaming Encoder-decoder Speech Recognition\nYear: 2023\nAbstract: Although frame-based models, such as CTC and transducers, have an affinity for streaming automatic speech recognition, their decoding uses no future knowledge, which could lead to incorrect pruning. Conversely, label-based attention encoder-decoder mitigates this issue using soft attention to the input, while it tends to overestimate labels biased towards its training domain, unlike CTC. We exploit these complementary attributes and propose to integrate the frame- and label-synchronous (F-/L-Sync) decoding alternately performed within a single beam-search scheme. F-Sync decoding leads the decoding for block-wise processing, while L-Sync decoding provides the prioritized hypotheses using look-ahead future frames within a block. We maintain the hypotheses from both decoding methods to perform effective pruning. Experiments demonstrate that the proposed search algorithm achieves lower error rates compared to the other search methods, while being robust against out-of-domain situations.",
  "We maintain the hypotheses from both decoding methods to perform effective pruning. Experiments demonstrate that the proposed search algorithm achieves lower error rates compared to the other search methods, while being robust against out-of-domain situations.\nAuthors: E. Tsunoo, Hayato Futami, Yosuke Kashiwagi, Siddhant Arora, Shinji Watanabe\nVenue: Interspeech\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes to integrate the frame- and label-synchronous (F-/L-Sync) decoding alternately performed within a single beam-search scheme and maintains the hypotheses from both decoding methods to perform effective pruning.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 6c33625c7b0ffc37955921a145531d9d4eaee713\nTitle: Exploring the Integration of Speech Separation and Recognition with Self-Supervised Learning Representation\nYear: 2023\nAbstract: Neural speech separation has made remarkable progress and its integration with automatic speech recognition (ASR) is an important direction towards realizing multi-speaker ASR. This work provides an insightful investigation of speech separation in reverberant and noisy-reverberant scenarios as an ASR front-end. In detail, we explore multi-channel separation methods, mask-based beamforming and complex spectral mapping, as well as the best features to use in the ASR back-end model. We employ the recent self-supervised learning representation (SSLR) as a feature and improve the recognition performance from the case with filterbank features. To further improve multi-speaker recognition performance, we present a carefully designed training strategy for integrating speech separation and recognition with SSLR. The proposed integration using TF-GridNet-based complex spectral mapping and WavLM-based SSLR achieves a 2.5% word error rate in reverberant WHAMR!",
  "The proposed integration using TF-GridNet-based complex spectral mapping and WavLM-based SSLR achieves a 2.5% word error rate in reverberant WHAMR! test set, significantly outperforming an existing mask-based MVDR beamforming and filterbank integration (28.9%).\nAuthors: Yoshiki Masuyama, Xuankai Chang, Wangyou Zhang, Samuele Cornell, Zhongqiu Wang, Nobutaka Ono, Y. Qian, Shinji Watanabe\nVenue: IEEE Workshop on Applications of Signal Processing to Audio and Acoustics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work provides an insightful investigation of speech separation in reverberant and noisy-reverberant scenarios as an ASR front-end, and employs the recent self-supervised learning representation (SSLR) as a feature and improves the recognition performance from the case with filterbank features.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 725cdb03a3d443c1698f6b98966cc78eaa53809b\nTitle: Software Design and User Interface of ESPnet-SE++: Speech Enhancement for Robust Speech Processing\nYear: 2023\nAbstract: None\nAuthors: Yen-Ju Lu, Xuankai Chang, Chenda Li, Wangyou Zhang, Samuele Cornell, Zhaoheng Ni, Yoshiki Masuyama, Brian Yan, Robin Scheibler, Zhong-Qiu Wang, Yu Tsao, Yanmin Qian, Shinji Watanabe\nVenue: Journal of Open Source Software\nTldr: None",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 786294f4008732a5dac9895a8507bc4c80450075\nTitle: Dynamic-SUPERB: Towards A Dynamic, Collaborative, and Comprehensive Instruction-Tuning Benchmark for Speech\nYear: 2023\nAbstract: Text language models have shown remarkable zero-shot capability in generalizing to unseen tasks when provided with well-formulated instructions. However, existing studies in speech processing primarily focus on limited or specific tasks. Moreover, the lack of standardized benchmarks hinders a fair comparison across different approaches. Thus, we present Dynamic-SUPERB, a benchmark designed for building universal speech models capable of leveraging instruction tuning to perform multiple tasks in a zero-shot fashion. To achieve comprehensive coverage of diverse speech tasks and harness instruction tuning, we invite the community to collaborate and contribute, facilitating the dynamic growth of the benchmark. To initiate, Dynamic-SUPERB features 55 evaluation instances by combining 33 tasks and 22 datasets. This spans a broad spectrum of dimensions, providing a comprehensive platform for evaluation. Additionally, we propose several approaches to establish benchmark baselines.",
  "To initiate, Dynamic-SUPERB features 55 evaluation instances by combining 33 tasks and 22 datasets. This spans a broad spectrum of dimensions, providing a comprehensive platform for evaluation. Additionally, we propose several approaches to establish benchmark baselines. These include the utilization of speech models, text language models, and the multimodal encoder. Evaluation results indicate that while these baselines perform reasonably on seen tasks, they struggle with unseen ones. We also conducted an ablation study to assess the robustness and seek improvements in the performance. We release all materials to the public and welcome researchers to collaborate on the project, advancing technologies in the field together.",
  "Evaluation results indicate that while these baselines perform reasonably on seen tasks, they struggle with unseen ones. We also conducted an ablation study to assess the robustness and seek improvements in the performance. We release all materials to the public and welcome researchers to collaborate on the project, advancing technologies in the field together.\nAuthors: Chien-yu Huang, Ke-Han Lu, Shi Wang, Chi-Yuan Hsiao, Chun-Yi Kuan, Haibin Wu, Siddhant Arora, Kai-Wei Chang, Jiatong Shi, Yifan Peng, Roshan Sharma, Shinji Watanabe, Bhiksha Ramakrishnan, Shady Shehata, Hung-yi Lee\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work presents Dynamic-SUPERB, a benchmark designed for building universal speech models capable of leveraging instruction tuning to perform multiple tasks in a zero-shot fashion, and invites the community to collaborate and contribute, facilitating the dynamic growth of the benchmark.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 7d4ad68dedff8c81e0fd9c08ea76b220a7e05d69\nTitle: Speaker-Independent Acoustic-to-Articulatory Speech Inversion\nYear: 2023\nAbstract: To build speech processing methods that can handle speech as naturally as humans, researchers have explored multiple ways of building an invertible mapping from speech to an interpretable space. The articulatory space is a promising inversion target, since this space captures the mechanics of speech production. To this end, we build an acoustic-to-articulatory inversion (AAI) model that leverages autoregression, adversarial training, and self supervision to generalize to unseen speakers. Our approach obtains 0.784 correlation on an electromagnetic articulography (EMA) dataset, improving the state-of-the-art by 12.5%. Additionally, we show the interpretability of these representations through directly com-paring the behavior of estimated representations with speech production behavior. Finally, we propose a resynthesis-based AAI evaluation metric that does not rely on articulatory labels, demonstrating its efficacy with an 18-speaker dataset.",
  "Additionally, we show the interpretability of these representations through directly com-paring the behavior of estimated representations with speech production behavior. Finally, we propose a resynthesis-based AAI evaluation metric that does not rely on articulatory labels, demonstrating its efficacy with an 18-speaker dataset.\nAuthors: Peter Wu, Li-Wei Chen, Cheol Jun Cho, Shinji Watanabe, L. Goldstein, A. Black, G. Anumanchipalli\nVenue: IEEE International Conference on Acoustics, Speech, and Signal Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work builds an acoustic-to-articulatory inversion (AAI) model that leverages autoregression, adversarial training, and self supervision to generalize to unseen speakers, and proposes a resynthesis-based AAI evaluation metric that does not rely on articulatory labels.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 7f995454efda9f660d2258f59f6e19a2125e688e\nTitle: Towards Practical and Efficient Image-to-Speech Captioning with Vision-Language Pre-training and Multi-modal Tokens\nYear: 2023\nAbstract: In this paper, we propose methods to build a powerful and efficient Image-to-Speech captioning (Im2Sp) model. To this end, we start with importing the rich knowledge related to image comprehension and language modeling from a large-scale pre-trained vision-language model into Im2Sp. We set the output of the proposed Im2Sp as discretized speech units, i.e., the quantized speech features of a self-supervised speech model. The speech units mainly contain linguistic information while suppressing other characteristics of speech. This allows us to incorporate the language modeling capability of the pre-trained vision-language model into the spoken language modeling of Im2Sp. With the vision-language pre-training strategy, we set new state-of-the-art Im2Sp performances on two widely used benchmark databases, COCO and Flickr8k. Then, we further improve the efficiency of the Im2Sp model.",
  "With the vision-language pre-training strategy, we set new state-of-the-art Im2Sp performances on two widely used benchmark databases, COCO and Flickr8k. Then, we further improve the efficiency of the Im2Sp model. Similar to the speech unit case, we convert the original image into image units, which are derived through vector quantization of the raw image. With these image units, we can drastically reduce the required data storage for saving image data to just 0.8% when compared to the original image data in terms of bits. Demo page: https://ms-dot-k.github.io/Image-to-Speech-Captioning.\nAuthors: Minsu Kim, J. Choi, Soumi Maiti, Jeong Hun Yeo, Shinji Watanabe, Y. Ro\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper starts with importing the rich knowledge related to image comprehension and language modeling from a large-scale pre-trained vision-language model into Im2Sp, and sets the output of the proposed Im2 Sp as discretized speech units, i.e., the quantized speech features of a self-supervised speech model.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 8402d64fde12cafaf8a1daa60de0acd1abedbffb\nTitle: Enhancing Speech-To-Speech Translation with Multiple TTS Targets\nYear: 2023\nAbstract: It has been known that direct speech-to-speech translation (S2ST) models usually suffer from the data scarcity issue because of the limited existing parallel materials for both source and target speech. Therefore to train a direct S2ST system, previous works usually utilize text-to-speech (TTS) systems to generate samples in the target language by augmenting the data from speech-to-text translation (S2TT). However, there is a limited investigation into how the synthesized target speech would affect the S2ST models. In this work, we analyze the effect of changing synthesized target speech for direct S2ST models. We find that simply combining the target speech from different TTS systems can potentially improve the S2ST performances. Following that, we also propose a multi-task framework that jointly optimizes the S2ST system with multiple targets from different TTS systems.",
  "We find that simply combining the target speech from different TTS systems can potentially improve the S2ST performances. Following that, we also propose a multi-task framework that jointly optimizes the S2ST system with multiple targets from different TTS systems. Extensive experiments demonstrate that our proposed framework achieves consistent improvements (2.8 BLEU) over the baselines on the Fisher Spanish-English dataset.\nAuthors: Jiatong Shi, Yun Tang, Ann Lee, H. Inaguma, Changhan Wang, J. Pino, Shinji Watanabe\nVenue: IEEE International Conference on Acoustics, Speech, and Signal Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is found that simply combining the target speech from different TTS systems can potentially improve the S2ST performances, and a multi-task framework is proposed that jointly optimizes the S1ST system with multiple targets from differentTTS systems.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 8bc617c9139648d7a92991d70c671230bac7b2e2\nTitle: AudioGPT: Understanding and Generating Speech, Music, Sound, and Talking Head\nYear: 2023\nAbstract: Large language models (LLMs) have exhibited remarkable capabilities across a variety of domains and tasks, challenging our understanding of learning and cognition. Despite the recent success, current LLMs are not capable of processing complex audio information or conducting spoken conversations (like Siri or Alexa). In this work, we propose a multi-modal AI system named AudioGPT, which complements LLMs (i.e., ChatGPT) with 1) foundation models to process complex audio information and solve numerous understanding and generation tasks; and 2) the input/output interface (ASR, TTS) to support spoken dialogue. With an increasing demand to evaluate multi-modal LLMs of human intention understanding and cooperation with foundation models, we outline the principles and processes and test AudioGPT in terms of consistency, capability, and robustness.",
  "With an increasing demand to evaluate multi-modal LLMs of human intention understanding and cooperation with foundation models, we outline the principles and processes and test AudioGPT in terms of consistency, capability, and robustness. Experimental results demonstrate the capabilities of AudioGPT in solving AI tasks with speech, music, sound, and talking head understanding and generation in multi-round dialogues, which empower humans to create rich and diverse audio content with unprecedented ease. Our system is publicly available at \\url{https://github.com/AIGC-Audio/AudioGPT}.",
  "Our system is publicly available at \\url{https://github.com/AIGC-Audio/AudioGPT}.\nAuthors: Rongjie Huang, Mingze Li, Dongchao Yang, Jiatong Shi, Xuankai Chang, Zhenhui Ye, Yuning Wu, Zhiqing Hong, Jia-Bin Huang, Jinglin Liu, Yixiang Ren, Zhou Zhao, Shinji Watanabe\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A multi-modal AI system named AudioGPT is proposed, which complements LLMs with 1) foundation models to process complex audio information and solve numerous understanding and generation tasks; and 2) the input/output interface (ASR, TTS) to support spoken dialogue.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 8f0a24d1678e4d0e584b0932196cd257d5c53c7d\nTitle: Improving Audio Captioning Models with Fine-grained Audio Features, Text Embedding Supervision, and LLM Mix-up Augmentation\nYear: 2023\nAbstract: Automated audio captioning (AAC) aims to generate informative descriptions for various sounds from nature and/or human activities. In recent years, AAC has quickly attracted research interest, with state-of-the-art systems now relying on a sequence-to-sequence (seq2seq) backbone powered by strong models such as Transformers. Following the macro-trend of applied machine learning research, in this work, we strive to improve the performance of seq2seq AAC models by extensively leveraging pretrained models and large language models (LLMs). Specifically, we utilize BEATs to extract fine-grained audio features. Then, we employ Instructor LLM to fetch text embeddings of captions, and infuse their language-modality knowledge into BEATs audio features via an auxiliary InfoNCE loss function.",
  "Specifically, we utilize BEATs to extract fine-grained audio features. Then, we employ Instructor LLM to fetch text embeddings of captions, and infuse their language-modality knowledge into BEATs audio features via an auxiliary InfoNCE loss function. Moreover, we propose a novel data augmentation method that uses ChatGPT to produce caption mix-ups (i.e., grammatical and compact combinations of two captions) which, together with the corresponding audio mixtures, increase not only the amount but also the complexity and diversity of training data. During inference, we propose to employ nucleus sampling and a hybrid reranking algorithm, which has not been explored in AAC research. Combining our efforts, our model achieves a new state-of-the-art 32.6 SPIDEr-FL score on the Clotho evaluation split, and wins the 2023 DCASE AAC challenge.",
  "Combining our efforts, our model achieves a new state-of-the-art 32.6 SPIDEr-FL score on the Clotho evaluation split, and wins the 2023 DCASE AAC challenge.\nAuthors: Shih-Lun Wu, Xuankai Chang, G. Wichern, Jee-weon Jung, Franccois G. Germain, Jonathan Le Roux, Shinji Watanabe\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work utilizes BEATs to extract fine-grained audio features and proposes a novel data augmentation method that uses ChatGPT to produce caption mix-ups which increase not only the amount but also the complexity and diversity of training data.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 91a06713cbccbfb1b5e1b9f7b62a1fba348616c3\nTitle: Voxtlm: unified decoder-only models for consolidating speech recognition/synthesis and speech/text continuation tasks\nYear: 2023\nAbstract: We propose a decoder-only language model, VoxtLM, that can perform four tasks: speech recognition, speech synthesis, text generation, and speech continuation. VoxtLM integrates text vocabulary with discrete speech tokens from self-supervised speech features and uses special tokens to enable multitask learning. Compared to a single-task model, VoxtLM exhibits a significant improvement in speech synthesis, with improvements in both speech intelligibility from 28.9 to 5.6 and objective quality from 2.68 to 3.90. VoxtLM also improves speech generation and speech recognition performance over the single-task counterpart. Further, VoxtLM is trained with publicly available data and training recipes and model checkpoints are open-sourced to make fully reproducible work.",
  "VoxtLM also improves speech generation and speech recognition performance over the single-task counterpart. Further, VoxtLM is trained with publicly available data and training recipes and model checkpoints are open-sourced to make fully reproducible work.\nAuthors: Soumi Maiti, Yifan Peng, Shukjae Choi, Jee-weon Jung, Xuankai Chang, Shinji Watanabe\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A decoder-only language model that can perform four tasks: speech recognition, speech synthesis, text generation, and speech continuation, VoxtLM is proposed, which exhibits a significant improvement in speech synthesis and improves speech intelligibility and objective quality.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 92b3753e56f5d85fd57a32084f52476839cc7221\nTitle: One model to rule them all ? Towards End-to-End Joint Speaker Diarization and Speech Recognition\nYear: 2023\nAbstract: This paper presents a novel framework for joint speaker diarization (SD) and automatic speech recognition (ASR), named SLIDAR (sliding-window diarization-augmented recognition). SLIDAR can process arbitrary length inputs and can handle any number of speakers, effectively solving ``who spoke what, when'' concurrently. SLIDAR leverages a sliding window approach and consists of an end-to-end diarization-augmented speech transcription (E2E DAST) model which provides, locally, for each window: transcripts, diarization and speaker embeddings. The E2E DAST model is based on an encoder-decoder architecture and leverages recent techniques such as serialized output training and ``Whisper-style\"prompting. The local outputs are then combined to get the final SD+ASR result by clustering the speaker embeddings to get global speaker identities.",
  "The E2E DAST model is based on an encoder-decoder architecture and leverages recent techniques such as serialized output training and ``Whisper-style\"prompting. The local outputs are then combined to get the final SD+ASR result by clustering the speaker embeddings to get global speaker identities. Experiments performed on monaural recordings from the AMI corpus confirm the effectiveness of the method in both close-talk and far-field speech scenarios.\nAuthors: Samuele Cornell, Jee-weon Jung, Shinji Watanabe, S. Squartini\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': \"SLIDAR (sliding-window diarization-augmented recognition) can process arbitrary length inputs and can handle any number of speakers, effectively solving ``who spoke what, when'' concurrently.\"}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 95aac8fe824bd0c83de594af0bf9d259e2416f53\nTitle: Learning to Speak from Text: Zero-Shot Multilingual Text-to-Speech with Unsupervised Text Pretraining\nYear: 2023\nAbstract: While neural text-to-speech (TTS) has achieved human-like natural synthetic speech, multilingual TTS systems are limited to resource-rich languages due to the need for paired text and studio-quality audio data. This paper proposes a method for zero-shot multilingual TTS using text-only data for the target language. The use of text-only data allows the development of TTS systems for low-resource languages for which only textual resources are available, making TTS accessible to thousands of languages. Inspired by the strong cross-lingual transferability of multilingual language models, our framework first performs masked language model pretraining with multilingual text-only data. Then we train this model with a paired data in a supervised manner, while freezing a language-aware embedding layer. This allows inference even for languages not included in the paired data but present in the text-only data.",
  "Then we train this model with a paired data in a supervised manner, while freezing a language-aware embedding layer. This allows inference even for languages not included in the paired data but present in the text-only data. Evaluation results demonstrate highly intelligible zero-shot TTS with a character error rate of less than 12% for an unseen language.\nAuthors: Takaaki Saeki, Soumi Maiti, Xinjian Li, Shinji Watanabe, Shinnosuke Takamichi, H. Saruwatari\nVenue: International Joint Conference on Artificial Intelligence\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Inspired by the strong cross-lingual transferability of multilingual language models, this framework first performs masked language model pretraining with multilingual text-only data, and trains this model with a paired data in a supervised manner, while freezing a language-aware embedding layer.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 9733b69b98142d2383f72ed1ebc3bd1d54138234\nTitle: Assessment of the frequency of SARS-CoV-2 Omicron variant escape from RNA-dependent RNA polymerase inhibitors and 3C-like protease inhibitors.\nYear: 2023\nAbstract: None\nAuthors: E. Takashita, Seiichiro Fujisaki, H. Morita, Shiho Nagata, H. Miura, M. Nagashima, Shinji Watanabe, M. Takeda, Y. Kawaoka, H. Hasegawa\nVenue: Antiviral Research\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The findings suggest that the frequency of SARS-CoV-2 mutant escape from RdRP inhibitors is lower than that from 3CLpro inhibitors, and that Delta variants were more likely to acquire amino acid substitutions associated with resistance to 3CL Pro inhibitors under the selective pressure of this drug compared with Omicron variants.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 9cbd933c04218c9b642c15a49f8470d54524d9fb\nTitle: FNeural Speech Enhancement with Very Low Algorithmic Latency and Complexity via Integrated full- and sub-band Modeling\nYear: 2023\nAbstract: We propose FSB-LSTM, a novel long short-term memory (LSTM) based architecture that integrates full- and sub-band (FSB) modeling, for single- and multi-channel speech enhancement in the short-time Fourier transform (STFT) domain. The model maintains an information highway to flow an over-complete input representation through multiple FSB-LSTM modules. Each FSB-LSTM module consists of a full-band block to model spectro-temporal patterns at all frequencies and a sub-band block to model patterns within each sub-band, where each of the two blocks takes a down-sampled representation as input and returns an up-sampled discriminative representation to be added to the block input via a residual connection.",
  "The model is designed to have a low algorithmic complexity, a small run-time buffer and a very low algorithmic latency, at the same time producing a strong enhancement performance on a noisy-reverberant speech enhancement task even if the hop size is as low as 2 ms.\nAuthors: Zhongqiu Wang, Samuele Cornell, Shukjae Choi, Younglo Lee, Byeonghak Kim, Shinji Watanabe\nVenue: IEEE International Conference on Acoustics, Speech, and Signal Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The proposed FSB-LSTM model is designed to have a low algorithmic complexity, a small run-time buffer and a very lowgorithmic latency, at the same time producing a strong enhancement performance on a noisy-reverberant speech enhancement task even if the hop size is as low as 2 ms.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: 9dcfb422f6057725b1585caf820e128c91d6dbb3\nTitle: Improving Massively Multilingual ASR with Auxiliary CTC Objectives\nYear: 2023\nAbstract: Multilingual Automatic Speech Recognition (ASR) models have extended the usability of speech technologies to a wide variety of languages. With how many languages these models have to handle, however, a key to understanding their imbalanced performance across different languages is to examine if the model actually knows which language it should transcribe. In this paper, we introduce our work on improving performance on FLEURS, a 102-language open ASR benchmark, by conditioning the entire model on language identity (LID). We investigate techniques inspired from recent Connectionist Temporal Classification (CTC) studies to help the model handle the large number of languages, conditioning on the LID predictions of auxiliary tasks. Our experimental results demonstrate the effectiveness of our technique over standard CTC/Attention-based hybrid models.",
  "We investigate techniques inspired from recent Connectionist Temporal Classification (CTC) studies to help the model handle the large number of languages, conditioning on the LID predictions of auxiliary tasks. Our experimental results demonstrate the effectiveness of our technique over standard CTC/Attention-based hybrid models. Furthermore, our state-of-the-art systems using self-supervised models with the Conformer architecture improve over the results of prior work on FLEURS by a relative 28.4% CER. Trained models are reproducible recipes are available at https://github.com/espnet/espnet/tree/master/egs2/fleurs/asr1.",
  "Trained models are reproducible recipes are available at https://github.com/espnet/espnet/tree/master/egs2/fleurs/asr1.\nAuthors: William Chen, Brian Yan, Jiatong Shi, Yifan Peng, Soumi Maiti, Shinji Watanabe\nVenue: IEEE International Conference on Acoustics, Speech, and Signal Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work introduces work on improving performance on FLEURS, a 102-language open ASR benchmark, by conditioning the entire model on language identity (LID), and investigates techniques inspired from recent Connectionist Temporal Classification studies to help the model handle the large number of languages.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: a2a5830e49b94349f4ff7d672fa6693888e54b82\nTitle: Magnetism and topological property in icosahedral quasicrystal\nYear: 2023\nAbstract: Quasicrystal (QC) has no periodicity but has a unique rotational symmetry forbidden in periodic crystals. Lack of microscopic theory of the crystalline electric field (CEF) in the QC and approximant crystal (AC) has prevented us from understanding the electric property, especially the magnetism. By developing the general formulation of the CEF in the rare-earth based QC and AC, we have analyzed the CEF in the QC Au-SM-Tb and AC (SM=Si, Ge, and Ga). The magnetic anisotropy arising from the CEF plays an important role in realizing unique magnetic states on the icosahedron (IC). By constructing the minimal model with the magnetic anisotropy, we have analyzed the ground-state properties of the IC, 1/1 AC, and QC.",
  "By constructing the minimal model with the magnetic anisotropy, we have analyzed the ground-state properties of the IC, 1/1 AC, and QC. The hedgehog state is characterized by the topological charge of one and the whirling-moment state is characterized by the topological charge of three. The uniform arrangement of the ferrimagnetic state is stabilized in the QC with the ferromagnetic (FM) interaction, which is a candidate for the magnetic structure recently observed FM long-range order in the QC Au-Ga-Tb. The uniform arrangement of the hedgehog state is stabilized in the QC with the antiferromagnetic interaction, which suggests the possibility of the topological magnetic long-range order.\nAuthors: S. Watanabe\nVenue: Journal of Physics: Conference Series\nTldr: None",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: a5ab124e57d1f26436821588aacd7d75b831259c\nTitle: Toward Universal Speech Enhancement For Diverse Input Conditions\nYear: 2023\nAbstract: The past decade has witnessed substantial growth of data-driven speech enhancement (SE) techniques thanks to deep learning. While existing approaches have shown impressive performance in some common datasets, most of them are designed only for a single condition (e.g., single-channel, multi-channel, or a fixed sampling frequency) or only consider a single task (e.g., denoising or dereverberation). Currently, there is no universal SE approach that can effectively handle diverse input conditions with a single model. In this paper, we make the first attempt to investigate this line of research. First, we devise a single SE model that is independent of microphone channels, signal lengths, and sampling frequencies. Second, we design a universal SE benchmark by combining existing public corpora with multiple conditions. Our experiments on a wide range of datasets show that the proposed single model can successfully handle diverse conditions with strong performance.",
  "Second, we design a universal SE benchmark by combining existing public corpora with multiple conditions. Our experiments on a wide range of datasets show that the proposed single model can successfully handle diverse conditions with strong performance.\nAuthors: Wangyou Zhang, Kohei Saijo, Zhong-Qiu Wang, Shinji Watanabe, Yanmin Qian\nVenue: Automatic Speech Recognition & Understanding\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper devise a single SE model that is independent of microphone channels, signal lengths, and sampling frequencies, and designs a universal SE benchmark by combining existing public corpora with multiple conditions.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: a60faa964c4dc744938c0b7812f7f3701a1250b8\nTitle: A Single Speech Enhancement Model Unifying Dereverberation, Denoising, Speaker Counting, Separation, And Extraction\nYear: 2023\nAbstract: We propose a multi-task universal speech enhancement (MUSE) model that can perform five speech enhancement (SE) tasks: dereverberation, denoising, speech separation (SS), target speaker extraction (TSE), and speaker counting. This is achieved by integrating two modules into an SE model: 1) an internal separation module that does both speaker counting and separation; and 2) a TSE module that extracts the target speech from the internal separation outputs using target speaker cues. The model is trained to perform TSE if the target speaker cue is given and SS otherwise. By training the model to remove noise and reverberation, we allow the model to tackle the five tasks mentioned above with a single model, which has not been accomplished yet. Evaluation results demonstrate that the proposed MUSE model can successfully handle multiple tasks with a single model.",
  "By training the model to remove noise and reverberation, we allow the model to tackle the five tasks mentioned above with a single model, which has not been accomplished yet. Evaluation results demonstrate that the proposed MUSE model can successfully handle multiple tasks with a single model.\nAuthors: Kohei Saijo, Wangyou Zhang, Zhong-Qiu Wang, Shinji Watanabe, Tetsunori Kobayashi, Tetsuji Ogawa\nVenue: Automatic Speech Recognition & Understanding\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Evaluation results demonstrate that the proposed MUSE model can successfully handle multiple tasks with a single model, which has not been accomplished yet.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: ab84b84b4a9641a172f9874108fee07a9f92f988\nTitle: E-Branchformer-Based E2E SLU Toward Stop on-Device Challenge\nYear: 2023\nAbstract: In this paper, we report our team\u2019s study on track 2 of the Spoken Language Understanding Grand Challenge, which is a component of the ICASSP Signal Processing Grand Challenge 2023. The task is intended for on-device processing and involves estimating semantic parse labels from speech using a model with 15 million parameters. We use E2E E-Branchformer-based spoken language understanding model, which is more parameter controllable than cascade models, and reduced the parameter size through sequential distillation and tensor decomposition techniques. On the STOP dataset, we achieved an exact match accuracy of 70.9% under the tight constraint of 15 million parameters.",
  "On the STOP dataset, we achieved an exact match accuracy of 70.9% under the tight constraint of 15 million parameters.\nAuthors: Yosuke Kashiwagi, Siddhant Arora, Hayato Futami, Jessica Huynh, Shih-Lun Wu, Yifan Peng, Brian Yan, E. Tsunoo, Shinji Watanabe\nVenue: IEEE International Conference on Acoustics, Speech, and Signal Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'E2E E-Branchformer-based spoken language understanding model is used, which is more parameter controllable than cascade models, and the parameter size is reduced through sequential distillation and tensor decomposition techniques.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: b4855ff933fb80846638469a1b43c1766df85d78\nTitle: The Pipeline System of ASR and NLU with MLM-based data Augmentation Toward Stop Low-Resource Challenge\nYear: 2023\nAbstract: This paper describes our system for the low-resource domain adaptation track (Track 3) in Spoken Language Understanding Grand Challenge, which is a part of ICASSP Signal Processing Grand Challenge 2023. In the track, we adopt a pipeline approach of ASR and NLU. For ASR, we fine-tune Whisper for each domain with upsampling. For NLU, we fine-tune BART on all the Track3 data and then on low-resource domain data. We apply masked LM (MLM) -based data augmentation, where some of input tokens and corresponding target labels are replaced using MLM. We also apply a retrieval-based approach, where model input is augmented with similar training samples.",
  "We apply masked LM (MLM) -based data augmentation, where some of input tokens and corresponding target labels are replaced using MLM. We also apply a retrieval-based approach, where model input is augmented with similar training samples. As a result, we achieved exact match (EM) accuracy 63.3/75.0 (average: 69.15) for reminder/weather domain, and won the 1st place at the challenge.\nAuthors: Hayato Futami, Jessica Huynh, Siddhant Arora, Shih-Lun Wu, Yosuke Kashiwagi, Yifan Peng, Brian Yan, E. Tsunoo, Shinji Watanabe\nVenue: IEEE International Conference on Acoustics, Speech, and Signal Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This system for the low-resource domain adaptation track (Track 3) in Spoken Language Understanding Grand Challenge, which is a part of ICASSP Signal Processing Grand Challenge 2023, adopts a pipeline approach of ASR and NLU and applies masked LM (MLM) -based data augmentation.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: b524ec331cd9708b125fad70d95d36189fa0d7b6\nTitle: A Study on the Integration of Pipeline and E2E SLU Systems for Spoken Semantic Parsing Toward Stop Quality Challenge\nYear: 2023\nAbstract: Recently there have been efforts to introduce new benchmark tasks for spoken language understanding (SLU), like semantic parsing. In this paper, we describe our proposed spoken semantic parsing system for the quality track (Track 1) in Spoken Language Understanding Grand Challenge which is part of ICASSP Signal Processing Grand Challenge 2023. We experiment with both end-to-end and pipeline systems for this task. Strong automatic speech recognition (ASR) models like Whisper and pretrained Language models (LM) like BART are utilized inside our SLU framework to boost performance. We also investigate the output level combination of various models to get an exact match accuracy of 80.8, which won the 1st place at the challenge.",
  "We also investigate the output level combination of various models to get an exact match accuracy of 80.8, which won the 1st place at the challenge.\nAuthors: Siddhant Arora, Hayato Futami, Shih-Lun Wu, Jessica Huynh, Yifan Peng, Yosuke Kashiwagi, E. Tsunoo, Brian Yan, Shinji Watanabe\nVenue: IEEE International Conference on Acoustics, Speech, and Signal Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper describes the proposed spoken semantic parsing system for the quality track (Track 1) in Spoken Language Understanding Grand Challenge which is part of ICASSP Signal Processing Grand Challenge 2023.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: b88a84fb2d35eecb5149caa3d0596942ae0a5a54\nTitle: A community cluster of influenza A(H3N2) virus infection with reduced susceptibility to baloxavir due to a PA E199G substitution in Japan, February to March 2023\nYear: 2023\nAbstract: A community cluster of influenza A(H3N2) caused by viruses with an E199G substitution in PA was detected in Nara, Japan, between February and March 2023. The three patients with these mutant viruses had not received antiviral treatment before specimen collection but patients in the same hospital had. The sequences of the mutant viruses were closely related, suggesting clonal spread in Nara. They showed reduced susceptibility to baloxavir in vitro; however, the clinical significance of the PA E199G substitution remains unclear.",
  "The sequences of the mutant viruses were closely related, suggesting clonal spread in Nara. They showed reduced susceptibility to baloxavir in vitro; however, the clinical significance of the PA E199G substitution remains unclear.\nAuthors: E. Takashita, Seiichiro Fujisaki, H. Morita, Shiho Nagata, H. Miura, Yuki Matsuura, Saya Yamamoto, Shoko Chiba, Yumiko Inoue, Iori Minami, Sayaka Yoshikawa, Seiko Yamazaki, N. Kishida, Kazuya Nakamura, Masayuki Shirakura, Shinji Watanabe, Hideki Hasegawa\nVenue: Euro surveillance : bulletin Europeen sur les maladies transmissibles = European communicable disease bulletin\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A community cluster of influenza A(H3N2) caused by viruses with an E199G substitution in PA was detected in Nara, Japan, between February and March 2023 and showed reduced susceptibility to baloxavir in vitro; however, the clinical significance remains unclear.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: bb4c59fc93d5be6b3d85dfde9d08e3dab80db9b7\nTitle: Exploring Speech Recognition, Translation, and Understanding with Discrete Speech Units: A Comparative Study\nYear: 2023\nAbstract: Speech signals, typically sampled at rates in the tens of thousands per second, contain redundancies, evoking inefficiencies in sequence modeling. High-dimensional speech features such as spectrograms are often used as the input for the subsequent model. However, they can still be redundant. Recent investigations proposed the use of discrete speech units derived from self-supervised learning representations, which significantly compresses the size of speech data. Applying various methods, such as de-duplication and subword modeling, can further compress the speech sequence length. Hence, training time is significantly reduced while retaining notable performance. In this study, we undertake a comprehensive and systematic exploration into the application of discrete units within end-to-end speech processing models.",
  "Hence, training time is significantly reduced while retaining notable performance. In this study, we undertake a comprehensive and systematic exploration into the application of discrete units within end-to-end speech processing models. Experiments on 12 automatic speech recognition, 3 speech translation, and 1 spoken language understanding corpora demonstrate that discrete units achieve reasonably good results in almost all the settings. We intend to release our configurations and trained models to foster future research efforts.\nAuthors: Xuankai Chang, Brian Yan, Kwanghee Choi, Jee-weon Jung, Yichen Lu, Soumi Maiti, Roshan Sharma, Jiatong Shi, Jinchuan Tian, Shinji Watanabe, Yuya Fujita, Takashi Maekaku, Pengcheng Guo, Yao-Fei Cheng, Pavel Denisov, Kohei Saijo, Hsiu-Hsuan Wang\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This study undertake a comprehensive and systematic exploration into the application of discrete units within end-to-end speech processing models, demonstrating that discrete units achieve reasonably good results in almost all the settings.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: bc3690edd40cc9946f8162727b357b926d1127bc\nTitle: Joint Modelling of Spoken Language Understanding Tasks with Integrated Dialog History\nYear: 2023\nAbstract: Most human interactions occur in the form of spoken conversations where the semantic meaning of a given utterance depends on the context. Each utterance in spoken conversation can be represented by many semantic and speaker attributes, and there has been an interest in building Spoken Language Understanding (SLU) systems for automatically predicting these attributes. Recent work has shown that incorporating dialogue history can help advance SLU performance. However, separate models are used for each SLU task, leading to an increase in inference time and computation cost. Motivated by this, we aim to ask: can we jointly model all the SLU tasks while incorporating context to facilitate low-latency and lightweight inference? To answer this, we propose a novel model architecture that learns dialog context to jointly predict the intent, dialog act, speaker role, and emotion for the spoken utterance.",
  "To answer this, we propose a novel model architecture that learns dialog context to jointly predict the intent, dialog act, speaker role, and emotion for the spoken utterance. Note that our joint prediction is based on an autoregressive model and we need to decide the prediction order of dialog attributes, which is not trivial. To mitigate the issue, we also propose an order agnostic training method. Our experiments show that our joint model achieves similar results to task-specific classifiers and can effectively integrate dialog context to further improve the SLU performance.1\nAuthors: Siddhant Arora, Hayato Futami, E. Tsunoo, Brian Yan, Shinji Watanabe\nVenue: IEEE International Conference on Acoustics, Speech, and Signal Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A novel model architecture is proposed that learns dialog context to jointly predict the intent, dialog act, speaker role, and emotion for the spoken utterance and achieves similar results to task-specific classifiers and can effectively integrateDialog context to further improve the SLU performance.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: bdf9ea3a67691e1b6a362f4019bf80c9cf31cecd\nTitle: Findings of the 2023 ML-Superb Challenge: Pre-Training And Evaluation Over More Languages And Beyond\nYear: 2023\nAbstract: The 2023 Multilingual Speech Universal Performance Benchmark (ML-SUPERB) Challenge expands upon the acclaimed SUPERB framework, emphasizing self-supervised models in multilingual speech recognition and language identification. The challenge comprises a research track focused on applying ML-SUPERB to specific multilingual subjects, a Challenge Track for model submissions, and a New Language Track where language resource researchers can contribute and evaluate their low-resource language data in the context of the latest progress in multilingual speech recognition. The challenge garnered 12 model submissions and 54 language corpora, resulting in a comprehensive benchmark encompassing 154 languages. The findings indicate that merely scaling models is not the definitive solution for multilingual speech tasks, and a variety of speech/voice types present significant challenges in multilingual speech processing.",
  "The challenge garnered 12 model submissions and 54 language corpora, resulting in a comprehensive benchmark encompassing 154 languages. The findings indicate that merely scaling models is not the definitive solution for multilingual speech tasks, and a variety of speech/voice types present significant challenges in multilingual speech processing.\nAuthors: Jiatong Shi, William Chen, Dan Berrebbi, Hsiu-Hsuan Wang, Wei-Ping Huang, En-Pei Hu, Ho-Lam Chuang, Xuankai Chang, Yuxun Tang, Shang-Wen Li, Abdelrahman Mohamed, Hung-yi Lee, Shinji Watanabe\nVenue: Automatic Speech Recognition & Understanding\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The 2023 Multilingual Speech Universal Performance Benchmark (ML-SUPERB) Challenge expands upon the acclaimed SUPERB framework, emphasizing self-supervised models in multilingual speech recognition and language identification, resulting in a comprehensive benchmark encompassing 154 languages.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: c2745e86ecc9bec372690cced53ccfdf44f407f8\nTitle: Enhancing End-to-End Conversational Speech Translation Through Target Language Context Utilization\nYear: 2023\nAbstract: Incorporating longer context has been shown to benefit machine translation, but the inclusion of context in end-to-end speech translation (E2E-ST) remains under-studied. To bridge this gap, we introduce target language context in E2E-ST, enhancing coherence and overcoming memory constraints of extended audio segments. Additionally, we propose context dropout to ensure robustness to the absence of context, and further improve performance by adding speaker information. Our proposed contextual E2E-ST outperforms the isolated utterance-based E2E-ST approach. Lastly, we demonstrate that in conversational speech, contextual information primarily contributes to capturing context style, as well as resolving anaphora and named entities.",
  "Our proposed contextual E2E-ST outperforms the isolated utterance-based E2E-ST approach. Lastly, we demonstrate that in conversational speech, contextual information primarily contributes to capturing context style, as well as resolving anaphora and named entities.\nAuthors: A. Hussein, Brian Yan, Antonios Anastasopoulos, Shinji Watanabe, S. Khudanpur\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work introduces target language context in E2E-ST, enhancing coherence and overcoming memory constraints of extended audio segments, and proposes context dropout to ensure robustness to the absence of context, and improves performance by adding speaker information.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: c6f5da5eb57457457a49256f1434bf1db23d1898\nTitle: Challenges of Corporate Alliance CLOMA toward Plastic Litter\nYear: 2023\nAbstract: None\nAuthors: Shinji Watanabe\nVenue: Oleoscience\nTldr: None",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: c823c04a6488673f936d72906130f170017288d0\nTitle: The Multimodal Information Based Speech Processing (MISP) 2023 Challenge: Audio-Visual Target Speaker Extraction\nYear: 2023\nAbstract: Previous Multimodal Information based Speech Processing (MISP) challenges mainly focused on audio-visual speech recognition (AVSR) with commendable success. However, the most advanced back-end recognition systems often hit performance limits due to the complex acoustic environments. This has prompted a shift in focus towards the Audio-Visual Target Speaker Extraction (AVTSE) task for the MISP 2023 challenge in ICASSP 2024 Signal Processing Grand Challenges. Unlike existing audio-visual speech enhance-ment challenges primarily focused on simulation data, the MISP 2023 challenge uniquely explores how front-end speech processing, combined with visual clues, impacts back-end tasks in real-world scenarios. This pioneering effort aims to set the first benchmark for the AVTSE task, offering fresh insights into enhancing the ac-curacy of back-end speech recognition systems through AVTSE in challenging and real acoustic environments.",
  "This pioneering effort aims to set the first benchmark for the AVTSE task, offering fresh insights into enhancing the ac-curacy of back-end speech recognition systems through AVTSE in challenging and real acoustic environments. This paper delivers a thorough overview of the task setting, dataset, and baseline system of the MISP 2023 challenge. It also includes an in-depth analysis of the challenges participants may encounter. The experimental results highlight the demanding nature of this task, and we look forward to the innovative solutions participants will bring forward.",
  "It also includes an in-depth analysis of the challenges participants may encounter. The experimental results highlight the demanding nature of this task, and we look forward to the innovative solutions participants will bring forward.\nAuthors: Shilong Wu, Chenxi Wang, Hang Chen, Yusheng Dai, Chenyue Zhang, Ruoyu Wang, Hongbo Lan, Jun Du, Chin-Hui Lee, Jingdong Chen, Shinji Watanabe, Sabato Marco Siniscalchi, O. Scharenborg, Zhong-Qiu Wang, Jia Pan, Jianqing Gao\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A thorough overview of the task setting, dataset, and baseline system of the MISP 2023 challenge is delivered, offering fresh insights into enhancing the ac-curacy of back-end speech recognition systems through AVTSE in challenging and real acoustic environments.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: d24d60719e90e69749a75c160cb760d1d9fca44a\nTitle: Incremental Blockwise Beam Search for Simultaneous Speech Translation with Controllable Quality-Latency Tradeoff\nYear: 2023\nAbstract: Blockwise self-attentional encoder models have recently emerged as one promising end-to-end approach to simultaneous speech translation. These models employ a blockwise beam search with hypothesis reliability scoring to determine when to wait for more input speech before translating further. However, this method maintains multiple hypotheses until the entire speech input is consumed -- this scheme cannot directly show a single \\textit{incremental} translation to users. Further, this method lacks mechanisms for \\textit{controlling} the quality vs. latency tradeoff. We propose a modified incremental blockwise beam search incorporating local agreement or hold-$n$ policies for quality-latency control. We apply our framework to models trained for online or offline translation and demonstrate that both types can be effectively used in online mode.",
  "latency tradeoff. We propose a modified incremental blockwise beam search incorporating local agreement or hold-$n$ policies for quality-latency control. We apply our framework to models trained for online or offline translation and demonstrate that both types can be effectively used in online mode. Experimental results on MuST-C show 0.6-3.6 BLEU improvement without changing latency or 0.8-1.4 s latency improvement without changing quality.\nAuthors: Peter Pol\u00e1k, Brian Yan, Shinji Watanabe, A. Waibel, Ondrej Bojar\nVenue: Interspeech\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A modified incremental blockwise beam search incorporating local agreement or hold-$n$ policies for quality-latency control is proposed and applied to models trained for online or offline translation and it is demonstrated that both types can be effectively used in online mode.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: d2897d70e1bceaf4799937e4b4aab0a45fc6e20c\nTitle: Bayes Risk Transducer: Transducer with Controllable Alignment Prediction\nYear: 2023\nAbstract: Automatic speech recognition (ASR) based on transducers is widely used. In training, a transducer maximizes the summed posteriors of all paths. The path with the highest posterior is commonly defined as the predicted alignment between the speech and the transcription. While the vanilla transducer does not have a prior preference for any of the valid paths, this work intends to enforce the preferred paths and achieve controllable alignment prediction. Specifically, this work proposes Bayes Risk Transducer (BRT), which uses a Bayes risk function to set lower risk values to the preferred paths so that the predicted alignment is more likely to satisfy specific desired properties. We further demonstrate that these predicted alignments with intentionally designed properties can provide practical advantages over the vanilla transducer.",
  "We further demonstrate that these predicted alignments with intentionally designed properties can provide practical advantages over the vanilla transducer. Experimentally, the proposed BRT saves inference cost by up to 46% for non-streaming ASR and reduces overall system latency by 41% for streaming ASR.\nAuthors: Jinchuan Tian, Jianwei Yu, Hangting Chen, Brian Yan, Chao Weng, Dong Yu, Shinji Watanabe\nVenue: Interspeech\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes Bayes Risk Transducer (BRT), which uses a Bayes risk function to set lower risk values to the preferred paths so that the predicted alignment is more likely to satisfy specific desired properties.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: d43338451cd8676548811e1ff8f9c92ea987c5bd\nTitle: Reproducing Whisper-Style Training Using An Open-Source Toolkit And Publicly Available Data\nYear: 2023\nAbstract: Pre-training speech models on large volumes of data has achieved remarkable success. OpenAI Whisper is a multilingual multitask model trained on 680k hours of supervised speech data. It generalizes well to various speech recognition and translation benchmarks even in a zero-shot setup. However, the full pipeline for developing such models (from data collection to training) is not publicly accessible, which makes it difficult for researchers to further improve its performance and address training-related issues such as efficiency, robustness, fairness, and bias. This work presents an Open Whisper-style Speech Model (OWSM), which reproduces Whisperstyle training using an open-source toolkit and publicly available data. OWSM even supports more translation directions and can be more efficient to train. We will publicly release all scripts used for data preparation, training, inference, and scoring as well as pretrained models and training logs to promote open science.",
  "OWSM even supports more translation directions and can be more efficient to train. We will publicly release all scripts used for data preparation, training, inference, and scoring as well as pretrained models and training logs to promote open science. 11https://github.com/espnet/espnet\nAuthors: Yifan Peng, Jinchuan Tian, Brian Yan, Dan Berrebbi, Xuankai Chang, Xinjian Li, Jiatong Shi, Siddhant Arora, William Chen, Roshan Sharma, Wangyou Zhang, Yui Sudo, Muhammad Shakeel, Jee-weon Jung, Soumi Maiti, Shinji Watanabe\nVenue: Automatic Speech Recognition & Understanding\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work presents an Open Whisper-style Speech Model (OWSM), which reproduces Whisperstyle training using an open-source toolkit and publicly available data and even supports more translation directions and can be more efficient to train.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: d4d5fe4a35e9de845877015075f727415e83d18f\nTitle: The CHiME-7 DASR Challenge: Distant Meeting Transcription with Multiple Devices in Diverse Scenarios\nYear: 2023\nAbstract: The CHiME challenges have played a significant role in the development and evaluation of robust automatic speech recognition (ASR) systems. We introduce the CHiME-7 distant ASR (DASR) task, within the 7th CHiME challenge. This task comprises joint ASR and diarization in far-field settings with multiple, and possibly heterogeneous, recording devices. Different from previous challenges, we evaluate systems on 3 diverse scenarios: CHiME-6, DiPCo, and Mixer 6. The goal is for participants to devise a single system that can generalize across different array geometries and use cases with no a-priori information. Another departure from earlier CHiME iterations is that participants are allowed to use open-source pre-trained models and datasets.",
  "The goal is for participants to devise a single system that can generalize across different array geometries and use cases with no a-priori information. Another departure from earlier CHiME iterations is that participants are allowed to use open-source pre-trained models and datasets. In this paper, we describe the challenge design, motivation, and fundamental research questions in detail. We also present the baseline system, which is fully array-topology agnostic and features multi-channel diarization, channel selection, guided source separation and a robust ASR model that leverages self-supervised speech representations (SSLR).",
  "We also present the baseline system, which is fully array-topology agnostic and features multi-channel diarization, channel selection, guided source separation and a robust ASR model that leverages self-supervised speech representations (SSLR).\nAuthors: Samuele Cornell, Matthew Wiesner, Shinji Watanabe, Desh Raj, Xuankai Chang, Paola Garc\u00eda, Yoshiki Masuyama, Zhong-Qiu Wang, S. Squartini, S. Khudanpur\nVenue: 7th International Workshop on Speech Processing in Everyday Environments (CHiME 2023)\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The ChiME-7 distant ASR (DASR) task, within the 7th CHiME challenge, is introduced and the baseline system is presented, which is fully array-topology agnostic and features multi-channel diarization, channel selection, guided source separation and a robust ASR model that leverages self-supervised speech representations (SSLR).'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: d8728d62b238b09630309c1df723036db84bac10\nTitle: Cross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing\nYear: 2023\nAbstract: Recent works in end-to-end speech-to-text translation (ST) have proposed multi-tasking methods with soft parameter sharing which leverage machine translation (MT) data via secondary encoders that map text inputs to an eventual cross-modal representation. In this work, we instead propose a ST/MT multi-tasking framework with hard parameter sharing in which all model parameters are shared cross-modally. Our method reduces the speech-text modality gap via a pre-processing stage which converts speech and text inputs into two discrete token sequences of similar length -- this allows models to indiscriminately process both modalities simply using a joint vocabulary. With experiments on MuST-C, we demonstrate that our multi-tasking framework improves attentional encoder-decoder, Connectionist Temporal Classification (CTC), transducer, and joint CTC/attention models by an average of +0.5 BLEU without any external MT data.",
  "With experiments on MuST-C, we demonstrate that our multi-tasking framework improves attentional encoder-decoder, Connectionist Temporal Classification (CTC), transducer, and joint CTC/attention models by an average of +0.5 BLEU without any external MT data. Further, we show that this framework incorporates external MT data, yielding +0.8 BLEU, and also improves transfer learning from pre-trained textual models, yielding +1.8 BLEU.\nAuthors: Brian Yan, Xuankai Chang, Antonios Anastasopoulos, Yuya Fujita, Shinji Watanabe\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes a ST/MT multi-tasking framework with hard parameter sharing in which all model parameters are shared cross-modally and reduces the speech-text modality gap via a pre-processing stage which converts speech and text inputs into two discrete token sequences of similar length.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: dab8e7dc79085774eea58bcb9ea2ed0ee20377eb\nTitle: ESPnet-ST-v2: Multipurpose Spoken Language Translation Toolkit\nYear: 2023\nAbstract: ESPnet-ST-v2 is a revamp of the open-source ESPnet-ST toolkit necessitated by the broadening interests of the spoken language translation community. ESPnet-ST-v2 supports 1) offline speech-to-text translation (ST), 2) simultaneous speech-to-text translation (SST), and 3) offline speech-to-speech translation (S2ST) \u2013 each task is supported with a wide variety of approaches, differentiating ESPnet-ST-v2 from other open source spoken language translation toolkits. This toolkit offers state-of-the-art architectures such as transducers, hybrid CTC/attention, multi-decoders with searchable intermediates, time-synchronous blockwise CTC/attention, Translatotron models, and direct discrete unit models.",
  "This toolkit offers state-of-the-art architectures such as transducers, hybrid CTC/attention, multi-decoders with searchable intermediates, time-synchronous blockwise CTC/attention, Translatotron models, and direct discrete unit models. In this paper, we describe the overall design, example models for each task, and performance benchmarking behind ESPnet-ST-v2, which is publicly available at https://github.com/espnet/espnet.\nAuthors: Brian Yan, Jiatong Shi, Yun Tang, H. Inaguma, Yifan Peng, Siddharth Dalmia, Peter Pol'ak, Patrick Fernandes, Dan Berrebbi, Tomoki Hayashi, Xiaohui Zhang, Zhaoheng Ni, Moto Hira, Soumi Maiti, J. Pino, Shinji Watanabe\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The overall design, example models for each task, and performance benchmarking behind ESPnet-ST-v2 are described, which is publicly available at https://github.com/espnet/esp net.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: dd5d797b837005fac464bb19b9396bddba61c0d8\nTitle: Multi-Channel Target Speaker Extraction with Refinement: The WavLab Submission to the Second Clarity Enhancement Challenge\nYear: 2023\nAbstract: This paper describes our submission to the Second Clarity Enhancement Challenge (CEC2), which consists of target speech enhancement for hearing-aid (HA) devices in noisy-reverberant environments with multiple interferers such as music and competing speakers. Our approach builds upon the powerful iterative neural/beamforming enhancement (iNeuBe) framework introduced in our recent work, and this paper extends it for target speaker extraction. We therefore name the proposed approach as iNeuBe-X, where the X stands for extraction.",
  "Our approach builds upon the powerful iterative neural/beamforming enhancement (iNeuBe) framework introduced in our recent work, and this paper extends it for target speaker extraction. We therefore name the proposed approach as iNeuBe-X, where the X stands for extraction. To address the challenges encountered in the CEC2 setting, we introduce four major novelties: (1) we extend the state-of-the-art TF-GridNet model, originally designed for monaural speaker separation, for multi-channel, causal speech enhancement, and large improvements are observed by replacing the TCNDenseNet used in iNeuBe with this new architecture; (2) we leverage a recent dual window size approach with future-frame prediction to ensure that iNueBe-X satisfies the 5 ms constraint on algorithmic latency required by CEC2; (3) we introduce a novel speaker-conditioning branch for TF-GridNet to achieve target speaker extraction; (4) we propose a fine-tuning step, where we compute an additional loss with respect to the target speaker signal compensated with the listener audiogram.",
  "Without using external data, on the official development set our best model reaches a hearing-aid speech perception index (HASPI) score of 0.942 and a scale-invariant signal-to-distortion ratio improvement (SI-SDRi) of 18.8 dB. These results are promising given the fact that the CEC2 data is extremely challenging (e.g., on the development set the mixture SI-SDR is -12.3 dB). A demo of our submitted system is available at WAVLab CEC2 demo.\nAuthors: Samuele Cornell, Zhongqiu Wang, Yoshiki Masuyama, Shinji Watanabe, Manuel Pariente, Nobutaka Ono\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The approach builds upon the powerful iterative neural/beamforming enhancement (iNeuBe) framework introduced in recent work, and this paper extends it for target speaker extraction, and is named as iNeu be-X, where the X stands for extraction.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: debb65ab30ceef2faef0e4af560a67f2abd03d14\nTitle: Fully Unsupervised Topic Clustering of Unlabelled Spoken Audio Using Self-Supervised Representation Learning and Topic Model\nYear: 2023\nAbstract: Unsupervised topic clustering of spoken audio is an important research topic for zero-resourced unwritten languages. A classical approach is to find a set of spoken terms from only the audio based on dynamic time warping or generative modeling (e.g., hidden Markov model), and apply a topic model to classify topics. The spoken term discovery is the most important and difficult part. In this paper, we propose to combine self-supervised representation learning (SSRL) methods as a component of spoken term discovery and probabilistic topic models. Most SSRL methods pre-train a model which predicts high-quality pseudo labels generated from an audio-only corpus. These pseudo labels can be used to produce a sequence of pseudo subwords by applying deduplication and a subword model.",
  "Most SSRL methods pre-train a model which predicts high-quality pseudo labels generated from an audio-only corpus. These pseudo labels can be used to produce a sequence of pseudo subwords by applying deduplication and a subword model. Then, we apply a topic model based on latent Dirichlet allocation for these pseudo-subword sequences in an unsupervised manner. The clustering performance is evaluated on the Fisher corpus using normalized mutual information. We confirm the improvement of the proposed method and its effectiveness compared to an existing approach using dynamic time warping and topic models although the experimental setups are not directly comparable.\nAuthors: Takashi Maekaku, Yuya Fujita, Xuankai Chang, Shinji Watanabe\nVenue: IEEE International Conference on Acoustics, Speech, and Signal Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper proposes to combine self-supervised representation learning (SSRL) methods as a component of spoken term discovery and probabilistic topic models and confirms the improvement of the proposed method and its effectiveness compared to an existing approach using dynamic time warping and topic models.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: e146e5221c124d93f69516c5ae7e1b7b1822848e\nTitle: TAPLoss: A Temporal Acoustic Parameter Loss for Speech Enhancement\nYear: 2023\nAbstract: Speech enhancement models have greatly progressed in recent years, but still show limits in perceptual quality of their speech outputs. We propose an objective for perceptual quality based on temporal acoustic parameters. These are fundamental speech features that play an essential role in various applications, including speaker recognition and paralinguistic analysis. We provide a differentiable estimator for four categories of low-level acoustic descriptors involving: frequency-related parameters, energy or amplitude-related parameters, spectral balance parameters, and temporal features. Un-like prior work that looks at aggregated acoustic parameters or a few categories of acoustic parameters, our temporal acoustic parameter (TAP) loss enables auxiliary optimization and improvement of many fine-grained speech characteristics in enhancement workflows. We show that adding TAPLoss as an auxiliary objective in speech enhancement produces speech with improved perceptual quality and intelligibility.",
  "We show that adding TAPLoss as an auxiliary objective in speech enhancement produces speech with improved perceptual quality and intelligibility. We use data from the Deep Noise Suppression 2020 Challenge to demonstrate that both time-domain models and time-frequency domain models can benefit from our method.\nAuthors: YUNYANG ZENG, Joseph Konan, Shuo Han, David Bick, Muqiao Yang, Anurag Kumar, Shinji Watanabe, B. Raj\nVenue: IEEE International Conference on Acoustics, Speech, and Signal Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work shows that adding TAPLoss as an auxiliary objective in speech enhancement produces speech with improved perceptual quality and intelligibility and uses data from the Deep Noise Suppression 2020 Challenge to demonstrate that both time-domain models and time-frequency domain models can benefit from the method.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: e25f6a60211aa74ecfde8001a5939ff206102de4\nTitle: End-to-End Speech Recognition: A Survey\nYear: 2023\nAbstract: In the last decade of automatic speech recognition (ASR) research, the introduction of deep learning has brought considerable reductions in word error rate of more than 50% relative, compared to modeling without deep learning. In the wake of this transition, a number of all-neural ASR architectures have been introduced. These so-called end-to-end (E2E) models provide highly integrated, completely neural ASR models, which rely strongly on general machine learning knowledge, learn more consistently from data, with lower dependence on ASR domain-specific experience. The success and enthusiastic adoption of deep learning, accompanied by more generic model architectures has led to E2E models now becoming the prominent ASR approach. The goal of this survey is to provide a taxonomy of E2E ASR models and corresponding improvements, and to discuss their properties and their relationship to classical hidden Markov model (HMM) based ASR architectures.",
  "The goal of this survey is to provide a taxonomy of E2E ASR models and corresponding improvements, and to discuss their properties and their relationship to classical hidden Markov model (HMM) based ASR architectures. All relevant aspects of E2E ASR are covered in this work: modeling, training, decoding, and external language model integration, discussions of performance and deployment opportunities, as well as an outlook into potential future developments.\nAuthors: Rohit Prabhavalkar, Takaaki Hori, Tara N. Sainath, R. Schluter, Shinji Watanabe\nVenue: IEEE/ACM Transactions on Audio Speech and Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A taxonomy of E2E ASR models and corresponding improvements is provided, and their properties and their relationship to classical hidden Markov model (HMM) based ASR architectures are discussed.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: e2826002978af39afce7529f172ffdc222342651\nTitle: The Multimodal Information Based Speech Processing (Misp) 2022 Challenge: Audio-Visual Diarization And Recognition\nYear: 2023\nAbstract: The Multi-modal Information based Speech Processing (MISP) challenge aims to extend the application of signal processing technology in specific scenarios by promoting the research into wake-up words, speaker diarization, speech recognition, and other technologies. The MISP2022 challenge has two tracks: 1) audio-visual speaker diarization (AVSD), aiming to solve \"who spoken when\" using both audio and visual data; 2) a novel audio-visual diarization and recognition (AVDR) task that focuses on addressing \"who spoken what when\" with audio-visual speaker diarization results. Both tracks focus on the Chinese language, and use far-field audio and video in real home-tv scenarios: 2-6 people communicating each other with TV noise in the background. This paper introduces the dataset, track settings, and baselines of the MISP2022 challenge.",
  "Both tracks focus on the Chinese language, and use far-field audio and video in real home-tv scenarios: 2-6 people communicating each other with TV noise in the background. This paper introduces the dataset, track settings, and baselines of the MISP2022 challenge. Our analyses of experiments and examples indicate the good performance of AVDR baseline system, and the potential difficulties in this challenge due to, e.g., the far-field video quality, the presence of TV noise in the background, and the indistinguishable speakers.",
  "Our analyses of experiments and examples indicate the good performance of AVDR baseline system, and the potential difficulties in this challenge due to, e.g., the far-field video quality, the presence of TV noise in the background, and the indistinguishable speakers.\nAuthors: Zhe Wang, Shilong Wu, Hang Chen, Maokui He, Jun Du, Chin-Hui Lee, Jingdong Chen, Shinji Watanabe, Sabato Marco Siniscalchi, O. Scharenborg, Diyuan Liu, Baocai Yin, Jia Pan, Jianqing Gao, Cong Liu\nVenue: IEEE International Conference on Acoustics, Speech, and Signal Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The dataset, track settings, and baselines of the MISP2022 challenge are introduced, and analyses of experiments and examples indicate the good performance of AVDR baseline system, and the potential difficulties in this challenge due to, e.g., the far-field video quality, the presence of TV noise in the background, andThe indistinguishable speakers.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: e4f2d75856ce149b994f079ae50fd33ca47245d3\nTitle: DPHuBERT: Joint Distillation and Pruning of Self-Supervised Speech Models\nYear: 2023\nAbstract: Self-supervised learning (SSL) has achieved notable success in many speech processing tasks, but the large model size and heavy computational cost hinder the deployment. Knowledge distillation trains a small student model to mimic the behavior of a large teacher model. However, the student architecture usually needs to be manually designed and will remain fixed during training, which requires prior knowledge and can lead to suboptimal performance. Inspired by recent success of task-specific structured pruning, we propose DPHuBERT, a novel task-agnostic compression method for speech SSL based on joint distillation and pruning. Experiments on SUPERB show that DPHuBERT outperforms pure distillation methods in almost all tasks. Moreover, DPHuBERT requires little training time and performs well with limited training data, making it suitable for resource-constrained applications. Our method can also be applied to various speech SSL models.",
  "Moreover, DPHuBERT requires little training time and performs well with limited training data, making it suitable for resource-constrained applications. Our method can also be applied to various speech SSL models. Our code and models will be publicly available.\nAuthors: Yifan Peng, Yui Sudo, Muhammad Shakeel, Shinji Watanabe\nVenue: Interspeech\nTldr: {'model': 'tldr@v2.0.0', 'text': 'DPHuBERT is proposed, a novel task-agnostic compression method for speech SSL based on joint distillation and pruning that requires little training time and performs well with limited training data, making it suitable for resource-constrained applications.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: e64d4b29a4a6ccac3673b4cedbefa1e54e774c20\nTitle: An external quality assessment feasibility study; cross laboratory comparison of haemagglutination inhibition assay and microneutralization assay performance for seasonal influenza serology testing: A FLUCOP study\nYear: 2023\nAbstract: Introduction External Quality Assessment (EQA) schemes are designed to provide a snapshot of laboratory proficiency, identifying issues and providing feedback to improve laboratory performance and inter-laboratory agreement in testing. Currently there are no international EQA schemes for seasonal influenza serology testing. Here we present a feasibility study for conducting an EQA scheme for influenza serology methods. Methods We invited participant laboratories from industry, contract research organizations (CROs), academia and public health institutions who regularly conduct hemagglutination inhibition (HAI) and microneutralization (MN) assays and have an interest in serology standardization. In total 16 laboratories returned data including 19 data sets for HAI assays and 9 data sets for MN assays.",
  "In total 16 laboratories returned data including 19 data sets for HAI assays and 9 data sets for MN assays. Results Within run analysis demonstrated good laboratory performance for HAI, with intrinsically higher levels of intra-assay variation for MN assays. Between run analysis showed laboratory and strain specific issues, particularly with B strains for HAI, whilst MN testing was consistently good across labs and strains. Inter-laboratory variability was higher for MN assays than HAI, however both assays showed a significant reduction in inter-laboratory variation when a human sera pool is used as a standard for normalization. Discussion This study has received positive feedback from participants, highlighting the benefit such an EQA scheme would have on improving laboratory performance, reducing inter laboratory variation and raising awareness of both harmonized protocol use and the benefit of biological standards for seasonal influenza serology testing.\nAuthors: J. Waldock, C. Weiss, Wei Wang, M. Levine, Stacie N. Jefferson, S. Ho, K. Hoschler, B. Londt, E. Masat, Louise A. Carolan, Stephany S\u00e1nchez-Ovando, A. Fox, Shinji Watanabe, Miki Akimoto, Aya Sato, N.",
  "Levine, Stacie N. Jefferson, S. Ho, K. Hoschler, B. Londt, E. Masat, Louise A. Carolan, Stephany S\u00e1nchez-Ovando, A. Fox, Shinji Watanabe, Miki Akimoto, Aya Sato, N. Kishida, A. Buys, Lorens Maake, Cardia Fourie, Catherine Caillet, Sandrine Raynaud, R. Webby, J. Debeauchamp, R. Cox, Sarah Lartey, C. Trombetta, S. Marchi, E. Montomoli, I. Sanz-Mu\u00f1oz, J. Eiros, Javier S\u00e1nchez-Mart\u00ednez, D. Duijsings, O. Engelhardt\nVenue: Frontiers in Immunology\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A feasibility study for conducting an EQA scheme for influenza serology methods showing good laboratory performance for HAI, with intrinsically higher levels of intra-assay variation for MN assays, and a significant reduction in inter-laboratory variation when a human sera pool is used as a standard for normalization.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: eadca5a91a755c9e8dbc1843c435b9c5ab930477\nTitle: Magnetic dynamics and nonreciprocal excitation in uniform hedgehog order in icosahedral 1/1 approximant crystal\nYear: 2023\nAbstract: None\nAuthors: Shinji Watanabe\nVenue: Scientific Reports\nTldr: None",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: ebb75ff5b5e55ba15e4239ed0ffa6ff2ad00b721\nTitle: Multi-Channel Speaker Extraction with Adversarial Training: The Wavlab Submission to The Clarity ICASSP 2023 Grand Challenge\nYear: 2023\nAbstract: In this work we detail our submission to the Clarity ICASSP 2023 grand challenge, in which participants have to develop a strong target speech enhancement system for hearing-aid (HA) devices in noisy-reverberant environments. Our system builds on our previous submission at the Second Clarity Enhancement Challenge (CEC2): iNeuBe-X, which consists in an iterative neural/conventional beamforming enhancement pipeline, guided by an enrollment utterance from the target speaker. This model, which won by a large margin the CEC2, is an extension of the state-of-the-art TF-GridNet model for multi-channel, streamable target-speaker speech enhancement. Here, this approach is extended and further improved by leveraging generative adversarial training, which we show proves especially useful when the training data is limited.",
  "Here, this approach is extended and further improved by leveraging generative adversarial training, which we show proves especially useful when the training data is limited. Using only the official 6k training scenes data, our best model achieves 0.80 hearing-aid speech perception index (HASPI) and 0.41 hearing-aid speech quality index (HASQI) scores on the synthetic evaluation set. However, our model generalized poorly on the semi-real evaluation set. This highlights the fact that our community should focus more on real-world evaluation and less on fully synthetic datasets.",
  "However, our model generalized poorly on the semi-real evaluation set. This highlights the fact that our community should focus more on real-world evaluation and less on fully synthetic datasets.\nAuthors: Samuele Cornell, Zhongqiu Wang, Yoshiki Masuyama, Shinji Watanabe, Manuel Pariente, Nobutaka Ono, S. Squartini\nVenue: IEEE International Conference on Acoustics, Speech, and Signal Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work details the submission to the Clarity ICASSP 2023 grand challenge, in which participants have to develop a strong target speech enhancement system for hearing-aid (HA) devices in noisy-reverberant environments, and builds on the previous submission at the Second Clarity Enhancement Challenge (CEC2): iNeuBe-X.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: ef567580e167c3e7c546345df93d644be5d4f66f\nTitle: AV-SUPERB: A Multi-Task Evaluation Benchmark for Audio-Visual Representation Models\nYear: 2023\nAbstract: Audio-visual representation learning aims to develop systems with human-like perception by utilizing correlation between auditory and visual information. However, current models often focus on a limited set of tasks, and generalization abilities of learned representations are unclear. To this end, we propose the AV-SUPERB benchmark that enables general-purpose evaluation of unimodal audio/visual and bimodal fusion representations on 7 datasets covering 5 audio-visual tasks in speech and audio processing. We evaluate 5 recent self-supervised models and show that none of these models generalize to all tasks, emphasizing the need for future study on improving universal model performance. In addition, we show that representations may be improved with intermediate-task fine-tuning and audio event classification with AudioSet serves as a strong intermediate task. We release our benchmark with evaluation code and a model submission platform to encourage further research in audio-visual learning.",
  "In addition, we show that representations may be improved with intermediate-task fine-tuning and audio event classification with AudioSet serves as a strong intermediate task. We release our benchmark with evaluation code and a model submission platform to encourage further research in audio-visual learning.\nAuthors: Yuan Tseng, Layne Berry, Yi-Ting Chen, I-Hsiang Chiu, Hsuan-Hao Lin, Max Liu, Puyuan Peng, Yi-Jen Shih, Hung-Yu Wang, Haibin Wu, Po-Yao Huang, Chun-Mao Lai, Shang-Wen Li, David F. Harwath, Yu Tsao, Shinji Watanabe, Abdel-rahman Mohamed, Chi-Luen Feng, Hung-yi Lee\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The AV-SUPERB benchmark is proposed that enables general-purpose evaluation of unimodal audio/visual and bimodal fusion representations on 7 datasets covering 5 audio-visual tasks in speech and audio processing and shows that representations may be improved with intermediate-task fine-tuning and audio event classification with AudioSet serves as a strong intermediate task.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: ef8b095292a8e38e9b8f56c54cbf3c67c3ed425d\nTitle: Improving Cascaded Unsupervised Speech Translation with Denoising Back-translation\nYear: 2023\nAbstract: Most of the speech translation models heavily rely on parallel data, which is hard to collect especially for low-resource languages. To tackle this issue, we propose to build a cascaded speech translation system without leveraging any kind of paired data. We use fully unpaired data to train our unsupervised systems and evaluate our results on CoVoST 2 and CVSS. The results show that our work is comparable with some other early supervised methods in some language pairs. While cascaded systems always suffer from severe error propagation problems, we proposed denoising back-translation (DBT), a novel approach to building robust unsupervised neural machine translation (UNMT). DBT successfully increases the BLEU score by 0.7--0.9 in all three translation directions.",
  "DBT successfully increases the BLEU score by 0.7--0.9 in all three translation directions. Moreover, we simplified the pipeline of our cascaded system to reduce inference latency and conducted a comprehensive analysis of every part of our work. We also demonstrate our unsupervised speech translation results on the established website.\nAuthors: Yu-Kuan Fu, Liang-Hsuan Tseng, Jiatong Shi, Chen-An Li, Tsung-Yuan Hsu, Shinji Watanabe, Hung-yi Lee\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposed denoising back-translation (DBT), a novel approach to building robust unsupervised neural machine translation (UNMT), which successfully increases the BLEU score by 0.7--0.9 in all three translation directions.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: f53b6f5a85f2d74deb32022795b5dab0aa753cf4\nTitle: Deep Speech Synthesis from MRI-Based Articulatory Representations\nYear: 2023\nAbstract: In this paper, we study articulatory synthesis, a speech synthesis method using human vocal tract information that offers a way to develop efficient, generalizable and interpretable synthesizers. While recent advances have enabled intelligible articulatory synthesis using electromagnetic articulography (EMA), these methods lack critical articulatory information like excitation and nasality, limiting generalization capabilities. To bridge this gap, we propose an alternative MRI-based feature set that covers a much more extensive articulatory space than EMA. We also introduce normalization and denoising procedures to enhance the generalizability of deep learning methods trained on MRI data. Moreover, we propose an MRI-to-speech model that improves both computational efficiency and speech fidelity. Finally, through a series of ablations, we show that the proposed MRI representation is more comprehensive than EMA and identify the most suitable MRI feature subset for articulatory synthesis.",
  "Moreover, we propose an MRI-to-speech model that improves both computational efficiency and speech fidelity. Finally, through a series of ablations, we show that the proposed MRI representation is more comprehensive than EMA and identify the most suitable MRI feature subset for articulatory synthesis.\nAuthors: Peter Wu, Tingle Li, Yijingxiu Lu, Yubin Zhang, Jiachen Lian, A. Black, L. Goldstein, Shinji Watanabe, G. Anumanchipalli\nVenue: Interspeech\nTldr: {'model': 'tldr@v2.0.0', 'text': 'An MRI-to-speech model that improves both computational efficiency and speech fidelity is proposed and the proposed MRI representation is more comprehensive than EMA and the most suitable MRI feature subset for articulatory synthesis is identified.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: f7e995c3cae465963ecaa8c9b4ce8b9b4323a71b\nTitle: FINDINGS OF THE IWSLT 2023 EVALUATION CAMPAIGN\nYear: 2023\nAbstract: This paper reports on the shared tasks organized by the 20th IWSLT Conference. The shared tasks address 9 scientific challenges in spoken language translation: simultaneous and offline translation, automatic subtitling and dubbing, speech-to-speech translation, multilingual, dialect and low-resource speech translation, and formality control. The shared tasks attracted a total of 38 submissions by 31 teams. The growing interest towards spoken language translation is also witnessed by the constantly increasing number of shared task organizers and contributors to the overview paper, almost evenly distributed across industry and academia.",
  "The shared tasks attracted a total of 38 submissions by 31 teams. The growing interest towards spoken language translation is also witnessed by the constantly increasing number of shared task organizers and contributors to the overview paper, almost evenly distributed across industry and academia.\nAuthors: Sweta Agrawal, Antonios Anastasopoulos, L. Bentivogli, Ondrej Bojar, Claudia Borg, Marine Carpuat, R. Cattoni, Mauro Cettolo, Mingda Chen, William Chen, K. Choukri, Alexandra Chronopoulou, Anna Currey, T. Declerck, Qianqian Dong, Kevin Duh, Y. Est\u00e8ve, Marcello Federico, Souhir Gahbiche, B. Haddow, B. Hsu, Phu Mon Htut, H. Inaguma, D\u00e1vid Javorsk\u00fd, J. Judge, Yasumasa Kano, Tom Ko, Rishu Kumar, Peng Li, Xutai Ma, Prashant Mathur, E. Matusov, Paul McNamee, John P. McCrae, Kenton Murray, Maria Nadejde, Satoshi Nakamura, Matteo Negri, H. Nguyen, J. Niehues, Xing Niu, Atul Kr.",
  "Ojha, John E. Ortega, Proyag Pal, J. Pino, Lonneke van der Plas, Peter Pol\u00e1k, Elijah Matthew Rippeth, Elizabeth Salesky, Jiatong Shi, Matthias Sperber, Sebastian St\u00fcker, Katsuhito Sudoh, Yun Tang, Brian Thompson, Ke M. Tran, Marco Turchi, A. Waibel, Mingxuan Wang, Shinji Watanabe, Rodolfo Zevallos\nVenue: International Workshop on Spoken Language Translation\nTldr: {'model': 'tldr@v2.0.0', 'text': None}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: f80c354908efd4d5617878e36e35446016534190\nTitle: Semi-Autoregressive Streaming ASR With Label Context\nYear: 2023\nAbstract: Non-autoregressive (NAR) modeling has gained significant interest in speech processing since these models achieve dramatically lower inference time than autoregressive (AR) models while also achieving good transcription accuracy. Since NAR automatic speech recognition (ASR) models must wait for the completion of the entire utterance before processing, some works explore streaming NAR models based on blockwise attention for low-latency applications. However, streaming NAR models significantly lag in accuracy compared to streaming AR and non-streaming NAR models. To address this, we propose a streaming\"semi-autoregressive\"ASR model that incorporates the labels emitted in previous blocks as additional context using a Language Model (LM) subnetwork. We also introduce a novel greedy decoding algorithm that addresses insertion and deletion errors near block boundaries while not significantly increasing the inference time.",
  "We also introduce a novel greedy decoding algorithm that addresses insertion and deletion errors near block boundaries while not significantly increasing the inference time. Experiments show that our method outperforms the existing streaming NAR model by 19% relative on Tedlium2, 16%/8% on Librispeech-100 clean/other test sets, and 19%/8% on the Switchboard(SWB)/Callhome(CH) test sets. It also reduced the accuracy gap with streaming AR and non-streaming NAR models while achieving 2.5x lower latency. We also demonstrate that our approach can effectively utilize external text data to pre-train the LM subnetwork to further improve streaming ASR accuracy.\nAuthors: Siddhant Arora, G. Saon, Shinji Watanabe, Brian Kingsbury\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes a streaming\"semi-autoregressive\"ASR model that incorporates the labels emitted in previous blocks as additional context using a Language Model (LM) subnetwork and introduces a novel greedy decoding algorithm that addresses insertion and deletion errors near block boundaries while not significantly increasing the inference time.'}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: fa5ebb425c57f6c4f1c36a7200ef1da867346e8c\nTitle: Speech collage: code-switched audio generation by collaging monolingual corpora\nYear: 2023\nAbstract: Designing effective automatic speech recognition (ASR) systems for Code-Switching (CS) often depends on the availability of the transcribed CS resources. To address data scarcity, this paper introduces Speech Collage, a method that synthesizes CS data from monolingual corpora by splicing audio segments. We further improve the smoothness quality of audio generation using an overlap-add approach. We investigate the impact of generated data on speech recognition in two scenarios: using in-domain CS text and a zero-shot approach with synthesized CS text. Empirical results highlight up to 34.4% and 16.2% relative reductions in Mixed-Error Rate and Word-Error Rate for in-domain and zero-shot scenarios, respectively. Lastly, we demonstrate that CS augmentation bolsters the model's code-switching inclination and reduces its monolingual bias.",
  "Empirical results highlight up to 34.4% and 16.2% relative reductions in Mixed-Error Rate and Word-Error Rate for in-domain and zero-shot scenarios, respectively. Lastly, we demonstrate that CS augmentation bolsters the model's code-switching inclination and reduces its monolingual bias.\nAuthors: A. Hussein, Dorsa Zeinali, Ondrej Klejch, Matthew Wiesner, Brian Yan, Shammur A. Chowdhury, Ahmed Ali, Shinji Watanabe, S. Khudanpur\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': \"Speech Collage is introduced, a method that synthesizes CS data from monolingual corpora by splicing audio segments that improves the smoothness quality of audio generation using an overlap-add approach and demonstrates that CS augmentation bolsters the model's code-switching inclination and reduces itsmonolingual bias.\"}",
  "Faculty Name: shinji watanabe\nMetadata:\nPaperid: fa75ef55e04e3b25b8af56435478c2fd17403ce8\nTitle: Exploration on HuBERT with Multiple Resolutions\nYear: 2023\nAbstract: Hidden-unit BERT (HuBERT) is a widely-used self-supervised learning (SSL) model in speech processing. However, we argue that its fixed 20ms resolution for hidden representations would not be optimal for various speech-processing tasks since their attributes (e.g., speaker characteristics and semantics) are based on different time scales. To address this limitation, we propose utilizing HuBERT representations at multiple resolutions for downstream tasks. We explore two approaches, namely the parallel and hierarchical approaches, for integrating HuBERT features with different resolutions. Through experiments, we demonstrate that HuBERT with multiple resolutions outperforms the original model. This highlights the potential of utilizing multiple resolutions in SSL models like HuBERT to capture diverse information from speech signals.",
  "We explore two approaches, namely the parallel and hierarchical approaches, for integrating HuBERT features with different resolutions. Through experiments, we demonstrate that HuBERT with multiple resolutions outperforms the original model. This highlights the potential of utilizing multiple resolutions in SSL models like HuBERT to capture diverse information from speech signals.\nAuthors: Jiatong Shi, Yun Tang, H. Inaguma, Hongyu Gong, J. Pino, Shinji Watanabe\nVenue: Interspeech\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Through experiments, it is demonstrated that HuBERT with multiple resolutions outperforms the original model, highlighting the potential of utilizing multiple resolutions in SSL models like HuberT to capture diverse information from speech signals.'}",
  "List of 2023 Open Access papers by shinji watanabe are:\nCrystalline electric field and magnetic anisotropy in Dy-based icosahedral quasicrystal and approximant\nMagnetism and topological property in icosahedral quasicrystal\nAssessment of the frequency of SARS-CoV-2 Omicron variant escape from RNA-dependent RNA polymerase inhibitors and 3C-like protease inhibitors.\nSaturation time of exposure interval for cross-neutralization response to SARS-CoV-2: Implications for vaccine dose interval\nJoint Prediction and Denoising for Large-Scale Multilingual Self-Supervised Learning\nTensor decomposition for minimization of E2E SLU model toward on-device processing\nDecoder-only Architecture for Speech Recognition with CTC Prompts and Text Data Augmentation\nML-SUPERB: Multilingual Speech Universal PERformance Benchmark\nStructured Pruning of Self-Supervised Pre-Trained Models for Speech Recognition and Understanding\nPrompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot Task Generalization\nA Comparative Study on E-Branchformer vs Conformer in Speech Recognition, Translation,",
  "Translation, and Understanding Tasks\nEfficient Sequence Transduction by Jointly Predicting Tokens and Durations\nSpeech Summarization of Long Spoken Document: Improving Memory Efficiency of Speech/Text Encoders\nUNSSOR: Unsupervised Neural Speech Separation by Leveraging Over-determined Training Mixtures\nSegment-Level Vectorized Beam Search Based on Partially Autoregressive Inference\nUnsupervised Data Selection for TTS: Using Arabic Broadcast News as a Case Study\nBASS: Block-wise Adaptation for Speech Summarization\nI3D: Transformer Architectures with Input-Dependent Dynamic Depth for Speech Recognition\nA Vector Quantized Approach for Text to Speech Synthesis on Real-World Spontaneous Speech\nA New Benchmark of Aphasia Speech Recognition and Detection Based on E-Branchformer and Multi-task Learning\nAntiviral Susceptibilities of Distinct Lineages of Influenza C and D Viruses\nPaaploss: A Phonetic-Aligned Acoustic Parameter Loss for Speech Enhancement\nSigMoreFun Submission to the SIGMORPHON Shared Task on Interlinear Glossing\nExploring the Integration of Speech Separation and Recognition with Self-Supervised Learning Representation\nDynamic-SUPERB: Towards A Dynamic, Collaborative,",
  "Collaborative, and Comprehensive Instruction-Tuning Benchmark for Speech\nSpeaker-Independent Acoustic-to-Articulatory Speech Inversion\nTowards Practical and Efficient Image-to-Speech Captioning with Vision-Language Pre-training and Multi-modal Tokens\nEnhancing Speech-To-Speech Translation with Multiple TTS Targets\nAudioGPT: Understanding and Generating Speech, Music, Sound, and Talking Head\nImproving Audio Captioning Models with Fine-grained Audio Features, Text Embedding Supervision,",
  "Music, Sound, and Talking Head\nImproving Audio Captioning Models with Fine-grained Audio Features, Text Embedding Supervision, and LLM Mix-up Augmentation\nVoxtlm: unified decoder-only models for consolidating speech recognition/synthesis and speech/text continuation tasks\nLearning to Speak from Text: Zero-Shot Multilingual Text-to-Speech with Unsupervised Text Pretraining\nFNeural Speech Enhancement with Very Low Algorithmic Latency and Complexity via Integrated full- and sub-band Modeling\nImproving Massively Multilingual ASR with Auxiliary CTC Objectives\nToward Universal Speech Enhancement For Diverse Input Conditions\nThe Pipeline System of ASR and NLU with MLM-based data Augmentation Toward Stop Low-Resource Challenge\nA Study on the Integration of Pipeline and E2E SLU Systems for Spoken Semantic Parsing Toward Stop Quality Challenge\nA community cluster of influenza A(H3N2) virus infection with reduced susceptibility to baloxavir due to a PA E199G substitution in Japan, February to March 2023\nExploring Speech Recognition, Translation, and Understanding with Discrete Speech Units: A Comparative Study\nJoint Modelling of Spoken Language Understanding Tasks with Integrated Dialog History\nEnhancing End-to-End Conversational",
  "February to March 2023\nExploring Speech Recognition, Translation, and Understanding with Discrete Speech Units: A Comparative Study\nJoint Modelling of Spoken Language Understanding Tasks with Integrated Dialog History\nEnhancing End-to-End Conversational Speech Translation Through Target Language Context Utilization\nChallenges of Corporate Alliance CLOMA toward Plastic Litter\nThe Multimodal Information Based Speech Processing (MISP) 2023 Challenge: Audio-Visual Target Speaker Extraction\nReproducing Whisper-Style Training Using An Open-Source Toolkit And Publicly Available Data\nThe CHiME-7 DASR Challenge: Distant Meeting Transcription with Multiple Devices in Diverse Scenarios\nCross-Modal Multi-Tasking for Speech-to-Text Translation via Hard Parameter Sharing\nESPnet-ST-v2: Multipurpose Spoken Language Translation Toolkit\nMulti-Channel Target Speaker Extraction with Refinement: The WavLab Submission to the Second Clarity Enhancement Challenge\nFully Unsupervised Topic Clustering of Unlabelled Spoken Audio Using Self-Supervised Representation Learning and Topic Model\nTAPLoss: A Temporal Acoustic Parameter Loss for Speech Enhancement\nEnd-to-End Speech Recognition: A Survey\nThe Multimodal Information Based Speech Processing (Misp)",
  "Challenge\nFully Unsupervised Topic Clustering of Unlabelled Spoken Audio Using Self-Supervised Representation Learning and Topic Model\nTAPLoss: A Temporal Acoustic Parameter Loss for Speech Enhancement\nEnd-to-End Speech Recognition: A Survey\nThe Multimodal Information Based Speech Processing (Misp) 2022 Challenge: Audio-Visual Diarization And Recognition\nDPHuBERT: Joint Distillation and Pruning of Self-Supervised Speech Models\nAn external quality assessment feasibility study;",
  "Speech Enhancement\nEnd-to-End Speech Recognition: A Survey\nThe Multimodal Information Based Speech Processing (Misp) 2022 Challenge: Audio-Visual Diarization And Recognition\nDPHuBERT: Joint Distillation and Pruning of Self-Supervised Speech Models\nAn external quality assessment feasibility study; cross laboratory comparison of haemagglutination inhibition assay and microneutralization assay performance for seasonal influenza serology testing: A FLUCOP study\nMulti-Channel Speaker Extraction with Adversarial Training: The Wavlab Submission to The Clarity ICASSP 2023 Grand Challenge\nAV-SUPERB: A Multi-Task Evaluation Benchmark for Audio-Visual Representation Models\nImproving Cascaded Unsupervised Speech Translation with Denoising Back-translation\nDeep Speech Synthesis from MRI-Based Articulatory Representations\nFINDINGS OF THE IWSLT 2023 EVALUATION CAMPAIGN\nSpeech collage: code-switched audio generation by collaging monolingual corpora\nExploration on HuBERT with Multiple Resolutions\nA Randomized, Double-Blind,",
  "Double-Blind, Controlled Trial Assessing If Medium-Chain Triglycerides in Combination with Moderate-Intensity Exercise Increase Muscle Strength in Healthy Middle-Aged and Older Adults\nSemi-Autoregressive Streaming ASR With Label Context\nIntegrating Pretrained ASR and LM to Perform Sequence Generation for Spoken Language Understanding\nReducing Barriers to Self-Supervised Learning: HuBERT Pre-training with Academic Compute\nFindAdaptNet: Find and Insert Adapters by Learned Layer Importance\nCMU\u2019s IWSLT 2023 Simultaneous Speech Translation System\nExploration of Efficient End-to-End ASR using Discretized Input from Self-Supervised Learning\nIntegration of Frame- and Label-synchronous Beam Search for Streaming Encoder-decoder Speech Recognition\nE-Branchformer-Based E2E SLU Toward Stop on-Device Challenge\nIncremental Blockwise Beam Search for Simultaneous Speech Translation with Controllable Quality-Latency Tradeoff\nBayes Risk Transducer: Transducer with Controllable Alignment Prediction\nUniverSLU: Universal Spoken Language Understanding for Diverse Classification and Sequence Generation Tasks with a Single Network\nOne model to rule them all ?",
  "Towards End-to-End Joint Speaker Diarization and Speech Recognition\nAntiviral efficacy against and replicative fitness of an XBB.1.9.1 clinical isolate\nSoftware Design and User Interface of ESPnet-SE++: Speech Enhancement for Robust Speech Processing\nA Single Speech Enhancement Model Unifying Dereverberation, Denoising, Speaker Counting, Separation, And Extraction\nAntigenic drift and subtype interference shape A(H3N2) epidemic dynamics in the United States\nFindings of the 2023 ML-Superb Challenge: Pre-Training And Evaluation Over More Languages And Beyond\nMagnetic dynamics and nonreciprocal excitation in uniform hedgehog order in icosahedral 1/1 approximant crystal\nTorchAudio 2.1: Advancing Speech Recognition, Self-Supervised Learning, and Audio Processing Components for Pytorch\nEffect of medium-chain triglycerides supplements and walking on health-related quality of life in sedentary, healthy middle-aged, and older adults with low BMIs: a randomized, double-blind, placebo-controlled, parallel-group trial",
  "Title: Rita Singh -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Rita Singh, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Core Faculty\" name=\"categories-1\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Rita Singh - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Rita Singh, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Rita\"/>\n<meta content=\"Lastname\" property=\"profile:Singh\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/singh-rita.",
  "cmu.edu//people/faculty/singh-rita.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nRita \n                        Singh\nAssociate Research Professor, Language Technologies Institute\nContact\n6703 \u2014Gates & Hillman Centers\nrsingh(through)cs.cmu.edu\n412-268-9859\n\nLinks:",
  "Title: Ravi Starzl -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Ravi Starzl, Adjunct Faculty at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Adjunct Faculty\" name=\"categories-1\"/>\n<meta content=\"Ph.D.",
  "in Language and Information Technology\" name=\"degrees\"/>\n<meta content=\"Alumni;Faculty\" name=\"global-categories\"/>\n<meta content=\"Ravi Starzl - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Ravi Starzl, Adjunct Faculty at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Ravi\"/>\n<meta content=\"Lastname\" property=\"profile:Starzl\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/starzl-ravi.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nRavi \n                        Starzl\nAdjunct Professor, Language Technologies Institute\nContact\n6701 \u2014Gates & Hillman Centers\nrstarzl(through)andrew.cmu.edu\n412-268-8425\nEducation\nPh.D.",
  "in Language and Information Technology, CMU LTI\n2012\nDoctoral Thesis\n\nLinks:",
  "Title: Richard Stern -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Richard Stern, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Affiliated Faculty\" name=\"categories-1\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Richard Stern - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Richard Stern, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Richard\"/>\n<meta content=\"Lastname\" property=\"profile:Stern\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/stern-richard.",
  "cmu.edu//people/faculty/stern-richard.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nRichard \n                        Stern\nProfessor, Electrical and Computer Engineering\nContact\nB24 \u2014Baker-Porter Hall\nrs1e(through)andrew.cmu.edu\n412-268-2535\nResearch\nMy research interests involve a number of topics joined by the common threads of signal processing, sound, and acoustics. At present I am most actively working on topics related to automatic speech recognition and signal processing in the auditory system. I have also been involved in projects in the areas of biomedical instrumentation, particularly with regard to the auditory system, physical acoustics, computer music, and computer-aided instructional systems.\nAutomatic Speech Recognition.\nThe SCS speech group is developing speech technology that can perform unlimited-vocabulary speech recognition on a speaker-independent basis under difficult acoustical conditions.",
  "Automatic Speech Recognition.\nThe SCS speech group is developing speech technology that can perform unlimited-vocabulary speech recognition on a speaker-independent basis under difficult acoustical conditions. We are also developing practical applications that make use of spoken language interfaces to perform useful tasks.The major goal of my own work speech research is to enable CMU's SPHINX recognition system to become as robust to changes in acoustical environment and ambience as it is to changes in speaker. In particular, we must deal with problems in recognition accuracy resulting from additive noise sources, background music, competing talkers, change of microphone, and room reverberation. We are developing several different types of solutions for these problems including improved noise cancellation and speech normalization methods, the use of representations of the speech waveform that are based on the processing of sounds by the human auditory system, and the use of arrays of microphones to improve signal-to-noise ratio. In previous knowledge-based speech-recognition systems I had also worked on statistical classification, speaker adaptation, and the integration of syntactic, grammatic, and semantic information.\nSignal Processing in the Auditory System.",
  "In previous knowledge-based speech-recognition systems I had also worked on statistical classification, speaker adaptation, and the integration of syntactic, grammatic, and semantic information.\nSignal Processing in the Auditory System.\nThe general goal of this research has been to develop a better understanding of how the auditory system processes sound, to apply this knowledge to the treatment of various kinds of hearing impairments, and to apply this knowledge to the development of more robust speech recognition systems. I am presently carrying out psychoacoustical measurements of various aspects of monaural and binaural perception, and developing models based on communications theory and linear system theory to relate the results of these experiments to neural coding of sounds by the auditory system. Most of my work in hearing has been concerned with the localization of sound and other aspects of binaural perception.\n\nLinks:",
  "Title: Emma Strubell -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Emma Strubell, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Core Faculty\" name=\"categories-1\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Emma Strubell - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Emma Strubell, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Emma\"/>\n<meta content=\"Lastname\" property=\"profile:Strubell\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/strubell-emma.",
  "cmu.edu//people/faculty/strubell-emma.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nEmma \n                        Strubell\nAssistant Professor, Language Technologies Institute\nContact\n6709 \u2014Gates Hillman\nestrubel(through)andrew.cmu.edu\nPersonal Website\n\nLinks:\nhttps://strubell.github.io/",
  "Faculty Name: teruko mitamura\nMetadata:\nPaperid: 444737639aeea4e1e616509e368afb0bae8f89d6\nTitle: Language-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA\nYear: 2023\nAbstract: The DialDoc 2023 shared task has expanded the document-grounded dialogue task to encompass multiple languages, despite having limited annotated data. This paper assesses the effectiveness of both language-agnostic and language-aware paradigms for multilingual pre-trained transformer models in a bi-encoder-based dense passage retriever (DPR), concluding that the language-agnostic approach is superior. Additionally, the study investigates the impact of query rewriting techniques using large language models, such as ChatGPT, on multilingual, document-grounded question-answering systems. The experiments conducted demonstrate that, for the examples examined, query rewriting does not enhance performance compared to the original queries. This failure is due to topic switching in final dialogue turns and irrelevant topics being considered for query rewriting.",
  "The experiments conducted demonstrate that, for the examples examined, query rewriting does not enhance performance compared to the original queries. This failure is due to topic switching in final dialogue turns and irrelevant topics being considered for query rewriting.\nAuthors: Srinivas Gowriraj, Soham Dinesh Tiwari, Mitali Potnis, Srijan Bansal, T. Mitamura, Eric Nyberg\nVenue: Workshop on Document-grounded Dialogue and Conversational Question Answering\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper assesses the effectiveness of both language-agnostic and language-aware paradigms for multilingual pre-trained transformer models in a bi-encoder-based dense passage retriever (DPR), concluding that the language-gnostic approach is superior.'}",
  "Faculty Name: teruko mitamura\nMetadata:\nPaperid: ff77105b2c345f54e1a87f4fbb3a701201f0c1a8\nTitle: Hierarchical Event Grounding\nYear: 2023\nAbstract: Event grounding aims at linking mention references in text corpora to events from a knowledge base (KB). Previous work on this task focused primarily on linking to a single KB event, thereby overlooking the hierarchical aspects of events. Events in documents are typically described at various levels of spatio-temporal granularity. These hierarchical relations are utilized in downstream tasks of narrative understanding and schema construction. In this work, we present an extension to the event grounding task that requires tackling hierarchical event structures from the KB. Our proposed task involves linking a mention reference to a set of event labels from a subevent hierarchy in the KB. We propose a retrieval methodology that leverages event hierarchy through an auxiliary hierarchical loss. On an automatically created multilingual dataset from Wikipedia and Wikidata, our experiments demonstrate the effectiveness of the hierarchical loss against retrieve and re-rank baselines. Furthermore, we demonstrate the systems' ability to aid hierarchical discovery among unseen events.",
  "On an automatically created multilingual dataset from Wikipedia and Wikidata, our experiments demonstrate the effectiveness of the hierarchical loss against retrieve and re-rank baselines. Furthermore, we demonstrate the systems' ability to aid hierarchical discovery among unseen events. Code is available at https://github.com/JefferyO/Hierarchical-Event-Grounding\nAuthors: Jiefu Ou, Adithya Pratapa, Rishubh Gupta, T. Mitamura\nVenue: AAAI Conference on Artificial Intelligence\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work presents an extension to the event grounding task that requires tackling hierarchical event structures from the KB, and proposes a retrieval methodology that leverages event hierarchy through an auxiliary hierarchical loss.'}",
  "List of 2023 Open Access papers by teruko mitamura are:\nLanguage-Agnostic Transformers and Assessing ChatGPT-Based Query Rewriting for Multilingual Document-Grounded QA\nHierarchical Event Grounding",
  "List of 2023 Open Access papers by thomas schaaf are:",
  "Faculty Name: tom mitchell\nMetadata:\nPaperid: 0a2c3e734349232781eb95319dc41f8d8fb671a0\nTitle: SmartPlay : A Benchmark for LLMs as Intelligent Agents\nYear: 2023\nAbstract: Recent large language models (LLMs) have demonstrated great potential toward intelligent agents and next-gen automation, but there currently lacks a systematic benchmark for evaluating LLMs' abilities as agents. We introduce SmartPlay: both a challenging benchmark and a methodology for evaluating LLMs as agents. SmartPlay consists of 6 different games, including Rock-Paper-Scissors, Tower of Hanoi, Minecraft. Each game features a unique setting, providing up to 20 evaluation settings and infinite environment variations. Each game in SmartPlay uniquely challenges a subset of 9 important capabilities of an intelligent LLM agent, including reasoning with object dependencies, planning ahead, spatial reasoning, learning from history, and understanding randomness. The distinction between the set of capabilities each game test allows us to analyze each capability separately.",
  "Each game in SmartPlay uniquely challenges a subset of 9 important capabilities of an intelligent LLM agent, including reasoning with object dependencies, planning ahead, spatial reasoning, learning from history, and understanding randomness. The distinction between the set of capabilities each game test allows us to analyze each capability separately. SmartPlay serves not only as a rigorous testing ground for evaluating the overall performance of LLM agents but also as a road-map for identifying gaps in current methodologies. We release our benchmark at github.com/microsoft/SmartPlay\nAuthors: Yue Wu, Xuan Tang, Tom M. Mitchell, Yuanzhi Li\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': \"SmartPlay is introduced: both a challenging benchmark and a methodology for evaluating LLMs' abilities as agents, which consists of 6 different games, including Rock-Paper-Scissors, Tower of Hanoi, Minecraft, and understanding randomness.\"}",
  "Faculty Name: tom mitchell\nMetadata:\nPaperid: 49ead7feab9902199fb0c7c6ae3acd7ddfe3c6a7\nTitle: Teaching open and reproducible scholarship: a critical review of the evidence base for current pedagogical methods and their outcomes\nYear: 2023\nAbstract: In recent years, the scientific community has called for improvements in the credibility, robustness and reproducibility of research, characterized by increased interest and promotion of open and transparent research practices. While progress has been positive, there is a lack of consideration about how this approach can be embedded into undergraduate and postgraduate research training. Specifically, a critical overview of the literature which investigates how integrating open and reproducible science may influence student outcomes is needed. In this paper, we provide the first critical review of literature surrounding the integration of open and reproducible scholarship into teaching and learning and its associated outcomes in students. Our review highlighted how embedding open and reproducible scholarship appears to be associated with (i) students' scientific literacies (i.e. students\u2019 understanding of open research, consumption of science and the development of transferable skills); (ii) student engagement (i.e.",
  "Our review highlighted how embedding open and reproducible scholarship appears to be associated with (i) students' scientific literacies (i.e. students\u2019 understanding of open research, consumption of science and the development of transferable skills); (ii) student engagement (i.e. motivation and engagement with learning, collaboration and engagement in open research) and (iii) students' attitudes towards science (i.e. trust in science and confidence in research findings). However, our review also identified a need for more robust and rigorous methods within pedagogical research, including more interventional and experimental evaluations of teaching practice. We discuss implications for teaching and learning scholarship.\nAuthors: Madeleine Pownall, F. Azevedo, L. M. K\u00f6nig, Hannah R. Slack, T. Evans, Zoe M. Flack, Sandra Grinschgl, M. Elsherif, K. Gilligan-Lee, Catia M. F. de Oliveira, B. Gjoneska, T. Kalandadze, K. Button, Sarah Ashcroft-Jones, Janet L. Terry, Nihan Albayrak\u2010Aydemir, F. D\u011bcht\u011brenko,",
  "Gilligan-Lee, Catia M. F. de Oliveira, B. Gjoneska, T. Kalandadze, K. Button, Sarah Ashcroft-Jones, Janet L. Terry, Nihan Albayrak\u2010Aydemir, F. D\u011bcht\u011brenko, Shilaan Alzahawi, Bradley J. Baker, M. Pittelkow, Lydia Riedl, Kathleen Schmidt, C. Pennington, John J. Shaw, Timo L\u00fcke, Matthew C. Makel, Helena Hartmann, Mirela Zaneva, Daniel Walker, S. Verheyen, Daniel Cox, Jennifer Mattschey, Tom Gallagher-Mitchell, P. Branney, Y. Weisberg, Kamil Izydorczak, Ali H. Al\u2010Hoorie, Ann-Marie Creaven, S. Stewart, Kai Krautter, K. Matvienko-Sikar, S. Westwood, Patr\u00edcia Arriaga, Meng Liu, Myriam A. Baum, Tobias Wingen, R. M. Ross, Aoife O'Mahony, Agata Bochynska, M. Jamieson,",
  "K. Matvienko-Sikar, S. Westwood, Patr\u00edcia Arriaga, Meng Liu, Myriam A. Baum, Tobias Wingen, R. M. Ross, Aoife O'Mahony, Agata Bochynska, M. Jamieson, Myrthe Vel Tromp, S. Yeung, Martin R. Vasilev, A. Gourdon-Kanhukamwe, L. Micheli, M. Konkol, David Moreau, James E. Bartlett, Kait Clark, G. Brekelmans, T. Gkinopoulos, S. Tyler, J. P. R\u00f6er, Zlatomira G. Ilchovska, C. Madan, Olly Robertson, Bethan J. Iley, Samuel Guay, Martina Sladekova, S. Sadhwani\nVenue: Royal Society Open Science\nTldr: None",
  "Faculty Name: tom mitchell\nMetadata:\nPaperid: 5b7dcf469c285381a83b1bfd85d2b22da121e0cc\nTitle: Ruffle&Riley: Towards the Automated Induction of Conversational Tutoring Systems\nYear: 2023\nAbstract: Conversational tutoring systems (CTSs) offer learning experiences driven by natural language interaction. They are known to promote high levels of cognitive engagement and benefit learning outcomes, particularly in reasoning tasks. Nonetheless, the time and cost required to author CTS content is a major obstacle to widespread adoption. In this paper, we introduce a novel type of CTS that leverages the recent advances in large language models (LLMs) in two ways: First, the system induces a tutoring script automatically from a lesson text. Second, the system automates the script orchestration via two LLM-based agents (Ruffle&Riley) with the roles of a student and a professor in a learning-by-teaching format. The system allows a free-form conversation that follows the ITS-typical inner and outer loop structure.",
  "Second, the system automates the script orchestration via two LLM-based agents (Ruffle&Riley) with the roles of a student and a professor in a learning-by-teaching format. The system allows a free-form conversation that follows the ITS-typical inner and outer loop structure. In an initial between-subject online user study (N = 100) comparing Ruffle&Riley to simpler QA chatbots and reading activity, we found no significant differences in post-test scores. Nonetheless, in the learning experience survey, Ruffle&Riley users expressed higher ratings of understanding and remembering and further perceived the offered support as more helpful and the conversation as coherent. Our study provides insights for a new generation of scalable CTS technologies.\nAuthors: Robin Schmucker, Meng Xia, A. Azaria, Tom Mitchell\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A novel type of CTS that leverages the recent advances in large language models (LLMs) and automates the script orchestration via two LLM-based agents (Ruffle&Riley) with the roles of a student and a professor in a learning-by-teaching format is introduced.'}",
  "Faculty Name: tom mitchell\nMetadata:\nPaperid: 5b8eaeee3a4bb4de7ab2ad573be33477828e7966\nTitle: Neuropilin-1 interacts with VE-cadherin and TGFBR2 to stabilize adherens junctions and prevent activation of endothelium under flow\nYear: 2023\nAbstract: Linear and disturbed flow differentially regulate gene expression, with disturbed flow priming endothelial cells (ECs) for a proinflammatory, atheroprone expression profile and phenotype. Here, we investigated the role of the transmembrane protein neuropilin-1 (NRP1) in ECs exposed to flow using cultured ECs, mice with an endothelium-specific knockout of NRP1, and a mouse model of atherosclerosis. We demonstrated that NRP1 was a constituent of adherens junctions that interacted with VE-cadherin and promoted its association with p120 catenin, stabilizing adherens junctions and inducing cytoskeletal remodeling in alignment with the direction of flow.",
  "We demonstrated that NRP1 was a constituent of adherens junctions that interacted with VE-cadherin and promoted its association with p120 catenin, stabilizing adherens junctions and inducing cytoskeletal remodeling in alignment with the direction of flow. We also showed that NRP1 interacted with transforming growth factor\u2013\u03b2 (TGF-\u03b2) receptor II (TGFBR2) and reduced the plasma membrane localization of TGFBR2 and TGF-\u03b2 signaling. NRP1 knockdown increased the abundance of proinflammatory cytokines and adhesion molecules, resulting in increased leukocyte rolling and atherosclerotic plaque size. These findings describe a role for NRP1 in promoting endothelial function and reveal a mechanism by which NRP1 reduction in ECs may contribute to vascular disease by modulating adherens junction signaling and promoting TGF-\u03b2 signaling and inflammation. Description The barrier function and quiescence of the endothelium are supported by transmembrane protein NRP1. Maintaining a quiescent endothelium Atherosclerosis causes disturbed blood flow that activates inflammatory pathways in endothelial cells, which attracts leukocytes to plaques and exacerbates disease progression.",
  "Description The barrier function and quiescence of the endothelium are supported by transmembrane protein NRP1. Maintaining a quiescent endothelium Atherosclerosis causes disturbed blood flow that activates inflammatory pathways in endothelial cells, which attracts leukocytes to plaques and exacerbates disease progression. Bosseboeuf et al. investigated the role of the transmembrane protein NRP1 in the response of the endothelium to flow. Under normal flow patterns, NRP1 stabilized protein complexes at cell-cell junctions called adherens junctions and suppressed endothelial inflammation. In mice, NRP1 deficiency was associated with greater numbers of rolling leukocytes on endothelial cells in vitro and in vivo and larger plaque sizes in a model of atherosclerosis. Thus, NRP1 maintains the endothelium in a quiescent state and may limit inflammation in the endothelium under the disturbed blood flow patterns that are characteristic of atherosclerosis.",
  "Thus, NRP1 maintains the endothelium in a quiescent state and may limit inflammation in the endothelium under the disturbed blood flow patterns that are characteristic of atherosclerosis. \u2014WW\nAuthors: Emy Bosseboeuf, Anissa Chikh, A. B. Chaker, T. P. Mitchell, Dhilakshani Vignaraja, Ridhi Rajendrakumar, R. Khambata, T. Nightingale, Justin Charles Mason, A. Randi, A. Ahluwalia, C. Raimondi\nVenue: Science Signaling\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A role for NRP1 in promoting endothelial function is described and a mechanism by which N RP1 reduction in ECs may contribute to vascular disease by modulating adherens junction signaling and promoting TGF-\u03b2 signaling and inflammation is revealed.'}",
  "Faculty Name: tom mitchell\nMetadata:\nPaperid: 5ce2f1dff23a5620f77f9b11f1e534422ab8ff3f\nTitle: Plan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents\nYear: 2023\nAbstract: Pre-trained large language models (LLMs) capture procedural knowledge about the world. Recent work has leveraged LLM's ability to generate abstract plans to simplify challenging control tasks, either by action scoring, or action modeling (fine-tuning). However, the transformer architecture inherits several constraints that make it difficult for the LLM to directly serve as the agent: e.g. limited input lengths, fine-tuning inefficiency, bias from pre-training, and incompatibility with non-text environments. To maintain compatibility with a low-level trainable actor, we propose to instead use the knowledge in LLMs to simplify the control problem, rather than solving it. We propose the Plan, Eliminate, and Track (PET) framework. The Plan module translates a task description into a list of high-level sub-tasks.",
  "We propose the Plan, Eliminate, and Track (PET) framework. The Plan module translates a task description into a list of high-level sub-tasks. The Eliminate module masks out irrelevant objects and receptacles from the observation for the current sub-task. Finally, the Track module determines whether the agent has accomplished each sub-task. On the AlfWorld instruction following benchmark, the PET framework leads to a significant 15% improvement over SOTA for generalization to human goal specifications.\nAuthors: Yue Wu, So Yeon Min, Yonatan Bisk, R. Salakhutdinov, A. Azaria, Yuan-Fang Li, Tom M. Mitchell, Shrimai Prabhumoye\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A framework to use the knowledge in LLMs to simplify the control problem, rather than solving it is proposed, which leads to a significant 15% improvement over SOTA for generalization to human goal specifications.'}",
  "Faculty Name: tom mitchell\nMetadata:\nPaperid: 61678a9f1d8291bb0f3d704a439ac8cd64fa6482\nTitle: Read and Reap the Rewards: Learning to Play Atari with the Help of Instruction Manuals\nYear: 2023\nAbstract: High sample complexity has long been a challenge for RL. On the other hand, humans learn to perform tasks not only from interaction or demonstrations, but also by reading unstructured text documents, e.g., instruction manuals. Instruction manuals and wiki pages are among the most abundant data that could inform agents of valuable features and policies or task-specific environmental dynamics and reward structures. Therefore, we hypothesize that the ability to utilize human-written instruction manuals to assist learning policies for specific tasks should lead to a more efficient and better-performing agent. We propose the Read and Reward framework. Read and Reward speeds up RL algorithms on Atari games by reading manuals released by the Atari game developers. Our framework consists of a QA Extraction module that extracts and summarizes relevant information from the manual and a Reasoning module that evaluates object-agent interactions based on information from the manual.",
  "Read and Reward speeds up RL algorithms on Atari games by reading manuals released by the Atari game developers. Our framework consists of a QA Extraction module that extracts and summarizes relevant information from the manual and a Reasoning module that evaluates object-agent interactions based on information from the manual. An auxiliary reward is then provided to a standard A2C RL agent, when interaction is detected. Experimentally, various RL algorithms obtain significant improvement in performance and training speed when assisted by our design.\nAuthors: Yue Wu, Yewen Fan, P. Liang, A. Azaria, Yuan-Fang Li, Tom Michael Mitchell\nVenue: Neural Information Processing Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is hypothesized that the ability to utilize human-written instruction manuals to assist learning policies for specific tasks should lead to a more efficient and better-performing agent in the Read and Reward framework.'}",
  "Faculty Name: tom mitchell\nMetadata:\nPaperid: 8874cd8cb99d00e133fba10454e5e5e64f38ca85\nTitle: Learning to Give Useful Hints: Assistance Action Evaluation and Policy Improvements\nYear: 2023\nAbstract: None\nAuthors: Robin Schmucker, Nimish Pachapurkar, Bala Shanmugam, Miral Shah, Tom Michael Mitchell\nVenue: European Conference on Technology Enhanced Learning\nTldr: None",
  "Faculty Name: tom mitchell\nMetadata:\nPaperid: 9fb2386f331b89202364e0f24553ed193c6bbd6d\nTitle: H2 generated by fermentation in the human gut microbiome influences metabolism and competitive fitness of gut butyrate producers\nYear: 2023\nAbstract: None\nAuthors: Austin Campbell, K. Gdanetz, A. Schmidt, T. Schmidt\nVenue: Microbiome\nTldr: {'model': 'tldr@v2.0.0', 'text': 'H_2 is a regulator of fermentation in the human gut microbiome and stimulates production of the anti-inflammatory metabolite butyrate, which is of particular interest due to its role as a mediator of colonic health through anti- inflammatory and anti-carcinogenic properties.'}",
  "Faculty Name: tom mitchell\nMetadata:\nPaperid: a2158d6705420f9e2958e2033e85380cbb54f843\nTitle: FLAIRR-Seq: A Method for Single-Molecule Resolution of Near Full-Length Antibody H Chain Repertoires.\nYear: 2023\nAbstract: Current Adaptive Immune Receptor Repertoire sequencing (AIRR-seq) using short-read sequencing strategies resolve expressed Ab transcripts with limited resolution of the C region. In this article, we present the near-full-length AIRR-seq (FLAIRR-seq) method that uses targeted amplification by 5' RACE, combined with single-molecule, real-time sequencing to generate highly accurate (99.99%) human Ab H chain transcripts. FLAIRR-seq was benchmarked by comparing H chain V (IGHV), D (IGHD), and J (IGHJ) gene usage, complementarity-determining region 3 length, and somatic hypermutation to matched datasets generated with standard 5' RACE AIRR-seq using short-read sequencing and full-length isoform sequencing.",
  "Together, these data demonstrate robust FLAIRR-seq performance using RNA samples derived from PBMCs, purified B cells, and whole blood, which recapitulated results generated by commonly used methods, while additionally resolving H chain gene features not documented in IMGT at the time of submission. FLAIRR-seq data provide, for the first time, to our knowledge, simultaneous single-molecule characterization of IGHV, IGHD, IGHJ, and IGHC region genes and alleles, allele-resolved subisotype definition, and high-resolution identification of class switch recombination within a clonal lineage. In conjunction with genomic sequencing and genotyping of IGHC genes, FLAIRR-seq of the IgM and IgG repertoires from 10 individuals resulted in the identification of 32 unique IGHC alleles, 28 (87%) of which were previously uncharacterized. Together, these data demonstrate the capabilities of FLAIRR-seq to characterize IGHV, IGHD, IGHJ, and IGHC gene diversity for the most comprehensive view of bulk-expressed Ab repertoires to date.",
  "Together, these data demonstrate the capabilities of FLAIRR-seq to characterize IGHV, IGHD, IGHJ, and IGHC gene diversity for the most comprehensive view of bulk-expressed Ab repertoires to date.\nAuthors: EA Ford, David Tieri, O. Rodriguez, Nancy J Francoeur, J. Soto, Justin T. Kos, Ayelet Peres, William S. Gibson, Catherine A. Silver, G. Deikus, E. Hudson, C. Woolley, N. Beckmann, A. Charney, T. Mitchell, Gur Yaari, R. Sebra, C. Watson, M. Smith\nVenue: Journal of Immunology\nTldr: {'model': 'tldr@v2.0.0', 'text': \"Near-full-length AIRR-seq method that uses targeted amplification by 5' RACE, combined with single-molecule, real-time sequencing to generate highly accurate (99.99%) human Ab H chain transcripts is presented.\"}",
  "Faculty Name: tom mitchell\nMetadata:\nPaperid: a71809bc20c51fc047eff57d3d1abce2aec978d3\nTitle: The Roles of Symbols in Neural-based AI: They are Not What You Think!\nYear: 2023\nAbstract: None\nAuthors: D. Silver, Tom M. Mitchell\nVenue: International Workshop on Neural-Symbolic Learning and Reasoning\nTldr: None",
  "Faculty Name: tom mitchell\nMetadata:\nPaperid: ad31573be48f5b87ade2f838d75e071e686bf296\nTitle: The unconventional Myosin-1C augments endothelial secretion of von Willebrand factor by linking contractile actomyosin machinery to the plasma membrane\nYear: 2023\nAbstract: Blood endothelial cells control the hemostatic and inflammatory response by secreting von Willebrand factor (VWF) and P-selectin from storage organelles called Weibel-Palade bodies (WPB). Actin-associated motor proteins regulate this secretory pathway at multiple points. Prior to fusion, myosin Va forms a complex that anchors WPBs to peripheral actin structures allowing maturation of content. Post-fusion, an actomyosin ring/coat is recruited and compresses to forcibly expel the largest VWF multimers. Here we provide the first evidence for the involvement of class I myosins during regulated VWF secretion.",
  "Post-fusion, an actomyosin ring/coat is recruited and compresses to forcibly expel the largest VWF multimers. Here we provide the first evidence for the involvement of class I myosins during regulated VWF secretion. We show that unconventional myosin-1C (Myo1c) is recruited post fusion via its pleckstrin homology domain in an actin-independent process providing a link between the actin ring and phosphatidylinositol 4,5-bisphosphate (PIP2) at the membrane of the fused organelle. This is necessary to ensure maximal VWF secretion in response to secretagogue stimulation. Inhibition of class I myosins using the inhibitor Pentachloropseudilin alters the kinetics of the exocytic actin ring. These data offer new insight into the control of an essential physiological process and provide a new potential way in which it might be therapeutically controlled. SIGNFICANCE STATEMENT Myosin motors play diverse roles in regulated secretion. In endothelial cells, the role of conventional myosins (e.g.",
  "SIGNFICANCE STATEMENT Myosin motors play diverse roles in regulated secretion. In endothelial cells, the role of conventional myosins (e.g. non-muscle myosin II) are well described however little is known about the requirement of unconventional myosins. Our data identify an important function of the class 1 myosin, Myosin-1C, in the actomyosin mediated expulsion of an essential blood clotting factor (von Willebrand factor) from endothelial cells. This is the first description of how class 1 myosins contribute to primary hemostasis and is therefore greatly improves our understanding of a fundamental physiological process.\nAuthors: S. El-Mansi, T. P. Mitchell, P. Miklavc, M. Frick, T. Nightingale\nVenue: bioRxiv\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The data identify an important function of the class 1 myosin, Myosin-1C, in the actomyosin mediated expulsion of an essential blood clotting factor (von Willebrand factor) from endothelial cells.'}",
  "Faculty Name: tom mitchell\nMetadata:\nPaperid: e44cae12e4d97c9032cabd7bff1e138b7b8e1506\nTitle: Synthetic biology open language (SBOL) version 3.1.0\nYear: 2023\nAbstract: Abstract Synthetic biology builds upon genetics, molecular biology, and metabolic engineering by applying engineering principles to the design of biological systems. When designing a synthetic system, synthetic biologists need to exchange information about multiple types of molecules, the intended behavior of the system, and actual experimental measurements. The Synthetic Biology Open Language (SBOL) has been developed as a standard to support the specification and exchange of biological design information in synthetic biology, following an open community process involving both bench scientists and scientific modelers and software developers, across academia, industry, and other institutions. This document describes SBOL 3.1.0, which improves on version 3.0.0 by including a number of corrections and clarifications as well as several other updates and enhancements. First, this version includes a complete set of validation rules for checking whether documents are valid SBOL 3.",
  "This document describes SBOL 3.1.0, which improves on version 3.0.0 by including a number of corrections and clarifications as well as several other updates and enhancements. First, this version includes a complete set of validation rules for checking whether documents are valid SBOL 3. Second, the best practices section has been moved to an online repository that allows for more rapid and interactive of sharing these conventions. Third, it includes updates based upon six community approved enhancement proposals. Two enhancement proposals are related to the representation of an object\u2019s namespace. In particular, the Namespace class has been removed and replaced with a namespace property on each class. Another enhancement is the generalization of the CombinatorialDeriviation class to allow direct use of Features and Measures. Next, the Participation class now allow Interactions to be participants to describe higher-order interactions. Another change is the use of Sequence Ontology terms for Feature orientation. Finally, this version of SBOL has generalized from using Unique Reference Identifiers (URIs) to Internationalized Resource Identifiers (IRIs) to support international character sets.",
  "Another change is the use of Sequence Ontology terms for Feature orientation. Finally, this version of SBOL has generalized from using Unique Reference Identifiers (URIs) to Internationalized Resource Identifiers (IRIs) to support international character sets.\nAuthors: Lukas Buecherl, Tom Mitchell, James Scott-Brown, P. Vaidyanathan, G. Vidal, Hasan Baig, Bryan A. Bartley, Jacob Beal, Matthew Crowther, P. Fontanarrosa, T. Gorochowski, Raik Gr\u00fcnberg, V. Kulkarni, James Alastair McLaughlin, Goksel Misirli, Ernst Oberortner, A. Wipat, C. Myers\nVenue: Journal of Integrative Bioinformatics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This document describes SBOL 3.1.0, which improves on version 3.0 by including a number of corrections and clarifications as well as several other updates and enhancements.'}",
  "Faculty Name: tom mitchell\nMetadata:\nPaperid: e98e4af918f3ad0f6ea65f2c68e2846a5b7eb333\nTitle: Genitourinary Management and Follow-Up for Patients with Stevens-Johnson Syndrome/Toxic Epidermal Necrolysis\nYear: 2023\nAbstract: None\nAuthors: Gina T. Baaklini, Tom Michael Mitchell, Jordan Davis, Kevin McGovern, J. Aden, L. Cancio\nVenue: Burns Open\nTldr: None",
  "Faculty Name: tom mitchell\nMetadata:\nPaperid: f406aceba4f29cc7cfbe7edb2f52f01374486589\nTitle: The Internal State of an LLM Knows When its Lying\nYear: 2023\nAbstract: While Large Language Models (LLMs) have shown exceptional performance in various tasks, one of their most prominent drawbacks is generating inaccurate or false information with a confident tone. In this paper, we provide evidence that the LLM's internal state can be used to reveal the truthfulness of statements. This includes both statements provided to the LLM, and statements that the LLM itself generates. Our approach is to train a classifier that outputs the probability that a statement is truthful, based on the hidden layer activations of the LLM as it reads or generates the statement. Experiments demonstrate that given a set of test sentences, of which half are true and half false, our trained classifier achieves an average of 71\\% to 83\\% accuracy labeling which sentences are true versus false, depending on the LLM base model. Furthermore, we explore the relationship between our classifier's performance and approaches based on the probability assigned to the sentence by the LLM.",
  "Furthermore, we explore the relationship between our classifier's performance and approaches based on the probability assigned to the sentence by the LLM. We show that while LLM-assigned sentence probability is related to sentence truthfulness, this probability is also dependent on sentence length and the frequencies of words in the sentence, resulting in our trained classifier providing a more reliable approach to detecting truthfulness, highlighting its potential to enhance the reliability of LLM-generated content and its practical applicability in real-world scenarios.\nAuthors: A. Azaria, Tom M. Mitchell\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': \"Evidence that the LLM's internal state can be used to reveal the truthfulness of statements is provided, highlighting its potential to enhance the reliability of LLM-generated content and its practical applicability in real-world scenarios.\"}",
  "Faculty Name: tom mitchell\nMetadata:\nPaperid: f456c96e97252f0f567d61f154ad59552621fc6a\nTitle: Fumarate induces vesicular release of mtDNA to drive innate immunity\nYear: 2023\nAbstract: None\nAuthors: V. Zecchini, Vincent Paupe, Irene Herranz-Montoya, Jo\u00eblle J E Janssen, Inge M. N. Wortel, Jordan L. Morris, Ashley N. Ferguson, Suvagata Roy Chowdury, Marc Segarra-Mondejar, Ana S. H. Costa, Gon\u00e7alo C. Pereira, L. Tronci, T. Young, Efterpi Nikitopoulou, Ming Yang, D. Bihary, F. Caicci, Shun Nagashima, Alyson Speed, K. Bokea, Zara Baig, S. Samarajiwa, M. Tran, T. Mitchell, Mark H. Johnson, J. Prudent, C. Frezza\nVenue: Nature\nTldr: {'model': 'tldr@v2.0.0',",
  "Alyson Speed, K. Bokea, Zara Baig, S. Samarajiwa, M. Tran, T. Mitchell, Mark H. Johnson, J. Prudent, C. Frezza\nVenue: Nature\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is shown that increased levels of intracellular fumarate induce a remodelling of the mitochondrial network and the generation of mitochondrial-derived vesicles, which allows the release of mtDNA into the cytosol and subsequent activation of the innate immune response.'}",
  "List of 2023 Open Access papers by tom mitchell are:\nPlan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents\nThe Roles of Symbols in Neural-based AI: They are Not What You Think!",
  "List of 2023 Open Access papers by tom mitchell are:\nPlan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents\nThe Roles of Symbols in Neural-based AI: They are Not What You Think!\nThe Internal State of an LLM Knows When its Lying\nNeuropilin-1 interacts with VE-cadherin and TGFBR2 to stabilize adherens junctions and prevent activation of endothelium under flow\nThe unconventional Myosin-1C augments endothelial secretion of von Willebrand factor by linking contractile actomyosin machinery to the plasma membrane\nRuffle&Riley: Towards the Automated Induction of Conversational Tutoring Systems\nSynthetic biology open language (SBOL) version 3.1.0\nRead and Reap the Rewards: Learning to Play Atari with the Help of Instruction Manuals\nLearning to Give Useful Hints: Assistance Action Evaluation and Policy Improvements\nGenitourinary Management and Follow-Up for Patients with Stevens-Johnson Syndrome/Toxic Epidermal Necrolysis\nFumarate induces vesicular release of mtDNA to drive innate immunity\nFLAIRR-Seq: A Method for Single-Molecule Resolution of Near Full-Length Antibody H Chain Repertoires.",
  "Teaching open and reproducible scholarship: a critical review of the evidence base for current pedagogical methods and their outcomes\nSmartPlay : A Benchmark for LLMs as Intelligent Agents\nH2 generated by fermentation in the human gut microbiome influences metabolism and competitive fitness of gut butyrate producers",
  "Title: Yulia Tsvetkov -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Yulia Tsvetkov, Adjunct Faculty at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Adjunct Faculty\" name=\"categories-1\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Yulia Tsvetkov - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Yulia Tsvetkov, Adjunct Faculty at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Yulia\"/>\n<meta content=\"Lastname\" property=\"profile:Tsvetkov\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/tsvetkov-yulia.",
  "cmu.edu//people/faculty/tsvetkov-yulia.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nYulia \n                        Tsvetkov\nAssistant Professor, University of Washington\nContact\nyuliats(through)cs.washington.edu\nPersonal Website\n\nLinks:\nhttps://homes.cs.washington.edu/~yuliats/",
  "Title: Alexander Waibel -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Alexander Waibel, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Core Faculty\" name=\"categories-1\"/>\n<meta content=\"Machine Learning;Machine Translation;Multimodal Computing and Interaction;Neural Networks;Speech Processing;Spoken Interfaces and Dialogue Processing;Spoken Language Translation\" name=\"categories-2\"/>\n<meta content=\"Yes\" name=\"show-categories-2\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Alexander Waibel - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Alexander Waibel,",
  "Faculty Member at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Alexander\"/>\n<meta content=\"Lastname\" property=\"profile:Waibel\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/waibel-alexander.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nAlexander \n                        Waibel\nProfessor (On Leave), Language Technologies Institute\nContact\n205 \u2014407 South Craig Street\nwaibel(through)cs.cmu.edu\n412-268-7676\nResearch Area\nMachine Learning, Machine Translation, Multimodal Computing and Interaction, Neural Networks, Speech Processing, Spoken Interfaces and Dialogue Processing, Spoken Language Translation\nBio\nDr. Alexander Waibel is a Professor of Computer Science at Carnegie Mellon University, Pittsburgh and at the Karlsruhe Institute of Technology, Germany.",
  "Machine Translation, Multimodal Computing and Interaction, Neural Networks, Speech Processing, Spoken Interfaces and Dialogue Processing, Spoken Language Translation\nBio\nDr. Alexander Waibel is a Professor of Computer Science at Carnegie Mellon University, Pittsburgh and at the Karlsruhe Institute of Technology, Germany. He is the director of the International Center for Advanced Communication Technologies (interACT). The Center works in a network with eight of the world\u2019s top research institutions. The Center\u2019s mission is to develop advanced machine learning algorithms to improve human-human and human-machine communication technologies. \u00a0Prof. Waibel and his team developed many statistical and neural network learning \u00a0algorithms that made such communication breakthroughs possible. Most notably, the \u201cTime-Delay Neural Network\u201d (1987) (the first \u201cconvolutional\u201d neural network) now is at the heart of many of today\u2019s AI technologies. System breakthroughs at Waibel\u2019s lab included early multimodal interfaces, speech and language interfaces, the first speech translation system in Europe & USA (1990/1991), the first simultaneous lecture translation system (2005), and Jibbigo, the first commercial speech translator on a phone (2009).\nDr.",
  "Dr. Waibel founded and served as chairmen of C-STAR, the Consortium for Speech Translation Advanced Research in 1991. He directed many research programs in speech, translation, multimodal interfaces and machine learning in the US, Europe and Asia. He served as director of EU-Bridge (2012-2015) and CHIL (2004-2007), two large European multi-site Integrated Project initiatives on intelligent assistants and speech translation services. He also was co-director of IMMI, a joint venture between KIT, CNRS & RWTH.\nDr. Waibel is an IEEE Fellow and received many awards for his work on multilingual and multimodal communication \u00a0and translation. He published extensively (>750 publications, >25,000 citations, h-index 80) in the field and received/filed numerous patents. Waibel was elected to the National Academy of Sciences of Germany in 2017, and was named Honorary Senator of the Hochschulrektorenkonferenz (Representation of German Universities).\nDuring his career, Dr. Waibel founded and built ten successful companies.",
  "Waibel was elected to the National Academy of Sciences of Germany in 2017, and was named Honorary Senator of the Hochschulrektorenkonferenz (Representation of German Universities).\nDuring his career, Dr. Waibel founded and built ten successful companies. Following the acquisition of Jibbigo by Facebook, Waibel served as founding director of the Language Technology Group at FB. He also deployed speech translation technologies in humanitarian and disaster relief missions. His team recently deployed the first simultaneous interpretation service for lectures at Universities and interpretation tools at the European Parliament.\nEducation\nDr. Waibel received his BS, MS and PhD degrees at Massachusetts Institute of Technology and CMU, respectively.\nPersonal Website\n\nLinks:\nhttps://www.cs.cmu.edu/~ahw/",
  "Title: Shinji Watanabe -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Shinji Watanabe, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Core Faculty\" name=\"categories-1\"/>\n<meta content=\"Natural Language Processing and Computational Linguistics;Speech Processing\" name=\"categories-2\"/>\n<meta content=\"Yes\" name=\"show-categories-2\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Shinji Watanabe - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Shinji Watanabe,",
  "Faculty Member at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Shinji\"/>\n<meta content=\"Lastname\" property=\"profile:Watanabe\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/watanabe-shinji.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nShinji \n                        Watanabe\nAssociate Professor, Language Technologies Institute\nContact\n6405 \u2014Gates & Hillman Centers\nswatanab(through)andrew.cmu.edu\n412-268-3687\nResearch Area\nNatural Language Processing and Computational Linguistics, Speech Processing\nPersonal Website\n\nLinks:\nhttps://sites.google.com/view/shinjiwatanabe?pli=1",
  "Title: Sean Welleck -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio page for Sean Welleck\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Core Faculty\" name=\"categories-1\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Sean Welleck - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio page for Sean Welleck\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Sean\"/>\n<meta content=\"Lastname\" property=\"profile:Welleck\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/welleck-sean.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.",
  "cmu.edu//people/faculty/welleck-sean.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nSean \n                        Welleck\nAssistant Professor, Language Technologies Institute\nContact\nswelleck(through)andrew.cmu.edu\nAddress\n5000 Forbes Avenue\nPittsburgh, PA 15213\n\nLinks:",
  "Faculty Name: william cohen\nMetadata:\nPaperid: 298be27bcc36e8a433a2f60bb2023a08b83d81b1\nTitle: Cardiothoracic Surgery Training: An Honest and Anonymous Assessment of the Trainee Experience\nYear: 2023\nAbstract: None\nAuthors: Fatima G Wilder, Jason J. Han, William G Cohen, C. Louis, J. Mehaffey, A. Brescia, D. Blitzer, Jessica GY Luc, G. Coyan, Jordan P. Bloom, M. Cevasco, Ahmet Kilic\nVenue: Journal of Surgical Research\nTldr: None",
  "Faculty Name: william cohen\nMetadata:\nPaperid: 2ca8e50ffd6e2e67f3fe2fbf1af57dbedb4cf493\nTitle: Answering Ambiguous Questions with a Database of Questions, Answers, and Revisions\nYear: 2023\nAbstract: Many open-domain questions are under-specified and thus have multiple possible answers, each of which is correct under a different interpretation of the question. Answering such ambiguous questions is challenging, as it requires retrieving and then reasoning about diverse information from multiple passages. We present a new state-of-the-art for answering ambiguous questions that exploits a database of unambiguous questions generated from Wikipedia. On the challenging ASQA benchmark, which requires generating long-form answers that summarize the multiple answers to an ambiguous question, our method improves performance by 15% (relative improvement) on recall measures and 10% on measures which evaluate disambiguating questions from predicted outputs. Retrieving from the database of generated questions also gives large improvements in diverse passage retrieval (by matching user questions q to passages p indirectly, via questions q' generated from p).",
  "Retrieving from the database of generated questions also gives large improvements in diverse passage retrieval (by matching user questions q to passages p indirectly, via questions q' generated from p).\nAuthors: Haitian Sun, William W. Cohen, R. Salakhutdinov\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A new state-of-the-art for answering ambiguous questions that exploits a database of unambiguous questions generated from Wikipedia, which improves performance by 15% (relative improvement) on recall measures and 10% on measures which evaluate disambiguating questions from predicted outputs.'}",
  "Faculty Name: william cohen\nMetadata:\nPaperid: 544726071e498e6178ac131cff09091bdf712b9b\nTitle: Orbital Hybridization and Hypersensitivity of Eu3+ in YXO4 (X=P, As, V)\nYear: 2023\nAbstract: \n A comparative study of Eu3+ ion luminescence in YXO4 (X=P, As, V) with the tetragonal zircon structure is conducted in relation to the intensity of the hypersensitivity 5D0\uf0ae7F2 (\u2206J=2) transition. Both the asymmetry ratio, R=(I(5_(D_0 )-7_(F_2 )))/(I(5_(D_0 )-7_(F_1 ))), and the Judd-Ofelt \uf0572 intensity parameter increases in the order YPO4 < YAsO4 < YVO4. This correlation is interpreted qualitatively in terms of the covalency and polarizability of (XO4)3-, which increases in the order (PO4)3- < (AsO4)3- < (VO4)3-.",
  "This correlation is interpreted qualitatively in terms of the covalency and polarizability of (XO4)3-, which increases in the order (PO4)3- < (AsO4)3- < (VO4)3-. The trend is supported by the results of electronic band structure calculations of the three compounds which establish the strength of hybridization between the X cation and the oxygen 2p states. The electronic structure of YAsO4 is calculated to probe the covalence of As-O bonding. The increasing oscillator strength of the Eu3+ 5D0\uf0ae7F2 transition in going from YPO4 to YAsO4 to YVO4 is consistent with the expectation of ligand dipolar polarization model for hypersensitivity which states that the oscillator strength of the 5D0\uf0ae7F2 transition is proportional to the square of the ligand dipolar polarizability. The connection between the mechanism of hypersensitivity and second harmonic generation (SHG) is presented.",
  "The connection between the mechanism of hypersensitivity and second harmonic generation (SHG) is presented.\nAuthors: A. Srivastava, M. Brik, W. Beers, B. Lou, Chonggeng Ma, M. Piasecki, W. Cohen\nVenue: ECS Journal of Solid State Science and Technology\nTldr: None",
  "Faculty Name: william cohen\nMetadata:\nPaperid: 5db8c4cc8742f410d6c40a3f23eeb4739d10d0fe\nTitle: Pre-computed memory or on-the-fly encoding? A hybrid approach to retrieval augmentation makes the most of your compute\nYear: 2023\nAbstract: Retrieval-augmented language models such as Fusion-in-Decoder are powerful, setting the state of the art on a variety of knowledge-intensive tasks. However, they are also expensive, due to the need to encode a large number of retrieved passages. Some work avoids this cost by pre-encoding a text corpus into a memory and retrieving dense representations directly. However, pre-encoding memory incurs a severe quality penalty as the memory representations are not conditioned on the current input. We propose LUMEN, a hybrid between these two extremes, pre-computing the majority of the retrieval representation and completing the encoding on the fly using a live encoder that is conditioned on the question and fine-tuned for the task.",
  "We propose LUMEN, a hybrid between these two extremes, pre-computing the majority of the retrieval representation and completing the encoding on the fly using a live encoder that is conditioned on the question and fine-tuned for the task. We show that LUMEN significantly outperforms pure memory on multiple question-answering tasks while being much cheaper than FiD, and outperforms both for any given compute budget. Moreover, the advantage of LUMEN over FiD increases with model size.\nAuthors: Michiel de Jong, Yury Zemlyanskiy, Nicholas FitzGerald, J. Ainslie, Sumit K. Sanghai, Fei Sha, W. Cohen\nVenue: International Conference on Machine Learning\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes LUMEN, a hybrid between these two extremes, pre-computing the majority of the retrieval representation and completing the encoding on the fly using a live encoder that is conditioned on the question and fine-tuned for the task.'}",
  "Faculty Name: william cohen\nMetadata:\nPaperid: 646cca9de110726000a6e44560743b241a4d7f91\nTitle: MEMORY-VQ: Compression for Tractable Internet-Scale Memory\nYear: 2023\nAbstract: Retrieval augmentation is a powerful but expensive method to make language models more knowledgeable about the world. Memory-based methods like LUMEN pre-compute token representations for retrieved passages to drastically speed up inference. However, memory also leads to much greater storage requirements from storing pre-computed representations. We propose MEMORY-VQ, a new method to reduce storage requirements of memory-augmented models without sacrificing performance. Our method uses a vector quantization variational autoencoder (VQ-VAE) to compress token representations. We apply MEMORY-VQ to the LUMEN model to obtain LUMEN-VQ, a memory model that achieves a 16x compression rate with comparable performance on the KILT benchmark. LUMEN-VQ enables practical retrieval augmentation even for extremely large retrieval corpora.",
  "We apply MEMORY-VQ to the LUMEN model to obtain LUMEN-VQ, a memory model that achieves a 16x compression rate with comparable performance on the KILT benchmark. LUMEN-VQ enables practical retrieval augmentation even for extremely large retrieval corpora.\nAuthors: Yury Zemlyanskiy, Michiel de Jong, L. Vilnis, Santiago Ontan'on, William W. Cohen, Sumit K. Sanghai, J. Ainslie\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes MEMORY-VQ, a new method to reduce storage requirements of memory-augmented models without sacrificing performance, which uses a vector quantization variational autoencoder (VQ-VAE) to compress token representations.'}",
  "Faculty Name: william cohen\nMetadata:\nPaperid: 6f3ce94a962170b1ed940489171494d7c43c2a85\nTitle: P72: Immediate Hemodynamic and Echocardiographic Changes after Impella 5.5 Implant\nYear: 2023\nAbstract: None\nAuthors: William G. Cohen, Alyson Brown, D. Rekhtman, M. Shin, A. Iyengar, M. Cevasco, Joyce W. Wald\nVenue: ASAIO journal (1992)\nTldr: None",
  "Faculty Name: william cohen\nMetadata:\nPaperid: 797d61ad4a4f1bcfcaaadcfa43921ae5907b81dc\nTitle: Figure of eight suture technique in aortic valve replacement decreases prosthesis-patient mismatch\nYear: 2023\nAbstract: None\nAuthors: Nabeel F. Rasheed, C. Stonebraker, Zhaozhi Li, U. Siddiqi, A. Lee, Willa Li, S. Lupo, J. Cruz, W. Cohen, Cathy Staub, D. Rodgers, Mark Myren, P. Combs, V. Jeevanandam, N. Hibino\nVenue: Journal of Cardiothoracic Surgery\nTldr: {'model': 'tldr@v2.0.0', 'text': 'While the pledget suture is the standard technique in AVR, the figure-of-eight suture technique may offer better structural and hemodynamic outcomes, especially for patients with a smaller aortic annulus.'}",
  "Faculty Name: william cohen\nMetadata:\nPaperid: 83b8e18488d8f31dd017ec0b26531cef4b635b36\nTitle: Subject-driven Text-to-Image Generation via Apprenticeship Learning\nYear: 2023\nAbstract: Recent text-to-image generation models like DreamBooth have made remarkable progress in generating highly customized images of a target subject, by fine-tuning an ``expert model'' for a given subject from a few examples. However, this process is expensive, since a new expert model must be learned for each subject. In this paper, we present SuTI, a Subject-driven Text-to-Image generator that replaces subject-specific fine tuning with in-context learning. Given a few demonstrations of a new subject, SuTI can instantly generate novel renditions of the subject in different scenes, without any subject-specific optimization. SuTI is powered by apprenticeship learning, where a single apprentice model is learned from data generated by a massive number of subject-specific expert models. Specifically, we mine millions of image clusters from the Internet, each centered around a specific visual subject.",
  "SuTI is powered by apprenticeship learning, where a single apprentice model is learned from data generated by a massive number of subject-specific expert models. Specifically, we mine millions of image clusters from the Internet, each centered around a specific visual subject. We adopt these clusters to train a massive number of expert models, each specializing in a different subject. The apprentice model SuTI then learns to imitate the behavior of these fine-tuned experts. SuTI can generate high-quality and customized subject-specific images 20x faster than optimization-based SoTA methods. On the challenging DreamBench and DreamBench-v2, our human evaluation shows that SuTI significantly outperforms existing models like InstructPix2Pix, Textual Inversion, Imagic, Prompt2Prompt, Re-Imagen and DreamBooth, especially on the subject and text alignment aspects.",
  "On the challenging DreamBench and DreamBench-v2, our human evaluation shows that SuTI significantly outperforms existing models like InstructPix2Pix, Textual Inversion, Imagic, Prompt2Prompt, Re-Imagen and DreamBooth, especially on the subject and text alignment aspects.\nAuthors: Wenhu Chen, Hexiang Hu, Yandong Li, Nataniel Rui, Xuhui Jia, Ming-Wei Chang, William W. Cohen\nVenue: Neural Information Processing Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Human evaluation shows that SuTI significantly outperforms existing models like InstructPix2Pix, Textual Inversion, Imagic, Prompt2Prompt, Re-Imagen and DreamBooth, especially on the subject and text alignment aspects.'}",
  "Faculty Name: william cohen\nMetadata:\nPaperid: c67099476f2b505dfd5a22c817707fad83de9994\nTitle: GLIMMER: generalized late-interaction memory reranker\nYear: 2023\nAbstract: Memory-augmentation is a powerful approach for efficiently incorporating external information into language models, but leads to reduced performance relative to retrieving text. Recent work introduced LUMEN, a memory-retrieval hybrid that partially pre-computes memory and updates memory representations on the fly with a smaller live encoder. We propose GLIMMER, which improves on this approach through 1) exploiting free access to the powerful memory representations by applying a shallow reranker on top of memory to drastically improve retrieval quality at low cost, and 2) incorporating multi-task training to learn a general and higher quality memory and live encoder. GLIMMER achieves strong gains in performance at faster speeds compared to LUMEN and FiD on the KILT benchmark of knowledge-intensive tasks.",
  "GLIMMER achieves strong gains in performance at faster speeds compared to LUMEN and FiD on the KILT benchmark of knowledge-intensive tasks.\nAuthors: Michiel de Jong, Yury Zemlyanskiy, Nicholas FitzGerald, Sumit K. Sanghai, William W. Cohen, J. Ainslie\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'GLIMMER is proposed, which improves on LUMEN through exploiting free access to the powerful memory representations by applying a shallow reranker on top of memory to drastically improve retrieval quality at low cost and incorporating multi-task training to learn a general and higher quality memory and live encoder.'}",
  "Faculty Name: william cohen\nMetadata:\nPaperid: caf1600391aa950e9b9d07a63c3edf1d2d5d1dc9\nTitle: The Influence of Optically Active Impurities on the Performance of Phosphors and Scintillators\nYear: 2023\nAbstract: This paper provides examples of a strategy employed to improve specific properties of phosphors and scintillators which would otherwise have limited their performance in lighting, cathode-ray tubes, and medical imaging technologies. When electron-hole pairs are produced by the exposure to high-energy radiation, the activator ion in the lattice preferentially captures one of the charge carriers. The subsequent capture of the carrier of opposite charge yields the activator ion luminescence. The carrier of the opposite charge can also be diverted to defects in the lattice. The trapping by defects reduces the brightness of phosphors and is responsible for the unwanted afterglow in scintillators. The strategy that is adopted to suppress the trapping by defects is to deliberately introduce an impurity ion that can compete successfully with the defects for the charge carrier.",
  "The trapping by defects reduces the brightness of phosphors and is responsible for the unwanted afterglow in scintillators. The strategy that is adopted to suppress the trapping by defects is to deliberately introduce an impurity ion that can compete successfully with the defects for the charge carrier. Since the impurity ion traps charge of the opposite sign to the activator ion, we label them as \u201canti-activators.\u201d While the use of anti-activators gained importance in the field of scintillators in the 1990\u2019s, results on their use for improving brightness of lamp and cathode-ray phosphors were available in the literature of the 1960\u2019s and 1970\u2019s.\nAuthors: A. Srivastava, C. Ronda, W. Beers, W. Cohen\nVenue: ECS Journal of Solid State Science and Technology\nTldr: None",
  "Faculty Name: william cohen\nMetadata:\nPaperid: db2374b1b1adc881b93f96818beb858d3b06ff45\nTitle: CARC5: Midterm Impella Support: A Review of Seventy-Two Patients Successfully Supported with Impella 5.5 Device\nYear: 2023\nAbstract: None\nAuthors: Joyce W. Wald, Alyson Brown, William G. Cohen, Kiranpreet Sidhu, Aditya Parikh, D. Rekhtman, M. Cevasco\nVenue: ASAIO journal (1992)\nTldr: None",
  "List of 2023 Open Access papers by william cohen are:\nPre-computed memory or on-the-fly encoding? A hybrid approach to retrieval augmentation makes the most of your compute\nAnswering Ambiguous Questions with a Database of Questions, Answers, and Revisions\nMEMORY-VQ: Compression for Tractable Internet-Scale Memory\nSubject-driven Text-to-Image Generation via Apprenticeship Learning\nGLIMMER: generalized late-interaction memory reranker\nOrbital Hybridization and Hypersensitivity of Eu3+ in YXO4 (X=P, As, V)\nThe Influence of Optically Active Impurities on the Performance of Phosphors and Scintillators\nFigure of eight suture technique in aortic valve replacement decreases prosthesis-patient mismatch\nP72: Immediate Hemodynamic and Echocardiographic Changes after Impella 5.5 Implant\nCARC5: Midterm Impella Support: A Review of Seventy-Two Patients Successfully Supported with Impella 5.5 Device\nCardiothoracic Surgery Training: An Honest and Anonymous Assessment of the Trainee Experience",
  "Title: Monika Woszczyna -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Monika Woszczyna, Adjunct Faculty at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Adjunct Faculty\" name=\"categories-1\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Monika Woszczyna - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Monika Woszczyna, Adjunct Faculty at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Monika\"/>\n<meta content=\"Lastname\" property=\"profile:Woszczyna\"/>\n<meta content=\"http://cms-staging.andrew.cmu.",
  "andrew.cmu.edu/lti/people/faculty/woszczyna-monika.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nMonika \n                        Woszczyna\nHead of Speech Technology Group, Multimodal Technologies Inc.\nContact\nmonikaw(through)andrew.cmu.edu\n\nLinks:",
  "Title: Eric P. Xing -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Eric P. Xing, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Core Faculty\" name=\"categories-1\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Eric P. Xing - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Eric P. Xing, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Eric\"/>\n<meta content=\"Lastname\" property=\"profile:Xing\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/xing-eric.",
  "cmu.edu//people/faculty/xing-eric.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nEric \n                            P. \n                        Xing\nProfessor (On Leave), Language Technologies Institute\nContact\n8101 \u2014Gates & Hillman Centers\nepxing(through)andrew.cmu.edu\n412-268-2559\nResearch\nThe major theme of Professor Xing's research lies in the development of machine learning and statistical methodology; especially for building quantitative models and predictive understandings of the evolutionary mechanism, regulatory circuitry, and developmental processes of biological systems; and for building intelligent systems for a wide range of applications in vision, IR and NLP that involves computational learning and reasoning under uncertainty.",
  "especially for building quantitative models and predictive understandings of the evolutionary mechanism, regulatory circuitry, and developmental processes of biological systems; and for building intelligent systems for a wide range of applications in vision, IR and NLP that involves computational learning and reasoning under uncertainty.\nFoundations of Statistical Learning\n, including theory and algorithms for: 1) Time/space varying-coefficient models with evolving structures; 2) Sparse structured input/output models in high-dimensional problems; 3) Nonparametric Bayesian techniques for infinite-dimensional models; 4) RKHS embedding, nonparametric inference, and spectral methods for graphical models; 5) Distributed and online algorithms for optimization, approximate inference, and sampling on massive data.\nLarge-scale Information & Intelligent System:\n1) Development of scalable parallel architecture, protocol, programming interface, generic algorithms and models, for Big Learning; 2) Multi-view latent space models, topics models, and sparse coding for image/text/relational data mining; 3) Evolving structure, stable metrics, and prediction for dynamic social networks, goal-driven network design and optimization; 4) Web-scale image understanding, search, prediction, and storyline synthesis; 5) Information visualization, indexing and storage, web/mobile app development.",
  "Computational Biology:\n1) Understanding genome-microenvironment interactions in cancer and embryogenesis via joint analysis of genomic, proteomic, and pathway signaling data; 2) Genetic analysis of population variation, demography and evolution; 3) Statistical inference of genome-transcriptome-phenome association in complex diseases; 4) Personalized diagnosis and treatment of spectrum diseases via next generation sequencing and computational \"omic\" analysis; 5) Biological image and text mining.\nPersonal Website\n\nLinks:\nhttp://www.cs.cmu.edu/~epxing/",
  "Title: Chenyan Xiong -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio page for Chenyan Xiong\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Core Faculty\" name=\"categories-1\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Chenyan Xiong - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio page for Chenyan Xiong\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Chenyan\"/>\n<meta content=\"Lastname\" property=\"profile:Xiong\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/xiong-chenyan.",
  "cmu.edu//people/faculty/xiong-chenyan.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nChenyan \n                        Xiong\nAssociate Professor, Language Technologies Institute\nContact\ncx(through)andrew.cmu.edu\nAddress\n5000 Forbes Avenue\nPittsburgh, PA 15213\n\nLinks:",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: 02ce4d3f93902a94ec2b57630b77696b7f18c84a\nTitle: PESCO: Prompt-enhanced Self Contrastive Learning for Zero-shot Text Classification\nYear: 2023\nAbstract: We present PESCO, a novel contrastive learning framework that substantially improves the performance of zero-shot text classification. We formulate text classification as a neural text retrieval problem where each document is treated as a query, and the system learns the mapping from each query to the relevant class labels by (1) adding prompts to enhance label retrieval, and (2) using retrieved labels to enrich the training set in a self-training loop of contrastive learning. PESCO achieves state-of-the-art performance on four benchmark text classification datasets. On DBpedia, we achieve 98.5% accuracy without any labeled data, which is close to the fully-supervised result. Extensive experiments and analyses show all the components of PESCO are necessary for improving the performance of zero-shot text classification.",
  "On DBpedia, we achieve 98.5% accuracy without any labeled data, which is close to the fully-supervised result. Extensive experiments and analyses show all the components of PESCO are necessary for improving the performance of zero-shot text classification.\nAuthors: Yau-Shian Wang, Ta-Chung Chi, Ruohong Zhang, Yiming Yang\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'PESCO is presented, a novel contrastive learning framework that substantially improves the performance of zero-shot text classification and achieves state-of-the-art performance on four benchmark text classification datasets.'}",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: 08a23cb1ae7b0748407146520c0630d7f2b51c4c\nTitle: Accelerating Diffusion-based Combinatorial Optimization Solvers by Progressive Distillation\nYear: 2023\nAbstract: Graph-based diffusion models have shown promising results in terms of generating high-quality solutions to NP-complete (NPC) combinatorial optimization (CO) problems. However, those models are often inefficient in inference, due to the iterative evaluation nature of the denoising diffusion process. This paper proposes to use progressive distillation to speed up the inference by taking fewer steps (e.g., forecasting two steps ahead within a single step) during the denoising process. Our experimental results show that the progressively distilled model can perform inference 16 times faster with only 0.019% degradation in performance on the TSP-50 dataset.",
  "Our experimental results show that the progressively distilled model can perform inference 16 times faster with only 0.019% degradation in performance on the TSP-50 dataset.\nAuthors: Junwei Huang, Zhiqing Sun, Yiming Yang\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Progressive distillation is proposed to use progressive distillation to speed up the inference by taking fewer steps (e.g., forecasting two steps ahead within a single step) during the denoising process.'}",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: 0a187bee2436f4a2e98dd94d3c2f18b83281efdb\nTitle: Automatic synchrotron tomographic alignment schemes based on genetic algorithms and human-in-the-loop software\nYear: 2023\nAbstract: A highly automatic alignment scheme is proposed to address the pressing challenge in tomographic alignment of future scanning tomography experiments. The results show that the proposed method exhibits excellent sub-pixel alignment accuracy and high time efficiency.\nAuthors: Zhen Zhang, Xiaoxue Bi, Pengcheng Li, Chenglong Zhang, Yiming Yang, Yu Liu, Gang Chen, Yuhui Dong, Gongfa Liu, Yi Zhang\nVenue: Journal of Synchrotron Radiation\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The results show that the proposed method exhibits excellent sub-pixel alignment accuracy and high time efficiency.'}",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: 0c00dd3f3c1111a09933b30d305a03ab00e866bc\nTitle: A Wideband Reconfigurable Intelligent Surface for 5G Millimeter-Wave Applications\nYear: 2023\nAbstract: Despite the growing interest in reconfigurable intelligent surfaces (RISs) for millimeter-wave (mm-wave) bands, and the considerable theoretical work reported by the communication community, there is a limited number of published works demonstrating practical implementations and experimental results. To the authors' knowledge, no published literature has reported experimental results for RISs covering the n257 and n258 mm-wave bands. In this work, we propose a novel wideband RIS design that covers the entire mm-wave 5G n257 and n258 bands. In simulations, the unit cell can maintain a phase difference of 180{\\deg} +- 20{\\deg} and a reflection magnitude greater than -2.8 dB within 22.7 to 30.5 GHz (29.3% bandwidth) using one-bit PIN switches.",
  "In simulations, the unit cell can maintain a phase difference of 180{\\deg} +- 20{\\deg} and a reflection magnitude greater than -2.8 dB within 22.7 to 30.5 GHz (29.3% bandwidth) using one-bit PIN switches. The proposed unit cell design with four circular cutouts and long vias could realize wideband performance by exciting two adjacent high-order resonances (2.5f and 3.5f). The periodic unit cells can maintain an angular stability of 30{\\deg}. Based on the proposed unit cell, a 20 by 20 RIS array is designed and fabricated with a size of 7.1{\\lambda} by 7.1{\\lambda}. The measurement results demonstrate that the proposed RIS could maintain a 3 dB peak gain variation bandwidth among various array configurations within 22.5 to 29.5 GHz (26.9%) and with a beam scanning capability of 50{\\deg}, making this design a good candidate for 5G mm-wave applications.",
  "Authors: Ruiqi Wang, Yiming Yang, Behrooz Makki, A. Shamim\nVenue: IEEE Transactions on Antennas and Propagation\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes a novel wideband RIS design that covers the entire mm-wave 5G n257 and n258 bands and demonstrates that the proposed RIS could maintain a 3 dB peak gain variation bandwidth among various array configurations within 22.5 to 29.5 GHz.'}",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: 15705015ad838324e7db6f585f9b527327994803\nTitle: Approximation and interpolation with neural network\nYear: 2023\nAbstract: In this paper we show that multilayer feedforward networks with one single hidden layer.and certain types of activation functions can approximate univariant continuous functions defined on a compact set. arbitrarily well. In particular, our results contain some usual activation functions such as sigmoidal functions, RELU functions and threshold functions. Besides, since interpolation problems are highly related to approximation problem, we demonstrate that a wide range of functions have the ability to interpolate and generalize our results to functions which are not polynomial on R. Compared to existing results by numerous work, our methods are more intuitive and less technical.",
  "Besides, since interpolation problems are highly related to approximation problem, we demonstrate that a wide range of functions have the ability to interpolate and generalize our results to functions which are not polynomial on R. Compared to existing results by numerous work, our methods are more intuitive and less technical. Lastly, the paper discusses the possibility of combining interpolation property and approximating property together, and demonstrates that given any Riemann integrable functions on a compact set in R, with several points on its graph, the finite combination of monotone sigmoidal functions can pass through these points and approximate the given function arbitrarily well with respect to L^1 (dx) (in the sense of Riemann integral) when the number of points getting large.\nAuthors: Yiming Yang\nVenue: Theoretical and Natural Science\nTldr: {'model': 'tldr@v2.0.0', 'text': None}",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: 16db1c1c00ac219984c28480cb60fd09b1897bf6\nTitle: High CD8+tumor-infiltrating lymphocytes indicate severe exhaustion and poor prognosis in angioimmunoblastic T-cell lymphoma\nYear: 2023\nAbstract: Background Exhaustion of CD8+ tumor-infiltrating lymphocytes (TILs), characterized by the overexpression of immune checkpoints (IC), is a major impediment to anti-tumor immunity. However, the exhaustion status of CD8+TILs in angioimmunoblastic T cell lymphoma (AITL) remains unclear. Therefore, we aimed to elucidate the exhaustion status of CD8+TILs in AITL and its influence on prognosis. Methods The correlation between CD8+TILs and IC expression in AITL was analyzed using single-cell RNA sequencing (n = 2), flow cytometry (n = 20), and RNA sequencing (n = 20).",
  "Methods The correlation between CD8+TILs and IC expression in AITL was analyzed using single-cell RNA sequencing (n = 2), flow cytometry (n = 20), and RNA sequencing (n = 20). Biological changes related to CD8+TILs exhaustion at different cytotoxic T lymphocyte (CTL) levels (mean expression levels of CD8A, CD8B, GZMA, GZMB, and PRF1) in AITL were evaluated using RNA sequencing (n = 20) and further validated using the GEO dataset (n = 51). The impact of CD8 protein expression and CTL levels on patient prognosis was analyzed using flow cytometry and RNA sequencing, respectively. Results Our findings demonstrated that the higher the infiltration of CD8+TILs, the higher was the proportion of exhausted CD8+TILs characterized by the overexpression of multiple IC. This was accompanied by extensive exhaustion-related biological changes, which suggested severe exhaustion in CD8+TILs and may be one of the main reasons for the poor prognosis of patients with high CD8+TILs and CTL.",
  "This was accompanied by extensive exhaustion-related biological changes, which suggested severe exhaustion in CD8+TILs and may be one of the main reasons for the poor prognosis of patients with high CD8+TILs and CTL. Conclusion Our study comprehensively reveals the exhaustion status of CD8+TILs and their potential negative impact on AITL prognosis, which facilitates further mechanistic studies and is valuable for guiding immunotherapy strategies.\nAuthors: Qiqi Zhu, Yiming Yang, Xueqin Deng, Ningning Chao, Zihang Chen, Y. Ye, Wenyan Zhang, Weiping Liu, Sha Zhao\nVenue: Frontiers in Immunology\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The study comprehensively reveals the exhaustion status of CD8+TILs and their potential negative impact on AITL prognosis, which facilitates further mechanistic studies and is valuable for guiding immunotherapy strategies.'}",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: 1786a2f9140ed7211b21302977de64e948b92308\nTitle: Learning Performance-Improving Code Edits\nYear: 2023\nAbstract: The waning of Moore's Law has shifted the focus of the tech industry towards alternative methods for continued performance gains. While optimizing compilers are a standard tool to help increase program efficiency, programmers continue to shoulder much responsibility in crafting and refactoring code with better performance characteristics. In this paper, we investigate the ability of large language models (LLMs) to suggest functionally correct, performance improving code edits. We hypothesize that language models can suggest such edits in ways that would be impractical for static analysis alone. We investigate these questions by curating a large-scale dataset of Performance-Improving Edits, PIE. PIE contains trajectories of programs, where a programmer begins with an initial, slower version and iteratively makes changes to improve the program's performance. We use PIE to evaluate and improve the capacity of large language models. Specifically, use examples from PIE to fine-tune multiple variants of CODEGEN, a billion-scale Transformer-decoder model.",
  "We use PIE to evaluate and improve the capacity of large language models. Specifically, use examples from PIE to fine-tune multiple variants of CODEGEN, a billion-scale Transformer-decoder model. Additionally, we use examples from PIE to prompt OpenAI's CODEX using a few-shot prompting. By leveraging PIE, we find that both CODEX and CODEGEN can generate performance-improving edits, with speedups of more than 2.5x for over 25% of the programs, for C++ and Python, even after the C++ programs were compiled using the O3 optimization level. Crucially, we show that PIE allows CODEGEN, an open-sourced and 10x smaller model than CODEX, to match the performance of CODEX on this challenging task. Overall, this work opens new doors for creating systems and methods that can help programmers write efficient code.",
  "Crucially, we show that PIE allows CODEGEN, an open-sourced and 10x smaller model than CODEX, to match the performance of CODEX on this challenging task. Overall, this work opens new doors for creating systems and methods that can help programmers write efficient code.\nAuthors: Aman Madaan, Alex Shypula, Uri Alon, Milad Hashemi, Parthasarathy Ranganathan, Yiming Yang, Graham Neubig, A. Yazdanbakhsh\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper investigates the ability of large language models (LLMs) to suggest functionally correct, performance improving code edits, and hypothesizes that language models can suggest such edits in ways that would be impractical for static analysis alone.'}",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: 1804dc14b1cf7bbae96bf3215997e9f14425d622\nTitle: Generation-driven Contrastive Self-training for Zero-shot Text Classification with Instruction-tuned GPT\nYear: 2023\nAbstract: Moreover, GPT-based zero-shot classification models tend to make independent predictions over test instances, which can be sub-optimal as the instance correlations and the decision boundaries in the target space are ignored. To address these difficulties and limitations, we propose a new approach to zero-shot text classification, namely \\ourmodelshort, which leverages the strong generative power of GPT to assist in training a smaller, more adaptable, and efficient sentence encoder classifier with contrastive self-training. Specifically, GenCo applies GPT in two ways: firstly, it generates multiple augmented texts for each input instance to enhance the semantic embedding of the instance and improve the mapping to relevant labels; secondly, it generates augmented texts conditioned on the predicted label during self-training, which makes the generative process tailored to the decision boundaries in the target space.",
  "In our experiments, GenCo outperforms previous state-of-the-art methods on multiple benchmark datasets, even when only limited in-domain text data is available.\nAuthors: Ruohong Zhang, Yau-Shian Wang, Yiming Yang\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes a new approach to zero-shot text classification, namely \\\\ourmodelshort, which leverages the strong generative power of GPT to assist in training a smaller, more adaptable, and efficient sentence encoder classifier with contrastive self-training.'}",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: 188c683099d99c3449a85f740066c4727d8a10ca\nTitle: TRPML1 as a potential therapeutic target for triple-negative breast cancer: a review\nYear: 2023\nAbstract: Triple-negative breast cancer (TNBC) is the most refractory subtype of breast cancer, and effective treatments are urgently needed owing to its poor prognosis. Surgery, radiotherapy, and chemotherapy, alone or in combination, are the leading choices for TNBC therapy. Although promising approaches and procedures have emerged, several challenges, such as off-target effects, drug resistance, and severe side effects, remain to be addressed. Recently, transient receptor potential channel mucolipin 1 (TRPML1) has attracted the attention of researchers because its expression has been implicated in numerous diseases, including cancer. TRPML1 regulates biological events and signaling pathways, including autophagic flux, exocytosis, ionic homeostasis, and lysosomal biogenesis, all contributing to tumorigenesis and cancer progression.",
  "TRPML1 regulates biological events and signaling pathways, including autophagic flux, exocytosis, ionic homeostasis, and lysosomal biogenesis, all contributing to tumorigenesis and cancer progression. TRPML1 also functions as a building block for cancer cell growth, mitogenic signaling, priming tissues for metastasis, and activation of transcriptional programs, processes involved in several malignant tumors. This review provides an overview of breast cancer epidemiology and diagnostic techniques and then discusses the existing therapeutics. Additionally, we elaborate on the development of, and associated challenges to, TNBC diagnostics and treatment and the feasibility of TRPML1 as a therapeutic target for TNBC.\nAuthors: Ying Pan, Qiancheng Zhao, Haitao He, Yubo Qi, Yujie Bai, Jia Zhao, Yiming Yang\nVenue: Frontiers in Oncology\nTldr: {'model': 'tldr@v2.0.0', 'text': 'An overview of breast cancer epidemiology and diagnostic techniques and the existing therapeutics is provided and the feasibility of TRPML1 as a therapeutic target for TNBC is elaborated.'}",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: 2206b7efd166ca0276ee8d169f4b76d8fa05af5c\nTitle: Experimental Study on Secondary Anchorage Bond Performance of Residual Stress after Corrosion Fracture at Ends of Prestressed Steel Strands\nYear: 2023\nAbstract: In order to explore the secondary bond anchorage performance between prestressed tendons and concrete after the fracture of steel strands in post-tensioned, prestressed concrete (PPC) beams, a total of seven post-tensioned, prestressed concrete specimens with a size of 3 \u00d7 7\u03d515.2 mm were constructed firstly, and the steel strands at the anchorage end were subjected to corrosion fracture. Then, the pull-out test of the specimens was conducted to explore the secondary anchorage bond mechanism of the residual stress of prestressed tendons experiencing local fracture. Moreover, the influences of factors such as the embedded length, release-tensioning speed, concrete strength, and stirrup configuration on anchorage bond performance were analyzed. Finally, the test results were further verified via finite element analysis.",
  "Moreover, the influences of factors such as the embedded length, release-tensioning speed, concrete strength, and stirrup configuration on anchorage bond performance were analyzed. Finally, the test results were further verified via finite element analysis. The results show that the failure of pull-out specimens under different parameters can be divided into two types: bond anchorage failure induced by the entire pull-out of steel strands and material failure triggered by the rupture of steel strands. The bond anchorage failure mechanism between steel strands and the concrete was revealed by combining the failure characteristics and pull-out load\u2013slippage relation curves. The bond strength between prestressed steel strands and concrete can be enhanced by increasing the embedded length of steel strands, elevating the concrete strength grade, and enlarging the diameter of stirrups so that the specimens are turned from bond anchorage failure into material failure.\nAuthors: Rihua Yang, Yiming Yang, Xuhui Zhang, Xinzhong Wang\nVenue: Materials\nTldr: None",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: 225086c2d9411cd20b62181bfe9d0b2883374652\nTitle: 16p11.2 CNV gene Doc2\u03b1 functions in neurodevelopment and social behaviors through interaction with Secretagogin.\nYear: 2023\nAbstract: None\nAuthors: Qiu-Wen Wang, Junhong Qin, Yan-Fen Chen, Yingfeng Tu, Yun-Yun Xing, Yuchen Wang, Lvyu Yang, Si-Yao Lu, Libo Geng, Wei Shi, Yiming Yang, Jun Yao\nVenue: Cell Reports\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is shown that Doc2\u03b1-deficient mice have neuronal morphological abnormalities and defects in neural activity, and it is demonstrated that SCGN functions in social/repetitive behaviors, glutamate release, and neuronal morphology of the mice through its Doc2 \u03b1-interacting activity, likely contributing to neurodevelopmental disorders through its interaction with SCGN.'}",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: 2445df274c402c8d6b07c2e81210e5b3b7b8e2f8\nTitle: Extension of Pt\u2013Ag cluster units by incorporating silver salts\nYear: 2023\nAbstract: \n A sterically controlled Z-shaped Pt2Ag2 complex showed a metalation reaction with a Ag ion via the formation of the thermodynamically unfavorable Pt2Ag2 complex with U-shaped configuration. Multiple dative bond formation between Pt and an additional Ag ion endowed enough thermodynamic stability on the Pt2Ag3 cluster to overcome the unfavorable steric effect from bulky substituents on the ligands in the U-shaped structure. A single crystal X-ray structural analysis revealed dimerized structure of the cationic Pt2Ag3 complex units bridged by [Ag2(OTf)4]2\u2212 (OTf\u2212 = triflate anion) via strong Ag\u2013\u03c0 coordination with pyrazole moiety in the solid state. The heteropolynuclear complexes showed photoluminescence properties depending on the structure of the Pt\u2013Ag clusters.",
  "The heteropolynuclear complexes showed photoluminescence properties depending on the structure of the Pt\u2013Ag clusters.\nAuthors: Yiming Yang, Shinnosuke Horiuchi, Kenichiro Omoto, Eri Sakuda, Yasuhiro Arikawa, K. Umakoshi\nVenue: Chemistry Letters\nTldr: None",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: 24df244bf7a6e8c93c5f183d3f62d39c0f773c68\nTitle: SALMON: Self-Alignment with Principle-Following Reward Models\nYear: 2023\nAbstract: Supervised Fine-Tuning (SFT) on response demonstrations combined with Reinforcement Learning from Human Feedback (RLHF) constitutes a powerful paradigm for aligning LLM-based AI agents. However, a significant limitation of such an approach is its dependency on high-quality human annotations, making its application to intricate tasks challenging due to difficulties in obtaining consistent response demonstrations and in-distribution response preferences. This paper presents a novel approach, namely SALMON (Self-ALignMent with principle-fOllowiNg reward models), to align base language models with minimal human supervision, using only a small set of human-defined principles, yet achieving superior performance. Central to our approach is a principle-following reward model. Trained on synthetic preference data, this model can generate reward scores based on arbitrary human-defined principles.",
  "Central to our approach is a principle-following reward model. Trained on synthetic preference data, this model can generate reward scores based on arbitrary human-defined principles. By merely adjusting these principles during the RL training phase, we gain full control over the preferences with the reward model, subsequently influencing the behavior of the RL-trained policies, and eliminating the reliance on the collection of online human preferences. Applying our method to the LLaMA-2-70b base language model, we developed an AI assistant named Dromedary-2. With only 6 exemplars for in-context learning and 31 human-defined principles, Dromedary-2 significantly surpasses the performance of several state-of-the-art AI systems, including LLaMA-2-Chat-70b, on various benchmark datasets. We have open-sourced the code and model weights to encourage further research into aligning LLM-based AI agents with enhanced supervision efficiency, improved controllability, and scalable oversight.",
  "We have open-sourced the code and model weights to encourage further research into aligning LLM-based AI agents with enhanced supervision efficiency, improved controllability, and scalable oversight.\nAuthors: Zhiqing Sun, Yikang Shen, Hongxin Zhang, Qinhong Zhou, Zhenfang Chen, David D. Cox, Yiming Yang, Chuang Gan\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A novel approach, namely SALMON (Self-ALignMent with principle-fOllowiNg reward models), to align base language models with minimal human supervision, using only a small set of human-defined principles, yet achieving superior performance.'}",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: 2bfa8ac40c1ff8e45c298115fcadae062526310e\nTitle: Numerical Investigation of Fatigue Crack Propagation Behaviour of 550E High-Performance Steel\nYear: 2023\nAbstract: The fatigue crack propagation behaviour of Q550E high-performance steel (HPS) is studied in this paper. Static tensile testing and fatigue crack propagation testing were carried out, and the results were compared with those of Q235. Finite element models were developed and verified against the experimental results. The impacts of the initial crack angle, crack depth ratio, stress ratio, thickness, and corrosion pitting on the fatigue crack propagation behaviour of the HPS were analysed. The results show that the fatigue life of Q550 was reduced by 18% due to the corrosion pitting, but it did not change the crack propagation path. When the stress intensity factor is higher than a certain value, the fatigue performance of Q235 is better than that of Q550E. The initial crack angle of 52.5\u00b0 is the critical angle of the crack stress intensity factor.",
  "When the stress intensity factor is higher than a certain value, the fatigue performance of Q235 is better than that of Q550E. The initial crack angle of 52.5\u00b0 is the critical angle of the crack stress intensity factor. The steel tends to fracture as the crack depth ratio increases, and more attention should be paid to the effective crack length in engineering practice. An increasing stress ratio leads to a smaller stress intensity factor, and the thickness affects the stress intensity factor in the later stage. The crack stress intensity factor around the corrosion pits gradually decreases along the thickness direction, and the crack tips around the corrosion pits tend to reach the yield state initially, accelerating the fatigue fracture of the specimen and ultimately leading to a decrease in fatigue life.\nAuthors: Linfa Xiao, Heng Lin, Yongxiang Wang, Yiming Yang, Huapeng Chen\nVenue: Metals\nTldr: None",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: 3040fcdfec29d63f9c25663ac1d58a8b5fec34db\nTitle: Expression of ALCAM in Clinical Colon Cancer and Relationship With Patients\u2019 Treatment Responses\nYear: 2023\nAbstract: Background/Aim: Activated leukocyte cell adhesion molecule (ALCAM) plays an important role in cancer via its homotypical and heterotypical interactions with ALCAM or other proteins and can also mediate cell-cell interactions. The present study investigated the expression of ALCAM in relation to epithelial\u2013to\u2013mesenchymal transition (EMT) markers and its downstream signal proteins including Ezrin-Moesin-Radixin (ERM), in clinical colon cancer and in the progression of the disease. Materials and Methods: Expression of ALCAM was determined in a clinical colon cancer cohort and assessed against the clinical pathological factors and outcome, together with the expression patterns of the ERM family and EMT markers. ALCAM protein was detected using immunohistochemistry. Cell line models, with ALCAM knock-down and over-expression, were established and used to test cells\u2019 responses to drugs.",
  "ALCAM protein was detected using immunohistochemistry. Cell line models, with ALCAM knock-down and over-expression, were established and used to test cells\u2019 responses to drugs. Results: Tumours from patients who had distant metastasis and died of colon cancer had low levels of ALCAM. Dukes B and C tumours also had lower ALCAM expression than Dukes A tumours. Patients with high levels of ALCAM had a significantly longer overall and disease-free survival than those with lower ALCAM levels (p=0.040 and p=0.044). ALCAM is not only significantly correlated with SNAI1 and TWIST, also positively correlated with SNAI2. ALCAM enhanced the adhesiveness of colorectal cancer, an effect inhibited by both sALCAM and SRC inhibitors. Finally, high ALCAM expression rendered cells resistant, especially to 5-fluorouracil. Conclusion: Reduced expression of ALCAM in colon cancer is an indicator of disease progression and a poor prognostic indicator for patient\u2019s survival. However, ALCAM can enhance the adhesion ability of cancer cells and render them resistant to chemotherapy drugs.",
  "Conclusion: Reduced expression of ALCAM in colon cancer is an indicator of disease progression and a poor prognostic indicator for patient\u2019s survival. However, ALCAM can enhance the adhesion ability of cancer cells and render them resistant to chemotherapy drugs.\nAuthors: Ziqian Fang, Jimmy Jianyuan Zeng, Yiming Yang, F. Ruge, J. Lane, R. Hargest, W. Jiang\nVenue: In Vivo\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Reduced expression of ALCAM in colon cancer is an indicator of disease progression and a poor prognostic indicator for patient\u2019s survival, however, A LCAM can enhance the adhesion ability of cancer cells and render them resistant to chemotherapy drugs.'}",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: 35f6015045c2fe38c8a063c3787fc516f9babfaa\nTitle: Strain-driven Kovacs-like memory effect in glasses\nYear: 2023\nAbstract: None\nAuthors: Yu Tong, L. Song, Yurong Gao, Longlong Fan, Fucheng Li, Yiming Yang, Guang Mo, Yanhui Liu, Xiaoxue Shui, Yan Zhang, Meng Gao, J. Huo, Jichao Qiao, E. Pineda, Jun-Qiang Wang\nVenue: Nature Communications\nTldr: None",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: 3aaf6a2cbad5850ad81ab5c163599cb3d523436f\nTitle: Self-Refine: Iterative Refinement with Self-Feedback\nYear: 2023\nAbstract: Like humans, large language models (LLMs) do not always generate the best output on their first try. Motivated by how humans refine their written text, we introduce Self-Refine, an approach for improving initial outputs from LLMs through iterative feedback and refinement. The main idea is to generate an initial output using an LLMs; then, the same LLMs provides feedback for its output and uses it to refine itself, iteratively. Self-Refine does not require any supervised training data, additional training, or reinforcement learning, and instead uses a single LLM as the generator, refiner, and feedback provider. We evaluate Self-Refine across 7 diverse tasks, ranging from dialog response generation to mathematical reasoning, using state-of-the-art (GPT-3.5, ChatGPT, and GPT-4) LLMs.",
  "We evaluate Self-Refine across 7 diverse tasks, ranging from dialog response generation to mathematical reasoning, using state-of-the-art (GPT-3.5, ChatGPT, and GPT-4) LLMs. Across all evaluated tasks, outputs generated with Self-Refine are preferred by humans and automatic metrics over those generated with the same LLM using conventional one-step generation, improving by ~20% absolute on average in task performance. Our work demonstrates that even state-of-the-art LLMs like GPT-4 can be further improved at test time using our simple, standalone approach.",
  "Our work demonstrates that even state-of-the-art LLMs like GPT-4 can be further improved at test time using our simple, standalone approach.\nAuthors: Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, S. Welleck, Bodhisattwa Prasad Majumder, Shashank Gupta, A. Yazdanbakhsh, Peter Clark\nVenue: Neural Information Processing Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Self-Refine is introduced, an approach for improving initial outputs from LLMs through iterative feedback and refinement that demonstrates that even state-of-the-art LLMs like GPT-4 can be further improved at test time using this simple, standalone approach.'}",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: 3bfe260eeb37141206adf719ce02ba40e9cb606a\nTitle: An Ultra-Low-Power Analog Multiplier\u2013Divider Compatible with Digital Code for RRAM-Based Computing-in-Memory Macros\nYear: 2023\nAbstract: This manuscript presents an ultra-low-power analog multiplier\u2013divider compatible with digital code words, which is applicable to the integrated structure of resistive random-access memory (RRAM)-based computing-in-memory (CIM) macros. Current multiplication and division are accomplished by a current-mirror-based structure. Compared with digital dividers to achieve higher precision and operation speed, analog dividers present the advantages of a reduced power consumption and a simple circuit structure in lower precision operations, thus improving the energy efficiency. Designed and fabricated in a 55 nm CMOS process, the proposed work is capable of achieving 8-bit precision for analog current multiplication and division operations. Measurement results show that the signal delay is 1 \u03bcs when performing 8-bit operation, with a bandwidth of 1.4 MHz. The power consumption is less than 6.15 \u03bcW with a 1.2 V supply voltage.",
  "Measurement results show that the signal delay is 1 \u03bcs when performing 8-bit operation, with a bandwidth of 1.4 MHz. The power consumption is less than 6.15 \u03bcW with a 1.2 V supply voltage. The proposed multiplier\u2013divider can increase the operation capacity by dividing the input current and digital code while reducing the power consumption and complexity required by division, which can be further utilized in real-time operation of edge computing devices.\nAuthors: Yiming Yang, Shidong Lv, Xiaoran Li, Xinghua Wang, Qian Wang, Yiyang Yuan, Sen Liang, Feng Zhang\nVenue: Micromachines\nTldr: {'model': 'tldr@v2.0.0', 'text': 'An ultra-low-power analog multiplier\u2013divider compatible with digital code words, which is applicable to the integrated structure of resistive random-access memory (RRAM)-based computing-in-memory (CIM) macros, is presented, capable of achieving 8-bit precision for analog current multiplication and division operations.'}",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: 3c92fd24ea2a49aeba4b368abe3ef13cbce40987\nTitle: Long-tailed Extreme Multi-label Text Classification by the Retrieval of Generated Pseudo Label Descriptions\nYear: 2023\nAbstract: Extreme Multi-label Text Classification (XMTC) has been a tough challenge in machine learning research and applications due to the sheer sizes of the label spaces and the severe data scarcity problem associated with the long tail of rare labels in highly skewed distributions. This paper addresses the challenge of tail label prediction by leveraging the power of dense neural retrieval model in mapping input documents (as queries) to relevant label descriptions. To further enhance the quality of label descriptions, we propose to generate pseudo label descriptions from a trained bag-of-words (BoW) classifier, which demonstrates better classification performance under severe scarce data conditions.The proposed approach achieves the state-of-the-art (SOTA) performance of overall label prediction on XMTC benchmark datasets and especially outperforms the SOTA models in the tail label prediction. We also provide a theoretical analysis for relating the BoW and neural models w.r.t. performance lower bound.",
  "We also provide a theoretical analysis for relating the BoW and neural models w.r.t. performance lower bound.\nAuthors: Ruohong Zhang, Yau-Shian Wang, Yiming Yang, Donghan Yu, Tom Vu, Li Lei\nVenue: Findings\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper addresses the challenge of tail label prediction by leveraging the power of dense neural retrieval model in mapping input documents to relevant label descriptions and generates pseudo label descriptions from a trained bag-of-words (BoW) classifier, which demonstrates better classification performance under severe scarce data conditions.'}",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: 402e8ae2a2b11aac5464d9fb5a31e15b4c0596ca\nTitle: Genome- and transcriptome-wide identification of trehalose-6-phosphate phosphatases (TPP) gene family and their expression patterns under abiotic stress and exogenous trehalose in soybean\nYear: 2023\nAbstract: None\nAuthors: Wenjing Shao, Xinlin Zhang, Zhiheng Zhou, Yue Ma, Duo Chu, Lei Wang, Yiming Yang, Lin Du, Yanli Du, Jidao Du, Qiang Zhao\nVenue: BMC Plant Biology\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Exogenous trehalose treatment up-regulated the expression of most TPP genes under saline-alkali conditions while increasing the carbohydrate and trehalose levels and reducing reactive oxygen species (ROS) accumulation in soybean sprouts, especially in the saline-alkali tolerant genotype.'}",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: 48bd660e0841ca990178cfafec01163ba2bb07ee\nTitle: Association between albumin-to-globulin ratio and the risk of overall survival in advanced non-small cell lung cancer patients with anlotinib treatment: a retrospective cohort study\nYear: 2023\nAbstract: None\nAuthors: Jinzhan Chen, Cong-jun Xie, Yiming Yang, Shuwen Yang, Jin-xiang Huang, Feiyang Ye, Zhenyang Lin, L. Tong, Jiaxin Liu\nVenue: BMC Pulmonary Medicine\nTldr: {'model': 'tldr@v2.0.0', 'text': 'AGR level is an independent protective factor for OS in advanced NSCLC patients who received anlotinib therapy, and was positively associated with OS when AGR was larger than 1.24, for every 1 unit increase in AGR, the risk of death lowered approximately by 80%.'}",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: 492289db63324fa7eab53df3bcfdc753ce7d8953\nTitle: Research on Comprehensive Performance Optimization Method of Explosives and Propellants Oriented to the Whole Process\nYear: 2023\nAbstract: Explosives and propellants are common basic energy for weapons and equipment to achieve delivery, damage, and control, and are an important manifestation of national defense power. However, due to the wide variety of products and complex performance, the traditional serial design optimization mode can no longer meet the requirements of product diversification and rapid development. In this paper, the design process of explosives is deeply studied, and a method for optimizing the comprehensive performance of explosives and propellants oriented to the whole process is proposed. The method uses a comprehensive performance optimization engine to numerically model different design links in a unified parameter space, connects different links horizontally, and adopts a multi-objective optimization algorithm to comprehensively consider the optimization objectives of different links, realizing the automatic execution of the optimization process according to the design process.",
  "The method uses a comprehensive performance optimization engine to numerically model different design links in a unified parameter space, connects different links horizontally, and adopts a multi-objective optimization algorithm to comprehensively consider the optimization objectives of different links, realizing the automatic execution of the optimization process according to the design process. In order to verify the effectiveness of the method, this paper optimizes the formula of explosives and propellants based on two different types of explosives, gun propellant and rocket propellant. Experimental results show that this method improves the design efficiency and improves product quality under the premise of ensuring safety and manufacturability.\nAuthors: Lin Zhang, Yiming Yang, Tongqing Liu, Rui Yan\nVenue: Highlights in Science Engineering and Technology\nTldr: None",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: 4ce987d4f8ae0f4680808c318980d42a82b9aa89\nTitle: Learning a Fourier Transform for Linear Relative Positional Encodings in Transformers\nYear: 2023\nAbstract: We propose a new class of linear Transformers called FourierLearner-Transformers (FLTs), which incorporate a wide range of relative positional encoding mechanisms (RPEs). These include regular RPE techniques applied for nongeometric data, as well as novel RPEs operating on the sequences of tokens embedded in higher-dimensional Euclidean spaces (e.g. point clouds). FLTs construct the optimal RPE mechanism implicitly by learning its spectral representation. As opposed to other architectures combining efficient low-rank linear attention with RPEs, FLTs remain practical in terms of their memory usage and do not require additional assumptions about the structure of the RPE-mask. FLTs allow also for applying certain structural inductive bias techniques to specify masking strategies, e.g. they provide a way to learn the so-called local RPEs introduced in this paper and providing accuracy gains as compared with several other linear Transformers for language modeling.",
  "FLTs allow also for applying certain structural inductive bias techniques to specify masking strategies, e.g. they provide a way to learn the so-called local RPEs introduced in this paper and providing accuracy gains as compared with several other linear Transformers for language modeling. We also thoroughly tested FLTs on other data modalities and tasks, such as: image classification and 3D molecular modeling. For 3D-data FLTs are, to the best of our knowledge, the first Transformers architectures providing RPE-enhanced linear attention.\nAuthors: K. Choromanski, Shanda Li, Valerii Likhosherstov, Kumar Avinava Dubey, Shengjie Luo, Di He, Yiming Yang, Tam\u00e1s Sarl\u00f3s, Thomas Weingarten, Adrian Weller\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'FLTs are the first Transformers architectures providing RPE-enhanced linear attention and provide a way to learn the so-called local RPEs introduced in this paper and providing accuracy gains as compared with several other linear Transformers for language modeling.'}",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: 535047a5e5845b3a05fb566d9733091448410d75\nTitle: Analysis of Volatile Components in Dried Fruits and Branch Exudates of Schisandra chinensis with Different Fruit Colors Using GC-IMS Technology\nYear: 2023\nAbstract: To investigate the volatile components of Schisandra chinensis (Turcz.) Bail (commonly known as northern Schisandra) of different colors and to explore their similarities and differences, to identify the main flavor substances in the volatile components of the branch exudates of northern schisandra, and finally to establish a fingerprint map of the volatile components of the dried fruits and branch exudates of northern Schisandra of different colors, we used GC-IMS technology to analyze the volatile components of the dried fruits and branch exudates of three different colors of northern Schisandra and established a fingerprint spectra. The results showed that a total of 60 different volatile chemical components were identified in the branch exudates and dried fruits of Schisandra. The components of germplasm resources with different fruit colors were significantly different.",
  "The results showed that a total of 60 different volatile chemical components were identified in the branch exudates and dried fruits of Schisandra. The components of germplasm resources with different fruit colors were significantly different. The ion mobility spectrum and OPLS-DA results showed that white and yellow fruits were more similar compared to red fruits. The volatile components in dried fruits were significantly higher than those in branch exudates. After VIP (variable importance in projection) screening, 41 key volatile substances in dried fruits and 30 key volatile substances in branch exudates were obtained. After screening by odor activity value (OAV), there were 24 volatile components greater than 1 in both dried fruits and branch exudates. The most important contributing volatile substance was 3-methyl-butanal, and the most important contributing volatile substance in white fruit was (E)-2-hexenal.\nAuthors: Yiping Yan, Wenpeng Lu, Taiping Tian, Nan Shu, Yiming Yang, Shutian Fan, Xianyan Han, Yunhua Ge, Peilei Xu\nVenue: Molecules\nTldr: None",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: 5886281fe8f522b2f82a5957d8ef53d44578b3e6\nTitle: Matrine induces ferroptosis in cervical cancer through activation of piezo1 channel.\nYear: 2023\nAbstract: None\nAuthors: Jiaqi Jin, Zhaofeng Fan, Yonglin Long, Yinping Li, Qian He, Yiming Yang, Weijian Zhong, Disheng Lin, Dawei Lian, Xiao Wang, Jing Xiao, Yang Chen\nVenue: Phytomedicine\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is indicated that matrine exerts a protective effect against cervical cancer by inducing ferroptosis through the activation of Piezo1, but not xCT or Tfr, while transferrin receptor and System Xc- (xCT) expression and interaction remained unaffected.'}",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: 5921cc9349dfc43acfefbddc4c9b81a4b6a0b1f9\nTitle: Secreted endogenous macrosomes reduce A\u03b2 burden and ameliorate Alzheimer\u2019s disease\nYear: 2023\nAbstract: Innovative therapeutic strategies are urgently needed for Alzheimer\u2019s disease (AD) due to the increasing size of the aging population and the lack of effective drug treatment. Here, we report the therapeutic effects of extracellular vesicles (EVs) secreted by microglia, including macrosomes and small EVs, on AD-associated pathology. Macrosomes strongly inhibited \u03b2-amyloid (A\u03b2) aggregation and rescued cells from A\u03b2 misfolding\u2013induced cytotoxicity. Furthermore, macrosome administration reduced A\u03b2 plaques and ameliorated cognitive impairment in mice with AD. In contrast, small EVs slightly promoted A\u03b2 aggregation and did not improve AD pathology. Proteomic analysis of small EVs and macrosomes revealed that macrosomes harbor several important neuroprotective proteins that inhibit A\u03b2 misfolding.",
  "In contrast, small EVs slightly promoted A\u03b2 aggregation and did not improve AD pathology. Proteomic analysis of small EVs and macrosomes revealed that macrosomes harbor several important neuroprotective proteins that inhibit A\u03b2 misfolding. In particular, the small integral membrane protein 10\u2013like protein 2B in macrosomes has been shown to inhibit A\u03b2 aggregation. Our observations provide an alternative therapeutic strategy for the treatment of AD over conventional ineffective drug treatments.\nAuthors: Cunli Wang, Yiming Yang, Xiaoyu Zhang, Zhenqiang Shi, Huiling Gao, Manli Zhong, Yong-gang Fan, Hongyan Zhang, Bo Liu, Guangyan Qing\nVenue: Science Advances\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The therapeutic effects of extracellular vesicles secreted by microglia, including macrosomes and small EVs, on AD-associated pathology are reported and macrosomes strongly inhibited \u03b2-amyloid aggregation and rescued cells from A\u03b2 misfolding\u2013induced cytotoxicity.'}",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: 5f90d43e6ece5c6ee6e8186e4b57d46c85377713\nTitle: DIFUSCO: Graph-based Diffusion Solvers for Combinatorial Optimization\nYear: 2023\nAbstract: Neural network-based Combinatorial Optimization (CO) methods have shown promising results in solving various NP-complete (NPC) problems without relying on hand-crafted domain knowledge. This paper broadens the current scope of neural solvers for NPC problems by introducing a new graph-based diffusion framework, namely DIFUSCO. Our framework casts NPC problems as discrete {0, 1}-vector optimization problems and leverages graph-based denoising diffusion models to generate high-quality solutions. We investigate two types of diffusion models with Gaussian and Bernoulli noise, respectively, and devise an effective inference schedule to enhance the solution quality. We evaluate our methods on two well-studied NPC combinatorial optimization problems: Traveling Salesman Problem (TSP) and Maximal Independent Set (MIS).",
  "We evaluate our methods on two well-studied NPC combinatorial optimization problems: Traveling Salesman Problem (TSP) and Maximal Independent Set (MIS). Experimental results show that DIFUSCO strongly outperforms the previous state-of-the-art neural solvers, improving the performance gap between ground-truth and neural solvers from 1.76% to 0.46% on TSP-500, from 2.46% to 1.17% on TSP-1000, and from 3.19% to 2.58% on TSP10000. For the MIS problem, DIFUSCO outperforms the previous state-of-the-art neural solver on the challenging SATLIB benchmark.\nAuthors: Zhiqing Sun, Yiming Yang\nVenue: Neural Information Processing Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'DIFUSCO is introduced, a new graph-based diffusion framework for NPC combinatorial optimization that outperforms the previous state-of-the-art neural solvers on the challenging SATLIB benchmark and investigates two types of diffusion models with Gaussian and Bernoulli noise, respectively.'}",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: 661ef7301c3c399130d3d8673098dd27f5696130\nTitle: Let's Sample Step by Step: Adaptive-Consistency for Efficient Reasoning with LLMs\nYear: 2023\nAbstract: A popular approach for improving the correctness of output from large language models (LLMs) is Self-Consistency \u2013 poll the LLM multiple times and output the most frequent so-lution. Existing Self-Consistency techniques always draw a constant number of samples per question, where a better approach will be to non-uniformly distribute the available bud-get based on the amount of agreement in the samples drawn so far. In response, we introduce Adaptive-Consistency, a cost-ef\ufb01cient, model-agnostic technique that dynamically adjusts the number of samples per question using a lightweight stopping criterion. Our experiments over 13 datasets and two LLMs demonstrate that Adaptive-Consistency reduces sample budget by up to 6.0 times with an average accuracy drop of less than 0.1%.",
  "Our experiments over 13 datasets and two LLMs demonstrate that Adaptive-Consistency reduces sample budget by up to 6.0 times with an average accuracy drop of less than 0.1%. 1\nAuthors: Pranjal Aggarwal, Aman Madaan, Yiming Yang, Mausam\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Adaptive-Consistency is introduced, a cost-ef\ufb01cient, model-agnostic technique that dynamically adjusts the number of samples per question using a lightweight stopping criterion that reduces sample budget by up to 6.0 times with an average accuracy drop of less than 01%.'}",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: 6a42f6362afa3a1a0936f7a6a8927d04a2285cc5\nTitle: Balancing Exploration and Exploitation in Hierarchical Reinforcement Learning via Latent Landmark Graphs\nYear: 2023\nAbstract: Goal-Conditioned Hierarchical Reinforcement Learning (GCHRL) is a promising paradigm to address the exploration-exploitation dilemma in reinforcement learning. It decomposes the source task into sub goal conditional subtasks and conducts exploration and exploitation in the subgoal space. The effectiveness of GCHRL heavily relies on sub goal representation functions and sub goal selection strategy. However, existing works often overlook the temporal coherence in GCHRL when learning latent sub goal representations and lack an efficient sub goal selection strategy that balances exploration and exploitation. This paper proposes HIerarchical reinforcement learning via dynamically building Latent Landmark graphs (HILL) to overcome these limitations. HILL learns latent subgoal representations that satisfy temporal coherence using a contrastive representation learning objective. Based on these representations, HILL dynamically builds latent landmark graphs and employs a novelty measure on nodes and a utility measure on edges.",
  "HILL learns latent subgoal representations that satisfy temporal coherence using a contrastive representation learning objective. Based on these representations, HILL dynamically builds latent landmark graphs and employs a novelty measure on nodes and a utility measure on edges. Finally, HILL develops a subgoal selection strategy that balances exploration and exploitation by jointly considering both measures. Experimental results demonstrate that HILL outperforms state-of-the-art baselines on continuous control tasks with sparse rewards in sample efficiency and asymptotic performance. Our code is available at https://github.com/papercode2022/HILL.\nAuthors: Qingyang Zhang, Yiming Yang, Jingqing Ruan, Xuantang Xiong, Dengpeng Xing, Bo Xu\nVenue: IEEE International Joint Conference on Neural Network\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper proposes HIerarchical reinforcement learning via dynamically building Latent Landmark graphs (HILL) to overcome limitations in GCHRL and develops a subgoal selection strategy that balances exploration and exploitation by jointly considering both measures.'}",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: 6b8072d781414a33730939ef0b1b4fd0a2291d86\nTitle: Numerical Analysis on the Influence of Joint Density on the Stability of Complex Jointed Roadway Surrounding Rock\nYear: 2023\nAbstract: The random distribution of a complex joint network within a coal\u2013rock mass has a significant weakening effect on its bearing capacity, making the surrounding rock of the roadway highly susceptible to instability and failure under the influence of in situ stress and mining-induced stress. This poses challenges in controlling the surrounding rock and seriously affects the normal production of mines. Consequently, it is imperative to conduct stability analysis on complex jointed roadway surrounding rock. Therefore, taking the transport roadway of Panel 11030 in the Zhaogu No. 2 Coal Mine as a case study, the microscopic contact parameters of particles and joint surfaces in each rock layer were calibrated through uniaxial compression and shear simulation tests using the particle flow simulation software PFC2D 5.0.",
  "2 Coal Mine as a case study, the microscopic contact parameters of particles and joint surfaces in each rock layer were calibrated through uniaxial compression and shear simulation tests using the particle flow simulation software PFC2D 5.0. Based on the calibrated microscopic contact parameters, a multilayered roadway surrounding rock model containing complex joints was established, and the joint density was quantified to analyze its effects on the displacement field, stress field, force chain field, and energy field of the roadway surrounding rock. The research findings indicate that as the distance to the sidewall decreases, the impact of joint density on the deformation of the surrounding rock of the roadway increases. The displacement of the roadway roof, floor, and sidewalls is affected differently by the joint density, predominantly contingent upon the properties of the rock mass. During the process of stress redistribution in the surrounding rock, the vertical stress of the roof and floor is released more intensively compared to the horizontal stress, while the horizontal stress of the sidewalls is released more intensively compared to the vertical stress. The increase in joint density leads to an increasing release rate of the surrounding rock stress, causing the load-bearing rock mass to transfer towards the deeper part.",
  "The increase in joint density leads to an increasing release rate of the surrounding rock stress, causing the load-bearing rock mass to transfer towards the deeper part. As the joint density increases, the force chain network gradually transitions from dense to sparse, resulting in a decrease in strong force chains and a decline in the bearing capacity of the surrounding rock, accompanied by an expansion in the range of force chain failure and deformation. With the continuous increase in joint density, the values of maximum released kinetic energy and residual released kinetic energy become larger. Once the joint density reaches a certain threshold, the kinetic energy stability zone consistently maintains a high energy level, indicating extreme instability in the roadway and sustained deformation. The results provide a valuable insight for analyzing the failure mechanism of complex jointed roadway surrounding rock and implementing corresponding support measures.\nAuthors: Wenhai Wang, Chaolei Wu, Yiming Yang, Xiaohan Peng, Li Jiang, Yifeng Huang\nVenue: Sustainability\nTldr: None",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: 70a6d974580a272e724936b6bc9cd27064098604\nTitle: Imaging Field\u2010Driven Melting of a Molecular Solid at the Atomic Scale\nYear: 2023\nAbstract: Solid\u2013liquid phase transitions are basic physical processes, but atomically resolved microscopy has yet to capture their full dynamics. A new technique is developed for controlling the melting and freezing of self\u2010assembled molecular structures on a graphene field\u2010effect transistor (FET) that allows phase\u2010transition behavior to be imaged using atomically resolved scanning tunneling microscopy. This is achieved by applying electric fields to 2,3,5,6\u2010tetrafluoro\u20107,7,8,8\u2010tetracyanoquinodimethane\u2010decorated FETs to induce reversible transitions between molecular solid and liquid phases at the FET surface. Nonequilibrium melting dynamics are visualized by rapidly heating the graphene substrate with an electrical current and imaging the resulting evolution toward new 2D equilibrium states. An analytical model is developed that explains observed mixed\u2010state phases based on spectroscopic measurement of solid and liquid molecular energy levels.",
  "Nonequilibrium melting dynamics are visualized by rapidly heating the graphene substrate with an electrical current and imaging the resulting evolution toward new 2D equilibrium states. An analytical model is developed that explains observed mixed\u2010state phases based on spectroscopic measurement of solid and liquid molecular energy levels. The observed nonequilibrium melting dynamics are consistent with Monte Carlo simulations.\nAuthors: Franklin Liou, H. Tsai, Zachary A H Goodwin, Andrew S. Aikawa, Ethan Ha, Michael Hu, Yiming Yang, Kenji Watanabe, T. Taniguchi, A. Zettl, J. Lischner, M. Crommie\nVenue: Advances in Materials\nTldr: None",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: 7e7ab2af26025d1aa2a6a90fab7713139a9327f7\nTitle: Inference of single cell profiles from histology stains with the Single-Cell omics from Histology Analysis Framework (SCHAF)\nYear: 2023\nAbstract: Tissue biology involves an intricate balance between cell-intrinsic processes and interactions between cells organized in specific spatial patterns, which can be respectively captured by single-cell profiling methods, such as single-cell RNA-seq (scRNA-seq), and histology imaging data, such as Hematoxylin-and-Eosin (H&E) stains. While single-cell profiles provide rich molecular information, they can be challenging to collect routinely and do not have spatial resolution. Conversely, histological H&E assays have been a cornerstone of tissue pathology for decades, but do not directly report on molecular details, although the observed structure they capture arises from molecules and cells.",
  "Conversely, histological H&E assays have been a cornerstone of tissue pathology for decades, but do not directly report on molecular details, although the observed structure they capture arises from molecules and cells. Here, we leverage adversarial machine learning to develop SCHAF (Single-Cell omics from Histology Analysis Framework), to generate a tissue sample\u2019s spatially-resolved single-cell omics dataset from its H&E histology image. We demonstrate SCHAF on two types of human tumors\u2014from lung and metastatic breast cancer\u2014training with matched samples analyzed by both sc/snRNA-seq and by H&E staining. SCHAF generated appropriate single-cell profiles from histology images in test data, related them spatially, and compared well to ground-truth scRNA-Seq, expert pathologist annotations, or direct MERFISH measurements. SCHAF opens the way to next-generation H&E2.0 analyses and an integrated understanding of cell and tissue biology in health and disease.",
  "SCHAF opens the way to next-generation H&E2.0 analyses and an integrated understanding of cell and tissue biology in health and disease.\nAuthors: Charles Comiter, E. D. Vaishnav, M. Ciampricotti, Bo Li, Yiming Yang, S. Rodig, M. Turner, Kathleen L. Pfaff, Judit Jan\u00e9-Valbuena, M. Slyper, Julia Waldman, Sebastian Vigneau, Jingyi Wu, Timothy R. Blosser, \u00c5. Segerstolpe, Daniel L. Abravanel, Nikil Wagle, X. Zhuang, C. Rudin, J. Klughammer, O. Rozenblatt-Rosen, Koseki J. Kobayash-Kirschvink, J. Shu, A. Regev\nVenue: bioRxiv\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Adversarial machine learning is used to develop SCHAF (Single-Cell omics from Histology Analysis Framework), to generate a tissue sample\u2019s spatially-resolved single-cell omics dataset from its H&E histology image, which opens the way to next-generation H &E2.0 analyses and an integrated understanding of cell and tissue biology in health and disease.'}",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: 844bb298d49ef4a07b5d4929dfdfd170f6a1d5f5\nTitle: Aligning Large Multimodal Models with Factually Augmented RLHF\nYear: 2023\nAbstract: Large Multimodal Models (LMM) are built across modalities and the misalignment between two modalities can result in\"hallucination\", generating textual outputs that are not grounded by the multimodal information in context. To address the multimodal misalignment issue, we adapt the Reinforcement Learning from Human Feedback (RLHF) from the text domain to the task of vision-language alignment, where human annotators are asked to compare two responses and pinpoint the more hallucinated one, and the vision-language model is trained to maximize the simulated human rewards. We propose a new alignment algorithm called Factually Augmented RLHF that augments the reward model with additional factual information such as image captions and ground-truth multi-choice options, which alleviates the reward hacking phenomenon in RLHF and further improves the performance.",
  "We propose a new alignment algorithm called Factually Augmented RLHF that augments the reward model with additional factual information such as image captions and ground-truth multi-choice options, which alleviates the reward hacking phenomenon in RLHF and further improves the performance. We also enhance the GPT-4-generated training data (for vision instruction tuning) with previously available human-written image-text pairs to improve the general capabilities of our model. To evaluate the proposed approach in real-world scenarios, we develop a new evaluation benchmark MMHAL-BENCH with a special focus on penalizing hallucinations. As the first LMM trained with RLHF, our approach achieves remarkable improvement on the LLaVA-Bench dataset with the 94% performance level of the text-only GPT-4 (while previous best methods can only achieve the 87% level), and an improvement by 60% on MMHAL-BENCH over other baselines. We opensource our code, model, data at https://llava-rlhf.github.io.",
  "We opensource our code, model, data at https://llava-rlhf.github.io.\nAuthors: Zhiqing Sun, Sheng Shen, Shengcao Cao, Haotian Liu, Chunyuan Li, Yikang Shen, Chuang Gan, Liangyan Gui, Yu-Xiong Wang, Yiming Yang, K. Keutzer, Trevor Darrell\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A new alignment algorithm called Factually Augmented RLHF is proposed that augments the reward model with additional factual information such as image captions and ground-truth multi-choice options, which alleviates the reward hacking phenomenon in RLHF and further improves the performance.'}",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: 846f60ef3b98590c7ad1d84727c66a08cc2258c8\nTitle: Efficient Temporal Sentence Grounding in Videos with Multi-Teacher Knowledge Distillation\nYear: 2023\nAbstract: Temporal Sentence Grounding in Videos (TSGV) aims to detect the event timestamps described by the natural language query from untrimmed videos. This paper discusses the challenge of achieving efficient computation in TSGV models while maintaining high performance. Most existing approaches exquisitely design complex architectures to improve accuracy with extra layers and loss, suffering from inefficiency and heaviness. Although some works have noticed that, they only make an issue of feature fusion layers, which can hardly enjoy the highspeed merit in the whole clunky network. To tackle this problem, we propose a novel efficient multi-teacher model (EMTM) based on knowledge distillation to transfer diverse knowledge from both heterogeneous and isomorphic networks. Specifically, We first unify different outputs of the heterogeneous models into one single form. Next, a Knowledge Aggregation Unit (KAU) is built to acquire high-quality integrated soft labels from multiple teachers.",
  "Specifically, We first unify different outputs of the heterogeneous models into one single form. Next, a Knowledge Aggregation Unit (KAU) is built to acquire high-quality integrated soft labels from multiple teachers. After that, the KAU module leverages the multi-scale video and global query information to adaptively determine the weights of different teachers. A Shared Encoder strategy is then proposed to solve the problem that the student shallow layers hardly benefit from teachers, in which an isomorphic teacher is collaboratively trained with the student to align their hidden states. Extensive experimental results on three popular TSGV benchmarks demonstrate that our method is both effective and efficient without bells and whistles.\nAuthors: Renjie Liang, Yiming Yang, Hui Lu, Li Li\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A novel efficient multi-teacher model (EMTM) based on knowledge distillation to transfer diverse knowledge from both heterogeneous and isomorphic networks is proposed, which is both effective and efficient without bells and whistles.'}",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: 8635b9f82f6d0af1c24e837502be4e7de9bfddde\nTitle: A Via-Less Fully Screen-Printed Reconfigurable Intelligent Surface for 5G Millimeter Wave Communication\nYear: 2023\nAbstract: In this paper, we propose a via-less fully screen-printed reconfigurable intelligent surface which can establish a second line-of-sight communication from 23.5GHz to 29.5GHz. By serially connecting the H shaped resonator along the H field of the incident wave, we minimize the effect of the biasing lines and make a via-less design, which reduces the fabrication difficulty and cost. The unit-cell simulation of the array with screen-printed VO2 switches shows a 215\u00b0 to 160\u00b0 phase shift difference between the ON and OFF states within bandwidth. During the field testing of the ideal arrays, we verify that the array can redirect the 45\u00b0 incident wave to 0\u00b0 reflection with a signal enhancement of at least 10 dB as compared to the array which has all unit cells in the OFF condition.",
  "During the field testing of the ideal arrays, we verify that the array can redirect the 45\u00b0 incident wave to 0\u00b0 reflection with a signal enhancement of at least 10 dB as compared to the array which has all unit cells in the OFF condition.\nAuthors: Yiming Yang, Ruiqi Wang, M. Vaseem, Behrooz Makki, A. Shamim\nVenue: 2023 IEEE International Symposium on Antennas and Propagation and USNC-URSI Radio Science Meeting (USNC-URSI)\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A via-less fully screen-printed reconfigurable intelligent surface which can establish a second line-of-sight communication and can redirect the 45\u00b0 incident wave to 0\u00b0 reflection with a signal enhancement of at least 10 dB as compared to the array which has all unit cells in the OFF condition.'}",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: 88884b8806262a4095036041e3567d450dba39f7\nTitle: Active Retrieval Augmented Generation\nYear: 2023\nAbstract: Despite the remarkable ability of large language models (LMs) to comprehend and generate language, they have a tendency to hallucinate and create factually inaccurate output. Augmenting LMs by retrieving information from external knowledge resources is one promising solution. Most existing retrieval augmented LMs employ a retrieve-and-generate setup that only retrieves information once based on the input. This is limiting, however, in more general scenarios involving generation of long texts, where continually gathering information throughout generation is essential. In this work, we provide a generalized view of active retrieval augmented generation, methods that actively decide when and what to retrieve across the course of the generation. We propose Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens.",
  "We propose Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens. We test FLARE along with baselines comprehensively over 4 long-form knowledge-intensive generation tasks/datasets. FLARE achieves superior or competitive performance on all tasks, demonstrating the effectiveness of our method. Code and datasets are available at https://github.com/jzbjyb/FLARE.\nAuthors: Zhengbao Jiang, Frank F. Xu, Luyu Gao, Zhiqing Sun, Qian Liu, Jane Dwivedi-Yu, Yiming Yang, Jamie Callan, Graham Neubig\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes Forward-Looking Active REtrieval augmented generation (FLARE), a generic method which iteratively uses a prediction of the upcoming sentence to anticipate future content, which is then utilized as a query to retrieve relevant documents to regenerate the sentence if it contains low-confidence tokens.'}",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: 915fef14d53ac91df037f7749e922d7ce568d91f\nTitle: Chinese EFL learners different from English natives in cataphora resolution: Evidence from eye-tracking studies\nYear: 2023\nAbstract: Previous studies on English natives have shown that encountering an English cataphoric pronoun triggers an active search for its antecedent and this searching process is modulated by syntactic constraints. It remains unknown whether the conclusion is universal to EFL (English as a Foreign Language) learners, particularly those with distinct L1 like Chinese in linguistic typology. Therefore, this study used two eye-tracking experiments to investigate how Chinese EFL learners resolve English cataphora. The experiments adopted the gender-mismatch paradigm. Experiment 1 investigated whether Chinese EFL learners with different proficiency would adopt the similar processing pattern to English natives and found that gender congruency elicited longer reading times than gender incongruency between the first potential antecedent and the cataphoric pronoun, the effect early observed in high-proficiency relative to low-proficiency learners.",
  "Experiment 2 explored whether the cataphora resolution process was modulated by Binding Principle B and revealed that longer first fixation durations and first pass reading times were observed in gender-mismatch than in gender-match conditions no matter the antecedents are binding-accessible or not while longer regression path durations occurred in gender-mismatch than in gender-match conditions only as the antecedents are binding-accessible. Taken together, these results indicate that Chinese EFL learners also adopt an active search mechanism to resolve cataphoric pronouns, yet along a processing path distinct from English natives\u2019. Specifically, Chinese EFL learners predictively link a cataphoric pronoun to the first potential antecedent in the sentence but only a gender-matching antecedent can prompt them to engage in deep processing of the antecedent. Moreover, the processing time varies with the learners\u2019 English proficiency.",
  "Specifically, Chinese EFL learners predictively link a cataphoric pronoun to the first potential antecedent in the sentence but only a gender-matching antecedent can prompt them to engage in deep processing of the antecedent. Moreover, the processing time varies with the learners\u2019 English proficiency. Furthermore, unlike native English speakers\u2019 early application of syntactic constraints in their cataphora resolution, Chinese EFL learners try to establish co-reference relations between cataphoric pronouns and antecedents regardless of following or flouting Binding Principle B in early processing stages whereas they exclusively link the cataphoric pronouns to the binding-accessible antecedents in late processing stages. This study adds evidence to the Shallow Structure Hypothesis whereby L2 learners resort to lexical prior to syntactic cues to process sentences in general, which is just opposite to the fashion adopted by the natives.\nAuthors: Tao Wang, Mingyao Geng, Yue Wang, Min Zhao, Tongquan Zhou, Yiming Yang\nVenue: Frontiers in Psychology\nTldr: None",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: 92e48a081c080d2a5b6fe17ea9e1cb9d218e3505\nTitle: A Graphene Geometric Diode with the Highest Asymmetry Ratio and Three States Gate\u2010Tunable Rectification Ability\nYear: 2023\nAbstract: Graphene geometric diodes, with applications in THz detection, energy harvesting, and high\u2010speed rectification, have been previously constrained by graphene quality and geometry feature size. This study presents significant advancements in graphene geometric diodes by employing the h\u2010BN/monolayer graphene/h\u2010BN heterojunction and extremely precise electron beam lithography. Two distinct designs of graphene geometric diodes with neck widths of 23 and 26\u00a0nm are fabricated, the superior of which demonstrated an asymmetry ratio of 1.97, a zero bias current responsivity of 0.6\u00a0A\u00a0W\u22121, and a voltage responsivity of 12,000\u00a0V\u00a0W\u22121, setting new benchmarks for such devices.",
  "Integrating this device into a rectification circuit, the experimentally validate that the rectified DC output voltage can be dynamically modulated and even inverted through adjustments to the diode's gate voltage. This behavior aligns seamlessly with graphene's intrinsic tunability of charge carriers, implying promising prospects for the device's application in advanced logic circuits, bidirectional switches, and signal modulation/demodulation techniques.\nAuthors: Heng Wang, Maolin Chen, Yiming Yang, Yinchang Ma, Linqu Luo, Chen Liu, Igor Getmanov, T. Anthopoulos, Xixiang Zhang, A. Shamim\nVenue: Advanced Electronic Materials\nTldr: None",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: 938d2951ba3aa26f3752d489c3c044ae67d5e809\nTitle: Retrieval-Enhanced Generative Model for Large-Scale Knowledge Graph Completion\nYear: 2023\nAbstract: The task of knowledge graph completion (KGC) is of great importance. To achieve scalability when dealing with large-scale knowledge graphs, recent works formulate KGC as a sequence-to-sequence process, where the incomplete triplet (input) and the missing entity (output) are both verbalized as text sequences. However, inference with these methods relies solely on the model parameters for implicit reasoning and neglects the use of KG itself, which limits the performance since the model lacks the capacity to memorize a vast number of triplets. To tackle this issue, we introduce ReSKGC, a Retrieval-enhanced Seq2seq KGC model, which selects semantically relevant triplets from the KG and uses them as evidence to guide output generation with explicit reasoning. Our method has demonstrated state-of-the-art performance on benchmark datasets Wikidata5M and WikiKG90Mv2, which contain about 5M and 90M entities, respectively.",
  "Our method has demonstrated state-of-the-art performance on benchmark datasets Wikidata5M and WikiKG90Mv2, which contain about 5M and 90M entities, respectively.\nAuthors: Donghan Yu, Yiming Yang\nVenue: Annual International ACM SIGIR Conference on Research and Development in Information Retrieval\nTldr: {'model': 'tldr@v2.0.0', 'text': 'ReSKGC is introduced, a Retrieval-enhanced Seq2seq KGC model, which selects semantically relevant triplets from the KG and uses them as evidence to guide output generation with explicit reasoning, and has demonstrated state-of-the-art performance on benchmark datasets Wikidata5M and WikiKG90Mv2.'}",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: 9a40b3eb8cd454c72dfb4340a595d9aec1c9b8c1\nTitle: Recent Advances in the Ecology of Bloom-Forming Raphidiopsis (Cylindrospermopsis) raciborskii: Expansion in China, Intraspecific Heterogeneity and Critical Factors for Invasion\nYear: 2023\nAbstract: Water blooms caused by the invasive cyanobacterium Raphidiopsis raciborskii occur in many reservoirs in the tropical and subtropical regions of China. In recent decades, this species has spread rapidly to temperate regions. Phenotypic plasticity and climate warming are thought to promote the worldwide dispersion of R. raciborskii. However, investigations into the genetic and phenotypic diversities of this species have revealed significant intraspecific heterogeneity. In particular, competition between R. raciborskii and Microcystis aeruginosa was highly strain dependent.",
  "However, investigations into the genetic and phenotypic diversities of this species have revealed significant intraspecific heterogeneity. In particular, competition between R. raciborskii and Microcystis aeruginosa was highly strain dependent. Although the concept of an ecotype was proposed to explain the heterogeneity of R. raciborskii strains with different geographic origins, microevolution is more reasonable for understanding the coexistence of different phenotypes and genotypes in the same environment. It has been suggested that intraspecific heterogeneity derived from microevolution is a strong driving force for the expansion of R. raciborskii. Additionally, temperature, nutrient fluctuations, and grazer disturbance are critical environmental factors that affect the population establishment of R. raciborskii in new environments. The present review provides new insights into the ecological mechanisms underlying the invasion of R. raciborskii in Chinese freshwater ecosystems.",
  "Additionally, temperature, nutrient fluctuations, and grazer disturbance are critical environmental factors that affect the population establishment of R. raciborskii in new environments. The present review provides new insights into the ecological mechanisms underlying the invasion of R. raciborskii in Chinese freshwater ecosystems.\nAuthors: Li Zheng, Yang Liu, Renhui Li, Yiming Yang, Yongguang Jiang\nVenue: International Journal of Environmental Research and Public Health\nTldr: {'model': 'tldr@v2.0.0', 'text': 'New insights are provided into the ecological mechanisms underlying the invasion of R. raciborskii in Chinese freshwater ecosystems and microevolution is more reasonable for understanding the coexistence of different phenotypes and genotypes in the same environment.'}",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: 9ad3bf432b4c71a7324d85c7d970e15d7681dbe0\nTitle: Widely Targeted Metabolomics Was Used to Reveal the Differences between Non-Volatile Compounds in Different Wines and Their Associations with Sensory Properties\nYear: 2023\nAbstract: In this study, metabolites from six varieties of wines, including \u2018Haasan\u2019 (A1), \u2018Zuoshaner\u2019 (A2), \u2018Beibinghong\u2019 (A3), \u2018Shuanghong\u2019 (A4), \u2018Zijingganlu\u2019 (A5), and \u2018Cabernet Sauvignon\u2019 (A6), were identified and quantified using widely targeted metabolomics analysis techniques. Based on the test results, 1172 metabolites were detected and classified into 18 categories. These include 62 amino acids, 178 alkaloids, 189 flavonoids, 106 phenols, 148 terpenoids, etc. Comparing the differential metabolites between the comparison groups of each variety, differences between varieties based on P-values and VIP values were shown.",
  "These include 62 amino acids, 178 alkaloids, 189 flavonoids, 106 phenols, 148 terpenoids, etc. Comparing the differential metabolites between the comparison groups of each variety, differences between varieties based on P-values and VIP values were shown. Among these differential metabolites, Trimethoprim and Crotonoside were screened out as core differential metabolites. Multiple comparisons also screened the biomarkers for each species. We used widely targeted metabolomics to reveal the differences between non-volatile compounds in different wines and their associations with sensory properties. We also used the simultaneous weighted gene co-expression network analysis (WGCNA) to correlate metabolites with sensory traits, including color difference values and taste characteristics. Two of the six key modules were screened by WGCNA for relevance to sensory traits (brown module and turquoise module). This study provides a high-throughput method for linking compounds to various sensory characteristics of food, opening up new avenues for explaining differences in different varieties of wine.\nAuthors: W. Cao, Nan Shu, Jinli Wen, Yiming Yang, Yanlin Wang, Wenpeng Lu\nVenue: Foods\nTldr: None",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: aa066313c58d9fa64a94d3f88e36cbc778916d76\nTitle: Optimization of Critical Factors Affecting Dynamic Membrane Formation in a Gravity-Driven Self-Forming Dynamic Membrane Bioreactor towards Low-Cost and Low-Maintenance Wastewater Treatment\nYear: 2023\nAbstract: Self-forming dynamic membrane (SFDM) formation is affected by a variety of operating conditions. However, previous studies have only focused on individual influencing factors and a systematic analysis of important factors is lacking. In this study, an aerobic self-forming dynamic membrane bioreactor (SFDMBR) was developed for the treatment of domestic wastewater with the critical factors that affect the effective formation of SFDM optimized, and the operational performances under optimized formation conditions confirmed. The results indicated that SFDM could be formed within 5 min using 48 \u03bcm stainless-steel mesh as the supporting material at a sludge concentration of 5\u20136 g/L and a gravity waterhead of 15 cm.",
  "The results indicated that SFDM could be formed within 5 min using 48 \u03bcm stainless-steel mesh as the supporting material at a sludge concentration of 5\u20136 g/L and a gravity waterhead of 15 cm. And the SFDM formed could maintain a stable flux of 30\u201350 LMH, and the removals of COD, SCOD, and NH4+-N were 93.28%, 82.85%, and 95.46%, respectively. Furthermore, the cake layer resistance (reversible fouling) contributed to 95.93% of the total filtration resistance, thus a simple physical cleaning can effectively restore the flux indicating a low-maintenance requirement. This study provides valuable insights into the optimization and application of the SFDMBR process.\nAuthors: Luhe Tang, Jingyu Zhang, Lulu Zha, Yisong Hu, Yiming Yang, Yunsheng Zhao, Xinglong Dong, Zhanjiu Wang, Weihang Deng, Yuan Yang\nVenue: Water\nTldr: None",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: aab67be24b412216ee3a048b20af146459d3c406\nTitle: Functional targeted therapy for glioma based on platelet membrane-coated nanogels\nYear: 2023\nAbstract: None\nAuthors: Qin Li, Jing-Jing Shen, Lingling Wu, S. Lei, Yiming Yang, Weide Xu, Ke Hao, Yi Zhang, Fei Kong, Wei-Qiong Yang, Yaling Wang, Lina Peng, Kai-qiang Li, Zhen Wang\nVenue: Cancer nanotechnology\nTldr: {'model': 'tldr@v2.0.0', 'text': 'DOX@PNGs increased drug penetration and prolonged mouse survival time during the treatment of orthotopic gliomas, indicating this biomimetic drug delivery system to be promising for glioma treatment and may be clinically translated in the future.'}",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: ab352439202d719acde8b9b005bba357c60401f6\nTitle: A Neural PDE Solver with Temporal Stencil Modeling\nYear: 2023\nAbstract: Numerical simulation of non-linear partial differential equations plays a crucial role in modeling physical science and engineering phenomena, such as weather, climate, and aerodynamics. Recent Machine Learning (ML) models trained on low-resolution spatio-temporal signals have shown new promises in capturing important dynamics in high-resolution signals, under the condition that the models can effectively recover the missing details. However, this study shows that significant information is often lost in the low-resolution down-sampled features. To address such issues, we propose a new approach, namely Temporal Stencil Modeling (TSM), which combines the strengths of advanced time-series sequence modeling (with the HiPPO features) and state-of-the-art neural PDE solvers (with learnable stencil modeling). TSM aims to recover the lost information from the PDE trajectories and can be regarded as a temporal generalization of classic finite volume methods such as WENO.",
  "TSM aims to recover the lost information from the PDE trajectories and can be regarded as a temporal generalization of classic finite volume methods such as WENO. Our experimental results show that TSM achieves the new state-of-the-art simulation accuracy for 2-D incompressible Navier-Stokes turbulent flows: it significantly outperforms the previously reported best results by 19.9% in terms of the highly-correlated duration time and reduces the inference latency into 80%. We also show a strong generalization ability of the proposed method to various out-of-distribution turbulent flow settings. Our code is available at\"https://github.com/Edward-Sun/TSM-PDE\".\nAuthors: Zhiqing Sun, Yiming Yang, Shinjae Yoo\nVenue: International Conference on Machine Learning\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Temporal Stencil Modeling is proposed, which combines the strengths of advanced time-series sequence modeling and state-of-the-art neural PDE solvers (with learnable stencil modeling), and aims to recover the lost information from the PDE trajectories.'}",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: b4a6c010724f0459c9791018e34a982cf96987cf\nTitle: Let's Sample Step by Step: Adaptive-Consistency for Efficient Reasoning and Coding with LLMs\nYear: 2023\nAbstract: A popular approach for improving the correctness of output from large language models (LLMs) is Self-Consistency - poll the LLM multiple times and output the most frequent solution. Existing Self-Consistency techniques always generate a constant number of samples per question, where a better approach will be to non-uniformly distribute the available budget based on the amount of agreement in the samples generated so far. In response, we introduce Adaptive-Consistency, a cost-efficient, model-agnostic technique that dynamically adjusts the number of samples per question using a lightweight stopping criterion. Our experiments over 17 reasoning and code generation datasets and three LLMs demonstrate that Adaptive-Consistency reduces sample budget by up to 7.9 times with an average accuracy drop of less than 0.1%.",
  "Our experiments over 17 reasoning and code generation datasets and three LLMs demonstrate that Adaptive-Consistency reduces sample budget by up to 7.9 times with an average accuracy drop of less than 0.1%. Our code and data are available at https://www.sample-step-by-step.info\nAuthors: Pranjal Aggarwal, Aman Madaan, Yiming Yang, Mausam\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Adaptive-Consistency is introduced, a cost-efficient, model-agnostic technique that dynamically adjusts the number of samples per question using a lightweight stopping criterion that reduces sample budget by up to 7.9 times with an average accuracy drop of less than 0.1%.'}",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: b946ca9514be9920e5d1eff11f597facb8f7c6b7\nTitle: An Experimental Study on Secondary Transfer Performances of Prestress after Anchoring Failure of Steel Wire Strands\nYear: 2023\nAbstract: To understand the secondary transfer performances of residual prestress after the anchoring failure of end-anchored steel wire strands due to corrosion fracture, six steel wire strand components of post-tensioning prestress were designed and fabricated. One-side fast corrosion was applied to the steel wire strand components using the electrochemical method until anchoring failure was reached. The sphere of influence, stress changes, and the retraction and swelling effect of broken beams after failure were investigated. The influences of factors such as concrete strength, stirrup area, and the length of the component on the secondary transfer length of residual prestress were discussed. Based on the deformation relationship between prestressed steel wire strands and concrete in the stress transfer zone, a stress equation was established and solved through a bond constitutive model. A prediction model of the effective stress transfer length of prestressed steel wire strand after failure was proposed.",
  "Based on the deformation relationship between prestressed steel wire strands and concrete in the stress transfer zone, a stress equation was established and solved through a bond constitutive model. A prediction model of the effective stress transfer length of prestressed steel wire strand after failure was proposed. The results demonstrated that residual prestress can have a secondary transfer after the corrosion fracture of end-anchored steel wire strands, but some effective prestress may be lost. Moreover, the loss of prestress is inversely proportional to concrete compressive strength. When the specimens are relatively short, the prestress loss increases significantly. Concrete strength has significant influences on the length of secondary transfer. The proposed simplified calculation method of the secondary transfer length of residual prestress has a relatively high accuracy, with an average error of 2.9% and a maximum error of 5.2%.\nAuthors: Rihua Yang, Yiming Yang, Xuhui Zhang, Xinzhong Wang\nVenue: Metals\nTldr: None",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: bde44227630b017525a9b39aa2643d86090cb9d6\nTitle: Dual Responsive Magnetic Drug Delivery Nanomicelles with Tumor Targeting for Enhanced Cancer Chemo/Magnetothermal Synergistic Therapy\nYear: 2023\nAbstract: Introduction Stimulus-responsive nanocarrier systems are promising in cancer treatment. They improve drug stability and facilitate controlled drug release. However, single-responsive nanocarriers still face insufficient tumor targeting and low efficacy. Methods In this study, we synthesized folate-modified DSPE-PEOz nanomicelles with PEG chains and loaded them with magnetic iron particles and doxorubicin (DOX). Folic acid (FA) was employed as a ligand to target cancer cells actively. The nanomicelles are biocompatible and acid-sensitive drug carriers. Magnetic field-responsive nanoparticles enable moderately controlled magnetothermal therapy of tumors regardless of tumor location. The pH/magnetic field dual-responsive nanomicelles shed their PEG layer in response to tumor tissue acidity and react to magnetic fields through magnetothermal effects.",
  "Magnetic field-responsive nanoparticles enable moderately controlled magnetothermal therapy of tumors regardless of tumor location. The pH/magnetic field dual-responsive nanomicelles shed their PEG layer in response to tumor tissue acidity and react to magnetic fields through magnetothermal effects. Results In vitro and in vivo experiments demonstrated that the nanomicelles could efficiently target cancer cells, release drugs in response to pH changes, and enhance drug uptake through magnetothermal effects. Discussion The dual-responsive magnetic nanomicelles are expected to enhance the anti-cancer efficacy of chemo/magnetothermal synergistic therapy.\nAuthors: Jianmeng Zhu, Yiming Yang, Jian Wang, Wenzhong Hong, Yiping Li, Zhen Wang, Kaiqiang Li\nVenue: International Journal of Nanomedicine\nTldr: {'model': 'tldr@v2.0.0', 'text': 'In vitro and in vivo experiments demonstrated that the dual-responsive magnetic nanomicelles could efficiently target cancer cells, release drugs in response to pH changes, and enhance drug uptake through magnetothermal effects.'}",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: ca5d6ee5ce52d039c109fe44b0c68b1fe1f0198a\nTitle: Claudin-10 in the Blood Brain Barrier Function of Cerebral Endothelial Cells and Transendothelial Invasion of Breast Cancer Cells\nYear: 2023\nAbstract: Background/Aim: Claudin-10 (CLDN10) is a membrane integral protein. It is one of the widely expressed tight junctional claudins with functions not well defined. In the present study, the expression profile and its role in cerebral endothelial cells and in the interaction between breast cancer and endothelial cells were investigated. Materials and Methods: CLDN10 expression was examined in a wide range of cell types. Brain endothelial cell models with or without CLDN10 expression were generated using the hCMEC/D3 cell line and used to test the barrier and permeability functions. Transendothelial drug delivery and invasion were also evaluated.",
  "Brain endothelial cell models with or without CLDN10 expression were generated using the hCMEC/D3 cell line and used to test the barrier and permeability functions. Transendothelial drug delivery and invasion were also evaluated. Results: hCMEC/D3 cells express high levels of CLDN10, compared with peripheral endothelial cells, mesothelial cells, fibroblasts, and breast cancer cells, which were either negative or expressed low levels of CLDN10. Knockdown of CLDN10 in hCMEC/D3 cells resulted in impaired tight junctions as seen by reduced transendothelial electric resistance and paracellular permeability. It also accelerated invasion of breast cancer cells through the endothelial cell layer. CLDN10 knockdown in hCMEC/D3 cells led to an increase in transendothelial chemodrug delivery. Furthermore, the SRC kinase inhibitor (AZM475271) was able to decrease the impedance and increase the paracellular permeability in cerebral endothelial cells.",
  "CLDN10 knockdown in hCMEC/D3 cells led to an increase in transendothelial chemodrug delivery. Furthermore, the SRC kinase inhibitor (AZM475271) was able to decrease the impedance and increase the paracellular permeability in cerebral endothelial cells. Conclusion: Cerebral endothelial cells express high levels of CLDN10, a protein regulating barrier function and thereby drug permeability and cancer invasiveness in brain endothelial cells, suggesting that it is a novel therapeutic target for the treatment of brain metastasis-related diseases.\nAuthors: Tracy A. Martin, Xinguo Zhuang, Wenxiao Ji, Ziqian Fang, Yiming Yang, F. Ruge, Q. Dou, LI Xun, XU Bing, W. Jiang, T. Martin\nVenue: Anticancer Research\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Cerebral endothelial cells express high levels of CLDN10, a protein regulating barrier function and thereby drug permeability and cancer invasiveness in brain endothelial Cells, suggesting that it is a novel therapeutic target for the treatment of brain metastasis-related diseases.'}",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: cfc9f23631c9dcb0935af6cf43d23854959a35c8\nTitle: De novo assembling a high-quality genome sequence of Amur grape (Vitis amurensis Rupr.) gives insight into Vitis divergence and sex determination\nYear: 2023\nAbstract: To date, there is no high-quality sequence for genomes of the East Asian grape species, hindering biological and breeding research efforts to improve grape cultivars. This study presents a \u223c522 Mb of the Vitis amurensis (Va) genome sequence containing 27,635 coding genes. Phylogenetic analysis indicated that V. riparia (Vr) may firstly split from the other two species, Va, V. Vinifera (Vv; Pinot Noir: PN40024 and Cabernet Sauvignon). Much divergent gene reservation among three grape duplicated gene sets suggests that the core eudicot common hexaploidy (ECH), 130 million years ago (Mya), has still played a non-negligible role in grape species divergence and biological innovation.",
  "Much divergent gene reservation among three grape duplicated gene sets suggests that the core eudicot common hexaploidy (ECH), 130 million years ago (Mya), has still played a non-negligible role in grape species divergence and biological innovation. Prominent accumulation of sequence variants might have improved cold resistance in Va, resulting in a more robust cold resistance gene regulatory network than those in Vv and Vr. In contrast, Va preserved much fewer NBS disease resistance genes than the other grapes. Notably, multi-omics analysis identified one trans-cinnamate 4-monooxygenase gene positively correlated to the resveratrol accumulated during Va berry development. A selective sweep analysis revealed a hypothetical Va sex-determination region (SDR). Besides, a PPR-containing protein-coding gene in the hypothetical SDR may be related with sex determination in Va. The content and arrangement order of genes in the putative SDR of female Va were similar to the SDR of female Vv. However, the putative SDR of female Va lost one Flavin-containing monooxygenases (FMO) and contained one extra uncharacterized protein-coding gene.",
  "The content and arrangement order of genes in the putative SDR of female Va were similar to the SDR of female Vv. However, the putative SDR of female Va lost one Flavin-containing monooxygenases (FMO) and contained one extra uncharacterized protein-coding gene. These findings will improve the understanding of Vitis biology and contribute to the improvement of grape breeding.\nAuthors: Pengfei Wang, Fanbo Meng, Yiming Yang, Qian Mu, Tingting Ding, Huiping Liu, Fengxia Wang, Ao Li, Qingtian Zhang, Shutian Fan, Bo Li, Zhiyao Ma, Tianhao Zhang, Yongfeng Zhou, Hongjun Zhao, Xiyin Wang\nVenue: bioRxiv\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A selective sweep analysis revealed a hypothetical Va sex-determination region (SDR), and a PPR-containing protein-coding gene in the hypothetical SDR may be related with sex determination in Va, which will improve the understanding of Vitis biology and contribute to the improvement of grape breeding.'}",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: e01515c6138bc525f7aec30fc85f2adf028d4156\nTitle: Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision\nYear: 2023\nAbstract: Recent AI-assistant agents, such as ChatGPT, predominantly rely on supervised fine-tuning (SFT) with human annotations and reinforcement learning from human feedback (RLHF) to align the output of large language models (LLMs) with human intentions, ensuring they are helpful, ethical, and reliable. However, this dependence can significantly constrain the true potential of AI-assistant agents due to the high cost of obtaining human supervision and the related issues on quality, reliability, diversity, self-consistency, and undesirable biases. To address these challenges, we propose a novel approach called SELF-ALIGN, which combines principle-driven reasoning and the generative power of LLMs for the self-alignment of AI agents with minimal human supervision.",
  "To address these challenges, we propose a novel approach called SELF-ALIGN, which combines principle-driven reasoning and the generative power of LLMs for the self-alignment of AI agents with minimal human supervision. Our approach encompasses four stages: first, we use an LLM to generate synthetic prompts, and a topic-guided method to augment the prompt diversity; second, we use a small set of human-written principles for AI models to follow, and guide the LLM through in-context learning from demonstrations (of principles application) to produce helpful, ethical, and reliable responses to user's queries; third, we fine-tune the original LLM with the high-quality self-aligned responses so that the resulting model can generate desirable responses for each query directly without the principle set and the demonstrations anymore; and finally, we offer a refinement step to address the issues of overly-brief or indirect responses. Applying SELF-ALIGN to the LLaMA-65b base language model, we develop an AI assistant named Dromedary. With fewer than 300 lines of human annotations (including<200 seed prompts, 16 generic principles, and 5 exemplars for in-context learning).",
  "Applying SELF-ALIGN to the LLaMA-65b base language model, we develop an AI assistant named Dromedary. With fewer than 300 lines of human annotations (including<200 seed prompts, 16 generic principles, and 5 exemplars for in-context learning). Dromedary significantly surpasses the performance of several state-of-the-art AI systems, including Text-Davinci-003 and Alpaca, on benchmark datasets with various settings.\nAuthors: Zhiqing Sun, Yikang Shen, Qinhong Zhou, Hongxin Zhang, Zhenfang Chen, David D. Cox, Yiming Yang, Chuang Gan\nVenue: Neural Information Processing Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'An AI assistant named Dromedary is developed, which combines principle-driven reasoning and the generative power of LLMs for the self-alignment of AI agents with minimal human supervision and significantly surpasses the performance of several state-of-the-art AI systems on benchmark datasets with various settings.'}",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: e27978b8c3ca83ccc42f2cac11771b14cf910104\nTitle: Synergistic Interface Engineering of RuO2/Co3O4 Heterostructures for Enhanced Overall Water Splitting in Acidic Media\nYear: 2023\nAbstract: Designing nanocomposites with heterointerface as bifunctional electrocatalysts is a potential strategy to overcome the intrinsic activity limitation of electrocatalytic water splitting in acidic media, but it remains challenging. Herein, the highly efficient RuO2/Co3O4 electrocatalyst with a uniform nanoflower structure is prepared by hydrothermal growth combined with interface engineering. Benefiting from the unique nanostructure, the migration of electrons and intermediates is optimized by the sufficient exposure of abundant micropores and defects. Moreover, the formation of strong electronic interaction at the RuO2/Co3O4 heterointerfaces boosts the electrochemical active surface area and accelerates the reaction kinetics, which effectively improve the catalytic activity and stability of the catalyst.",
  "Moreover, the formation of strong electronic interaction at the RuO2/Co3O4 heterointerfaces boosts the electrochemical active surface area and accelerates the reaction kinetics, which effectively improve the catalytic activity and stability of the catalyst. Based on enhanced intrinsic activity and electron transfer, the as\u2010synthesized RuO2/Co3O4 displays impressive hydrogen evolution reaction and oxygen evolution reaction activity, which respectively require low overpotentials of 240 and 100\u2009mV to achieve a current density of 10\u2009mA\u2009cm\u22122 in 0.5\u2009m H2SO4. As a bifunctional electrode, RuO2/Co3O4 exhibits a low operating voltage of 1.58\u2009V at 10\u2009mA\u2009cm\u22122 for overall electrochemical water splitting. This study demonstrates the importance of heterostructure engineering in providing an avenue to achieve acid\u2010stable bifunctional electrocatalysts for energy conversion applications.",
  "This study demonstrates the importance of heterostructure engineering in providing an avenue to achieve acid\u2010stable bifunctional electrocatalysts for energy conversion applications.\nAuthors: Yiming Yang, Luqi Wang, Ming-yue Ma, Feng Hu, Linlin Li, Y. Tan, D. Kai, J. Ren, Shengjie Peng\nVenue: Advanced Energy and Sustainability Research\nTldr: None",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: e55d2e5eaabf1ecef8a4d27c669413deb51690e9\nTitle: The Relationship between the Serum NLRP1 Level and Coronary Lesions in Patients with Coronary Artery Disease\nYear: 2023\nAbstract: Background The pathogenesis of coronary artery disease is complex, and inflammation is one of the regulatory factors. The nucleotide-binding oligomerization domain (NOD)-like receptor protein 1 (NLRP1) plays an important role in the cellular inflammatory response, cell apoptosis, cell death, and autoimmune diseases. Whether the level of NLRP1 is related to the severity of coronary artery stenosis in patients with coronary artery disease (CAD) has not been reported. Objective To test the serum level of NLRP1 in unstable angina (UA) patients and investigate the effect of NLRP1 on coronary stenosis severity of the coronary artery disease (CAD).",
  "Objective To test the serum level of NLRP1 in unstable angina (UA) patients and investigate the effect of NLRP1 on coronary stenosis severity of the coronary artery disease (CAD). Methods 307 patients hospitalized in the Department of Cardiology of the Affiliated Hospital of Xuzhou Medical University for coronary angiography from January 1, 2021, to December 31, 2022 were included. We detect the level of NLRP1 in the serum of the included patients. Patients were divided into UA group and control group according to coronary angiography results and other clinical data. We use logistic regression to screen the influencing factors of UA. Then, subgroups were divided according to the Gensini score and the number of coronary artery lesions, and the difference of serum NLRP1 level between the groups was compared. Spearman correlation analysis was used to explore the correlation between the serum NLRP1 level and Gensini score. We analyze the diagnostic value of NLRP1 for UA by drawing ROC curve.",
  "Spearman correlation analysis was used to explore the correlation between the serum NLRP1 level and Gensini score. We analyze the diagnostic value of NLRP1 for UA by drawing ROC curve. Results The median level of serum NLRP1 in patients with UA (n\u2009=\u2009257) was 49.71\u2009pg/ml, IQR 30.15, 80.21, and that in patients without UA (n\u2009=\u200950) was 24.75\u2009pg/ml, IQR 13.49, 41.95. Serum NLRP1 levels were significantly different among different subgroups. The patient's Gensini score was correlated with the patient's serum NLRP1 level. Conclusion The serum NLRP1 level is increased in patients with UA, which is increased with the increasing severity of coronary lesions.",
  "Serum NLRP1 levels were significantly different among different subgroups. The patient's Gensini score was correlated with the patient's serum NLRP1 level. Conclusion The serum NLRP1 level is increased in patients with UA, which is increased with the increasing severity of coronary lesions.\nAuthors: Jing Zong, Yixiao Wang, Siyu Pan, Yiming Yang, Jingfeng Peng, Fangfang Li, Luhong Xu, Shanshan Li, Wen-hao Qian\nVenue: International journal of clinical practice\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The serumNLRP1 level is increased in patients with UA, which is increased with the increasing severity of coronary lesions, and the diagnostic value of NLRP1 for UA is analyzed by drawing ROC curve.'}",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: f1a75a847c99ab399454c911235f0d5f7854c5a4\nTitle: MRI Features for Predicting Microvascular Invasion and Postoperative Recurrence in Hepatocellular Carcinoma Without Peritumoral Hypointensity\nYear: 2023\nAbstract: Purpose To identify MRI features of hepatocellular carcinoma (HCC) that predict microvascular invasion (MVI) and postoperative intrahepatic recurrence in patients without peritumoral hepatobiliary phase (HBP) hypointensity. Patients and Methods One hundred and thirty patients with HCC who underwent preoperative gadoxetate-enhanced MRI and curative hepatic resection were retrospectively reviewed. Two radiologists reviewed all preoperative MR images and assessed the radiological features of HCCs. The ability of peritumoral HBP hypointensity to identify MVI and intrahepatic recurrence was analyzed. We then assessed the MRI features of HCC that predicted the MVI and intrahepatic recurrence-free survival (RFS) in the subgroup without peritumoral HBP hypointensity.",
  "We then assessed the MRI features of HCC that predicted the MVI and intrahepatic recurrence-free survival (RFS) in the subgroup without peritumoral HBP hypointensity. Finally, a two-step flowchart was constructed to assist in clinical decision-making. Results Peritumoral HBP hypointensity (odds ratio, 3.019; 95% confidence interval: 1.071\u20138.512; P=0.037) was an independent predictor of MVI. The sensitivity, specificity, positive predictive value, negative predictive value, and AUROC of peritumoral HBP hypointensity in predicting MVI were 23.80%, 91.04%, 71.23%, 55.96%, and 0.574, respectively. Intrahepatic RFS was significantly shorter in patients with peritumoral HBP hypointensity (P<0.001). In patients without peritumoral HBP hypointensity, the only significant difference between MVI-positive and MVI-negative HCCs was the presence of a radiological capsule (P=0.038).",
  "In patients without peritumoral HBP hypointensity, the only significant difference between MVI-positive and MVI-negative HCCs was the presence of a radiological capsule (P=0.038). Satellite nodule was an independent risk factor for intrahepatic RFS (hazard ratio,3.324; 95% CI: 1.733\u20136.378; P<0.001). The high-risk HCC detection rate was significantly higher when using the two-step flowchart that incorporated peritumoral HBP hypointensity and satellite nodule than when using peritumoral HBP hypointensity alone (P<0.001). Conclusion In patients without peritumoral HBP hypointensity, a radiological capsule is useful for identifying MVI and satellite nodule is an independent risk factor for intrahepatic RFS.",
  "Conclusion In patients without peritumoral HBP hypointensity, a radiological capsule is useful for identifying MVI and satellite nodule is an independent risk factor for intrahepatic RFS.\nAuthors: Zhiyuan Chen, Xiaohuan Li, Yu Zhang, Yiming Yang, Yan Zhang, Dongjing Zhou, Yu Yang, Shuping Zhang, Yupin Liu\nVenue: Journal of Hepatocellular Carcinoma\nTldr: {'model': 'tldr@v2.0.0', 'text': 'In patients without peritumoral HBP hypointensity, a radiological capsule is useful for identifying MVI and satellite nodule is an independent risk factor for intrahepatic RFS, and a two-step flowchart was constructed to assist in clinical decision-making.'}",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: f41fd54d122d7de833e2d5b2a57444c301ca99eb\nTitle: Cardsformer: Grounding Language to Learn a Generalizable Policy in Hearthstone\nYear: 2023\nAbstract: None\nAuthors: Wannian Xia, Yiming Yang, Jingqing Ruan, Dengpeng Xing, Bo Xu\nVenue: European Conference on Artificial Intelligence\nTldr: None",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: fe9fe9f15f24fbbb19b62bcd9a3418511a699b84\nTitle: Policy Representation via Diffusion Probability Model for Reinforcement Learning\nYear: 2023\nAbstract: Popular reinforcement learning (RL) algorithms tend to produce a unimodal policy distribution, which weakens the expressiveness of complicated policy and decays the ability of exploration. The diffusion probability model is powerful to learn complicated multimodal distributions, which has shown promising and potential applications to RL. In this paper, we formally build a theoretical foundation of policy representation via the diffusion probability model and provide practical implementations of diffusion policy for online model-free RL. Concretely, we character diffusion policy as a stochastic process, which is a new approach to representing a policy. Then we present a convergence guarantee for diffusion policy, which provides a theory to understand the multimodality of diffusion policy. Furthermore, we propose the DIPO which is an implementation for model-free online RL with DIffusion POlicy. To the best of our knowledge, DIPO is the first algorithm to solve model-free online RL problems with the diffusion model.",
  "Furthermore, we propose the DIPO which is an implementation for model-free online RL with DIffusion POlicy. To the best of our knowledge, DIPO is the first algorithm to solve model-free online RL problems with the diffusion model. Finally, extensive empirical results show the effectiveness and superiority of DIPO on the standard continuous control Mujoco benchmark.\nAuthors: Long Yang, Zhixiong Huang, Fenghao Lei, Yucun Zhong, Yiming Yang, Cong Fang, Shiting Wen, Binbin Zhou, Zhouchen Lin\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A theoretical foundation of policy representation via the diffusion probability model is formally built, a convergence guarantee for diffusion policy is presented, and the DIPO is proposed, which is an implementation for model-free online RL with DIffusion POlicy.'}",
  "Faculty Name: yang yiming\nMetadata:\nPaperid: ff4bd0966db6a5f30fe41c8479765e9d9702a8c0\nTitle: Impact of local governments\u2019 construction land allocation strategies on innovation-driven development of China\nYear: 2023\nAbstract: None\nAuthors: Jian Wang, Shangui Peng, Yuhao Feng, Yiming Yang, Qun Wu\nVenue: \u8d44\u6e90\u79d1\u5b66\nTldr: None",
  "List of 2023 Open Access papers by yang yiming are:\nFunctional targeted therapy for glioma based on platelet membrane-coated nanogels\nDual Responsive Magnetic Drug Delivery Nanomicelles with Tumor Targeting for Enhanced Cancer Chemo/Magnetothermal Synergistic Therapy\nExpression of ALCAM in Clinical Colon Cancer and Relationship With Patients\u2019 Treatment Responses\nClaudin-10 in the Blood Brain Barrier Function of Cerebral Endothelial Cells and Transendothelial Invasion of Breast Cancer Cells\nAccelerating Diffusion-based Combinatorial Optimization Solvers by Progressive Distillation\nAutomatic synchrotron tomographic alignment schemes based on genetic algorithms and human-in-the-loop software\nHigh CD8+tumor-infiltrating lymphocytes indicate severe exhaustion and poor prognosis in angioimmunoblastic T-cell lymphoma\nNumerical Investigation of Fatigue Crack Propagation Behaviour of 550E High-Performance Steel\nAssociation between albumin-to-globulin ratio and the risk of overall survival in advanced non-small cell lung cancer patients with anlotinib treatment: a retrospective cohort study\nAnalysis of Volatile Components in Dried Fruits and Branch Exudates of Schisandra chinensis with Different Fruit Colors Using GC-IMS Technology\nSecreted",
  "ratio and the risk of overall survival in advanced non-small cell lung cancer patients with anlotinib treatment: a retrospective cohort study\nAnalysis of Volatile Components in Dried Fruits and Branch Exudates of Schisandra chinensis with Different Fruit Colors Using GC-IMS Technology\nSecreted endogenous macrosomes reduce A\u03b2 burden and ameliorate Alzheimer\u2019s disease\nDIFUSCO: Graph-based Diffusion Solvers for Combinatorial Optimization\nBalancing Exploration and Exploitation in Hierarchical Reinforcement Learning via Latent Landmark Graphs\nAligning Large Multimodal Models with Factually Augmented RLHF\nAn Experimental Study on Secondary Transfer Performances of Prestress after Anchoring Failure of Steel Wire Strands\nMRI Features for Predicting Microvascular Invasion and Postoperative Recurrence in Hepatocellular Carcinoma Without Peritumoral Hypointensity\nImpact of local governments\u2019 construction land allocation strategies on innovation-driven development of China\nSynergistic Interface Engineering of RuO2/Co3O4 Heterostructures for Enhanced Overall Water Splitting in Acidic Media\nNumerical Analysis on the Influence of Joint Density on the Stability of Complex Jointed Roadway Surrounding Rock\nExperimental Study on Secondary Anchorage Bond Performance",
  "development of China\nSynergistic Interface Engineering of RuO2/Co3O4 Heterostructures for Enhanced Overall Water Splitting in Acidic Media\nNumerical Analysis on the Influence of Joint Density on the Stability of Complex Jointed Roadway Surrounding Rock\nExperimental Study on Secondary Anchorage Bond Performance of Residual Stress after Corrosion Fracture at Ends of Prestressed Steel Strands\nThe Relationship between the Serum NLRP1 Level and Coronary Lesions in Patients with Coronary Artery Disease\nMatrine induces ferroptosis in cervical cancer through activation of piezo1 channel.\n16p11.2 CNV gene Doc2\u03b1 functions in neurodevelopment and social behaviors through interaction with Secretagogin.\nChinese EFL learners different from English natives in cataphora resolution: Evidence from eye-tracking studies\nStrain-driven Kovacs-like memory effect in glasses\nTRPML1 as a potential therapeutic target for triple-negative breast cancer: a review\nLet's Sample Step by Step: Adaptive-Consistency for Efficient Reasoning with LLMs\nGenome- and transcriptome-wide identification of trehalose-6-phosphate phosphatases (TPP) gene family and their expression patterns under abiotic stress and exogenous",
  "triple-negative breast cancer: a review\nLet's Sample Step by Step: Adaptive-Consistency for Efficient Reasoning with LLMs\nGenome- and transcriptome-wide identification of trehalose-6-phosphate phosphatases (TPP) gene family and their expression patterns under abiotic stress and exogenous trehalose in soybean\nImaging Field\u2010Driven Melting of a Molecular Solid at the Atomic Scale\nA Wideband Reconfigurable Intelligent Surface for 5G Millimeter-Wave Applications\nA Via-Less Fully Screen-Printed Reconfigurable Intelligent Surface for 5G Millimeter Wave Communication\nSALMON: Self-Alignment with Principle-Following Reward Models\nWidely Targeted Metabolomics Was Used to Reveal the Differences between Non-Volatile Compounds in Different Wines and Their Associations with Sensory Properties\nCardsformer: Grounding Language to Learn a Generalizable Policy in Hearthstone\nApproximation and interpolation with neural network\nA Graphene Geometric Diode with the Highest Asymmetry Ratio and Three States Gate\u2010Tunable Rectification Ability\nDe novo assembling a high-quality genome sequence of Amur grape (Vitis amurensis Rupr.) gives insight into Vitis",
  "and interpolation with neural network\nA Graphene Geometric Diode with the Highest Asymmetry Ratio and Three States Gate\u2010Tunable Rectification Ability\nDe novo assembling a high-quality genome sequence of Amur grape (Vitis amurensis Rupr.) gives insight into Vitis divergence and sex determination\nPESCO: Prompt-enhanced Self Contrastive Learning for Zero-shot Text Classification\nLearning Performance-Improving Code Edits\nGeneration-driven Contrastive Self-training for Zero-shot Text Classification with Instruction-tuned GPT\nSelf-Refine: Iterative Refinement with Self-Feedback\nLong-tailed Extreme Multi-label Text Classification by the Retrieval of Generated Pseudo Label Descriptions\nLearning a Fourier Transform for Linear Relative Positional Encodings in Transformers\nEfficient Temporal Sentence Grounding in Videos with Multi-Teacher Knowledge Distillation\nActive Retrieval Augmented Generation\nRetrieval-Enhanced Generative Model for Large-Scale Knowledge Graph Completion\nLet's Sample Step by Step: Adaptive-Consistency for Efficient Reasoning and Coding with LLMs\nPrinciple-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision\nPolicy Representation via Diffusion Probability Model for Reinforcement Learning\nA Neural PDE Solver",
  "Large-Scale Knowledge Graph Completion\nLet's Sample Step by Step: Adaptive-Consistency for Efficient Reasoning and Coding with LLMs\nPrinciple-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision\nPolicy Representation via Diffusion Probability Model for Reinforcement Learning\nA Neural PDE Solver with Temporal Stencil Modeling\nResearch on Comprehensive Performance Optimization Method of Explosives and Propellants Oriented to the Whole Process\nInference of single cell profiles from histology stains with the Single-Cell omics from Histology Analysis Framework (SCHAF)\nRecent Advances in the Ecology of Bloom-Forming Raphidiopsis (Cylindrospermopsis) raciborskii: Expansion in China, Intraspecific Heterogeneity and Critical Factors for Invasion\nAn Ultra-Low-Power Analog Multiplier\u2013Divider Compatible with Digital Code for RRAM-Based Computing-in-Memory Macros\nExtension of Pt\u2013Ag cluster units by incorporating silver salts\nOptimization of Critical Factors Affecting Dynamic Membrane Formation in a Gravity-Driven Self-Forming Dynamic Membrane Bioreactor towards Low-Cost and Low-Maintenance Wastewater Treatment",
  "Title: Yiming Yang -     Language Technologies Institute -     School of Computer Science - Carnegie Mellon University\n\nMeta Tags:\n<meta charset=\"utf-8\"/>\n<meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n<meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n<meta content=\"Bio of Yiming Yang, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" name=\"description\"/>\n<meta content=\"Carnegie Mellon University\" name=\"author\"/>\n<meta content=\"Core Faculty\" name=\"categories-1\"/>\n<meta content=\"Faculty\" name=\"global-categories\"/>\n<meta content=\"Yiming Yang - Language Technologies Institute - School of Computer Science - Carnegie Mellon University\" property=\"og:title\"/>\n<meta content=\"Bio of Yiming Yang, Faculty Member at Carnegie Mellon University's Language Technologies Institute\" property=\"og:description\"/>\n<meta content=\"profile\" property=\"og:type\"/>\n<meta content=\"Firstname\" property=\"profile:Yiming\"/>\n<meta content=\"Lastname\" property=\"profile:Yang\"/>\n<meta content=\"http://lti.cmu.edu//people/faculty/yiming-yang.",
  "cmu.edu//people/faculty/yiming-yang.html\" property=\"og:url\"/>\n<meta data-siteid=\"lti\" id=\"siteId\"/>\n<meta content=\"#9f0000\" name=\"msapplication-TileColor\"/>\n<meta content=\"//www.cmu.edu/favicon-144.png\" name=\"msapplication-TileImage\"/>\n\nContent:\nYiming \n                        Yang\nProfessor, Language Technologies Institute\nContact\n6717 \u2014Gates & Hillman Centers\nyiming(through)cs.cmu.edu\n412-268-1364\nResearch\nMy research has centered on statistical learning methods/algorithms and application to very-large-scale text categorization, web-mining for concept graph discovery, semi-supervised clustering, multitask learning, novelty-based information retrieval, large-scale optimization for online advertising, social network analysis for personalized email prioritization, etc.",
  "web-mining for concept graph discovery, semi-supervised clustering, multitask learning, novelty-based information retrieval, large-scale optimization for online advertising, social network analysis for personalized email prioritization, etc. My recent research focuses on the following topics:\nLarge-Scale Structured Learning for Hierarchical Classification\n(\nGopal & Yang, KDD 2013\n;\nGopal\n& Yang, ICML 2013 & Supplementary\u00a0 ;\nGopal et al., NIPS 2012\n)\nProviding organizational views of multi-source Big Data (e.g., Wikipedia, online shops, Coursera)\nState-of-the-art classifiers for large-scale classification over hundreds of thousands of categories\nScalable variational inference for joint optimization of one trillion (4 TB) model parameters\nScalable Machine Learning for Time Series Analysis (\nTopic Detection and Tracking)\nFrom scientific literature, news stories, sensor signals, maintenance reports, etc.\nModeling multi-source and multi-scale evidence of dynamic chances in temporal sequences.",
  "Modeling multi-source and multi-scale evidence of dynamic chances in temporal sequences. (\nOn-going NSF project\n;\nGopal, PhD Thesis\n)\nA new family of Bayesian von Mices Fischer (vMF) clustering techniques (\nGopal & Yang, ICML 2014\n&\nSupplementary\n)\nUnsupervised clustering and semi-supervised metric learning and supervised classification (\nGopal & Yang, UAI 2014\n&\nSupplimentary\n).\nConcept Graph Learning for Online Education\n(\nNSF project\n;\nYang et al., WSDM 2015\n)\nMapping online course materials to Wikipedia categories as the Interlingua (universal concepts)\nPredicting conceptual dependencies among courses based on partially observed prerequisites\nPlanning customized curriculum for individuals based on backgrounds and goals\nMacro-Level Information Fusion for Events and Entities\n(joint effort with Jaime Carbonell in the DARPA DEFT project)\nDetecting entities and events of interest in various forms of mentions in text to enable high-precision, semi-structured information fusion and summarization. Using a corporate acquisition event as an example, different (and partially redundant) sentences can mention acquirer, price, date, approvals, joint-management, etc.",
  "Using a corporate acquisition event as an example, different (and partially redundant) sentences can mention acquirer, price, date, approvals, joint-management, etc. This multi-aspect information needs to be jointly extracted into a unified structured form for this event type, with uncertainty estimates in the aggregated representation.",
  "Using a corporate acquisition event as an example, different (and partially redundant) sentences can mention acquirer, price, date, approvals, joint-management, etc. This multi-aspect information needs to be jointly extracted into a unified structured form for this event type, with uncertainty estimates in the aggregated representation.\nPersonal Website\n\nLinks:\nhttp://nyc.lti.cs.cmu.edu/yiming/Publications/gopal-kdd13.pdf\nhttp://nyc.lti.cs.cmu.edu/yiming/Publications/gopal-icml13.pdf\nhttp://nyc.lti.cs.cmu.edu/yiming/Publications/gopal-nips12.pdf\nhttp://nyc.lti.cs.cmu.edu/mfhdt/index.html\nhttp://lti.cs.cmu.edu/sites/default/files/research/reports/2014/CMU-LTI-14-005-D.pdf\nhttp://nyc.lti.cs.cmu.edu/yiming/Publications/gopal-icml14-vmf.pdf\nhttp://nyc.lti.cs.cmu.edu/yiming/Publications/gopal-icml14-supp.pdf\nhttp://nyc.lti.cs.cmu.edu/yiming/Publications/gopal-uai14.pdf\nhttp://nyc.lti.cs.cmu.edu/yiming/Publications/gopal-uai14-supp.pdf\nhttp://nyc.lti.cs.cmu.edu/teacher/index.html\nhttp://nyc.lti.cs.cmu.edu/yiming/Publications/yang-wsdm15.pdf\nhttp://www.cs.cmu.edu/~yiming/",
  "Faculty Name: yonatan bisk\nMetadata:\nPaperid: 376f494126d1ea4f571ea0263c43ac2b6331800a\nTitle: SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs\nYear: 2023\nAbstract: In this work, we introduce Semantic Pyramid AutoEncoder (SPAE) for enabling frozen LLMs to perform both understanding and generation tasks involving non-linguistic modalities such as images or videos. SPAE converts between raw pixels and interpretable lexical tokens (or words) extracted from the LLM's vocabulary. The resulting tokens capture both the semantic meaning and the fine-grained details needed for visual reconstruction, effectively translating the visual content into a language comprehensible to the LLM, and empowering it to perform a wide array of multimodal tasks. Our approach is validated through in-context learning experiments with frozen PaLM 2 and GPT 3.5 on a diverse set of image understanding and generation tasks. Our method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%.",
  "Our method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%.\nAuthors: Lijun Yu, Yong Cheng, Zhiruo Wang, Vivek Kumar, Wolfgang Macherey, Yanping Huang, David A. Ross, Irfan Essa, Yonatan Bisk, Ming Yang, K. Murphy, A. Hauptmann, Lu Jiang\nVenue: Neural Information Processing Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This method marks the first successful attempt to enable a frozen LLM to generate image content while surpassing state-of-the-art performance in image understanding tasks, under the same setting, by over 25%.'}",
  "Faculty Name: yonatan bisk\nMetadata:\nPaperid: 3b0c02955e88f5862e61b560c7f70ba8cf235b1d\nTitle: HomeRobot: Open-Vocabulary Mobile Manipulation\nYear: 2023\nAbstract: HomeRobot (noun): An affordable compliant robot that navigates homes and manipulates a wide range of objects in order to complete everyday tasks. Open-Vocabulary Mobile Manipulation (OVMM) is the problem of picking any object in any unseen environment, and placing it in a commanded location. This is a foundational challenge for robots to be useful assistants in human environments, because it involves tackling sub-problems from across robotics: perception, language understanding, navigation, and manipulation are all essential to OVMM. In addition, integration of the solutions to these sub-problems poses its own substantial challenges. To drive research in this area, we introduce the HomeRobot OVMM benchmark, where an agent navigates household environments to grasp novel objects and place them on target receptacles.",
  "In addition, integration of the solutions to these sub-problems poses its own substantial challenges. To drive research in this area, we introduce the HomeRobot OVMM benchmark, where an agent navigates household environments to grasp novel objects and place them on target receptacles. HomeRobot has two components: a simulation component, which uses a large and diverse curated object set in new, high-quality multi-room home environments; and a real-world component, providing a software stack for the low-cost Hello Robot Stretch to encourage replication of real-world experiments across labs. We implement both reinforcement learning and heuristic (model-based) baselines and show evidence of sim-to-real transfer. Our baselines achieve a 20% success rate in the real world; our experiments identify ways future research work improve performance. See videos on our website: https://ovmm.github.io/.",
  "We implement both reinforcement learning and heuristic (model-based) baselines and show evidence of sim-to-real transfer. Our baselines achieve a 20% success rate in the real world; our experiments identify ways future research work improve performance. See videos on our website: https://ovmm.github.io/.\nAuthors: Sriram Yenamandra, A. Ramachandran, Karmesh Yadav, Austin S. Wang, Mukul Khanna, Th\u00e9ophile Gervet, Tsung-Yen Yang, Vidhi Jain, Alexander Clegg, John Turner, Z. Kira, M. Savva, Angel X. Chang, Devendra Singh Chaplot, Dhruv Batra, Roozbeh Mottaghi, Yonatan Bisk, Chris Paxton\nVenue: Conference on Robot Learning\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The HomeRobot OVMM benchmark is introduced, where an agent navigates household environments to grasp novel objects and place them on target receptacles, and baselines achieve a 20% success rate in the real world; the experiments identify ways future research work improve performance.'}",
  "Faculty Name: yonatan bisk\nMetadata:\nPaperid: 5ce2f1dff23a5620f77f9b11f1e534422ab8ff3f\nTitle: Plan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents\nYear: 2023\nAbstract: Pre-trained large language models (LLMs) capture procedural knowledge about the world. Recent work has leveraged LLM's ability to generate abstract plans to simplify challenging control tasks, either by action scoring, or action modeling (fine-tuning). However, the transformer architecture inherits several constraints that make it difficult for the LLM to directly serve as the agent: e.g. limited input lengths, fine-tuning inefficiency, bias from pre-training, and incompatibility with non-text environments. To maintain compatibility with a low-level trainable actor, we propose to instead use the knowledge in LLMs to simplify the control problem, rather than solving it. We propose the Plan, Eliminate, and Track (PET) framework. The Plan module translates a task description into a list of high-level sub-tasks.",
  "We propose the Plan, Eliminate, and Track (PET) framework. The Plan module translates a task description into a list of high-level sub-tasks. The Eliminate module masks out irrelevant objects and receptacles from the observation for the current sub-task. Finally, the Track module determines whether the agent has accomplished each sub-task. On the AlfWorld instruction following benchmark, the PET framework leads to a significant 15% improvement over SOTA for generalization to human goal specifications.\nAuthors: Yue Wu, So Yeon Min, Yonatan Bisk, R. Salakhutdinov, A. Azaria, Yuan-Fang Li, Tom M. Mitchell, Shrimai Prabhumoye\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A framework to use the knowledge in LLMs to simplify the control problem, rather than solving it is proposed, which leads to a significant 15% improvement over SOTA for generalization to human goal specifications.'}",
  "Faculty Name: yonatan bisk\nMetadata:\nPaperid: 69b8cd15966c4c9c3e44e71769e557f1c87fb3f9\nTitle: MOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception\nYear: 2023\nAbstract: A holistic understanding of object properties across diverse sensory modalities (e.g., visual, audio, and haptic) is essential for tasks ranging from object categorization to complex manipulation. Drawing inspiration from cognitive science studies that emphasize the significance of multi-sensory integration in human perception, we introduce MOSAIC (Multimodal Object property learning with Self-Attention and Interactive Comprehension), a novel framework designed to facilitate the learning of unified multi-sensory object property representations. While it is undeniable that visual information plays a prominent role, we acknowledge that many fundamental object properties extend beyond the visual domain to encompass attributes like texture, mass distribution, or sounds, which significantly influence how we interact with objects. In MOSAIC, we leverage this profound insight by distilling knowledge from multimodal foundation models and aligning these representations not only across vision but also haptic and auditory sensory modalities.",
  "In MOSAIC, we leverage this profound insight by distilling knowledge from multimodal foundation models and aligning these representations not only across vision but also haptic and auditory sensory modalities. Through extensive experiments on a dataset where a humanoid robot interacts with 100 objects across 10 exploratory behaviors, we demonstrate the versatility of MOSAIC in two task families: object categorization and object-fetching tasks. Our results underscore the efficacy of MOSAIC's unified representations, showing competitive performance in category recognition through a simple linear probe setup and excelling in the fetch object task under zero-shot transfer conditions. This work pioneers the application of sensory grounding in foundation models for robotics, promising a significant leap in multi-sensory perception capabilities for autonomous systems. We have released the code, datasets, and additional results: https://github.com/gtatiya/MOSAIC.",
  "This work pioneers the application of sensory grounding in foundation models for robotics, promising a significant leap in multi-sensory perception capabilities for autonomous systems. We have released the code, datasets, and additional results: https://github.com/gtatiya/MOSAIC.\nAuthors: Gyan Tatiya, Jonathan M Francis, Ho-Hsiang Wu, Yonatan Bisk, Jivko Sinapov\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work pioneers the application of sensory grounding in foundation models for robotics, promising a significant leap in multi-sensory perception capabilities for autonomous systems.'}",
  "Faculty Name: yonatan bisk\nMetadata:\nPaperid: 8035a247980cb18abf2bb7b9d96e7d4c63622ef2\nTitle: Reasoning about the Unseen for Efficient Outdoor Object Navigation\nYear: 2023\nAbstract: Robots should exist anywhere humans do: indoors, outdoors, and even unmapped environments. In contrast, the focus of recent advancements in Object Goal Navigation(OGN) has targeted navigating in indoor environments by leveraging spatial and semantic cues that do not generalize outdoors. While these contributions provide valuable insights into indoor scenarios, the broader spectrum of real-world robotic applications often extends to outdoor settings. As we transition to the vast and complex terrains of outdoor environments, new challenges emerge. Unlike the structured layouts found indoors, outdoor environments lack clear spatial delineations and are riddled with inherent semantic ambiguities. Despite this, humans navigate with ease because we can reason about the unseen. We introduce a new task OUTDOOR, a new mechanism for Large Language Models (LLMs) to accurately hallucinate possible futures, and a new computationally aware success metric for pushing research forward in this more complex domain.",
  "Despite this, humans navigate with ease because we can reason about the unseen. We introduce a new task OUTDOOR, a new mechanism for Large Language Models (LLMs) to accurately hallucinate possible futures, and a new computationally aware success metric for pushing research forward in this more complex domain. Additionally, we show impressive results on both a simulated drone and physical quadruped in outdoor environments. Our agent has no premapping and our formalism outperforms naive LLM-based approaches\nAuthors: Quanting Xie, Tianyi Zhang, Kedi Xu, M. Johnson-Roberson, Yonatan Bisk\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'A new task OUTDOOR is introduced, a new mechanism for Large Language Models (LLMs) to accurately hallucinate possible futures, and a new computationally aware success metric for pushing research forward in this more complex domain are introduced.'}",
  "Faculty Name: yonatan bisk\nMetadata:\nPaperid: b777aa86b5a1d49ce8eababc5c2ee56d3562801e\nTitle: The Framework Tax: Disparities Between Inference Efficiency in Research and Deployment\nYear: 2023\nAbstract: Increased focus on the computational efficiency of NLP systems has motivated the design of efficient model architectures and improvements to underlying hardware accelerators. However, the resulting increases in computational throughput and reductions in floating point operations have not directly translated to improvements in wall-clock inference latency. We demonstrate that these discrepancies can be largely attributed to bottlenecks introduced by deep learning frameworks. We denote this phenomenon as the \\textit{framework tax}, and observe that the disparity is growing as hardware speed increases over time. In this work, we examine this phenomenon through a series of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency. Code is available at https://github.com/JaredFern/Framework-Tax.",
  "In this work, we examine this phenomenon through a series of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency. Code is available at https://github.com/JaredFern/Framework-Tax.\nAuthors: Jared Fernandez, Jacob Kahn, Clara Na, Yonatan Bisk, Emma Strubell\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work examines the effects of model design decisions, framework paradigms, and hardware platforms on total model latency through a series of case studies analyzing the effects of model design decisions, framework paradigms, and hardware platforms on total model latency.'}",
  "Faculty Name: yonatan bisk\nMetadata:\nPaperid: e41482f4ee984f17382f6cdd900df094d928be06\nTitle: WebArena: A Realistic Web Environment for Building Autonomous Agents\nYear: 2023\nAbstract: With advances in generative AI, there is now potential for autonomous agents to manage daily tasks via natural language commands. However, current agents are primarily created and tested in simplified synthetic environments, leading to a disconnect with real-world scenarios. In this paper, we build an environment for language-guided agents that is highly realistic and reproducible. Specifically, we focus on agents that perform tasks on the web, and create an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management. Our environment is enriched with tools (e.g., a map) and external knowledge bases (e.g., user manuals) to encourage human-like task-solving. Building upon our environment, we release a set of benchmark tasks focusing on evaluating the functional correctness of task completions. The tasks in our benchmark are diverse, long-horizon, and designed to emulate tasks that humans routinely perform on the internet.",
  "Building upon our environment, we release a set of benchmark tasks focusing on evaluating the functional correctness of task completions. The tasks in our benchmark are diverse, long-horizon, and designed to emulate tasks that humans routinely perform on the internet. We experiment with several baseline agents, integrating recent techniques such as reasoning before acting. The results demonstrate that solving complex tasks is challenging: our best GPT-4-based agent only achieves an end-to-end task success rate of 14.41%, significantly lower than the human performance of 78.24%. These results highlight the need for further development of robust agents, that current state-of-the-art large language models are far from perfect performance in these real-life tasks, and that WebArena can be used to measure such progress.",
  "These results highlight the need for further development of robust agents, that current state-of-the-art large language models are far from perfect performance in these real-life tasks, and that WebArena can be used to measure such progress.\nAuthors: Shuyan Zhou, Frank F. Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, Yonatan Bisk, Daniel Fried, Uri Alon, Graham Neubig\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This paper builds an environment for language-guided agents that is highly realistic and reproducible, and creates an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management.'}",
  "Faculty Name: yonatan bisk\nMetadata:\nPaperid: e7b3b692b0816821aafc0d354749bc3802cbf6ac\nTitle: Computational Language Acquisition with Theory of Mind\nYear: 2023\nAbstract: Unlike current state-of-the-art language models, young children actively acquire language through interactions with their surrounding environment and caretakers. One mechanism that has been argued to be critical to language learning is the ability to infer the mental states of other agents in social environments, coined Theory of Mind (ToM) by Premack&Woodruff (1978). Drawing inspiration from the modern operationalized versions of ToM implemented in Rabinowitz et al. (2018) and Zhu et al. (2021), we build language-learning agents equipped with ToM, and measure its effects on the learning process. We model ToM by giving the speaker agent an internal listener model that is trained alongside the speaker and used to rerank potential utterances. We experiment with varying task difficulty, hypothesizing that models will acquire more complex language to adapt to stronger environmental pressures.",
  "We model ToM by giving the speaker agent an internal listener model that is trained alongside the speaker and used to rerank potential utterances. We experiment with varying task difficulty, hypothesizing that models will acquire more complex language to adapt to stronger environmental pressures. We find that training speakers with a highly weighted ToM listener component leads to performance gains in our image referential game setting. We also find some evidence that increasing task difficulty in the training process results in more fluent and precise utterances in evaluation. This suggests the potential utility of further incorporating ToM, as well as other insights from child language acquisition, into computational models of language acquisition.\nAuthors: Andy T. Liu, Hao Zhu, Emmy Liu, Yonatan Bisk, Graham Neubig\nVenue: International Conference on Learning Representations\nTldr: {'model': 'tldr@v2.0.0', 'text': \"It is found that training speakers with a highly weighted ToM listener component leads to performance gains in the authors' image referential game setting, and suggests the potential utility of further incorporating ToM, as well as other insights from child language acquisition, into computational models of language acquisition.\"}",
  "List of 2023 Open Access papers by yonatan bisk are:\nSPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs\nHomeRobot: Open-Vocabulary Mobile Manipulation\nPlan, Eliminate, and Track - Language Models are Good Teachers for Embodied Agents\nMOSAIC: Learning Unified Multi-Sensory Object Property Representations for Robot Perception\nReasoning about the Unseen for Efficient Outdoor Object Navigation\nThe Framework Tax: Disparities Between Inference Efficiency in Research and Deployment\nWebArena: A Realistic Web Environment for Building Autonomous Agents\nComputational Language Acquisition with Theory of Mind",
  "Faculty Name: yulia tsvetkov\nMetadata:\nPaperid: 000cc7bff1a286193286f095f1668eacedbefc1a\nTitle: LatticeGen: A Cooperative Framework which Hides Generated Text in a Lattice for Privacy-Aware Generation on Cloud\nYear: 2023\nAbstract: In the current user-server interaction paradigm of prompted generation with large language models (LLM) on cloud, the server fully controls the generation process, which leaves zero options for users who want to keep the generated text to themselves. We propose LatticeGen, a cooperative framework in which the server still handles most of the computation while the user controls the sampling operation. The key idea is that the true generated sequence is mixed with noise tokens by the user and hidden in a noised lattice. Considering potential attacks from a hypothetically malicious server and how the user can defend against it, we propose the repeated beam-search attack and the mixing noise scheme. In our experiments we apply LatticeGen to protect both prompt and generation.",
  "Considering potential attacks from a hypothetically malicious server and how the user can defend against it, we propose the repeated beam-search attack and the mixing noise scheme. In our experiments we apply LatticeGen to protect both prompt and generation. It is shown that while the noised lattice degrades generation quality, LatticeGen successfully protects the true generation to a remarkable degree under strong attacks (more than 50% of the semantic remains hidden as measured by BERTScore).\nAuthors: Meng Zhang, Tianxing He, Tianle Wang, Fatemehsadat Mireshghallah, Binyi Chen, Hao Wang, Yulia Tsvetkov\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'While the noised lattice degrades generation quality, LatticeGen successfully protects the true generation to a remarkable degree under strong attacks (more than 50% of the semantic remains hidden as measured by BERTScore).'}",
  "Faculty Name: yulia tsvetkov\nMetadata:\nPaperid: 12902f724619344dfeae330043c4b7b1c9d99bd0\nTitle: Understanding Ethics in NLP Authoring and Reviewing\nYear: 2023\nAbstract: With NLP research now quickly being transferred into real-world applications, it is important to be aware of and think through the consequences of our scientific investigation. Such ethical considerations are important in both authoring and reviewing. This tutorial will equip participants with basic guidelines for thinking deeply about ethical issues and review common considerations that recur in NLP research. The methodology is interactive and participatory, including case studies and working in groups. Importantly, the participants will be co-building the tutorial outcomes and will be working to create further tutorial materials to share as public outcomes.\nAuthors: Luciana Benotti, Kar\u00ebn Fort, Min-Yen Kan, Yulia Tsvetkov\nVenue: Conference of the European Chapter of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This tutorial will equip participants with basic guidelines for thinking deeply about ethical issues and review common considerations that recur in NLP research.'}",
  "Faculty Name: yulia tsvetkov\nMetadata:\nPaperid: 17605c43ca3eb982c99642052ddc21a93d116594\nTitle: GlobalBench: A Benchmark for Global Progress in Natural Language Processing\nYear: 2023\nAbstract: Despite the major advances in NLP, significant disparities in NLP system performance across languages still exist. Arguably, these are due to uneven resource allocation and sub-optimal incentives to work on less resourced languages. To track and further incentivize the global development of equitable language technology, we introduce GlobalBench. Prior multilingual benchmarks are static and have focused on a limited number of tasks and languages. In contrast, GlobalBench is an ever-expanding collection that aims to dynamically track progress on all NLP datasets in all languages. Rather than solely measuring accuracy, GlobalBench also tracks the estimated per-speaker utility and equity of technology across all languages, providing a multi-faceted view of how language technology is serving people of the world. Furthermore, GlobalBench is designed to identify the most under-served languages, and rewards research efforts directed towards those languages.",
  "Furthermore, GlobalBench is designed to identify the most under-served languages, and rewards research efforts directed towards those languages. At present, the most under-served languages are the ones with a relatively high population, but nonetheless overlooked by composite multilingual benchmarks (like Punjabi, Portuguese, and Wu Chinese). Currently, GlobalBench covers 966 datasets in 190 languages, and has 1,128 system submissions spanning 62 languages.",
  "Currently, GlobalBench covers 966 datasets in 190 languages, and has 1,128 system submissions spanning 62 languages.\nAuthors: Yueqi Song, Catherine Cui, Simran Khanuja, Pengfei Liu, FAHIM FAISAL, Alissa Ostapenko, Genta Indra Winata, Alham Fikri Aji, Samuel Cahyawijaya, Yulia Tsvetkov, Antonios Anastasopoulos, Graham Neubig\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work introduces GlobalBench, an ever-expanding collection that aims to dynamically track progress on all NLP datasets in all languages and tracks the estimated per-speaker utility and equity of technology across all languages, providing a multi-faceted view of how language technology is serving people of the world.'}",
  "Faculty Name: yulia tsvetkov\nMetadata:\nPaperid: 17fbffb05fa14e21d1c506fd5f0f568b955fe983\nTitle: Do All Languages Cost the Same? Tokenization in the Era of Commercial Language Models\nYear: 2023\nAbstract: Language models have graduated from being research prototypes to commercialized products offered as web APIs, and recent works have highlighted the multilingual capabilities of these products. The API vendors charge their users based on usage, more specifically on the number of ``tokens'' processed or generated by the underlying language models. What constitutes a token, however, is training data and model dependent with a large variance in the number of tokens required to convey the same information in different languages. In this work, we analyze the effect of this non-uniformity on the fairness of an API's pricing policy across languages. We conduct a systematic analysis of the cost and utility of OpenAI's language model API on multilingual benchmarks in 22 typologically diverse languages. We show evidence that speakers of a large number of the supported languages are overcharged while obtaining poorer results.",
  "We conduct a systematic analysis of the cost and utility of OpenAI's language model API on multilingual benchmarks in 22 typologically diverse languages. We show evidence that speakers of a large number of the supported languages are overcharged while obtaining poorer results. These speakers tend to also come from regions where the APIs are less affordable to begin with. Through these analyses, we aim to increase transparency around language model APIs' pricing policies and encourage the vendors to make them more equitable.\nAuthors: Orevaoghene Ahia, Sachin Kumar, Hila Gonen, Jungo Kasai, David R. Mortensen, Noah A. Smith, Yulia Tsvetkov\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': \"This work conducts a systematic analysis of the cost and utility of OpenAI's language model API on multilingual benchmarks in 22 typologically diverse languages and shows evidence that speakers of a large number of the supported languages are overcharged while obtaining poorer results.\"}",
  "Faculty Name: yulia tsvetkov\nMetadata:\nPaperid: 1bc0dc96d745325d89ec5bee1da1541255e6d1eb\nTitle: BotPercent: Estimating Twitter Bot Populations from Groups to Crowds\nYear: 2023\nAbstract: Twitter bot detection has become increasingly important in combating misinformation, identifying malicious online cam-paigns, and protecting the integrity of social media discourse. While existing bot detection literature mostly focuses on identifying individual bots, it remains underexplored how to estimate the proportion of bots within speci\ufb01c communities and social networks, which has great implications for both content moderators and day-to-day users. In this work, we propose community-level bot detection , a novel approach to estimating the amount of malicious interference in online communities by estimating the percentage of bot accounts. Speci\ufb01cally, we introduce BotPercent , an amalgamation of Twitter bot-detection datasets and feature, text, and graph-based models that overcome generalization issues in existing individual-level models, resulting in a more accurate community-level bot estimation.",
  "Speci\ufb01cally, we introduce BotPercent , an amalgamation of Twitter bot-detection datasets and feature, text, and graph-based models that overcome generalization issues in existing individual-level models, resulting in a more accurate community-level bot estimation. Experiments demonstrate that BotPercent achieves state-of-the-art community-level bot detection performance on the TwiBot-22 benchmark while showing great robustness towards the tampering of speci\ufb01c user features. Armed with BotPercent , we analyze bot rates in different Twitter groups and communities, such as all active Twitter users, users that interact with partisan news media, users that participate in Elon Musk\u2019s content moderation votes, and the political communities in different countries and regions. Our experimental results demonstrate that the existence of Twitter bots is not homogeneous, but rather a spatial-temporal distribution whose heterogeneity should be taken into account for content moderation, social media policy making, and more.",
  "Our experimental results demonstrate that the existence of Twitter bots is not homogeneous, but rather a spatial-temporal distribution whose heterogeneity should be taken into account for content moderation, social media policy making, and more. The BotPercent implementation is available at https://github.com/TamSiuhin/BotPercent\nAuthors: Zhaoxuan Tan, Shangbin Feng, Melanie Sclar, Herun Wan, Minnan Luo, Yejin Choi, Yulia Tsvetkov\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The experimental results demonstrate that the existence of Twitter bots is not homogeneous, but rather a spatial-temporal distribution whose heterogeneity should be taken into account for content moderation, social media policy making, and more.'}",
  "Faculty Name: yulia tsvetkov\nMetadata:\nPaperid: 33d944de189d6edf3a510ea195803a381c5a3bab\nTitle: Knowledge Crosswords: Geometric Reasoning over Structured Knowledge with Large Language Models\nYear: 2023\nAbstract: Large language models (LLMs) are widely adopted in knowledge-intensive tasks and have achieved impressive performance thanks to their knowledge abilities. While LLMs have demonstrated outstanding performance on atomic or linear (multi-hop) QA tasks, whether they can reason in knowledge-rich scenarios with interweaving constraints remains an underexplored problem. In this work, we propose geometric reasoning over structured knowledge, where pieces of knowledge are connected in a graph structure and models need to fill in the missing information. Such geometric knowledge reasoning would require the ability to handle structured knowledge, reason with uncertainty, verify facts, and backtrack when an error occurs. We propose Knowledge Crosswords, a multi-blank QA dataset where each problem consists of a natural language question representing the geometric constraints of an incomplete entity network, where LLMs are tasked with working out the missing entities while meeting all factual constraints.",
  "We propose Knowledge Crosswords, a multi-blank QA dataset where each problem consists of a natural language question representing the geometric constraints of an incomplete entity network, where LLMs are tasked with working out the missing entities while meeting all factual constraints. Knowledge Crosswords contains 2,101 individual problems, covering various knowledge domains and further divided into three difficulty levels. We conduct extensive experiments to evaluate existing LLM prompting approaches on the Knowledge Crosswords benchmark. We additionally propose two new approaches, Staged Prompting and Verify-All, to augment LLMs' ability to backtrack and verify structured constraints. Our results demonstrate that while baseline approaches perform well on easier problems but struggle with hard ones, our proposed Verify-All outperforms other methods by a large margin and is more robust with hard problems. Further analysis reveals that LLMs' ability of geometric reasoning over structured knowledge is still far from robust or perfect, susceptible to confounders such as the order of options, certain structural patterns, assumption of existence of correct answer, and more.",
  "Further analysis reveals that LLMs' ability of geometric reasoning over structured knowledge is still far from robust or perfect, susceptible to confounders such as the order of options, certain structural patterns, assumption of existence of correct answer, and more.\nAuthors: Wenxuan Ding, Shangbin Feng, Yuhan Liu, Zhaoxuan Tan, Vidhisha Balachandran, Tianxing He, Yulia Tsvetkov\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes Knowledge Crosswords, a multi-blank QA dataset where each problem consists of a natural language question representing the geometric constraints of an incomplete entity network, where LLMs are tasked with working out the missing entities while meeting all factual constraints.'}",
  "Faculty Name: yulia tsvetkov\nMetadata:\nPaperid: 346e4f35a5a81ef893792133ec1fec18f23c1768\nTitle: Examining risks of racial biases in NLP tools for child protective services\nYear: 2023\nAbstract: Although much literature has established the presence of demographic bias in natural language processing (NLP) models, most work relies on curated bias metrics that may not be reflective of real-world applications. At the same time, practitioners are increasingly using algorithmic tools in high-stakes settings, with particular recent interest in NLP. In this work, we focus on one such setting: child protective services (CPS). CPS workers often write copious free-form text notes about families they are working with, and CPS agencies are actively seeking to deploy NLP models to leverage these data. Given well-established racial bias in this setting, we investigate possible ways deployed NLP is liable to increase racial disparities. We specifically examine word statistics within notes and algorithmic fairness in risk prediction, coreference resolution, and named entity recognition (NER).",
  "Given well-established racial bias in this setting, we investigate possible ways deployed NLP is liable to increase racial disparities. We specifically examine word statistics within notes and algorithmic fairness in risk prediction, coreference resolution, and named entity recognition (NER). We document consistent algorithmic unfairness in NER models, possible algorithmic unfairness in coreference resolution models, and little evidence of exacerbated racial bias in risk prediction. While there is existing pronounced criticism of risk prediction, our results expose previously undocumented risks of racial bias in realistic information extraction systems, highlighting potential concerns in deploying them, even though they may appear more benign. Our work serves as a rare realistic examination of NLP algorithmic fairness in a potential deployed setting and a timely investigation of a specific risk associated with deploying NLP in CPS settings.",
  "Our work serves as a rare realistic examination of NLP algorithmic fairness in a potential deployed setting and a timely investigation of a specific risk associated with deploying NLP in CPS settings.\nAuthors: Anjalie Field, Amanda Coston, Nupoor Gandhi, A. Chouldechova, Emily Putnam-Hornstein, David Steier, Yulia Tsvetkov\nVenue: Conference on Fairness, Accountability and Transparency\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work investigates possible ways deployed NLP is liable to increase racial disparities and examines word statistics within notes and algorithmic fairness in risk prediction, coreference resolution, and named entity recognition (NER).'}",
  "Faculty Name: yulia tsvetkov\nMetadata:\nPaperid: 36f7bc27c9a37eb337c35df4ae86f148e13d4e9a\nTitle: Understanding In-Context Learning via Supportive Pretraining Data\nYear: 2023\nAbstract: In-context learning (ICL) improves language models\u2019 performance on a variety of NLP tasks by simply demonstrating a handful of examples at inference time. It is not well understood why ICL ability emerges, as the model has never been specifically trained on such demonstrations. Unlike prior work that explores implicit mechanisms behind ICL, we study ICL via investigating the pretraining data. Specifically, we first adapt an iterative, gradient-based approach to find a small subset of pretraining data that supports ICL. We observe that a continued pretraining on this small subset significantly improves the model\u2019s ICL ability, by up to 18%. We then compare the supportive subset constrastively with random subsets of pretraining data and discover: (1) The supportive pretraining data to ICL do not have a higher domain relevance to downstream tasks.",
  "We then compare the supportive subset constrastively with random subsets of pretraining data and discover: (1) The supportive pretraining data to ICL do not have a higher domain relevance to downstream tasks. (2) The supportive pretraining data have a higher mass of rarely occurring, long-tail tokens. (3) The supportive pretraining data are challenging examples where the information gain from long-range context is below average, indicating learning to incorporate difficult long-range context encourages ICL. Our work takes a first step towards understanding ICL via analyzing instance-level pretraining data. Our insights have a potential to enhance the ICL ability of language models by actively guiding the construction of pretraining data in the future.",
  "Our work takes a first step towards understanding ICL via analyzing instance-level pretraining data. Our insights have a potential to enhance the ICL ability of language models by actively guiding the construction of pretraining data in the future.\nAuthors: Xiaochuang Han, Daniel Simig, Todor Mihaylov, Yulia Tsvetkov, Asli Celikyilmaz, Tianlu Wang\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work first adapts an iterative, gradient-based approach to find a small subset of pretraining data that supports ICL and observes that a continued pretraining on this small subset significantly improves the model\u2019s ICL ability, by up to 18%.'}",
  "Faculty Name: yulia tsvetkov\nMetadata:\nPaperid: 3f4ccf64ffe23b5dc095ae0401eecf9445deb024\nTitle: Resolving Knowledge Conflicts in Large Language Models\nYear: 2023\nAbstract: Large language models (LLMs) often encounter knowledge conflicts, scenarios where discrepancy arises between the internal parametric knowledge of LLMs and non-parametric information provided in the prompt context. In this work we ask what are the desiderata for LLMs when a knowledge conflict arises and whether existing LLMs fulfill them. We posit that LLMs should 1) identify knowledge conflicts, 2) pinpoint conflicting information segments, and 3) provide distinct answers or viewpoints in conflicting scenarios. To this end, we introduce KNOWLEDGE CONFLICT, an evaluation framework for simulating contextual knowledge conflicts and quantitatively evaluating to what extent LLMs achieve these goals. KNOWLEDGE CONFLICT includes diverse and complex situations of knowledge conflict, knowledge from diverse entities and domains, two synthetic conflict creation methods, and settings with progressively increasing difficulty to reflect realistic knowledge conflicts.",
  "KNOWLEDGE CONFLICT includes diverse and complex situations of knowledge conflict, knowledge from diverse entities and domains, two synthetic conflict creation methods, and settings with progressively increasing difficulty to reflect realistic knowledge conflicts. Extensive experiments with the KNOWLEDGE CONFLICT framework reveal that while LLMs perform well in identifying the existence of knowledge conflicts, they struggle to determine the specific conflicting knowledge and produce a response with distinct answers amidst conflicting information. To address these challenges, we propose new instruction-based approaches that augment LLMs to better achieve the three goals. Further analysis shows that abilities to tackle knowledge conflicts are greatly impacted by factors such as knowledge domain and prompt text, while generating robust responses to knowledge conflict scenarios remains an open research question.",
  "To address these challenges, we propose new instruction-based approaches that augment LLMs to better achieve the three goals. Further analysis shows that abilities to tackle knowledge conflicts are greatly impacted by factors such as knowledge domain and prompt text, while generating robust responses to knowledge conflict scenarios remains an open research question.\nAuthors: Yike Wang, Shangbin Feng, Heng Wang, Weijia Shi, Vidhisha Balachandran, Tianxing He, Yulia Tsvetkov\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work introduces KNOWLEDGE CONFLICT, an evaluation framework for simulating contextual knowledge conflicts and proposes new instruction-based approaches that augment LLMs to better achieve three goals: identify knowledge conflicts, pinpoint conflicting information segments, and provide distinct answers or viewpoints in conflicting scenarios.'}",
  "Faculty Name: yulia tsvetkov\nMetadata:\nPaperid: 49f1fa0d609ff06564b46270cbc022b7d9d195f4\nTitle: Assessing Language Model Deployment with Risk Cards\nYear: 2023\nAbstract: This paper introduces RiskCards, a framework for structured assessment and documentation of risks associated with an application of language models. As with all language, text generated by language models can be harmful, or used to bring about harm. Automating language generation adds both an element of scale and also more subtle or emergent undesirable tendencies to the generated text. Prior work establishes a wide variety of language model harms to many different actors: existing taxonomies identify categories of harms posed by language models; benchmarks establish automated tests of these harms; and documentation standards for models, tasks and datasets encourage transparent reporting. However, there is no risk-centric framework for documenting the complexity of a landscape in which some risks are shared across models and contexts, while others are specific, and where certain conditions may be required for risks to manifest as harms. RiskCards address this methodological gap by providing a generic framework for assessing the use of a given language model in a given scenario.",
  "RiskCards address this methodological gap by providing a generic framework for assessing the use of a given language model in a given scenario. Each RiskCard makes clear the routes for the risk to manifest harm, their placement in harm taxonomies, and example prompt-output pairs. While RiskCards are designed to be open-source, dynamic and participatory, we present a\"starter set\"of RiskCards taken from a broad literature survey, each of which details a concrete risk presentation. Language model RiskCards initiate a community knowledge base which permits the mapping of risks and harms to a specific model or its application scenario, ultimately contributing to a better, safer and shared understanding of the risk landscape.\nAuthors: Leon Derczynski, Hannah Rose Kirk, Vidhisha Balachandran, Sachin Kumar, Yulia Tsvetkov, M. Leiser, Saif Mohammad\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Language model RiskCards initiate a community knowledge base which permits the mapping of risks and harms to a specific model or its application scenario, ultimately contributing to a better, safer and shared understanding of the risk landscape.'}",
  "Faculty Name: yulia tsvetkov\nMetadata:\nPaperid: 5471114e37448bea2457b74894b1ecb92bbcfdf6\nTitle: From Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models\nYear: 2023\nAbstract: Language models (LMs) are pretrained on diverse data sources\u2014news, discussion forums, books, online encyclopedias. A significant portion of this data includes facts and opinions which, on one hand, celebrate democracy and diversity of ideas, and on the other hand are inherently socially biased. Our work develops new methods to (1) measure media biases in LMs trained on such corpora, along social and economic axes, and (2) measure the fairness of downstream NLP models trained on top of politically biased LMs. We focus on hate speech and misinformation detection, aiming to empirically quantify the effects of political (social, economic) biases in pretraining data on the fairness of high-stakes social-oriented tasks.",
  "We focus on hate speech and misinformation detection, aiming to empirically quantify the effects of political (social, economic) biases in pretraining data on the fairness of high-stakes social-oriented tasks. Our findings reveal that pretrained LMs do have political leanings which reinforce the polarization present in pretraining corpora, propagating social biases into hate speech predictions and media biases into misinformation detectors. We discuss the implications of our findings for NLP research and propose future directions to mitigate unfairness.\nAuthors: Shangbin Feng, Chan Young Park, Yuhan Liu, Yulia Tsvetkov\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The findings reveal that pretrained LMs do have political leanings which reinforce the polarization present in pretraining corpora, propagating social biases into hate speech predictions and media biases into misinformation detectors.'}",
  "Faculty Name: yulia tsvetkov\nMetadata:\nPaperid: 5cd7c5f4e21cb541d7c553b04074335e858847c2\nTitle: BotPercent: Estimating Bot Populations in Twitter Communities\nYear: 2023\nAbstract: Twitter bot detection is vital in combating misinformation and safeguarding the integrity of social media discourse. While malicious bots are becoming more and more sophisticated and personalized, standard bot detection approaches are still agnostic to social environments (henceforth, communities) the bots operate at. In this work, we introduce community-specific bot detection, estimating the percentage of bots given the context of a community. Our method -- BotPercent -- is an amalgamation of Twitter bot detection datasets and feature-, text-, and graph-based models, adjusted to a particular community on Twitter. We introduce an approach that performs confidence calibration across bot detection models, which addresses generalization issues in existing community-agnostic models targeting individual bots and leads to more accurate community-level bot estimations.",
  "We introduce an approach that performs confidence calibration across bot detection models, which addresses generalization issues in existing community-agnostic models targeting individual bots and leads to more accurate community-level bot estimations. Experiments demonstrate that BotPercent achieves state-of-the-art performance in community-level Twitter bot detection across both balanced and imbalanced class distribution settings, %outperforming existing approaches and presenting a less biased estimator of Twitter bot populations within the communities we analyze. We then analyze bot rates in several Twitter groups, including users who engage with partisan news media, political communities in different countries, and more. Our results reveal that the presence of Twitter bots is not homogeneous, but exhibiting a spatial-temporal distribution with considerable heterogeneity that should be taken into account for content moderation and social media policy making. The implementation of BotPercent is available at https://github.com/TamSiuhin/BotPercent.",
  "Our results reveal that the presence of Twitter bots is not homogeneous, but exhibiting a spatial-temporal distribution with considerable heterogeneity that should be taken into account for content moderation and social media policy making. The implementation of BotPercent is available at https://github.com/TamSiuhin/BotPercent.\nAuthors: Zhaoxuan Tan, Shangbin Feng, Melanie Sclar, Herun Wan, Minnan Luo, Yejin Choi, Yulia Tsvetkov\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'The results reveal that the presence of Twitter bots is not homogeneous, but exhibiting a spatial-temporal distribution with considerable heterogeneity that should be taken into account for content moderation and social media policy making.'}",
  "Faculty Name: yulia tsvetkov\nMetadata:\nPaperid: 663d743272e9ab04f54d9105a3c3a3f6e22dd1dd\nTitle: FactKB: Generalizable Factuality Evaluation using Language Models Enhanced with Factual Knowledge\nYear: 2023\nAbstract: Evaluating the factual consistency of automatically generated summaries is essential for the progress and adoption of reliable summarization systems. Despite recent advances, existing factuality evaluation models are not robust, being especially prone to entity and relation errors in new domains. We propose FactKB, a simple new approach to factuality evaluation that is generalizable across domains, in particular with respect to entities and relations. FactKB is based on language models pretrained using facts extracted from external knowledge bases. We introduce three types of complementary factuality pretraining objectives based on direct entity facts, facts grounded in auxiliary knowledge about entities, and facts constructed compositionally through knowledge base walks. The resulting factuality evaluation model achieves state-of-the-art performance on two in-domain news summarization benchmarks as well as on three out-of-domain scientific literature datasets.",
  "The resulting factuality evaluation model achieves state-of-the-art performance on two in-domain news summarization benchmarks as well as on three out-of-domain scientific literature datasets. Further analysis of FactKB shows improved ability to detect erroneous entities and relations in summaries and is robust and generalizable across domains.\nAuthors: Shangbin Feng, Vidhisha Balachandran, Yuyang Bai, Yulia Tsvetkov\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'FactKB is a simple new approach to factuality evaluation that is generalizable across domains, in particular with respect to entities and relations and shows improved ability to detect erroneous entities and relation in summaries.'}",
  "Faculty Name: yulia tsvetkov\nMetadata:\nPaperid: 926dece297434dc535733814efca28759b94ab82\nTitle: TalkUp: Paving the Way for Understanding Empowering Language\nYear: 2023\nAbstract: Empowering language is important in many real-world contexts, from education to workplace dynamics to healthcare. Though language technologies are growing more prevalent in these contexts, empowerment has seldom been studied in NLP, and moreover, it is inherently challenging to operationalize because of its implicit nature. This work builds from linguistic and social psychology literature to explore what characterizes empowering language. We then crowdsource a novel dataset of Reddit posts labeled for empowerment, reasons why these posts are empowering to readers, and the social relationships between posters and readers. Our preliminary analyses show that this dataset, which we call TalkUp, can be used to train language models that capture empowering and disempowering language. More broadly, TalkUp provides an avenue to explore implication, presuppositions, and how social context influences the meaning of language.",
  "Our preliminary analyses show that this dataset, which we call TalkUp, can be used to train language models that capture empowering and disempowering language. More broadly, TalkUp provides an avenue to explore implication, presuppositions, and how social context influences the meaning of language.\nAuthors: Lucille Njoo, Chan Young Park, Octavia Stappart, Marvin Thielk, Yi Chu, Yulia Tsvetkov\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work builds from linguistic and social psychology literature to explore what characterizes empowering language, and crowdsource a novel dataset of Reddit posts labeled for empowerment, reasons why these posts are empowering to readers, and the social relationships between posters and readers.'}",
  "Faculty Name: yulia tsvetkov\nMetadata:\nPaperid: 94be9ee72de86a909fd29a739f203e1aa6bc165e\nTitle: On the Zero-Shot Generalization of Machine-Generated Text Detectors\nYear: 2023\nAbstract: The rampant proliferation of large language models, fluent enough to generate text indistinguishable from human-written language, gives unprecedented importance to the detection of machine-generated text. This work is motivated by an important research question: How will the detectors of machine-generated text perform on outputs of a new generator, that the detectors were not trained on? We begin by collecting generation data from a wide range of LLMs, and train neural detectors on data from each generator and test its performance on held-out generators. While none of the detectors can generalize to all generators, we observe a consistent and interesting pattern that the detectors trained on data from a medium-size LLM can zero-shot generalize to the larger version. As a concrete application, we demonstrate that robust detectors can be built on an ensemble of training data from medium-sized models.",
  "While none of the detectors can generalize to all generators, we observe a consistent and interesting pattern that the detectors trained on data from a medium-size LLM can zero-shot generalize to the larger version. As a concrete application, we demonstrate that robust detectors can be built on an ensemble of training data from medium-sized models.\nAuthors: Xiao Pu, Jingyu Zhang, Xiaochuang Han, Yulia Tsvetkov, Tianxing He\nVenue: Conference on Empirical Methods in Natural Language Processing\nTldr: {'model': 'tldr@v2.0.0', 'text': 'It is demonstrated that robust detectors can be built on an ensemble of training data from medium-sized models, and a consistent and interesting pattern is observed that the detectors trained on data from a medium-size LLM can zero-shot generalize to the larger version.'}",
  "Faculty Name: yulia tsvetkov\nMetadata:\nPaperid: 984d4a1d41bfc8184fb77b8aa0eb8e96d536d048\nTitle: Trusting Your Evidence: Hallucinate Less with Context-aware Decoding\nYear: 2023\nAbstract: Language models (LMs) often struggle to pay enough attention to the input context, and generate texts that are unfaithful or contain hallucinations. To mitigate this issue, we present context-aware decoding (CAD), which follows a contrastive output distribution that amplifies the difference between the output probabilities when a model is used with and without context. Our experiments show that CAD, without additional training, significantly improves the faithfulness of different LM families, including OPT, GPT, LLaMA and FLAN-T5 for summarization tasks (e.g., 14.3% gain for LLaMA in factuality metrics). Furthermore, CAD is particularly effective in overriding a model's prior knowledge when it contradicts the provided context, leading to substantial improvements in tasks where resolving the knowledge conflict is essential.",
  "Furthermore, CAD is particularly effective in overriding a model's prior knowledge when it contradicts the provided context, leading to substantial improvements in tasks where resolving the knowledge conflict is essential.\nAuthors: Weijia Shi, Xiaochuang Han, M. Lewis, Yulia Tsvetkov, Luke Zettlemoyer, S. Yih\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'Context-aware decoding (CAD), which follows a contrastive output distribution that amplifies the difference between the output probabilities when a model is used with and without context, improves the faithfulness of different LM families.'}",
  "Faculty Name: yulia tsvetkov\nMetadata:\nPaperid: ad454e24bd32408559512b4bac4cd5237794210f\nTitle: BUFFET: Benchmarking Large Language Models for Few-shot Cross-lingual Transfer\nYear: 2023\nAbstract: Despite remarkable advancements in few-shot generalization in natural language processing, most models are developed and evaluated primarily in English. To facilitate research on few-shot cross-lingual transfer, we introduce a new benchmark, called BUFFET, which unifies 15 diverse tasks across 54 languages in a sequence-to-sequence format and provides a fixed set of few-shot examples and instructions. BUFFET is designed to establish a rigorous and equitable evaluation framework for few-shot cross-lingual transfer across a broad range of tasks and languages. Using BUFFET, we perform thorough evaluations of state-of-the-art multilingual large language models with different transfer methods, namely in-context learning and fine-tuning. Our findings reveal significant room for improvement in few-shot in-context cross-lingual transfer.",
  "Using BUFFET, we perform thorough evaluations of state-of-the-art multilingual large language models with different transfer methods, namely in-context learning and fine-tuning. Our findings reveal significant room for improvement in few-shot in-context cross-lingual transfer. In particular, ChatGPT with in-context learning often performs worse than much smaller mT5-base models fine-tuned on English task data and few-shot in-language examples. Our analysis suggests various avenues for future research in few-shot cross-lingual transfer, such as improved pretraining, understanding, and future evaluations.",
  "Our analysis suggests various avenues for future research in few-shot cross-lingual transfer, such as improved pretraining, understanding, and future evaluations.\nAuthors: Akari Asai, Sneha Kudugunta, Xinyan Velocity Yu, Terra Blevins, Hila Gonen, Machel Reid, Yulia Tsvetkov, Sebastian Ruder, Hannaneh Hajishirzi\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work introduces a new benchmark, called BUFFET, which unifies 15 diverse tasks across 54 languages in a sequence-to-sequence format and provides a fixed set of few- shot examples and instructions and suggests various avenues for future research in few-shot cross-lingual transfer, such as improved pretraining, understanding, and future evaluations.'}",
  "Faculty Name: yulia tsvetkov\nMetadata:\nPaperid: cb0335107f12d331ace2cbf220eb3c7bdcf653c5\nTitle: Mitigating Societal Harms in Large Language Models\nYear: 2023\nAbstract: ,\nAuthors: Sachin Kumar, Vidhisha Balachandran, Lucille Njoo, Antonios Anastasopoulos, Yulia Tsvetkov\nVenue: Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Tutorial Abstracts\nTldr: {'model': 'tldr@v2.0.0', 'text': None}",
  "Faculty Name: yulia tsvetkov\nMetadata:\nPaperid: d7a3f5c612930a3c08f1632b88934252edc66d67\nTitle: Minding Language Models\u2019 (Lack of) Theory of Mind: A Plug-and-Play Multi-Character Belief Tracker\nYear: 2023\nAbstract: Theory of Mind (ToM)\u2014the ability to reason about the mental states of other people\u2014is a key element of our social intelligence. Yet, despite their ever more impressive performance, large-scale neural language models still lack basic theory of mind capabilities out-of-the-box. We posit that simply scaling up models will not imbue them with theory of mind due to the inherently symbolic and implicit nature of the phenomenon, and instead investigate an alternative: can we design a decoding-time algorithm that enhances theory of mind of off-the-shelf neural language models without explicit supervision? We present SymbolicToM, a plug-and-play approach to reason about the belief states of multiple characters in reading comprehension tasks via explicit symbolic representation.",
  "We present SymbolicToM, a plug-and-play approach to reason about the belief states of multiple characters in reading comprehension tasks via explicit symbolic representation. More concretely, our approach tracks each entity\u2019s beliefs, their estimation of other entities\u2019 beliefs, and higher-order levels of reasoning, all through graphical representations, allowing for more precise and interpretable reasoning than previous approaches. Empirical results on the well-known ToMi benchmark (Le et al., 2019) demonstrate that SymbolicToM dramatically enhances off-the-shelf neural networks\u2019 theory of mind in a zero-shot setting while showing robust out-of-distribution performance compared to supervised baselines. Our work also reveals spurious patterns in existing theory of mind benchmarks, emphasizing the importance of out-of-distribution evaluation and methods that do not overfit a particular dataset.",
  "Our work also reveals spurious patterns in existing theory of mind benchmarks, emphasizing the importance of out-of-distribution evaluation and methods that do not overfit a particular dataset.\nAuthors: Melanie Sclar, Sachin Kumar, Peter West, Alane Suhr, Yejin Choi, Yulia Tsvetkov\nVenue: Annual Meeting of the Association for Computational Linguistics\nTldr: {'model': 'tldr@v2.0.0', 'text': 'SymbolicToM is presented, a plug-and-play approach to reason about the belief states of multiple characters in reading comprehension tasks via explicit symbolic representation that dramatically enhances off-the-shelf neural networks\u2019 theory of mind in a zero-shot setting while showing robust out-of-distribution performance compared to supervised baselines.'}",
  "Faculty Name: yulia tsvetkov\nMetadata:\nPaperid: df2beaae63e4d68ef8e762bcd4704c9f11f856d9\nTitle: Can Language Models Solve Graph Problems in Natural Language?\nYear: 2023\nAbstract: Large language models (LLMs) are increasingly adopted for a variety of tasks with implicit graphical structures, such as planning in robotics, multi-hop question answering or knowledge probing, structured commonsense reasoning, and more. While LLMs have advanced the state-of-the-art on these tasks with structure implications, whether LLMs could explicitly process textual descriptions of graphs and structures, map them to grounded conceptual spaces, and perform structured operations remains underexplored. To this end, we propose NLGraph (Natural Language Graph), a comprehensive benchmark of graph-based problem solving designed in natural language. NLGraph contains 29,370 problems, covering eight graph reasoning tasks with varying complexity from simple tasks such as connectivity and shortest path up to complex problems such as maximum flow and simulating graph neural networks.",
  "NLGraph contains 29,370 problems, covering eight graph reasoning tasks with varying complexity from simple tasks such as connectivity and shortest path up to complex problems such as maximum flow and simulating graph neural networks. We evaluate LLMs (GPT-3/4) with various prompting approaches on the NLGraph benchmark and find that 1) language models do demonstrate preliminary graph reasoning abilities, 2) the benefit of advanced prompting and in-context learning diminishes on more complex graph problems, while 3) LLMs are also (un)surprisingly brittle in the face of spurious correlations in graph and problem settings. We then propose Build-a-Graph Prompting and Algorithmic Prompting, two instruction-based approaches to enhance LLMs in solving natural language graph problems. Build-a-Graph and Algorithmic prompting improve the performance of LLMs on NLGraph by 3.07% to 16.85% across multiple tasks and settings, while how to solve the most complicated graph reasoning tasks in our setup with language models remains an open research question. The NLGraph benchmark and evaluation code are available at https://github.com/Arthur-Heng/NLGraph.",
  "The NLGraph benchmark and evaluation code are available at https://github.com/Arthur-Heng/NLGraph.\nAuthors: Heng Wang, Shangbin Feng, Tianxing He, Zhaoxuan Tan, Xiaochuang Han, Yulia Tsvetkov\nVenue: Neural Information Processing Systems\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work evaluates LLMs (GPT-3/4) with various prompting approaches on the NLGraph benchmark and finds that language models do demonstrate preliminary graph reasoning abilities, but the benefit of advanced prompting and in-context learning diminishes on more complex graph problems, while LLMs are also (un)surprisingly brittle in the face of spurious correlations in graph and problem settings.'}",
  "Faculty Name: yulia tsvetkov\nMetadata:\nPaperid: eac59779da7262968a9043985e7cd933c00247a5\nTitle: MatFormer: Nested Transformer for Elastic Inference\nYear: 2023\nAbstract: Transformer models are deployed in a wide range of settings, from multi-accelerator clusters to standalone mobile phones. The diverse inference constraints in these scenarios necessitate practitioners to train foundation models such as PaLM 2, Llama,&ViTs as a series of models of varying sizes. Due to significant training costs, only a select few model sizes are trained and supported, limiting more fine-grained control over relevant tradeoffs, including latency, cost, and accuracy. This work introduces MatFormer, a nested Transformer architecture designed to offer elasticity in a variety of deployment constraints. Each Feed Forward Network (FFN) block of a MatFormer model is jointly optimized with a few nested smaller FFN blocks. This training procedure allows for the Mix'n'Match of model granularities across layers -- i.e., a trained universal MatFormer model enables extraction of hundreds of accurate smaller models, which were never explicitly optimized.",
  "This training procedure allows for the Mix'n'Match of model granularities across layers -- i.e., a trained universal MatFormer model enables extraction of hundreds of accurate smaller models, which were never explicitly optimized. We empirically demonstrate MatFormer's effectiveness across different model classes (decoders&encoders), modalities (language&vision), and scales (up to 2.6B parameters). We find that a 2.6B decoder-only MatFormer language model (MatLM) allows us to extract smaller models spanning from 1.5B to 2.6B, each exhibiting comparable validation loss and one-shot downstream evaluations to their independently trained counterparts. Furthermore, we observe that smaller encoders extracted from a universal MatFormer-based ViT (MatViT) encoder preserve the metric-space structure for adaptive large-scale retrieval. Finally, we showcase that speculative decoding with the accurate and consistent submodels extracted from MatFormer can further reduce inference latency.",
  "Furthermore, we observe that smaller encoders extracted from a universal MatFormer-based ViT (MatViT) encoder preserve the metric-space structure for adaptive large-scale retrieval. Finally, we showcase that speculative decoding with the accurate and consistent submodels extracted from MatFormer can further reduce inference latency.\nAuthors: Devvrit, Sneha Kudugunta, Aditya Kusupati, Tim Dettmers, Kaifeng Chen, Inderjit Dhillon, Yulia Tsvetkov, Hannaneh Hajishirzi, S. Kakade, Ali Farhadi, Prateek Jain\nVenue: arXiv.org\nTldr: {'model': 'tldr@v2.0.0', 'text': \"This work introduces MatFormer, a nested Transformer architecture designed to offer elasticity in a variety of deployment constraints and empirically demonstrates MatFormer's effectiveness across different model classes (decoders&encoders), modalities, and scales.\"}",
  "Faculty Name: yulia tsvetkov\nMetadata:\nPaperid: f9a5af5b21563b9bdd09630a8dec62d515479678\nTitle: LEXPLAIN: Improving Model Explanations via Lexicon Supervision\nYear: 2023\nAbstract: Model explanations that shed light on the model\u2019s predictions are becoming a desired additional output of NLP models, alongside their predictions. Challenges in creating these explanations include making them trustworthy and faithful to the model\u2019s predictions. In this work, we propose a novel framework for guiding model explanations by supervising them explicitly. To this end, our method, LEXplain, uses task-related lexicons to directly supervise model explanations. This approach consistently improves the model\u2019s explanations without sacrificing performance on the task, as we demonstrate on sentiment analysis and toxicity detection. Our analyses show that our method also demotes spurious correlations (i.e., with respect to African American English dialect) when performing the task, improving fairness.",
  "This approach consistently improves the model\u2019s explanations without sacrificing performance on the task, as we demonstrate on sentiment analysis and toxicity detection. Our analyses show that our method also demotes spurious correlations (i.e., with respect to African American English dialect) when performing the task, improving fairness.\nAuthors: Orevaoghene Ahia, Hila Gonen, Vidhisha Balachandran, Yulia Tsvetkov, Noah A. Smith\nVenue: STARSEM\nTldr: {'model': 'tldr@v2.0.0', 'text': 'This work proposes a novel framework for guiding model explanations by supervising them explicitly by using task-related lexicons to directly supervise model explanations, which consistently improves the model\u2019s explanations without sacrificing performance on the task, as well as demonstrating on sentiment analysis and toxicity detection.'}",
  "List of 2023 Open Access papers by yulia tsvetkov are:\nLatticeGen: A Cooperative Framework which Hides Generated Text in a Lattice for Privacy-Aware Generation on Cloud\nKnowledge Crosswords: Geometric Reasoning over Structured Knowledge with Large Language Models\nResolving Knowledge Conflicts in Large Language Models\nOn the Zero-Shot Generalization of Machine-Generated Text Detectors\nGlobalBench: A Benchmark for Global Progress in Natural Language Processing\nDo All Languages Cost the Same?",
  "Tokenization in the Era of Commercial Language Models\nBotPercent: Estimating Twitter Bot Populations from Groups to Crowds\nExamining risks of racial biases in NLP tools for child protective services\nUnderstanding In-Context Learning via Supportive Pretraining Data\nAssessing Language Model Deployment with Risk Cards\nFrom Pretraining Data to Language Models to Downstream Tasks: Tracking the Trails of Political Biases Leading to Unfair NLP Models\nFactKB: Generalizable Factuality Evaluation using Language Models Enhanced with Factual Knowledge\nTalkUp: Paving the Way for Understanding Empowering Language\nTrusting Your Evidence: Hallucinate Less with Context-aware Decoding\nBUFFET: Benchmarking Large Language Models for Few-shot Cross-lingual Transfer\nMitigating Societal Harms in Large Language Models\nMinding Language Models\u2019 (Lack of) Theory of Mind: A Plug-and-Play Multi-Character Belief Tracker\nCan Language Models Solve Graph Problems in Natural Language?\nLEXPLAIN: Improving Model Explanations via Lexicon Supervision\nMatFormer: Nested Transformer for Elastic Inference\nUnderstanding Ethics in NLP Authoring and Reviewing\nBotPercent: Estimating Bot Populations in Twitter Communities"
]