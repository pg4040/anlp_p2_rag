{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d98c85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def add_category_column(input_file, output_file):\n",
    "    with open(input_file, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        header = next(reader)  # Read the header row\n",
    "        data = list(reader)   # Read the remaining rows\n",
    "        \n",
    "        # Add the new column header and values to each row\n",
    "        header.append('Category')\n",
    "        for row in data:\n",
    "            row.append('Courses')\n",
    "        \n",
    "        # Write the updated data back to the CSV file\n",
    "        with open(output_file, 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow(header)\n",
    "            writer.writerows(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f24484cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Questions and answers extracted and saved to text files successfully.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Specify the CSV file name\n",
    "csv_file = \"Commencement_QnA.csv\"\n",
    "\n",
    "# Specify the output text file names\n",
    "questions_file = \"Commencement_questions.txt\"\n",
    "answers_file = \"Commencement_answers.txt\"\n",
    "\n",
    "# Read data from CSV and write questions and answers to separate text files\n",
    "with open(csv_file, \"r\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    with open(questions_file, \"w\", encoding=\"utf-8\") as q_file, open(answers_file, \"w\", encoding=\"utf-8\") as a_file:\n",
    "        for row in reader:\n",
    "            question = row[\"Question\"].strip()\n",
    "            answer = row[\"Answer\"].strip()\n",
    "            q_file.write(question + \"\\n\")\n",
    "            a_file.write(answer + \"\\n\")\n",
    "\n",
    "print(\"Questions and answers extracted and saved to text files successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f0d9827",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import fitz\n",
    "# References\n",
    "# https://beautiful-soup-4.readthedocs.io/en/latest/: Basic syntax\n",
    "# ChatGPT 3.5\n",
    "# Copy of /data_processing/scraping_and_beautify.py\n",
    "\n",
    "\"\"\"\n",
    "This function extracts the text and metadata part from a url and puts into text file.\n",
    "Params:\n",
    "    url = url of website\n",
    "    id = document id you want assigned to the document\n",
    "    topic_category = the category of the topic\n",
    "    further_processing = function that performs further processing of text\n",
    "Ensures:\n",
    "    Creates a <topicCategory_docId.txt> document for the text of \n",
    "    the webpage and a <topicCategory_docId_metadata.txt> that contains the metadata and\n",
    "    topic_category in /data/documents/.\n",
    "Returns:\n",
    "    Nothing\n",
    "\"\"\"\n",
    "def html_to_text(url, id, topic_category, further_processing):\n",
    "    # Get response from url\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code==200:\n",
    "        # Parse HTML content\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        base_dir = 'Academics_data/documents'\n",
    "        if not os.path.exists(base_dir):\n",
    "            os.makedirs(base_dir)\n",
    "\n",
    "        # Create doc txt file\n",
    "        doc_file_name = os.path.join(base_dir, f'{topic_category}_{id}.txt')\n",
    "        text = soup.get_text().strip()\n",
    "        text = re.sub('\\s+', ' ', text)\n",
    "        # print(\"text: \", text)\n",
    "\n",
    "        # text_elements = soup.find_all(text=True)\n",
    "\n",
    "        # text = ' '.join(text_elements)\n",
    "\n",
    "        # text = re.sub('\\s+', ' ', text).strip()\n",
    "\n",
    "        processed_text = further_processing(text)\n",
    "        with open(doc_file_name,\"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(processed_text)\n",
    "        \n",
    "        # Get metadata\n",
    "       \n",
    "        metadata_json = {}\n",
    "        metadata_json['title']=soup.title.text\n",
    "        metadata_tags = soup.find_all('meta')\n",
    "\n",
    "        for tag in metadata_tags:\n",
    "            name = tag.get('name')\n",
    "            if name:\n",
    "                metadata_json[name] = tag.get('content')\n",
    "            else:\n",
    "                property_attr = tag.get('property')\n",
    "                if property_attr:\n",
    "                    metadata_json[property_attr] = tag.get('content')\n",
    "                    \n",
    "        # Create metadata txt file\n",
    "        meta_file_name = os.path.join(base_dir, f'{topic_category}_{id}_metadata.txt')\n",
    "        with open(meta_file_name, \"w\", encoding=\"utf-8\") as meta_file:\n",
    "            json.dump(metadata_json, meta_file, indent=2)\n",
    "            # Append the category information to the metadata file\n",
    "            meta_file.write('\\nTopic category is ' + topic_category)\n",
    "            \n",
    "def html_file_to_text(webpage, id, topic_category, further_processing):\n",
    "    # Get response from url\n",
    "    with open(webpage, 'r', encoding='utf-8') as file:\n",
    "        html_content = file.read()\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    base_dir = 'Academics_data/documents'\n",
    "    if not os.path.exists(base_dir):\n",
    "        os.makedirs(base_dir)\n",
    "\n",
    "        # Create doc txt file\n",
    "    doc_file_name = os.path.join(base_dir, f'{topic_category}_{id}.txt')\n",
    "    # text = soup.get_text().strip()\n",
    "    # text = re.sub('\\s+', ' ', text)\n",
    "    # print(\"text: \", text)\n",
    "\n",
    "    # text_elements = soup.find_all(text=True)\n",
    "\n",
    "    # text = ' '.join(text_elements)\n",
    "\n",
    "    # text = re.sub('\\s+', ' ', text).strip()\n",
    "    \n",
    "    article_body_div = soup.find('div', class_='article-body')\n",
    "\n",
    "    if article_body_div:\n",
    "        article_body_text = article_body_div.get_text(separator='\\n')\n",
    "\n",
    "    text = '\\n'.join(line.strip() for line in article_body_text.splitlines() if line.strip())\n",
    "\n",
    "    processed_text = further_processing(text)\n",
    "    with open(doc_file_name,\"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(processed_text)\n",
    "        \n",
    "    metadata_json = {}\n",
    "    metadata_json['title']=soup.title.text\n",
    "    metadata_tags = soup.find_all('meta')\n",
    "    for tag in metadata_tags:\n",
    "        name = tag.get('name')\n",
    "        if name:\n",
    "            metadata_json[name] = tag.get('content')\n",
    "        else:\n",
    "            property_attr = tag.get('property')\n",
    "            if property_attr:\n",
    "                metadata_json[property_attr] = tag.get('content')\n",
    "                    \n",
    "        # Create metadata txt file\n",
    "    meta_file_name = os.path.join(base_dir, f'{topic_category}_{id}_metadata.txt')\n",
    "    with open(meta_file_name, \"w\", encoding=\"utf-8\") as meta_file:\n",
    "        json.dump(metadata_json, meta_file, indent=2)\n",
    "        # Append the category information to the metadata file\n",
    "        meta_file.write('\\nTopic category is ' + topic_category)\n",
    "\n",
    "def pdf_to_text(page, id, topic_category, further_processing):\n",
    "    try:\n",
    "        # Open the PDF file\n",
    "        with fitz.open(page) as pdf_doc:\n",
    "            text = \"\"\n",
    "\n",
    "            # Iterate over pages\n",
    "            for page_num in range(pdf_doc.page_count):\n",
    "                # Get the page\n",
    "                page = pdf_doc[page_num]\n",
    "\n",
    "                # Extract text from the page\n",
    "                text += page.get_text()\n",
    "\n",
    "            # Specify the base directory\n",
    "            base_dir = 'Academics_data/documents'\n",
    "\n",
    "            # Create the base directory if it doesn't exist\n",
    "            if not os.path.exists(base_dir):\n",
    "                os.makedirs(base_dir)\n",
    "\n",
    "            # Create the doc txt file\n",
    "            doc_file_name = os.path.join(base_dir, f'{topic_category}_{id}.txt')\n",
    "\n",
    "            # Process the text\n",
    "            processed_text = further_processing(text)\n",
    "\n",
    "            # Write the processed text to the doc txt file\n",
    "            with open(doc_file_name, \"w\", encoding=\"utf-8\") as file:\n",
    "                file.write(processed_text)\n",
    "\n",
    "            # Create metadata dictionary\n",
    "            metadata_json = {'title': 'CMU fact sheet'}\n",
    "\n",
    "            # Create the metadata file\n",
    "            meta_file_name = os.path.join(base_dir, f'{topic_category}_{id}_metadata.txt')\n",
    "\n",
    "            # Write metadata to the metadata file\n",
    "            with open(meta_file_name, \"w\", encoding=\"utf-8\") as meta_file:\n",
    "                json.dump(metadata_json, meta_file, indent=2)\n",
    "\n",
    "                # Append the category information to the metadata file\n",
    "                meta_file.write('\\nTopic category is ' + topic_category)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing PDF: {str(e)}\")\n",
    "\n",
    "\n",
    "\"\"\"Add further processing as needed\"\"\"\n",
    "def further_process(text):\n",
    "    return text\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "452521e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyMuPDF\n",
      "  Obtaining dependency information for PyMuPDF from https://files.pythonhosted.org/packages/cf/28/a50440fd3cdb263c1843bf166d48fc68d219ff7dccff7b854f19426ef4ee/PyMuPDF-1.23.26-cp311-none-win_amd64.whl.metadata\n",
      "  Downloading PyMuPDF-1.23.26-cp311-none-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting PyMuPDFb==1.23.22 (from PyMuPDF)\n",
      "  Obtaining dependency information for PyMuPDFb==1.23.22 from https://files.pythonhosted.org/packages/a7/79/2822a5c60909fdacaa1bc455c91e2b2dec9fc79537860b538f09ccad229d/PyMuPDFb-1.23.22-py3-none-win_amd64.whl.metadata\n",
      "  Downloading PyMuPDFb-1.23.22-py3-none-win_amd64.whl.metadata (1.4 kB)\n",
      "Downloading PyMuPDF-1.23.26-cp311-none-win_amd64.whl (3.4 MB)\n",
      "   ---------------------------------------- 0.0/3.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/3.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/3.4 MB 495.5 kB/s eta 0:00:07\n",
      "   --- ------------------------------------ 0.3/3.4 MB 2.5 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 1.2/3.4 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 2.4/3.4 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.4/3.4 MB 13.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.4/3.4 MB 12.0 MB/s eta 0:00:00\n",
      "Downloading PyMuPDFb-1.23.22-py3-none-win_amd64.whl (24.5 MB)\n",
      "   ---------------------------------------- 0.0/24.5 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 2.0/24.5 MB 42.3 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 3.1/24.5 MB 32.4 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 4.4/24.5 MB 31.3 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 5.4/24.5 MB 29.0 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 6.7/24.5 MB 28.7 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 7.4/24.5 MB 26.4 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 8.6/24.5 MB 26.2 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 9.5/24.5 MB 25.3 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 10.6/24.5 MB 24.2 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 11.3/24.5 MB 23.4 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 12.8/24.5 MB 22.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 14.3/24.5 MB 22.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 15.5/24.5 MB 24.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 17.0/24.5 MB 23.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 18.3/24.5 MB 26.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 19.6/24.5 MB 25.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 21.0/24.5 MB 27.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.5/24.5 MB 28.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.8/24.5 MB 28.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.5/24.5 MB 28.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.5/24.5 MB 28.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.5/24.5 MB 22.6 MB/s eta 0:00:00\n",
      "Installing collected packages: PyMuPDFb, PyMuPDF\n",
      "Successfully installed PyMuPDF-1.23.26 PyMuPDFb-1.23.22\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c93c136",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    }
   ],
   "source": [
    "url = \"https://lti.cs.cmu.edu/academics/phd-programs/files/handbook_phd_2023-2024.pdf\"\n",
    "id = \"phd_handbook\"\n",
    "topic_category = \"academics\"\n",
    "html_to_text(url, id, topic_category, further_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a285e0a8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def html_to_text(url, id, topic_category, further_processing):\n",
    "    # Get response from url\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # Parse HTML content\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        base_dir = 'Academics_data/documents'\n",
    "        if not os.path.exists(base_dir):\n",
    "            os.makedirs(base_dir)\n",
    "\n",
    "        # Create doc txt file\n",
    "        doc_file_name = os.path.join(base_dir, f'{topic_category}_{id}.txt')\n",
    "        text = soup.get_text().strip()\n",
    "        text = re.sub('\\s+', ' ', text)\n",
    "\n",
    "        processed_text = further_processing(text)\n",
    "        with open(doc_file_name, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(processed_text)\n",
    "        \n",
    "        # Get metadata\n",
    "        metadata_json = {}\n",
    "        title_tag = soup.title\n",
    "        if title_tag:\n",
    "            metadata_json['title'] = title_tag.text\n",
    "        metadata_tags = soup.find_all('meta')\n",
    "\n",
    "        for tag in metadata_tags:\n",
    "            name = tag.get('name')\n",
    "            if name:\n",
    "                metadata_json[name] = tag.get('content')\n",
    "            else:\n",
    "                property_attr = tag.get('property')\n",
    "                if property_attr:\n",
    "                    metadata_json[property_attr] = tag.get('content')\n",
    "                    \n",
    "        # Create metadata txt file\n",
    "        meta_file_name = os.path.join(base_dir, f'{topic_category}_{id}_metadata.txt')\n",
    "        with open(meta_file_name, \"w\", encoding=\"utf-8\") as meta_file:\n",
    "            json.dump(metadata_json, meta_file, indent=2)\n",
    "            # Append the category information to the metadata file\n",
    "            meta_file.write('\\nTopic category is ' + topic_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4add3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def generated(qna_pairs):\n",
    "    # Load existing CSV file into DataFrame\n",
    "    existing_file = \"Academics_QnA.csv\"\n",
    "    df = pd.read_csv(existing_file)\n",
    "    \n",
    "    # Create a new DataFrame from the new data\n",
    "    new_df = pd.DataFrame(qna_pairs)\n",
    "    \n",
    "    # Concatenate the original DataFrame with the new DataFrame\n",
    "    df = pd.concat([df, new_df], ignore_index=True)\n",
    "    \n",
    "    # Save the updated DataFrame back to the CSV file\n",
    "    df.to_csv(existing_file, index=False)\n",
    "    \n",
    "    print(\"New data added to the CSV file successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "df5251f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data added to the CSV file successfully.\n"
     ]
    }
   ],
   "source": [
    "generated(qna_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9834fa9f",
   "metadata": {},
   "source": [
    "# Last Append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "40c557e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF downloaded as handbook_phd_2023-2024.pdf\n",
      "Text extracted and saved to handbook_phd_2023-2024.txt\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "def download_pdf(url, local_filename):\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "    # Save the PDF locally\n",
    "    with open(local_filename, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"PDF downloaded as {local_filename}\")\n",
    "\n",
    "def pdf_to_text(pdf_path, txt_path):\n",
    "    # Open the downloaded PDF file\n",
    "    doc = fitz.open(pdf_path)\n",
    "    \n",
    "    # Create or overwrite the text file\n",
    "    with open(txt_path, 'w') as txt_file:\n",
    "        # Read each page from the PDF and extract text\n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc.load_page(page_num)\n",
    "            text = page.get_text()\n",
    "            txt_file.write(text)\n",
    "    \n",
    "    # Close the PDF document\n",
    "    doc.close()\n",
    "    print(f\"Text extracted and saved to {txt_path}\")\n",
    "\n",
    "# URL of the PDF file\n",
    "pdf_url = 'https://lti.cs.cmu.edu/academics/phd-programs/files/handbook_phd_2023-2024.pdf'\n",
    "# Local path to save the downloaded PDF\n",
    "pdf_path = 'handbook_phd_2023-2024.pdf'\n",
    "# The output text file path and name\n",
    "txt_path = 'handbook_phd_2023-2024.txt'\n",
    "\n",
    "# Download the PDF from the web link\n",
    "download_pdf(pdf_url, pdf_path)\n",
    "\n",
    "# Convert the downloaded PDF to text\n",
    "pdf_to_text(pdf_path, txt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "004a9e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF downloaded as mlt-student-handbook-2023-2024.pdf\n",
      "Text extracted and saved to mlt-student-handbook-2023-2024.txt\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "def download_pdf(url, local_filename):\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "    # Save the PDF locally\n",
    "    with open(local_filename, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"PDF downloaded as {local_filename}\")\n",
    "\n",
    "def pdf_to_text(pdf_path, txt_path):\n",
    "    # Open the downloaded PDF file\n",
    "    doc = fitz.open(pdf_path)\n",
    "    \n",
    "    # Create or overwrite the text file\n",
    "    with open(txt_path, 'w') as txt_file:\n",
    "        # Read each page from the PDF and extract text\n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc.load_page(page_num)\n",
    "            text = page.get_text()\n",
    "            txt_file.write(text)\n",
    "    \n",
    "    # Close the PDF document\n",
    "    doc.close()\n",
    "    print(f\"Text extracted and saved to {txt_path}\")\n",
    "\n",
    "# URL of the PDF file\n",
    "pdf_url = 'https://lti.cs.cmu.edu/academics/masters-programs/files/mlt-student-handbook-2023-2024.pdf'\n",
    "# Local path to save the downloaded PDF\n",
    "pdf_path = 'mlt-student-handbook-2023-2024.pdf'\n",
    "# The output text file path and name\n",
    "txt_path = 'mlt-student-handbook-2023-2024.txt'\n",
    "\n",
    "# Download the PDF from the web link\n",
    "download_pdf(pdf_url, pdf_path)\n",
    "\n",
    "# Convert the downloaded PDF to text\n",
    "pdf_to_text(pdf_path, txt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1240ec71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF downloaded as miis-handbook_2023-2024.pdf\n"
     ]
    },
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'charmap' codec can't encode character '\\uf0a7' in position 1204: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[83], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m download_pdf(pdf_url, pdf_path)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Convert the downloaded PDF to text\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m pdf_to_text(pdf_path, txt_path)\n",
      "Cell \u001b[1;32mIn[83], line 22\u001b[0m, in \u001b[0;36mpdf_to_text\u001b[1;34m(pdf_path, txt_path)\u001b[0m\n\u001b[0;32m     20\u001b[0m         page \u001b[38;5;241m=\u001b[39m doc\u001b[38;5;241m.\u001b[39mload_page(page_num)\n\u001b[0;32m     21\u001b[0m         text \u001b[38;5;241m=\u001b[39m page\u001b[38;5;241m.\u001b[39mget_text()\n\u001b[1;32m---> 22\u001b[0m         txt_file\u001b[38;5;241m.\u001b[39mwrite(text)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Close the PDF document\u001b[39;00m\n\u001b[0;32m     25\u001b[0m doc\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\encodings\\cp1252.py:19\u001b[0m, in \u001b[0;36mIncrementalEncoder.encode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m codecs\u001b[38;5;241m.\u001b[39mcharmap_encode(\u001b[38;5;28minput\u001b[39m,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors,encoding_table)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'charmap' codec can't encode character '\\uf0a7' in position 1204: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import fitz  # PyMuPDF\n",
    "\n",
    "def download_pdf(url, local_filename):\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "    # Save the PDF locally\n",
    "    with open(local_filename, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"PDF downloaded as {local_filename}\")\n",
    "\n",
    "def pdf_to_text(pdf_path, txt_path):\n",
    "    # Open the downloaded PDF file\n",
    "    doc = fitz.open(pdf_path)\n",
    "    \n",
    "    # Create or overwrite the text file\n",
    "    with open(txt_path, 'w') as txt_file:\n",
    "        # Read each page from the PDF and extract text\n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc.load_page(page_num)\n",
    "            text = page.get_text()\n",
    "            txt_file.write(text)\n",
    "    \n",
    "    # Close the PDF document\n",
    "    doc.close()\n",
    "    print(f\"Text extracted and saved to {txt_path}\")\n",
    "\n",
    "# URL of the PDF file\n",
    "pdf_url = 'https://lti.cs.cmu.edu/academics/masters-programs/files/miis-handbook_2023-2024.pdf'\n",
    "# Local path to save the downloaded PDF\n",
    "pdf_path = 'miis-handbook_2023-2024.pdf'\n",
    "# The output text file path and name\n",
    "txt_path = 'miis-handbook_2023-2024.txt'\n",
    "\n",
    "# Download the PDF from the web link\n",
    "download_pdf(pdf_url, pdf_path)\n",
    "\n",
    "# Convert the downloaded PDF to text\n",
    "pdf_to_text(pdf_path, txt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ea499142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_text(pdf_path, txt_path):\n",
    "    # Open the downloaded PDF file\n",
    "    doc = fitz.open(pdf_path)\n",
    "    \n",
    "    # Create or overwrite the text file with UTF-8 encoding\n",
    "    with open(txt_path, 'w', encoding='utf-8') as txt_file:\n",
    "        # Read each page from the PDF and extract text\n",
    "        for page_num in range(len(doc)):\n",
    "            page = doc.load_page(page_num)\n",
    "            text = page.get_text()\n",
    "            txt_file.write(text)\n",
    "    \n",
    "    # Close the PDF document\n",
    "    doc.close()\n",
    "    print(f\"Text extracted and saved to {txt_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6f7e473c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF downloaded as miis-handbook_2023-2024.pdf\n",
      "Text extracted and saved to miis-handbook_2023-2024.txt\n"
     ]
    }
   ],
   "source": [
    "# URL of the PDF file\n",
    "pdf_url = 'https://lti.cs.cmu.edu/academics/masters-programs/files/miis-handbook_2023-2024.pdf'\n",
    "# Local path to save the downloaded PDF\n",
    "pdf_path = 'miis-handbook_2023-2024.pdf'\n",
    "# The output text file path and name\n",
    "txt_path = 'miis-handbook_2023-2024.txt'\n",
    "\n",
    "# Download the PDF from the web link\n",
    "download_pdf(pdf_url, pdf_path)\n",
    "\n",
    "# Convert the downloaded PDF to text\n",
    "pdf_to_text(pdf_path, txt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "09b2f8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF downloaded as mcds-student-handbook-2023_2024.pdf\n",
      "Text extracted and saved to mcds-student-handbook-2023_2024.txt\n"
     ]
    }
   ],
   "source": [
    "# URL of the PDF file\n",
    "pdf_url = 'https://lti.cs.cmu.edu/academics/masters-programs/files/mcds-student-handbook-2023_2024.pdf'\n",
    "# Local path to save the downloaded PDF\n",
    "pdf_path = 'mcds-student-handbook-2023_2024.pdf'\n",
    "# The output text file path and name\n",
    "txt_path = 'mcds-student-handbook-2023_2024.txt'\n",
    "\n",
    "# Download the PDF from the web link\n",
    "download_pdf(pdf_url, pdf_path)\n",
    "\n",
    "# Convert the downloaded PDF to text\n",
    "pdf_to_text(pdf_path, txt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2224db2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF downloaded as handbook-msaii-2022-2023.pdf\n",
      "Text extracted and saved to handbook-msaii-2022-2023.txt\n"
     ]
    }
   ],
   "source": [
    "# URL of the PDF file\n",
    "pdf_url = 'https://lti.cs.cmu.edu/academics/masters-programs/files/handbook-msaii-2022-2023.pdf'\n",
    "# Local path to save the downloaded PDF\n",
    "pdf_path = 'handbook-msaii-2022-2023.pdf'\n",
    "# The output text file path and name\n",
    "txt_path = 'handbook-msaii-2022-2023.txt'\n",
    "\n",
    "# Download the PDF from the web link\n",
    "download_pdf(pdf_url, pdf_path)\n",
    "\n",
    "# Convert the downloaded PDF to text\n",
    "pdf_to_text(pdf_path, txt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a9ddf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
