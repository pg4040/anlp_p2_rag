Title: Extracting Training Data from Diffusion Models
Authors: Nicholas Carlini, Jamie Hayes, Milad Nasr, Matthew Jagielski, Vikash Sehwag, Florian Tramèr, Borja Balle, Daphne Ippolito, Eric Wallace, Ann Graham Lotz
Section: 9 Discussion and Conclusion
each wrote the corresponding sections of the paper. • Jamie performed the membership inference attacks and inpainting attacks on CIFAR-10 diffusion models, and Nicholas performed the diffusion extraction experiments; each wrote the corresponding sections of the paper. • Matthew ran experiments for canary memorization and wrote the corresponding section of the paper. • Florian and Vikash performed preliminary experiments on memorization in GANs, and Milad and Vikash ran the experiments included in the paper. • Milad ran the membership inference experiments on GANs. • Vikash ran extraction experiments on pretrained GANs. • Daphne and Florian improved figure clarity and presentation. • Daphne, Borja, and Eric edited the paper and contributed to paper framing. • Nicholas organized the project and wrote the initial paper draft. Acknowledgements and Conflicts of Interest The authors are grateful to Tom Goldstein, Olivia Wiles, Katherine Lee, Austin Tarango, Ian Wilbur, Jeff Dean, Andreas Terzis, Robin Rombach, and Andreas Blattmann for comments on early drafts of this paper. Nicholas, Milad, Matthew, and Daphne are employed at Google, and Jamie and Borja are employed at DeepMind, companies that both train large machine learning models (including diffusion models) on both public and private datasets. Eric Wallace is supported by the Apple Scholars in AI/ML Fellowship.