Title: Fusion-in-T5: Unifying Document Ranking Signals for Improved Information Retrieval
Authors: Shi Yu, Chenghao Fan, Chenyan Xiong, David Jin, Zhiyuan Liu, Zhenghao Liu
Section: D Experiment Details
In the experiment analyzing attention distribution in §5.4, we compute attention values using the fol- 1https://sourceforge.net/p/lemur/code/HEAD/tree/RankLib/ lowing method. We assume that the global attention similarity between the i-th and k-th samples in the j-th layer of transformers is denoted by Aji,k: Aji,k = ĥji,[CLS] · ĥ j k,[CLS] ||ĥji,[CLS]||||ĥ j k,[CLS]|| (5) Assuming the i-th sample is associated with a relevance label li for query q, we compute the mean value of global attention similarity Ajq(R1, R2) in the j-th layer between samples with relevance scores R1 and R2,which indicate the model’s ability to distinguish between similar documents. Ajq(R1, R2) = ∑n i=1,li=R1 ∑n k=1,rk=R2 Aji,k∑n i=1,li=R1 ∑n k=1,lk=R2 1 (6) To facilitate smoother visualization of the results for all queries, we perform min-max normalization on the those scores in the same layer j. {Ajq(R1, R2)} = Min-Max({Ajq(R1, R2)}) (7) For j equal to 10, 11, and 12, with R1 and R2 ranging from 0 to 3, the outcomes are presented in Figure 2a. Additionally, for j equal to 12, with R1 at 3 and R2 ranging from 0 to 3, the outcomes are shown in Figure 2b.