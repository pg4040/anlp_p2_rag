Title: ONE MODEL TO RULE THEM ALL ? TOWARDS END-TO-END JOINT SPEAKER DIARIZATION AND SPEECH RECOGNITION
Authors: Samuele Cornell, Jee-weon Jung, Shinji Watanabe, Stefano Squartini
Section: 6. REFERENCES
the state of the art of streaming distant conversational speech recognition,” ArXiv, 2022. [19] M. Kolbæk, D. Yu, Z.-H. Tan and J. Jensen, “Multitalker speech separation with utterance-level permutation invariant training of deep recurrent neural networks,” IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol. 25, no. 10, pp. 1901–1913, 2017. [20] N. Kanda, Y. Gaur, X. Wang et al., “Serialized output training for endto-end overlapped speech recognition,” in Proc. InterSpeech, 2020. [21] X. Chang, W. Zhang, Y. Qian et al., “End-to-end multi-speaker speech recognition with transformer,” in Proc. ICASSP. IEEE, 2020, pp. 6134– 6138. [22] L. Lu, N. Kanda, J. Li and Y. Gong, “Streaming end-to-end multi-talker speech recognition,” IEEE SPL, vol. 28, 2021. [23] D. Raj, L. Lu, Z. Chen et al., “Continuous streaming multi-talker asr with dual-path transducers,” in Proc. ICASSP. IEEE, 2022, pp. 7317– 7321. [24] N. Kanda, J. Wu, Y. Wu et al., “Streaming multi-talker ASR with tokenlevel serialized output training,” in Proc. InterSpeech, 2022. [25] C. Boeddeker, J. Heitkaemper, J. Schmalenstroeer et al., “Front-end processing for the CHiME-5 dinner party scenario,” in CHiME5 Workshop, 2018. [26] M. Delcroix, K. Zmolikova, K. Kinoshita et al., “Single channel target speaker extraction and recognition with speaker beam,” in Proc. ICASSP, 2018. [27] N. Kanda, Y. Gaur, X. Wang et al., “Joint speaker counting, speech recognition, and speaker identification for overlapped speech of any number of speakers,” in Proc. InterSpeech, 2020. [28] N. Kanda, X. Chang, Y. Gaur et al., “Investigation of end-to-end speaker-attributed asr for continuous multi-talker recordings,” in Proc. SLT, 2021. [29] N. Kanda, J. Wu, Y. Wu et al., “Streaming speaker-attributed asr with token-level speaker embeddings,” Proc. InterSpeech, 2022. [30] T. Moriya, H. Sato, T. Ochiai et al., “Streaming end-to-end target speaker ASR,” in Proc. InterSpeech, 2022. [31] Z. Huang, D. Raj, P. Garcı́a and S. Khudanpur, “Adapting selfsupervised models to multi-talker speech recognition using speaker embeddings,” in Proc. ICASSP, 2023. [32] N. Kanda, X. Xiao, Y. Gaur et al., “Transcribe-to-diarize: Neural speaker diarization for unlimited number of speakers using end-to-end speaker-attributed ASR,” in Proc. ICASSP. IEEE, 2022, pp. 8082– 8086. [33] S. Chen, C. Wang, Z. Chen et al., “WavLM: Large-scale self-supervised pre-training for full stack speech processing,” IEEE Journal of Selected Topics in Signal Processing, vol. 16, no. 6, 2022. [34] A. Radford, J. W. Kim, T. Xu et al., “Robust speech recognition via large-scale weak supervision,” ArXiv, 2022. [35] T. von Neumann, C. Boeddeker, M. Delcroix and R. Haeb-Umbach, “Meeteval: A toolkit for computation of word error rates for meeting transcription systems,”