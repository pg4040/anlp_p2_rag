Title: ALERT: Adapting Language Models to Reasoning Tasks
Authors: Ping Yu, Tianlu Wang, Olga Golovneva, Badr AlKhamissi, Siddharth Verma, Zhijing Jin, Gargi Ghosh, Mona Diab, Asli Celikyilmaz
Section: A For every submission:
3 A1. Did you describe the limitations of your work? Section 7 7 A2. Did you discuss any potential risks of your work? We did not see any potential risks in our paper 3 A3. Do the abstract and introduction summarize the paperâ€™s main claims? Section 1 7 A4. Have you used AI writing assistants when working on this paper? Left blank. B 3 Did you use or create scientific artifacts? Our data and pretrained model may contain scientific artifacts. Section 2 (data part). Section 3 (model part) 3 B1. Did you cite the creators of artifacts you used? Section 2 and Section 3 3 B2. Did you discuss the license or terms for use and / or distribution of any artifacts? Section D in appendix 3 B3. Did you discuss if your use of existing artifact(s) was consistent with their intended use, provided that it was specified? For the artifacts you create, do you specify intended use and whether that is compatible with the original access conditions (in particular, derivatives of data accessed for research purposes should not be used outside of research contexts)? Section 2 and Section D in appendix 7 B4. Did you discuss the steps taken to check whether the data that was collected / used contains any information that names or uniquely identifies individual people or offensive content, and the steps taken to protect / anonymize it? No, we use public datasets. 7 B5. Did you provide documentation of the artifacts, e.g., coverage of domains, languages, and linguistic phenomena, demographic groups represented, etc.? No, we use public datasets. 3 B6. Did you report relevant statistics like the number of examples, details of train / test / dev splits, etc. for the data that you used / created? Even for commonly-used benchmark datasets, include the number of examples in train / validation / test splits, as these provide necessary context for a reader to understand experimental results. For example, small differences in accuracy on large test sets may be significant, while on small test sets they may not be. Appendix C 3 Did you run computational experiments? Section 3 3 C1. Did you report the number of parameters in the models used, the total computational budget (e.g., GPU hours), and computing infrastructure used? Section 3 The Responsible NLP Checklist used at ACL 2023 is adopted from NAACL 2022, with the addition of a question on AI writing assistance. 3 C2. Did you discuss the experimental setup, including hyperparameter search and best-found hyperparameter values? Section 3 3