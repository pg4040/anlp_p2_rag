Title: "You might think about slightly revising the title": Identifying Hedges in Peer-tutoring Interactions
Authors: Yann Raphalen, Chlo√© Clavel, Justine Cassell
Section: A Additional information on the experimental settings
We used PyTorch (Paszke et al., 2019) to implement the neural models. For each set of features, hyperparameters were selected using Optuna (Akiba, 2019), a parameter search framework. We reimplemented the Attention-CNN with Glove (Pennington et al., 2014) 300-D words embeddings as the vector representation. For each models, the results are cross-validated using 5 folds (we chose 5 instead of 10 to avoid having folds with too few samples per class). We corrected the loss function for class imbalance to force the model to adapt more to the less frequent classes. The strength of this correction depended on the model, and was selected because it provided a satisfying compromise between favoring recall and precision in the classification results of that model. For LightGBM, a "square root of the square root of the inverse class proportion" correction was selected. Neural models were trained using AdamW as an optimizer (Loshchilov and Hutter, 2018), and used a reduced feature vector, obtained with the application of PCA (dinit = 1800; d = 100 ; 99.8 % of the information is conserved). No significant performance differences were observed between the original vector and the reduced vector for training the models. To compute the SHAP values mentioned in the paper, we kept one split to perform the 5-split of the dataset, and leave 1 split to validate and early stop the model, in order to avoid overfitting. A complete configuration of hyperparameters used for each model is reported in the GitHub repository with the code of the paper: https://github.com/YannRaphalen/HedgesDetection. The BERT model was fine-tuned on a Nvidia Quadro RTX 8000 GPU. B Tables