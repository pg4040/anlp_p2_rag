Title: REPRODUCING WHISPER-STYLE TRAINING USING AN OPEN-SOURCE TOOLKIT AND PUBLICLY AVAILABLE DATA
Authors: Yifan Peng, Jinchuan Tian, Brian Yan, Dan Berrebbi, Xuankai Chang, Xinjian Li, Jiatong Shi, Siddhant Arora, William Chen, Roshan Sharma, Wangyou Zhang, Yui Sudo, Muhammad Shakeel, Jee-weon Jung, Soumi Maiti, Shinji Watanabe
Section: 7. REFERENCES
[1] A. Vaswani et al., “Attention is all you need,” in Proc. NeurIPS, 2017. [2] Tom Brown et al., “Language models are few-shot learners,” 2020. [3] Jack W Rae et al., “Scaling language models: Methods, analysis & insights from training gopher,” arXiv:2112.11446, 2021. [4] Aakanksha Chowdhery et al., “Palm: Scaling language modeling with pathways,” arXiv:2204.02311, 2022. [5] Susan Zhang et al., “Opt: Open pre-trained transformer language models,” arXiv:2205.01068, 2022. [6] Hugo Touvron et al., “Llama: Open and efficient foundation language models,” arXiv:2302.13971, 2023. [7] OpenAI, “GPT-4 Technical Report,” arXiv:2303.08774, 2023. [8] Alexei Baevski, Yuhao Zhou, et al., “wav2vec 2.0: A framework for self-supervised learning of speech representations,” in Proc. NeurIPS, 2020. [9] Wei-Ning Hsu et al., “HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units,” IEEE/ACM Trans. Audio, Speech, Lang. Process., vol. 29, pp. 3451–3460, 2021. [10] Arun Babu, Changhan Wang, Andros Tjandra, et al., “XLS-R: Self-supervised Cross-lingual Speech Representation Learning at Scale,” in Proc. Interspeech, 2022. [11] Shu wen Yang et al., “SUPERB: Speech Processing Universal PERformance Benchmark,” in Proc. Interspeech, 2021. [12] Abdelrahman Mohamed et al., “Self-supervised speech representation learning: A review,” IEEE J. Sel. Topics Signal Process., vol. 16, no. 6, pp. 1179–1210, 2022. [13] Xuankai Chang, Takashi Maekaku, et al., “An exploration of self-supervised pretrained representations for end-to-end speech recognition,” in Proc. ASRU, 2021. [14] Yifan Peng et al., “A Study on the Integration of Pre-trained SSL, ASR, LM and SLU Models for Spoken Language Understanding,” in Proc. SLT, 2022. [15] Alec Radford et al., “Robust speech recognition via large-scale weak supervision,” arXiv:2212.04356, 2022. [16] William Chan et al., “Speechstew: Simply mix all available speech recognition data to train one large neural network,” arXiv:2104.02133, 2021. [17] Bo Li et al., “Scaling end-to-end models for large-scale multilingual asr,” in Proc. ASRU, 2021. [18] Yu Zhang et al., “Google USM: Scaling automatic speech recognition beyond 100 languages,” arXiv:2303.01037, 2023. [19] Paul Pu Liang et al., “Towards understanding and mitigating social biases in language models,” in Proc. ICML, 2021. [20] Jindong Wang et al., “On the robustness of chatgpt: An adversarial and out-of-distribution perspective,” arXiv:2302.12095, 2023. [21] Sébastien Bubeck et al., “Sparks of artificial general intelligence: Early experiments with gpt-4,” arXiv:2303.12712, 2023. [22] Shinji Watanabe et al., “ESPnet: End-to-End Speech Processing Toolkit,” in Proc. Interspeech, 2018. [23] Hui Bu et al., “AISHELL-1: An open-source Mandarin speech corpus and a speech recognition baseline,” in Proc. O-COCOSDA, 2017. [24] Changhan Wang et al., “CoVoST 2 and Massively Multilingual Speech Translation,” in Interspeech, 2021. [25] Guoguo Chen et al., “GigaSpeech: