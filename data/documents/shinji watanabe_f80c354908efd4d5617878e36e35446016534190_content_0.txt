Title: SEMI-AUTOREGRESSIVE STREAMING ASR WITH LABEL CONTEXT
Authors: Siddhant Arora, George Saon, Shinji Watanabe, Brian Kingsbury
Section: 4.4. Results and Discussion
Table 1 presents the performance of our streaming SAR models alongside topline and baseline models. We observe that the streaming NAR model with greedy (C5) and overlap greedy (C6) decoding [34] achieves impressively low latency but significantly degrades accuracy compared to streaming AR (B2) and non-streaming NAR (A4) models. Our experiments reveal that training with alignments using cross-entropy loss mostly yield inferior results compared to training with CTC loss (D3 vs C6), possibly due to imperfections in frame-level alignments. Notably, our streaming SAR model improves accuracy (E1 vs D3) by incorporating the LM subnetwork to encode the label context. Additionally, our proposed “alignment decoding” proves to be a valuable enhancement, delivering a significant boost in accuracy (E2 vs E1) compared to the “overlap decoding” proposed in prior work [34]. Further improvements are achieved by introducing intermediate CTC (E3) and employing “random block” (E4) regularization. Our best-performing streaming SAR model (E4) surpasses the streaming NAR model with overlap decoding (C6) by a relative margin of 19% on Tedlium-2, 16%/8% on the clean/other test sets of Librispeech-100, 19%/8% on the Switchboard(SWB)/Callhome(CH) test sets of SWB with only a slight increase in latency. We further conduct significance tests and observe a p-value of less than 0.003 using Matched Pair, Signed Paired, Wilcoxon and McNemar tests for all test datasets. Moreover, our streaming SAR model outperforms the streaming NAR model 2http://www.openslr.org/resources/11/ librispeech-lm-norm.txt.gz 3Full details regarding models, configuration files, and data preparation setup will be made publicly available as part of the ESPnet [3] toolkit. with full path decoding (E4 vs C4) by a relative 8%, 4%, 5% on Tedlium-2, Librispeech-100 and SWB, respectively, while achieving a 2.5x reduction in latency. Impressively, our proposed streaming SAR model effectively bridges the accuracy gap with non-streaming NAR models (E4,C6 vs A4) and can even match or surpass streaming AR models (E4 vs B2) on Tedlium2 and Librispeech-100 all while delivering a 5x and 2.5x faster processing speed respectively. Ablation study on incorporating label context: Table 2 shows our findings for conformer based models with “overlap decoding” inference on Tedlium2 dataset. First, we experiment with using “forced alignment” from a non-streaming NAR model and observe that forced alignments from a streaming NAR model leads to better accuracy. In the case of the LM subnetwork, we explore not finetuning the LM during training of the streaming SAR model, which proves that proposed finetuning is effective. We also experiment with not pre-training the subnetwork on a causal LM objective, and again observe that our formulation of initialising the LM subnetwork