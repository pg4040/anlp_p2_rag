Title: Quantifying & Modeling Multimodal Interactions: An Information Decomposition Framework
Authors: Paul Pu Liang, Yun Cheng, Xiang Fan, Chun Kai Ling, Suzanne Nie, Richard J. Chen, Zihao Deng, Nicholas Allen, Randy Auerbach, Faisal Mahmood, Ruslan Salakhutdinov, Louis-Philippe Morency
Section: E.2 Broader Impact
Multimodal data and models are ubiquitous in a range of real-world applications. Our proposed framework based on PID is our attempt to systematically quantify the plethora of datasets and models currently in use. While these contributions will accelerate research towards multimodal datasets and models as well as their real-world deployment, we believe that special care must be taken in the following regard to ensure that these models are safely deployed: Care in interpreting PID values: Just like with any approximate estimator, the returned PID values are only an approximation to the actual interactions and care should be taken to not overfit to these values. Other appropriate forms of dataset visualization and quantification should still be conducted to obtain holistic understanding of multimodal datasets. Privacy, security, and biases: There may be privacy risks associated with making predictions from multimodal data if the datasets include recorded videos of humans or health indicators. In our experiments with real-world data where people are involved (i.e., healthcare and affective computing), the creators of these datasets have taken the appropriate steps to only access public data which participants/content creators have consented for released to the public. We also acknowledge the risk of exposure bias due to imbalanced datasets that may cause biases towards certain genders, races, and demographic groups. Therefore, care should be taken in understanding the social risks of each multimodal dataset in parallel to understanding its interactions via PID. Time & space complexity: Modern multimodal datasets and models, especially those pretrained on internet-scale data, may cause broader impacts resulting from the cost of hardware, electricity, and computation, as well as environmental impacts resulting from the carbon footprint required to fuel modern hardware. Future work should carefully investigate the role of size on the interactions learned by models through estimated PID values. Our preliminary experiments showed that smaller models could still capture high degrees of each interaction, which may pave away towards designing new inductive biases that enable interaction modeling while using fewer parameters. Overall, PID offers opportunities to study the potential social and environmental issues in multimodal datasets by obtaining a deeper understanding of the underlying feature interactions, providing a path towards interpretable and lightweight models. We plan to continue expanding our understanding of PID via deeper engagement with domain experts and how they use this framework in their work. Our released datasets, models, and code will also present a step towards scalable quantification of feature interactions for future work.