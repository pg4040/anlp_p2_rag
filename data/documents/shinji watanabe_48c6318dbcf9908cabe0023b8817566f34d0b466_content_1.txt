Title: I3D: TRANSFORMER ARCHITECTURES WITH INPUT-DEPENDENT DYNAMIC DEPTH FOR SPEECH RECOGNITION
Authors: Yifan Peng, Jaesong Lee, Shinji Watanabe
Section: 6. REFERENCES
networks,” in Proc. CVPR, 2018. [22] J. Shen, Y. Wang, et al., “Fractional skipping: Towards finergrained dynamic cnn inference,” in Proc. AAAI, 2020. [23] C. Li, G. Wang, et al., “Dynamic slimmable network,” in Proc. CVPR, 2021. [24] J. Macoskey, G. P. Strimel, and A. Rastrow, “Bifocal neural asr: Exploiting keyword spotting for inference optimization,” in Proc. ICASSP, 2021. [25] Y. Shi, V. Nagaraja, C. Wu, et al., “Dynamic encoder transducer: a flexible solution for trading off accuracy for latency,” arXiv:2104.02176, 2021. [26] F. Weninger, M. Gaudesi, R. Leibold, R. Gemello, and P. Zhan, “Dual-encoder architecture with encoder selection for joint close-talk and far-talk speech recognition,” in Proc. ASRU, 2021. [27] J. Macoskey, G. P. Strimel, J. Su, and A. Rastrow, “Amortized neural networks for low-latency speech recognition,” arXiv:2108.01553, 2021. [28] Y. Xie, J. J. Macoskey, et al., “Compute Cost Amortized Transformer for Streaming ASR,” in Proc. Interspeech, 2022. [29] J. Lee, J. Kang, and S. Watanabe, “Layer pruning on demand with intermediate CTC,” in Proc. Interspeech, 2021. [30] E. Jang, S. Gu, and B. Poole, “Categorical reparameterization with gumbel-softmax,” in Proc. ICLR, 2017. [31] C. J. Maddison, A. Mnih, and Y. Teh, “The concrete distribution: A continuous relaxation of discrete random variables,” in Proc. ICLR, 2017. [32] A. Paszke, S. Gross, F. Massa, et al., “Pytorch: An imperative style, high-performance deep learning library,” in Proc. NeurIPS, 2019. [33] S. Watanabe, T. Hori, S. Karita, et al., “ESPnet: End-to-End Speech Processing Toolkit,” in Proc. Interspeech, 2018. [34] V. Panayotov, G. Chen, D. Povey, and S. Khudanpur, “Librispeech: An ASR corpus based on public domain audio books,” in Proc. ICASSP, 2015. [35] A. Rousseau, P. Deléglise, Y. Esteve, et al., “Enhancing the ted-lium corpus with selected data for language modeling and more ted talks.,” in Proc. LREC, 2014. [36] G. Huang, Y. Sun, Z. Liu, D. Sedra, and K. Weinberger, “Deep networks with stochastic depth,” in Proc. ECCV, 2016. [37] A. Fan, E. Grave, and A. Joulin, “Reducing transformer depth on demand with structured dropout,” in Proc. ICLR, 2020. [38] J. Lee and S. Watanabe, “Intermediate loss regularization for ctc-based speech recognition,” in Proc. ICASSP, 2021. [39] C. K. Reddy, V. Gopal, and R. Cutler, “Dnsmos p.835: A nonintrusive perceptual objective speech quality metric to evaluate noise suppressors,” in Proc. ICASSP, 2022.