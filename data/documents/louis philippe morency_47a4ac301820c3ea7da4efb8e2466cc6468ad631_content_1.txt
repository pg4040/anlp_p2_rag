Title: SENTECON: Leveraging Lexicons to Learn Human-Interpretable Language Representations
Authors: Victoria Lin, Louis-Philippe Morency
Section: B Experimental Details
• Not expressed: Out of all possible interpretations of the sentence above, you cannot imagine a scenario in which the speaker of the sentence was expressing the topic. • Potentially expressed: You can imagine at least one scenario in which the speaker of the sentence was expressing the topic. • Most likely expressed: The most natural interpretation of the sentence clearly expresses the topic. Category batches. As mentioned in the main paper, the 52 LIWC categories were randomly split into 5 sets of roughly equal size to avoid annotator fatigue. The splits were as follows: • Batch 1: netspeak, differ, cause, nonflu, discrep, drivers, relig, swear, feel, home, family • Batch 2: leisure, sexual, see, bio, certain, money, percept, female, death, anger, cogproc • Batch 3: filler, sad, posemo, friend, relativ, ingest, body, work, time, social, informal • Batch 4: focusfuture, anx, affiliation, motion, power, reward, space, tentat, risk, focuspresent, affect • Batch 5: negemo, hear, male, health, insight, achiev, focuspast, assent Inter-rater reliability. To assess the reliability of our annotations, we calculated intraclass correlation coefficients (ICCs) using the agreement software package (Girard, 2020). For each batch of sentences, we computed the ICC and its 95% confidence interval, then averaged these across category batches (Table 7). We averaged ICCs over all batches to obtain the overall ICC. Annotators. Annotators were required to be fluent in English and to be nationals of one of the following countries: the United States, the United Kingdom, Ireland, Australia, or Canada. Annotators were further required to have a prior approval rating of ≥ 95%, and an attention check question was included in every sentence batch. All annotators passed the attention check. We took care to compensate annotators at a rate above the local minimum wage. Annotators received an average hourly wage of 8.00 USD. B.4 Data Details of train, test, and reference corpus splits are provided in Table 8, including dataset composition and licensing information. For datasets released with existing train and test splits, we split the existing test set into a reference corpus and new test set. As mentioned in the main paper, all datasets are already publicly available, and the additional splits created for the reference corpora are available on our GitHub repository. All datasets are in English. B.5 Training details Our language models were built on the HuggingFace10 transformers library (version 4.16.2), with pre-trained models taken from the HuggingFace model hub. When fine-tuning these models on the task datasets, we used an Adam optimizer and learning rates [10−1, 10−2, 10−3, 10−4, 10−5],