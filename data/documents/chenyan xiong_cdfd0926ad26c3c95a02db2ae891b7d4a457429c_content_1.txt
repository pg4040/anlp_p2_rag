Title: OpenMatch-v2: An All-in-one Multi-Modality PLM-based Information Retrieval Toolkit
Authors: Shi Yu, Zhenghao Liu, Chenyan Xiong, Zhiyuan Liu
Section: 4.3 Infrastructure
expose interfaces for random access (via memory -mapping) class MappingCustomTrainDataset(MappingTrainDatasetMixin , CustomTrainDataset): pass Listing 1: Defining a new dataset class and endowing it with streaming/random access feature. To define a custom training dataset class, users can inherit Train DatasetBase, the base class for all training dataset classes, and fill in the unimplemented get_process_fn function, as shown in Listing 1. To enable the new dataset to be streamed or randomaccessed, users can mix in MappingTrainDatasetMixin or Stream TrainDatasetMixin. With the feature of Python mixin classes, the mixed-in classes will have the corresponding data-access abilities without the need for any additional lines of code. 2https://arrow.apache.org/ Sharded Search. Dense retrieval models require all documents to be loaded into CPU/GPU memory for searching. However, as IR datasets continue to grow larger, it becomes increasingly difficult to fit all the data into a single device’s memory. Take NQ as an example, its 20M documents can consume 20M × 768 dimensions × 4 bytes per dimension ≈ 60GB of memory. Typical GPU search is challenging for such a large index due to limited resources. To address this issue, OpenMatch-v2 introduces a shard-twice approach to break down the search process into smaller, more manageable steps, as illustrated in Figure 2. The first round of sharding partitions the document embeddings into several large shards, which are then loaded one by one and further split into smaller shards to fit within the available devices. The smaller shards are then searched in parallel, and the results are aggregated in the final step. We present the trade-off between search time and resource usage of searching on the NQ dataset in Table 4.