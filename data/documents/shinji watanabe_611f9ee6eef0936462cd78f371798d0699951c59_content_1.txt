Title: PAAPLOSS: A PHONETIC-ALIGNED ACOUSTIC PARAMETER LOSS FOR SPEECH ENHANCEMENT
Authors: Muqiao Yang, Joseph Konan, David Bick, Yunyang Zeng, Shuo Han, Anurag Kumar, Shinji Watanabe, Bhiksha Raj
Section: 7. REFERENCES
[15] S.-W. Fu, C.-F. Liao, Y. Tsao, and S.-D. Lin, “Metricgan: Generative adversarial networks based black-box metric scores optimization for speech enhancement,” in International Conference on Machine Learning, PMLR, 2019, pp. 2031–2041. [16] T.-A. Hsieh, C. Yu, S.-W. Fu, X. Lu, and Y. Tsao, “Improving perceptual quality by phone-fortified perceptual loss using Wasserstein distance for speech enhancement,” Proc. Interspeech, 2021. [17] F. Eyben, K. R. Scherer, B. W. Schuller, J. Sundberg, E. André, C. Busso, L. Y. Devillers, J. Epps, P. Laukka, S. S. Narayanan, et al., “The geneva minimalistic acoustic parameter set (GeMAPS) for voice research and affective computing,” IEEE transactions on affective computing, vol. 7, no. 2, pp. 190–202, 2015. [18] G. d. Krom, “Some spectral correlates of pathological breathy and rough voice quality for different types of vowel fragments,” Journal of Speech, Language, and Hearing Research, vol. 38, no. 4, pp. 794– 811, 1995. [19] J. Hillenbrand, R. Cleveland, and R. Erickson, “Acoustic correlates of breathy vocal quality,” Journal of speech and hearing research, vol. 37, pp. 769–78, Sep. 1994. [20] H. Kasuya, S. Ogawa, Y. Kikuchi, and S. Ebihara, “An acoustic analysis of pathological voice and its application to the evaluation of laryngeal pathology,” Speech Communication, 1986. [21] M. Yang, J. Konan, D. Bick, A. Kumar, S. Watanabe, and B. Raj, “Improving speech enhancement through fine-grained speech characteristics,” in Proc. Interspeech, 2022. [22] Y. Zeng, J. Konan, S. Han, D. Bick, M. Yang, A. Kumar, S. Watanabe, and B. Raj, “TAPLoss: A temporal acoustic parameter loss for speech enhancement,” in Proc. ICASSP, 2023. [23] A. Alwan, J. Jiang, and W. Chen, “Perception of place of articulation for plosives and fricatives in noise,” Speech communication, vol. 53, no. 2, pp. 195–209, 2011. [24] W. Styler, “On the acoustical features of vowel nasality in english and french,” The Journal of the Acoustical Society of America, vol. 142, no. 4, pp. 2469–2482, 2017. [25] H. G. Yi, M. K. Leonard, and E. F. Chang, “The encoding of speech sounds in the superior temporal gyrus,” Neuron, vol. 102, no. 6, pp. 1096–1110, 2019. [26] O. Tal, M. Mandel, F. Kreuk, and Y. Adi, “A Systematic Comparison of Phonetic Aware Techniques for Speech Enhancement,” in Proc. Interspeech, 2022, pp. 1193–1197. [27] W.-N. Hsu, B. Bolte, Y.-H. H. Tsai, K. Lakhotia, R. Salakhutdinov, and A. Mohamed, “Hubert: Self-supervised speech representation learning by masked prediction of hidden units,” IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol. 29, pp. 3451– 3460, 2021. [28] J. F. Gemmeke, D. P. Ellis, D. Freedman, A. Jansen,