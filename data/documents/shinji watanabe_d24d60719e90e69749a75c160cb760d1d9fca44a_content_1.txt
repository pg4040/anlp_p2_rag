Title: Incremental Blockwise Beam Search for Simultaneous Speech Translation with Controllable Quality-Latency Tradeoff
Authors: Peter Polák, Brian Yan, Shinji Watanabe, Alex Waibel, Ondřej Bojar
Section: 6. References
2016, pp. 2513–2517. [18] J. Niehues et al., “Low-latency neural speech translation,” in 19th Annual Conference of the International Speech Communication, INTERSPEECH 2018; Hyderabad International Convention Centre (HICC)Hyderabad; India; 2 September 2018 through 6 September 2018. Ed.: C.C. Sekhar, ser. Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH, vol. 2018-September, 2018, pp. 1293–1297. [19] X. Ma et al., “Simuleval: An evaluation toolkit for simultaneous translation,” in Proc. EMNLP, 2020, pp. 144–150. [20] E. Ansari et al., “FINDINGS OF THE IWSLT 2020 EVALUATION CAMPAIGN,” in Proceedings of the 17th International Conference on Spoken Language Translation, 2020, pp. 1–34. [21] K. Cho and M. Esipova, “Can neural machine translation do simultaneous translation?” arXiv preprint arXiv:1606.02012, 2016. [22] F. Dalvi et al., “Incremental decoding and training methods for simultaneous translation in neural machine translation,” in Proc. ACL, 2018, pp. 493–499. [23] J. Gu et al., “Learning to translate in real-time with neural machine translation,” in Proc. ACL, 2017, pp. 1053–1062. [24] N. Arivazhagan et al., “Monotonic infinite lookback attention for simultaneous machine translation,” in Proc. ACL, 2019, pp. 1313–1323. [25] B. Zheng et al., “Simpler and faster learning of adaptive policies for simultaneous translation,” in Proc. EMNLP, 2019, pp. 1349– 1354. [26] B. Zheng et al., “Simultaneous translation with flexible policy via restricted imitation learning,” in Proc. ACL, 2019, pp. 5816– 5822. [27] L. Dong et al., “A comparison of label-synchronous and framesynchronous end-to-end models for speech recognition,” arXiv preprint arXiv:2005.10113, 2020. [28] S. Jean et al., “Montreal neural machine translation systems for wmt’15,” in Proceedings of the tenth workshop on statistical machine translation, 2015, pp. 134–140. [29] N. Boulanger-Lewandowski, Y. Bengio, and P. Vincent, “Audio chord recognition with recurrent neural networks.,” in ISMIR, 2013, pp. 335–340. [30] R. Cattoni et al., “Must-c: A multilingual corpus for end-toend speech translation,” Computer Speech & Language, vol. 66, p. 101 155, 2021. [31] H. Inaguma et al., “ESPnet-ST: All-in-one speech translation toolkit,” in Proc. ACL, 2020, pp. 302–311. [32] T. Kudo, “Subword regularization: Improving neural network translation models with multiple subword candidates,” in Proc. ACL, 2018, pp. 66–75. [33] B. Yan et al., “Ctc alignments improve autoregressive translation,” arXiv preprint arXiv:2210.05200, 2022. [34] Y. Tang et al., “Unified speech-text pre-training for speech translation and recognition,” in Proc. ACL, 2022, pp. 1488–1499. [35] M. Ott et al., “Fairseq: A fast, extensible toolkit for sequence modeling,” in Proceedings of NAACL-HLT 2019: Demonstrations, 2019. [36] A. Baevski et al., “Wav2vec 2.0: A framework for selfsupervised learning of speech representations,” Advances in Neural Information Processing