Title: IMPROVING AUDIO CAPTIONING MODELS WITH FINE-GRAINED AUDIO FEATURES, TEXT EMBEDDING SUPERVISION, AND LLM MIX-UP AUGMENTATION
Authors: Shih-Lun Wu, Xuankai Chang, Gordon Wichern, Jee-weon Jung, François Germain, Jonathan Le Roux, Shinji Watanabe
Section: 3.4. Ablation Study
Automated audio captioning with weakly supervised pre-training and word selection methods,” Tech. Rep., DCASE Challenge, 2021. [5] X. Xu, Z. Xie, M. Wu and K. Yu, “The SJTU system for DCASE2022 challenge task 6: Audio captioning with audiotext retrieval pre-training,” Tech. Rep., DCASE Challenge, 2022. [6] Z. Ye, Y. Zou, F. Cui and Y. Wang, “Automated audio captioning with multi-task learning,” Tech. Rep., DCASE Challenge, 2022. [7] J.-H. Cho, Y.-A. Park, J. Kim and J.-H. Chang, “HYU submission for the DCASE 2023 task 6a: Automated audio captioning model using AL-MixGen and synonyms substitution,” Tech. Rep., DCASE Challenge, 2023. [8] E. Labbé, T. Pellegrini and J. Pinquier, “IRIT-UPS DCASE 2023 audio captioning and retrieval system,” Tech. Rep., DCASE Challenge, 2023. [9] C. P. Narisetty, T. Hayashi, R. Ishizaki et al., “Leveraging state-of-the-art ASR techniques to audio captioning.,” in Proc. DCASE, 2021. [10] Q. Kong, Y. Cao, T. Iqbal et al., “PANNs: Large-scale pretrained audio neural networks for audio pattern recognition,” IEEE/ACM Transactions on Audio, Speech, and Language Processing, 2020. [11] K. Chen, X. Du, B. Zhu et al., “HTS-AT: A hierarchical tokensemantic audio transformer for sound classification and detection,” in Proc. ICASSP, 2022. [12] P.-Y. Huang, H. Xu, J. Li et al., “Masked autoencoders that listen,” in Proc. NeurIPS, 2022. [13] S. Chen, Y. Wu, C. Wang et al., “BEATs: Audio pre-training with acoustic tokenizers,” arXiv preprint arXiv:2212.09058, 2022. [14] J. F. Gemmeke, D. P. Ellis, D. Freedman et al., “Audio Set: An ontology and human-labeled dataset for audio events,” in Proc. ICASSP, 2017. [15] L. Ouyang, J. Wu, X. Jiang et al., “Training language models to follow instructions with human feedback,” in Proc. NeurIPS, 2022. [16] H. Touvron, T. Lavril, G. Izacard et al., “LLaMA: Open and efficient foundation language models,” arXiv preprint arXiv:2302.13971, 2023. [17] H. Su, J. Kasai, Y. Wang et al., “One embedder, any task: Instruction-finetuned text embeddings,” Findings of ACL, 2023. [18] J. Schulman, B. Zoph, C. Kim et al., “Introducing ChatGPT,” OpenAI Blog, 2022. [19] A. van den Oord, Y. Li and O. Vinyals, “Representation learning with contrastive predictive coding,” arXiv preprint arXiv:1807.03748, 2018. [20] A. Gulati, J. Qin, C.-C. Chiu et al., “Conformer: Convolutionaugmented transformer for speech recognition,” in Proc. Interspeech, 2020. [21] K. Miyazaki, T. Komatsu, T. Hayashi et al., “Convolutionaugmented transformer for semi-supervised sound event detection,” in Proc. DCASE, 2020. [22] D. S. Park, W. Chan, Y. Zhang et al., “SpecAugment: A simple data augmentation method for automatic speech recognition,” in Proc. Interspeech, 2019. [23] H. Zhang, M. Cisse, Y. N. Dauphin