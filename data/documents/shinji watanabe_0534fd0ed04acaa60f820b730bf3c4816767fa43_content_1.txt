Title: TENSOR DECOMPOSITION FOR MINIMIZATION OF E2E SLU MODEL TOWARD ON-DEVICE PROCESSING
Authors: Yosuke Kashiwagi, Siddhant Arora, Hayato Futami, Jessica Huynh, Shih-Lun Wu, Yifan Peng, Brian Yan, Emiru Tsunoo, Shinji Watanabe
Section: 5. Conclusion
setting,” Computer Speech & Language, vol. 75, pp. 101369, 2022. [11] Akshat Gupta, “On building spoken language understanding systems for low resourced languages,” in Proceedings of the 19th SIGMORPHON Workshop on Computational Research in Phonetics, Phonology, and Morphology, Seattle, Washington, July 2022, pp. 1–11, Association for Computational Linguistics. [12] Pu Wang et al., “Bottleneck low-rank transformers for lowresource spoken language understanding,” Proceedings Interspeech 2022, 2022. [13] Anderson R Avila, Khalil Bibi, Rui Heng Yang, Xinlin Li, Chao Xing, and Xiao Chen, “Low-bit shift network for end-to-end spoken language understanding,” Proc. Interspeech 2022, pp. 2698– 2702, 2022. [14] Yingying Gao, Junlan Feng, Chao Deng, and Shilei Zhang, “Meta auxiliary learning for low-resource spoken language understanding,” Proc. Interspeech 2022, pp. 2703–2707, 2022. [15] Marco Dinarelli, Marco Naguib, and François Portet, “Toward low-cost end-to-end spoken language understanding,” Proc. Interspeech 2022, pp. 2728–2732, 2022. [16] Anmol Gulati, James Qin, Chung-Cheng Chiu, Niki Parmar, Yu Zhang, Jiahui Yu, Wei Han, Shibo Wang, Zhengdong Zhang, Yonghui Wu, et al., “Conformer: Convolution-augmented transformer for speech recognition,” Proc. Interspeech 2020, pp. 5036– 5040, 2020. [17] Yifan Peng, Siddharth Dalmia, Ian Lane, and Shinji Watanabe, “Branchformer: Parallel mlp-attention architectures to capture local and global context for speech recognition and understanding,” in International Conference on Machine Learning. PMLR, 2022, pp. 17627–17643. [18] Kwangyoun Kim, Felix Wu, Yifan Peng, Jing Pan, Prashant Sridhar, Kyu J Han, and Shinji Watanabe, “E-Branchformer: Branchformer with enhanced merging for speech recognition,” in 2022 IEEE Spoken Language Technology Workshop (SLT). IEEE, 2023, pp. 84–91. [19] Jeffrey Josanne Michael, Nagendra Kumar Goel, Jonas Robertson, Shravan Mishra, et al., “Comparison of svd and factorized tdnn approaches for speech to text,” arXiv preprint arXiv:2110.07027, 2021. [20] Yuekai Zhang, Sining Sun, and Long Ma, “Tiny transducer: A highly-efficient speech recognition model on edge devices,” in ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2021, pp. 6024– 6028. [21] Emily L Denton, Wojciech Zaremba, Joan Bruna, Yann LeCun, and Rob Fergus, “Exploiting linear structure within convolutional networks for efficient evaluation,” Advances in neural information processing systems, vol. 27, 2014. [22] Siddhant Arora, Siddharth Dalmia, Pavel Denisov, Xuankai Chang, Yushi Ueda, Yifan Peng, Yuekai Zhang, Sujay Kumar, Karthik Ganesan, Brian Yan, et al., “Espnet-slu: Advancing spoken language understanding through espnet,” in ICASSP 2022- 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2022, pp. 7167–7171. [23] Andros Tjandra, Sakriani Sakti, and Satoshi Nakamura, “Compressing recurrent neural network with tensor train,” in 2017 International Joint Conference on Neural Networks (IJCNN). IEEE, 2017, pp. 4451–4458. [24]