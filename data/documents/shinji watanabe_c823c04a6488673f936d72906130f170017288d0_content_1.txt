Title: THE MULTIMODAL INFORMATION BASED SPEECH PROCESSING (MISP) 2023 CHALLENGE: AUDIO-VISUAL TARGET SPEAKER EXTRACTION
Authors: Shilong Wu, Chenxi Wang, Hang Chen, Yusheng Dai, Chenyue Zhang, Ruoyu Wang, Hongbo Lan, Jun Du, Chin-Hui Lee, Jingdong Chen, Shinji Watanabe, Sabato Marco Siniscalchi, Odette Scharenborg, Zhong-Qiu Wang, Jia Pan, Jianqing Gao
Section: 6. REFERENCES
IEEE Spoken Language Technology Workshop (SLT). IEEE, 2023, pp. 465–471. [15] Chandan KA Reddy, Vishak Gopal, and Ross Cutler, “Dnsmos p. 835: A non-intrusive perceptual objective speech quality metric to evaluate noise suppressors,” in ICASSP 2022- 2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2022, pp. 886–890. [16] Cees H Taal, Richard C Hendriks, Richard Heusdens, et al., “A short-time objective intelligibility measure for time-frequency weighted noisy speech,” in 2010 IEEE international conference on acoustics, speech and signal processing. IEEE, 2010, pp. 4214–4217. [17] Antony W Rix, John G Beerends, Michael P Hollier, et al., “Perceptual evaluation of speech quality (pesq)-a new method for speech quality assessment of telephone networks and codecs,” in 2001 IEEE international conference on acoustics, speech, and signal processing. Proceedings (Cat. No. 01CH37221). IEEE, 2001, vol. 2, pp. 749–752. [18] Kazuma Iwamoto, Tsubasa Ochiai, Marc Delcroix, et al., “How bad are artifacts?: Analyzing the impact of speech enhancement errors on ASR,” in Proc. INTERSPEECH, 2022, pp. 5418–5422. [19] Hang Chen, Hengshun Zhou, Jun Du, et al., “The first multimodal information based speech processing (misp) challenge: Data, tasks, baselines and results,” in ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2022, pp. 9266–9270. [20] Zhe Wang, Shilong Wu, Hang Chen, et al., “The multimodal information based speech processing (misp) 2022 challenge: Audio-visual diarization and recognition,” in ICASSP 2023- 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2023, pp. 1–5. [21] Hang Chen, Jun Du, Yusheng Dai, et al., “Audio-visual speech recognition in misp2021 challenge: Dataset release and deep analysis,” in Proc. INTERSPEECH, 2022, pp. 1766–1770. [22] Yusheng Dai, Hang Chen, Jun Du, et al., “Improving audiovisual speech recognition by lip-subword correlation based visual pre-training and cross-modal fusion encoder,” in 2023 IEEE International Conference on Multimedia and Expo (ICME), 2023, pp. 2627–2632. [23] Desh Raj, Daniel Povey, and Sanjeev Khudanpur, “GPUaccelerated Guided Source Separation for Meeting Transcription,” in Proc. INTERSPEECH, 2023, pp. 3507–3511. [24] Christopher Hummersone, Toby Stokes, and Tim Brookes, “On the ideal ratio mask as the goal of computational auditory scene analysis,” in Blind source separation: advances in theory, algorithms and applications, pp. 349–368. Springer, 2014. [25] Shinji Watanabe, Takaaki Hori, Suyoun Kim, et al., “Hybrid ctc/attention architecture for end-to-end speech recognition,” IEEE Journal of Selected Topics in Signal Processing, vol. 11, no. 8, pp. 1240–1253, 2017. [26] Xavier Anguera, Chuck Wooters, and Javier Hernando, “Acoustic beamforming for speaker diarization of meetings,” IEEE Transactions on Audio, Speech, and Language Processing, vol. 15, no.