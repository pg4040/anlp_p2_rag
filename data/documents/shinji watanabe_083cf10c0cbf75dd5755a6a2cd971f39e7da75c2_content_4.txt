Title: UNIVERSLU: UNIVERSAL SPOKEN LANGUAGE UNDERSTANDING FOR DIVERSE CLASSIFICATION AND SEQUENCE GENERATION TASKS WITH A SINGLE NETWORK
Authors: Siddhant Arora, Hayato Futami, Jee-weon Jung, Yifan Peng, Roshan Sharma, Yosuke Kashiwagi, Emiru Tsunoo, Shinji Watanabe
Section: 7. REFERENCES
S. Park, and Y. Zhang, “Universal paralinguistic speech representations using self-supervised conformers,” in Proc. ICASSP, 2022, pp. 3169–3173. [75] K. Hechmi, T. N. Trong, V. Hautamäki, and T. Kinnunen, “Voxceleb enrichment for age and gender recognition,” in Proc. ASRU, 2021, pp. 687–693. [76] F. Jia, S. Majumdar, and B. Ginsburg, “Marblenet: Deep 1d timechannel separable convolutional neural network for voice activity detection,” in Proc. ICASSP, 2021, pp. 6818–6822. [77] K. Chen, X. Du, B. Zhu, Z. Ma, T. Berg-Kirkpatrick, and S. Dubnov, “HTS-AT: A hierarchical token-semantic audio transformer for sound classification and detection,” in Proc. ICASSP, 2022, pp. 646–650. [78] S. Arora et al., “A study on the integration of pipeline and E2E SLU systems for spoken semantic parsing toward STOP quality challenge,” CoRR, vol. abs/2305.01620, 2023. [79] E. Fonseca et al., “Freesound datasets: A platform for the creation of open audio datasets,” in ISMIR, 2017, pp. 486–493. [80] A. Paszke et al., “Pytorch: An imperative style, high-performance deep learning library,” Proc. NeurIPS, vol. 32, 2019. [81] D. S. Park et al., “Specaugment: A simple data augmentation method for automatic speech recognition,” in Proc. Interspeech, 2019, pp. 2613–2617. [82] N. Srivastava, G. Hinton, A. Krizhevsky, I. Sutskever, and R. Salakhutdinov, “Dropout: A simple way to prevent neural networks from overfitting,” The journal of machine learning research, vol. 15, no. 1, pp. 1929–1958, 2014. [83] R. Müller, S. Kornblith, and G. E. Hinton, “When does label smoothing help?” Advances in neural information processing systems, vol. 32, 2019.