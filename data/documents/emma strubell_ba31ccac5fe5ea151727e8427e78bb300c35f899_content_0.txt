Title: Data-efficient Active Learning for Structured Prediction with Partial Annotation and Self-Training
Authors: Zhisong Zhang, Emma Strubell, Eduard Hovy
Section: D Extra Results
D.1 Using Different Acquisition Functions In the main experiments, our acquisition function is based on margin-based uncertainty, that is, selecting the instances that have the largest marginal differences between the most and second-most confident predictions. Here, we compare it with various other acquisition functions, including leastconfident (-LC), max-entropy (-E) and BALD (- B) (Houlsby et al., 2011). We take DPAR as the studying case and the results for full annotation and partial annotation are shown in Figure 8 and 7, respectively. Generally, there are no large differences between the adopted querying methods and the margin-based method can obtain the overall best results. Notice that regardless of the adopted acquisition function, we can see the effectiveness of our partial selection scheme: it requires lower labeling cost than full annotation to reach the upper bound. This shows that our method is extensible to different AL querying methods and it will be interesting to explore the combination of our method with more complex and advanced acquisition func- tions, such as those considering representativeness. D.2 IE Experiments In this section, we present more results of the IE experiments. First, Figure 9 shows the mention extraction results for the event extraction task. The overall trends are very similar to those in NER: PA can obtain similar results to FA with the same reading texts and less mention labeling cost. In Figure 10, we show the results for mention and relation extractions. In the ACE dataset, relations are very sparsely annotated, and around 97% of the entities are linked with less or equal to two relations. Considering this fact, we measure the cost of FA relation extraction by two times the annotated entities, while PA still counts the number of the queried relations. The relation results are similar to the patterns for event argument extraction, showing the benefits of selecting and annotating with partial sub-structures. Notice that in some of the mention extraction results, there seems to be less obvious differences between the AL strategies over the random baseline. This may be due to our focus on the second sub-task for relations (or event arguments), directly reflected by its high weight (Î²) in calculating sentence uncertainty. It will be interesting to explore better ways to enhance both sub-tasks, probably with an adaptive combination scheme (Roth and Small, 2008).