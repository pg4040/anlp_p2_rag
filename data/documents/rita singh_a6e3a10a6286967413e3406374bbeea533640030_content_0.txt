Title: The Hidden Dance of Phonemes and Visage: Unveiling the Enigmatic Link between Phonemes and Facial Features
Authors: Liao Qu, Xianwei Zou, Xiang Li, Yandong Wen, Rita Singh, Bhiksha Raj
Section: 6. References
[1] M. H. Bahari, M. McLaren, H. V. hamme, and D. A. van Leeuwen, “Age estimation from telephone speech using i-vectors,” in Interspeech, 2012. [2] S. McGilloway, R. Cowie, and E. Douglas-Cowie, “Automatic recognition of emotion from voice: a rough benchmark,” 2000. [3] P. H. Ptacek and E. K. Sander, “Age recognition from voice.” Journal of speech and hearing research, vol. 9 2, pp. 273–7, 1966. [4] S. Li, D. Raj, X. Lu, P. Shen, T. Kawahara, and H. Kawai, “Improving transformer-based speech recognition systems with compressed structure and speech attributes augmentation,” in Interspeech, 2019. [5] H. A. Sánchez-Hevia, R. Gil-Pita, M. Utrilla-Manso, and M. Rosa-Zurera, “Age group classification and gender recognition from speech with temporal convolutional neural networks,” Multimedia Tools and Applications, vol. 81, pp. 3535 – 3552, 2022. [6] Z. Zhang, B. Wu, and B. Schuller, “Attention-augmented endto-end multi-task learning for emotion prediction from speech,” ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 6705–6709, 2019. [7] P. Belin, S. Fecteau, and C. Bédard, “Thinking the voice: neural correlates of voice perception,” Trends in Cognitive Sciences, vol. 8, pp. 129–135, 2004. [8] W. J. Hardcastle and J. Laver, “The handbook of phonetic sciences,” Language, vol. 75, p. 152, 1999. [9] T.-H. Oh, T. Dekel, C. Kim, I. Mosseri, W. T. Freeman, M. Rubinstein, and W. Matusik, “Speech2face: Learning the face behind a voice,” 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 7531–7540, 2019. [10] H.-S. Choi, C. Park, and K. Lee, “From inference to generation: End-to-end fully self-supervised generation of human face from speech,” ArXiv, vol. abs/2004.05830, 2020. [11] Y. Wen, B. Raj, and R. Singh, “Face reconstruction from voice using generative adversarial networks,” in Neural Information Processing Systems, 2019. [12] I. J. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. WardeFarley, S. Ozair, A. C. Courville, and Y. Bengio, “Generative adversarial nets,” in NIPS, 2014. [13] C.-Y. Wu, C.-C. Hsu, and U. Neumann, “Cross-modal perceptionist: Can face geometry be gleaned from voices?” 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 10 442–10 451, 2022. [14] C.-Y. Wu, K. Xu, C.-C. Hsu, and U. Neumann, “Voice2mesh: Cross-modal 3d face model generation from voices,” ArXiv, vol. abs/2104.10299, 2021. [15] R. H. C. Bull, H. Rathborn, and B. R. Clifford, “The voicerecognition accuracy of blind listeners,” Perception, vol. 12, pp. 223 – 226, 1983. [16] M. Ravanelli and Y. Bengio, “Speaker recognition from raw waveform with sincnet,” 2018 IEEE Spoken Language Technology Workshop (SLT), pp. 1021–1028, 2018. [17]