Title: Transformer Working Memory Enables Regular Language Reasoning And Natural Language Length Extrapolation
Authors: Ta-Chung Chi, Ting-Han Fan, Alexander I. Rudnicky, Peter J. Ramadge
Section: C Proof of Lemma 1
Lemma 1 (Approximation for Binary Matrix Product). Let A,B ∈ {0, 1}n×n be binary matrices of dimension n × n. Then, there exists a two-layer ReLU network such that fmlp([Flat(A),Flat(B)]) = Flat(AB), where Flat(X)(i−1)n+j = Xi,j for i, j ∈ [1, ..., n] is the operation that flattens a matrix into a vector. Proof. Observe that a ReLU operation can perfectly approximate the multiplication of two binary scalars: ReLU(a+ b− 1) = a · b, for a, b ∈ {0, 1}. The binary matrix product AB is composed of n3 binary scalar products of the form: AikBkj = x(i−1)n+kx(n+k−1)n+j for i, j, k ∈ [1, .., n], where x = [Flat(A),Flat(B)] is the concatenated flattened input. Our goal is to construct two neural network layers. The first layer computes all n3 binary scalar products. The second layer sums these products into the form of matrix product; i.e.,∑n k=1AikBkj . The first layer’s binary weight matrix W (1) ∈ {0, 1}2n2×n3 is constructed as: For z ∈ [1, ..., 2n2], i, j, k ∈ [1, ..., n], W (1) z,(i−1)n2+(j−1)n+k ={ 1 if z = (i− 1)n+ k or (n+ k − 1)n+ j 0 otherwise. (3) Then, the first layer computes all n3 binary scalar products as follows: ReLU ( [Flat(A),Flat(B)]W (1)−1> n3 ) (i−1)n2+(j−1)n+k = AikBkj for i, j, k ∈ [1, ..., n]. To sum these n3 products into n2 results, the second layer’s binary weight matrix W (2) ∈ {0, 1}n3×n2 is constructed as: W (2) = In2 ⊗ 1n = 1n 0n 0n . . . 0n 0n 1n 0n . . . 0n ... ... 0n . . . 0n 1n ∈ {0, 1}n3×n2 , where In2 is an n2 × n2 identity matrix, ⊗ is the Kronecker product, 0n is an n-dimensional column vector of all zeros, and 1n is an n-dimensional column vector of all ones. We arrive at a twolayer ReLU network that perfectly approximates the multiplication of two binary matrices: fmlp([Flat(A),Flat(B)]) =ReLU ( [Flat(A),Flat(B)]W (1)−1> n3 ) W (2) = Flat(AB). D Illustration of Lemma 1 D.1 Illustration of the Binary Weight Matrices We illustrate W (1) and W (2) of Lemma 1 as follows: import numpy as np def get_W1 ( n ) : n2 = n*n W1 = np . z e r o s ( ( 2 * n*n , n*n*n ) , d t y p e = i n t ) f o r i in range ( n ) : f o r j in