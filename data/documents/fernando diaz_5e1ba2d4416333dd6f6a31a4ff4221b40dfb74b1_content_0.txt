Title: Overview of the TREC 2021 Fair Ranking Track
Authors: Michael D. Ekstrand, Graham McDonald
Section: 56 0.008593 0.124741 0.009902 0.000342 0.000587 0.015458 0.001078
57 0.012217 0.006500 0.007919 0.000100 0.001217 0.000533 0.000533 30 id 1 3.311463e-06 2 2.401088e-06 3 1.941043e-05 4 2.960754e-06 5 1.737119e-05 6 2.797145e-05 7 2.226348e-05 8 3.745849e-05 9 1.909121e-05 10 5.600064e-06 11 1.234124e-05 12 2.253246e-05 13 2.260124e-05 14 1.030686e-05 15 2.074047e-05 16 1.545478e-05 17 1.736444e-05 18 1.535626e-05 19 1.673026e-05 20 1.152258e-05 21 1.022368e-05 22 2.313905e-05 23 1.727819e-05 24 3.485431e-06 25 1.763800e-05 26 1.113115e-05 27 4.564918e-06 28 2.462878e-05 29 9.977184e-06 30 1.756400e-05 31 5.445081e-06 32 9.152766e-04 33 6.680830e-06 34 1.340159e-05 35 1.587440e-05 36 9.847201e-06 37 4.564955e-06 38 1.841747e-05 39 2.742263e-04 40 2.971187e-06 41 2.115769e-05 42 7.113344e-06 43 4.781607e-06 44 1.934433e-05 45 7.035552e-05 46 9.814252e-06 47 4.353830e-06 48 2.179402e-05 49 2.199888e-05 50 2.345797e-05 51 1.906569e-05 52 2.666984e-06 53 1.749368e-05 54 1.075735e-05 55 3.381175e-07 56 4.295529e-05 57 1.077000e-05 [57 rows x 31 columns] And save: t1 train metric = metrics.Task1Metric(train qrels.set index('id'), page kia, train qtarget) binpickle.dump(t1 train metric, 'task1-train-metric.bpk', codec=codec) INFO:binpickle.write:pickled 1493808204 bytes with 5 buffers Do the same for eval: eval qtarget = eval qrels.groupby('id').apply(query xalign) t1 eval metric = metrics.Task1Metric(eval qrels.set index('id'), page kia, eval qtarget) binpickle.dump(t1 eval metric, 'task1-eval-metric.bpk', codec=codec) INFO:binpickle.write:pickled 1493808200 bytes with 5 buffers A.6 Task 2 Metric Preparation Task 2 requires some different preparation. We’re going to start by computing work-needed information: page work = pages.set index('page id').quality score disc.astype(pd.CategoricalDtype(ordered=True)) page work = page work.cat.reorder categories(work order) page work.name = 'quality' A.6.1 Work and Target Exposure The first thing we need to do to prepare the metric is to compute the work-needed for each topic’s pages, and use that to compute the target exposure for each (relevant) page in the topic. This is because an ideal ranking orders relevant documents in decreasing order of work needed, followed by irrelevant documents. All relevant documents at a given work level should receive the same expected exposure. First, look up the work for each query page (’query page work’, or qpw): qpw = qrels.join(page work, on='page id') qpw id page_id quality 0 1 572 C 1 1 627 FA 2 1 903 C 3 1 1193 B 4 1 1542 GA ... ... ... ... 2199072 150 63656179 Start 2199073 150 63807245 NaN 2199074 150 64614938 C 2199075 150 64716982 C 2199076 150 65355704 C [2199077 rows x 3 columns] And now use that to compute the number of documents at each work level: qwork = qpw.groupby(['id', 'quality'])['page id'].count() qwork id quality 1 Stub 1527 Start 2822 C 1603 B 610 GA 240 ... 150 Start 138 C 127 B 35 GA 16 FA 8 Name: page_id, Length: 636, dtype: