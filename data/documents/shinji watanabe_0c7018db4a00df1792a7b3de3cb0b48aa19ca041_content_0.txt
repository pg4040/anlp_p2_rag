Title: Integrating Pretrained ASR and LM to Perform Sequence Generation for Spoken Language Understanding
Authors: Siddhant Arora, Hayato Futami, Yosuke Kashiwagi, Emiru Tsunoo, Brian Yan, Shinji Watanabe
Section: 7. References
[1] D. Yu, M. Cohn, et al., “Gunrock: A social bot for complex and engaging long conversations,” in Proc. EMNLP-IJCNLP - System Demonstrations, 2019. [2] A. Coucke et al., “Snips voice platform: An embedded spoken language understanding system for private-by-design voice interfaces,” CoRR, vol. abs/1805.10190, 2018. [3] P. Tomasello et al., “Stop: A dataset for spoken task oriented semantic parsing,” in Proc. SLT, 2022, pp. 991–998. [4] S. Shon et al., “SLUE phase-2: A benchmark suite of diverse spoken language understanding tasks,” CoRR, vol. abs/2212.10525, 2022. [5] E. Bastianelli et al., “SLURP: A spoken language understanding resource package,” in Proc. EMNLP, 2020. [6] S. Shon et al., “SLUE: new benchmark tasks for spoken language understanding evaluation on natural speech,” in Proc. ICASSP, 2022, pp. 7927–7931. [7] D. Jurafsky and J. H. Martin, Speech and language processing: an introduction to natural language processing, computational linguistics, and speech recognition, 2nd Edition (Prentice Hall series in artificial intelligence). 2009. [8] S. Arora et al., “Token-level sequence labeling for spoken language understanding using compositional end-to-end models,” in Findings of the EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022, Y. Goldberg, Z. Kozareva, and Y. Zhang, Eds., 2022, pp. 5419–5429. [9] L. Zhai et al., “Using n-best lists for named entity recognition from chinese speech,” in Proceedings of HLT-NAACL 2004: Short Papers, Boston, Massachusetts, USA, May 2-7, 2004, 2004. [10] D. D. Palmer and M. Ostendorf, “Improving information extraction by modeling errors in speech recognizer output,” in Proceedings of the First International Conference on Human Language Technology Research, 2001. [11] J. Horlock and S. King, “Discriminative methods for improving named entity extraction on speech data,” in Proc. 8th European Conference on Speech Communication and Technology (Eurospeech 2003), 2003, pp. 2765–2768. [12] F. Béchet et al., “Detecting and extracting named entities from spontaneous speech in a mixed-initiative spoken dialogue context: How may I help you?sm, tm,” Speech Commun., vol. 42, no. 2, pp. 207–225, 2004. [13] T. Tran et al., “Parsing speech: A neural approach to integrating lexical and acoustic-prosodic information,” in Proc. NAACL, M. A. Walker, H. Ji, and A. Stent, Eds., 2018, pp. 69–81. [14] J. Godfrey, E. Holliman, and J. McDaniel, “Switchboard: Telephone speech corpus for research and development,” in Proc. ICASSP, vol. 1, 1992, 517–520 vol.1. [15] S. Arora et al., “ESPnet-SLU: Advancing spoken language understanding through espnet,” in Proc. ICASSP, 2022, pp. 7167– 7171. [16] S. Ghannay et al., “End-to-end named entity and semantic concept extraction from speech,” in Proc. SLT, 2018, pp. 692–699. [17] Y. Peng et al.,