Title: Chain-of-Skills: A Configurable Model for Open-Domain Question Answering
Authors: Kaixin Ma, Hao Cheng, Yu Zhang, Xiaodong Liu, Eric Nyberg, Jianfeng Gao
Section: B Experimental Details
is optimized using Adam with the initial learning rate of 1e-4. The final checkpoint is used for fine-tuning later. Finetuning When initializing from pretrained COS, the weights mapping for the first 5 experts are illustrated in Figure 3 and the last expert is initialized from BERT-base-uncased. For all experiments, we train models for 40 epochs with the batch size of 192, the learning rate of 2e-5, and the max sequence length of 256. During training, each batch only contains training data for one of the skills from one dataset, thus the model can effectively benefit from the in-batch negatives. To train the entity span proposal skill, we use the same data as entity linking. In particular, we route the data to span proposal experts 20% of the time otherwise the data go through entity linking experts. B.3 Inference Details Zero-shot-evaluation We directly use the single retrieval skill to find the top100 documents and compute the results in Table 1. Supervised and Cross-dataset For NQ, EntityQuestions and SQuAD, the reasoning path has a length of 1, i.e., only single passages. We use both single retrieval and linking skills to find a total of top 1000 passages first, and then reduce the set to top 100 using the reranking skill. Both HotpotQA and OTT-QA have reasoning paths with max length 2. For OTT-QA, we first Dataset Train Dev Test Skill Training Data # Examples Pretraining - - - single retrieval 6M expanded query retrieval 6M passage entity linking 9M NQ 79,168 8,757 3,610 single retrieval 86,252 reranking 86,252 HotpotQA 90,447 7,405 7,405 single retrieval 90,447 expanded query retrieval 90,447 question entity linking 80,872 passage entity linking 104,335 reranking 90,447 OTT-QA 41,469 2,214 2,158 single retrieval 41,469 expanded query retrieval 31,638 table entity linking 19,764 reranking 41,479 EntityQuestions - 22,068 22,075 - - WebQ - - 2,032 - - SQuAD - - 10,570 - - Table A1: Statistics of datasets used in our experiments, columns 2-4 represent the number of questions in each split. The last two columns contain the type of training data and the corresponding number of instances find top 100 tables using the single retrieval skill following (Ma et al., 2022a). Then we break down tables into rows and use the reranking skill to keep only top 200 rows. Then for each row, expanded query retrieval and linking skills are used to find the second-hop passages, where we keep top 10 passages from every expanded query retrieval and top 1 passage from every linked entity. Finally, we apply the same