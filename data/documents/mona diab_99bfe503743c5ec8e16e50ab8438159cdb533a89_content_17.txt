Title: The Troubling Emergence of Hallucination in Large Language Models – An Extensive Definition, Quantification, and Prescriptive Remediations
Authors: Vipula Rawte, Swagata Chakraborty, Agnibh Pathak, Anubhav Sarkar, S.M Towhidul Islam Tonmoy, Aman Chadha, Amit Sheth, Amitava Das
Section: 
sentence-wise approach. Our annotation process involves three layers of annotation: (i) Orientation: This layer captures the orientation of hallucinations. (ii) Category: This layer classifies the category of hallucination, and (iii) Degree: This layer quantifies the intensity or magnitude of hallucination. By employing these three layers, we aim to provide a comprehensive and detailed annotation for hallucination in AI-generated text. Algorithm 1: Annotation Guidelines 1 Split the paragraph into a list of sentences. 2 Annotate the orientation of hallucination as intrinsic or extrinsic. 3 Annotate the category of hallucination. 4 Annotate the degree of hallucination. • Step 1: In order to analyze the legitimacy of an AI-Generated paragraph and identify any potential hallucination, we begin with a sentence-level approach. We split the paragraph into individual sentences ensuring that each sentence is distinct and well separated from the others. Each sentence undergoes rigorous scrutiny to determine its legitimacy. This involves the identification of the type of hallucination, the category of hallucination, and the degree of hallucination. • Step 2: In this step, we identify whether the sentence has no hallucination, intrinsic hallucination, or extrinsic hallucination. The absence of both intrinsic and extrinsic hallucination implies no hallucination. To identify whether the sentence has intrinsic hallucination or extrinsic hallucination, we refer to the definitions in Section 2. We annotate each sentence using the annotations listed in Table 3 • Step 3: In this step, we identify whether the detected hallucinated sentences of the previous step belong to any of the categories mentioned in Fig. 1. To identify the categories we refer to the definitions mentioned in Section 2. If the hallucinated sentence does not fall under any of the identified categories, it implies a miscellaneous category. Once we have identified the category, we annotate each sentence using the annotations listed in Table 3. • Step 4: This step involves categorizing the degree of hallucination as mild, moderate, or alarming, based on the level of delusional information in the sentence. A high degree refers to completely delusional information, a moderate degree to partially delusional information, and a low degree to minimal delusional information. Once we have identified the degree of hallucination, we annotate it as listed in Table 3. B.3 Web Interface for Annotation In order to facilitate the annotation process for the annotators, it is crucial to provide them with a user-friendly interface that enables easy navigation. Fig. 9 shows our annotation web interface used to construct the HILT dataset. The interface is designed to offer a comprehensive view to the annotator. For instance,