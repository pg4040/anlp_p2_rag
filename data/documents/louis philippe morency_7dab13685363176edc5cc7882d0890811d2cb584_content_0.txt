Title: Counterfactual Augmentation for Multimodal Learning Under Presentation Bias
Authors: Victoria Lin, Louis-Philippe Morency, Srinagesh Sharma
Section: B Additional Experiments
B.1 Counterfactual augmentation without feature evolution In this section, we present results (Tables 10, 11, 12, and 13) that verify that counterfactual augmentation does not require feature evolution to successfully correct presentation bias. We follow the same experimental procedures as in Section 4; however, for all three datasets—Synthetic, Airbnb, and Clothing—we use only tabular features for all data splits Doriginal, Dtrain, Deval, and Dbiased. We observe that as is the case in our main results, counterfactual augmentation generally produces improvements in overall performance and macro/minority class performance, both relative to the uncorrected baseline and to the competing bias-correction baselines, IPW and Dragonnet. Performance of both the baselines and counterfactual augmentation is less consistent compared to the feature evolution setting (this is particularly evident in the clothing regression task, where R2 is negative). We hypothesize that there is not sufficient information encoded in the tabular data to learn certain tasks well. Furthermore, it is also more difficult to generate the counterfactuals for counterfactual augmentation, since the GAN now also has access only to tabular data. B.2 Modality ablations To further demonstrate the utility of counterfactual augmentation in natural language settings, in this section we report results from experiments with ablated (language-only) versions of the Airbnb and Synthetic datasets (Tables 14, 15, 16). Again, we follow the same experimental procedures as in Section 4, but we make only language features available in Dtrain, Deval, and Dbiased. We find that—consistent with our other results— counterfactual augmentation continues to outperform uncorrected models and existing biascorrection methods. Interestingly, we observe that bias correction appears to work better in some data settings given only the text modality, relative to models that have access to both text and images.