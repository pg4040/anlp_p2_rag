Title: The Devil is in the Errors: Leveraging Large Language Models for Fine-grained Machine Translation Evaluation
Authors: Patrick Fernandes, Daniel Deutsch, Mara Finkelstein, Parker Riley, André F. T. Martins, Graham Neubig, Ankush Garg, Jonathan H. Clark, Markus Freitag, Orhan Firat
Section: 6.1 Experimental Setup
every span the major severity. 6We use a small variation of the zero-shot prompt, asking models for scores from the same 5 buckets used in finetuning. averaged over a set of language pairs (Kocmi et al., 2021). System-level scores are defined as the average score across all segments. At the segment-level, the standard correlation that is reported by WMT is Kendall’s τ . However, recent work pointed out problems with Kendall’s τ with respect to ties (Deutsch et al., 2023). In short, different variants of τ are inconsistent with respect to ties and even biased against metrics that predict ties, as our metrics do in this work. Deutsch et al. (2023) recommend reporting a pairwise accuracy score, which rewards metrics for correctly ranking translations as well as correctly predicting ties, in combination with a tie calibration procedure that automatically introduces ties into metric scores so that the meta-evaluation is fairer. This accuracy score, denoted acc∗, ranges between 0 and 1, and a random metric would achieve 33% accuracy. We report the “group-by-item” variant of the pairwise accuracy score from Deutsch et al. (2023) in addition to Pearson’s ρ, a complementary signal to rank-based correlations that measure the strength of the linear relationship between two variables (and one of the standard correlations reported in WMT). Span Meta-Evaluation Since AUTOMQM provides not only scores but also the identified error spans, we can compare the predicted spans with the errors marked by annotators in the MQM annotations. We evaluate quality of predicted spans using: (1) Span Precision (SP), which measures the overlap of predicted spans and gold (annotated) spans; and (2) Major recall (MR), which captures the percentage of gold major errors that were predicted as errors (either minor or major). More formally, consider the set of ground truth spans S⋆, where each span consists of a sequence of words, i.e., si = (w(a), w(a+1), · · · ). Let S⋆maj ⊆ S⋆ be the subset containing only the major errors. Given a span set S, we define its positional set P (S) as the set containing the positions of all the words in every span in S. For example, assuming a span si = (w(n), w(n+1), · · · ) in S starts at the nth position in the text, its corresponding positional set will include the positions {n, n+1, ..., n+len(si)− 1}. Then for a set of predicted spans Ŝ, SP and MR are defined as: SP(Ŝ) = |P (Ŝ) ∩ P (S⋆)| |P (Ŝ)| (1) MR(Ŝ) = |P (Ŝ) ∩