Title: Integration of Frame- and Label-synchronous Beam Search for Streaming Encoder–decoder Speech Recognition
Authors: Emiru Tsunoo, Hayato Futami, Yosuke Kashiwagi, Siddhant Arora, Shinji Watanabe
Section: 6. References
speech recognition with recurrent neural networks,” in Proc. ICASSP, 2016, pp. 5335–5339. [33] S. Watanabe, T. Hori, S. Kim, J. R. Hershey, and T. Hayashi, “Hybrid CTC/attention architecture for end-to-end speech recognition,” Journal of Selected Topics in Signal Processing, vol. 11, no. 8, pp. 1240–1253, 2017. [34] V. Panayotov, G. Chen, D. Povey, and S. Khudanpur, “LibriSpeech: An ASR corpus based on public domain audio books,” in Proc. ICASSP, 2015, pp. 5206–5210. [35] F. Hernandez, V. Nguyen, S. Ghannay, N. Tomashenko, and Y. Esteve, “TED-LIUM 3: Twice as much data and corpus repartition for experiments on speaker adaptation,” in International conference on speech and computer, 2018, pp. 198–208. [36] P. Tomasello, A. Shrivastava, D. Lazar, P.-C. Hsu, D. Le, A. Sagar, A. Elkahky, J. Copet, W.-N. Hsu, Y. Adi, et al., “STOP: A dataset for spoken task oriented semantic parsing,” in Proc. SLT, 2023, pp. 991–998. [37] K. Maekawa, H. Koiso, S. Furui, and H. Isahara, “Spontaneous speech corpus of Japanese,” in Proc. of the International Conference on Language Resources and Evaluation (LREC), 2000, pp. 947–9520. [38] S. Ando and H. Fujihara, “Construction of a large-scale Japanese ASR corpus on TV recordings,” in Proc. ICASSP, 2021, pp. 6948–6952. [39] S. Karita, Y. Kubo, M. A. U. Bacchiani, and L. Jones, “A comparative study on neural architectures and training methods for Japanese speech recognition,” in Proc. Interspeech, 2021, pp. 2092–2096.