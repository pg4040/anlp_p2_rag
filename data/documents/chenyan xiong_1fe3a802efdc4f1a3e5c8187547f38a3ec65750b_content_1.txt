Title: Unsupervised Dense Retrieval Training with Web Anchors
Authors: Yiqing Xie, Xiao Liu, Chenyan Xiong
Section: 4.4 Performance Analysis
the vaccine might make them susceptible to more severe diseases... not in others. To analyze the effectiveness of Anchor-DR on different datasets, we categorize the datasets into three subsets: (1) Search/QA, where the query is a question or keywords related to the document; (2) Context/Paraphrase, where the query and document contain coherent or overlapping information; and (3) Others. Figure 1(a) shows that Anchor-DR performs better on Search/QA datasets and co-doc is better on Context/Paraphrase datasets. The results are consistent with our hypothesis that the referral relation between query-document pairs is similar to the information-seeking relation between search queries and relevant documents. We further quantitatively analyze the information pattern of query-document pairs captured by Anchor-DR and co-doc. Figure 1(b) shows the performance gap between Anchor-DR and co-doc versus the degree of information overlap between queries and documents in each test dataset, which is measured using Jaccard Similarity. We observe that Anchor-DR performs much better on datasets where queries and documents contain less overlapping information. The primary emphasis of datasets with high query-document similarity is mainly on paraphrasing and coherency, which are distinct from the relation between search queries and documents. Case studies. We show in Table 4 the contrastive pairs of AnchorDR and co-doc, as well as the positive pairs in ArguAna and TRECCOVID, which represent the Search/QA and Context/Paraphrase datasets. The query-doc pairs of ArguAna are arguments around the same topic, which are coherent and have similar formats. Similarly, the contrastive pairs of co-doc contain either coherent (e.g., the claim and recent work of the vegetarian society) or repeating information (e.g., COVID vaccine may cause diseases), which may explain its good performance on Context/Paraphrase datasets. In contrast, in TREC-COVID, the answer to the query is contained in the document. As shown in Table 4, the anchor text in Anchor-DR could be the topic of the linked document, or in the format of a question. In both examples, the anchor text can serve as a search query and the document can provide the information the query is seeking, which could be the reason why Anchor-DR achieves strong performance on the Search/QA datasets.