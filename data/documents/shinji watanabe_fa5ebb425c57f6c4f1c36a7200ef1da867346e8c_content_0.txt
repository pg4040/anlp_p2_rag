Title: SPEECH COLLAGE: CODE-SWITCHED AUDIO GENERATION BY COLLAGING MONOLINGUAL CORPORA
Authors: Amir Hussein, Dorsa Zeinali, Ondřej Klejch, Matthew Wiesner, Brian Yan, Shammur Chowdhury, Ahmed Ali, Shinji Watanabe, Sanjeev Khudanpur
Section: 7. REFERENCES
[1] C. M. Scotton, “The possibility of code-switching: Motivation for maintaining multilingualism,” Anthropological linguistics, pp. 432– 444, 1982. [2] S. Sitaram et al., “A survey of code-switched speech and language processing,” ArXiv preprint, vol. abs/1904.00784, 2019. [3] K. Taneja et al., “Exploiting monolingual speech corpora for codemixed speech recognition,” in Proc. Interspeech, G. Kubin and Z. Kacic, Eds., 2019, pp. 2150–2154. [4] G. Liu and L. Cao, “Code-switch speech rescoring with monolingual data,” in Proc. ICASSP, 2021, pp. 6229–6233. [5] S. Chuang, T. Sung, and H. Lee, “Training code-switching language model with monolingual data,” in Proc. ICASSP, 2020, pp. 7949– 7953. [6] S. Shah et al., “Learning to recognize code-switched speech without forgetting monolingual speech recognition,” ArXiv preprint, vol. abs/2006.00782, 2020. [7] S. A. Chowdhury et al., “Towards one model to rule all: Multilingual strategy for dialectal code-switching arabic ASR,” in Proc. Interspeech, H. Hermansky et al., Eds., 2021, pp. 2466–2470. [8] A. Ali et al., “Arabic code-switching speech recognition using monolingual data,” in Proc. Interspeech, H. Hermansky et al., Eds., 2021, pp. 3475–3479. [9] X. Zhou et al., “Multi-encoder-decoder transformer for code-switching speech recognition,” ArXiv preprint, vol. abs/2006.10414, 2020. [10] B. Yan et al., “Joint modeling of code-switched and monolingual asr via conditional factorization,” in Proc. ICASSP, 2022, pp. 6412–6416. [11] B. Yan et al., “Towards zero-shot code-switched speech recognition,” in Proc. ICASSP, 2023, pp. 1–5. [12] A. Hussein et al., “Balanced end-to-end monolingual pre-training for low-resourced indic languages code-switching speech recognition,” arXiv e-prints, arXiv–2106, 2021. [13] A. Hussein et al., “Textual data augmentation for arabic-english codeswitching speech recognition,” in Proc. SLT, 2023, pp. 777–784. [14] H. Seki et al., “An end-to-end language-tracking speech recognizer for mixed-language speech,” in Proc. ICASSP, 2018, pp. 4919–4923. [15] S. Nakayama et al., “Japanese-english code-switching speech data construction,” in 2018 Oriental COCOSDA - International Conference on Speech Database and Assessments, 2018, pp. 67–71. [16] Y. Sharma et al., “Improving low resource code-switched ASR using augmented code-switched TTS,” in Proc. Interspeech, H. Meng, B. Xu, and T. F. Zheng, Eds., 2020, pp. 4771–4775. [17] S. Murthy, D. Sitaram, and S. Sitaram, “Effect of TTS generated audio on OOV detection and word error rate in ASR for low-resource languages,” in Proc. Interspeech, B. Yegnanarayana, Ed., 2018, pp. 1026–1030. [18] C. Peyser et al., “Improving performance of end-to-end ASR on numeric sequences,” in Proc. Interspeech, G. Kubin and Z. Kacic, Eds., 2019, pp. 2185–2189. [19] A. Rosenberg et al., “Speech recognition with augmented synthesized speech,” in ASRU, 2019. [20] G. Wang et al., “Improving speech recognition