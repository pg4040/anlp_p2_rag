Title: SEGMENT-LEVEL VECTORIZED BEAM SEARCH BASED ON PARTIALLY AUTOREGRESSIVE INFERENCE
Authors: Masao Someki, Nicholas Eng, Yosuke Higuchi, Shinji Watanabe
Section: 5.3.3. Segment-level Vectorized Beam Search
Sridhar, Kyu J. Han, and Shinji Watanabe, “E-Branchformer: Branchformer with enhanced merging for speech recognition,” in Proc. SLT, 2023, pp. 84–91. [7] Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, and Ilya Sutskever, “Robust speech recognition via large-scale weak supervision,” 2022. [8] Hirofumi Inaguma, Shun Kiyono, Kevin Duh, Shigeki Karita, Nelson Yalta, Tomoki Hayashi, and Shinji Watanabe, “ESPnetST: All-in-one speech translation toolkit,” in Proc. ACL, Online, 06 2020, pp. 302–311, Association for Computational Linguistics. [9] Jiatao Gu, James Bradbury, Caiming Xiong, Victor OK Li, and Richard Socher, “Non-autoregressive neural machine translation,” in Proc. ICML, 2018. [10] Yisheng Xiao, Lijun Wu, Junliang Guo, Juntao Li, Min Zhang, Tao Qin, and Tie-yan Liu, “A survey on non-autoregressive generation for neural machine translation and beyond,” IEEE Transactions on Pattern Analysis and Machine Intelligence, 2023. [11] Nanxin Chen, Shinji Watanabe, Jesús Villalba, Piotr Żelasko, and Najim Dehak, “Non-autoregressive transformer for speech recognition,” IEEE Signal Processing Letters, vol. 28, pp. 121– 125, 2021. [12] William Chan, Chitwan Saharia, Geoffrey Hinton, Mohammad Norouzi, and Navdeep Jaitly, “Imputer: Sequence modelling via imputation and dynamic programming,” in Proc. ICML, 2020, pp. 1403–1413. [13] Yosuke Higuchi, Shinji Watanabe, Nanxin Chen, Tetsuji Ogawa, and Tetsunori Kobayashi, “Mask CTC: NonAutoregressive End-to-End ASR with CTC and Mask Predict,” in Proc. Interspeech, 2020, pp. 3655–3659. [14] Ethan A Chi, Julian Salazar, and Katrin Kirchhoff, “AlignRefine: Non-autoregressive speech recognition via iterative realignment,” in Proc. NAACL-HLT, 2021, pp. 1920–1927. [15] Ilya Sutskever, Oriol Vinyals, and Quoc V Le, “Sequence to sequence learning with neural networks,” in Proc. NeurIPS, Z. Ghahramani, M. Welling, C. Cortes, N. Lawrence, and K.Q. Weinberger, Eds. 2014, vol. 27, Curran Associates, Inc. [16] William Chan, Navdeep Jaitly, Quoc Le, and Oriol Vinyals, “Listen, attend and spell: A neural network for large vocabulary conversational speech recognition,” in Proc. ICASSP, 2016, pp. 4960–4964. [17] Yosuke Higuchi, Nanxin Chen, Yuya Fujita, Hirofumi Inaguma, Tatsuya Komatsu, Jaesong Lee, Jumon Nozaki, Tianzi Wang, and Shinji Watanabe, “A comparative study on nonautoregressive modelings for speech-to-text generation,” in Proc. ASRU, 2021, pp. 47–54. [18] Yann LeCun, John Denker, and Sara Solla, “Optimal brain damage,” in Proc. NeurIPS, 01 1989, vol. 2, pp. 598–605. [19] Frankle Jonathan and Carbin Michael, “The lottery ticket hypothesis: Finding sparse, trainable neural networks,” in Proc. ICLR, 2019. [20] Cheng-I Jeff Lai, Yang Zhang, Alexander H Liu, Shiyu Chang, Yi-Lun Liao, Yung-Sung Chuang, Kaizhi Qian, Sameer Khurana, David Cox, and Jim Glass, “PARP: Prune, adjust and reprune for self-supervised speech recognition,” Proc. NeurIPS, vol. 34, pp. 21256–21272, 2021. [21] Geoffrey Hinton,