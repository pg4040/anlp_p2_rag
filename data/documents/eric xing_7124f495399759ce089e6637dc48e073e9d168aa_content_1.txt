Title: 3D Semantic Segmentation in the Wild: Learning Generalized Models for Adverse-Condition Point Clouds
Authors: Aoran Xiao, Jiaxing Huang, Weihao Xuan, Ruijie Ren, Kangcheng Liu, Dayan Guan, Abdulmotaleb El Saddik, Shijian Lu, Eric Xing
Section: A. Domain generalization
set of snow, and no bicycle and motorcyclist in the validation set of rain. This is reasonable as the LiDAR data of SemanticSTF is collected in European countries including Germany, Sweden, Denmark, and Finland where motorcycles are not widely used for the reason of environmental protection. In addition, people usually do not ride bicycles or motorcycles in adverse weather conditions. As a result, classes motor, motorcyclist, and bicyclist have extremely lower occurrence frequency, leading to an absence of these classes in the validation set of SemanticSTF under relevant weather conditions. Tables 7, 8, 9, and 10 present corresponding class-level IoU performance for each adverse weather in Table 3 of the submitted paper. A.3. Ablation study Data augmentation. We study how data augmentation techniques affect generalized semantic segmentation of point clouds (3DSS) and compare them with the proposed PointDR. As Table 11 shows, we report seven models over the benchmark “SemanticKITTI→SemanticSTF”: 1) The Baseline is a source-only model that is trained by using the training data of SemanticKITTI; 2) The drop-out, noise perturbation, flipping, and jittering are segmentation models with different augmentation techniques over input data; All is the model that combines of all these augmentation techniques; 3) Our proposed PointDR. We can see that implementing each of these augmentation techniques improves the generalization capability of the segmentation model clearly and consistently. However, the combination of them all did not yield the best segmentation performance, largely because the combination brings too many distortions to the input point clouds. On the contrary, the proposed PointDR achieves the best segmentation performance, indicating its superior ability to learn universal representations for all-weather 3DSS. Parameter analysis. We examine the parameter λcl in Eq. 2 in the paper that balances the cross entropy loss and the contrastive loss. As Table 12 shows, optimizing the proposed contrastive loss is able to improve segmentation performance consistently while different λcl produce quite different mIoUs. The best mIoU is obtained when λcl = 0.10. Table 13 below shows segmentation performance with different momentum values (m) used for updating the memory bank B. It performs reasonably well when m is 0.98 or 0.99, showing that a slowly progressing memory bank is beneficial. However, when m is too large (at 0.999), the memory bank updates too slowly to capture the latest and representative feature embeddings, which fails to serve as the class-wise proxy and ultimately leads to a clear segmentation performance drop.