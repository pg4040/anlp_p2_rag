Title: Effective Multi-Agent Deep Reinforcement Learning Control with Relative Entropy Regularization
Authors: Chenyang Miao, Yunduan Cui, Huiyun Li, Xinyu Wu
Section: V. CONCLUSIONS
This article proposed a novel MARL approach MACDPP to improve the learning capability and sample effectively in a wide range of control scenarios including multiple agents cooperative/competitive tasks and joint control of a single complicated system. It naturally alleviated the inherent inconsistency over multiple agents policy updates by integrating the relative entropy regularization to the AC structure and CTDE framework. MACDPP successfully extended FKDPP which has been successfully implemented in the real-world chemical plant by Yokogawa [32], [33] towards a modern approach that supports deep neural networks, AC structure and CTDE framework in order to fit a wider range of control scenarios. Through evaluation of different benchmark tasks, ranging from multi-agent cooperation/competition to Mujoco simulator and robot arm manipulation, our proposed method consistently demonstrated significant superiority in both learning capability and sample efficiency compared with related multi-agent and single-agent RL baselines. All these results indicated the potential of relative entropy regularized MARL in effectively learning complex systems divided into multiple agents with lower sampling costs and better control performance.