Title: JOINT MODELLING OF SPOKEN LANGUAGE UNDERSTANDING TASKS WITH INTEGRATED DIALOG HISTORY
Authors: Siddhant Arora, Hayato Futami, Emiru Tsunoo, Brian Yan, Shinji Watanabe
Section: 8. REFERENCES
[1] R. De Mori, F. Bechet, D. Hakkani-Tur, et al., “Spoken language understanding,” IEEE Signal Processing Magazine, vol. 25, no. 3, pp. 50–58, 2008. [2] J. F. Allen, D. K. Byron, M. Dzikovska, et al., “Toward conversational human-computer interaction,” AI magazine, vol. 22, no. 4, pp. 27–27, 2001. [3] B. Agrawal, M. Müller, M. Radfar, et al., “Tie your embeddings down: Cross-modal latent spaces for end-to-end spoken language understanding,” arXiv preprint arXiv:2011.09044, 2020. [4] S. Cha, W. Hou, H. Jung, et al., “Speak or chat with me: End-to-end spoken language understanding with flexible inputs,” arXiv, 2021. [5] A. Bhargava, A. Celikyilmaz, D. Hakkani-Tür, et al., “Easy contextual intent prediction and slot detection,” in Proc. ICASSP, 2013, pp. 8337–8341. [6] P. Xu and R. Sarikaya, “Contextual domain classification in spoken language understanding systems using recurrent neural network,” in Proc. ICASSP, 2014, pp. 136–140. [7] P. Colombo, E. Chapuis, M. Manica, et al., “Guiding attention in sequence-to-sequence models for dialogue act prediction,” in Proceedings of the AAAI Conference on Artificial Intelligence, vol. 34, 2020, pp. 7594–7601. [8] C. Bothe, C. Weber, S. Magg, et al., “A context-based approach for dialogue act recognition using simple recurrent neural networks,” arXiv preprint arXiv:1805.06280, 2018. [9] V. Raheja and J. Tetreault, “Dialogue act classification with contextaware self-attention,” arXiv preprint arXiv:1904.02594, 2019. [10] S. Kim, S. Dalmia, and F. Metze, “Gated embeddings in e2e speech recognition for conversational-context fusion,” in Proc. ACL, 2019, pp. 1131–1141. [11] ——, “Cross-Attention End-to-End ASR for Two-Party Conversations,” in Proc. Interspeech, 2019, pp. 4380–4384. [12] T. Hori, N. Moritz, C. Hori, et al., “Transformer-based long-context end-to-end speech recognition.,” in Proc. Interspeech, 2020, pp. 5011– 5015. [13] Y.-N. Chen, D. Hakkani-Tür, G. Tür, et al., “End-to-end memory networks with knowledge carryover for multi-turn spoken language understanding.,” in Proc. Interspeech, 2016, pp. 3245–3249. [14] C. Sankar, S. Subramanian, C. Pal, et al., “Do neural dialog systems use the conversation history effectively? an empirical study,” arXiv preprint arXiv:1906.01603, 2019. [15] A. Bapna, G. Tur, D. Hakkani-Tur, et al., “Sequential dialogue context modeling for spoken language understanding,” arXiv preprint arXiv:1705.03455, 2017. [16] V. Vukotić, C. Raymond, and G. Gravier, “A step beyond local observations with a dialog aware bidirectional gru network for spoken language understanding,” in Proc. Interspeech, 2016, pp. 3241–3244. [17] J. Ganhotra, S. Thomas, H.-K. J. Kuo, et al., “Integrating dialog history into end-to-end spoken language understanding systems,” arXiv preprint arXiv:2108.08405, 2021. [18] V. Sunder, S. Thomas, H.-K. J. Kuo, et al., “Towards end-to-end integration of dialog history for improved spoken language understanding,” in