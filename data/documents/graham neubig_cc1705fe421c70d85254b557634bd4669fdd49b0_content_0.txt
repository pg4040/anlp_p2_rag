Title: DataFinder: Scientific Dataset Recommendation from Natural Language Descriptions
Authors: Vijay Viswanathan, Luyu Gao, Tongshuang Wu, Pengfei Liu, Graham Neubig
Section: A Few-Shot Prompt for Generating Keyphrases and Queries
When constructing our training set, we use incontext few-shot learning with the 6.7B parameter version of Galactica (Taylor et al., 2022). We perform in-context few-shot learning with the following prompt: Given an abstract from an artificial intelligence paper: 1) Extract keyphrases regarding the task (e.g. image classification), data modality (e.g. images or speech), domain (e.g. biomedical or aerial), training style (unsupervised, semi-supervised, fully supervised, or reinforcement learning), text length (sentence-level or paragraph-level), language required (e.g. English) 2) Write a brief, single-sentence summary containing these relevant keyphrases. This summary must describe the task studied in the paper. Abstract: We study automatic question generation for sentences from text passages in reading comprehension. We introduce an attention-based sequence learning model for the task and investigate the effect of encoding sentence- vs. paragraph-level information. In contrast to all previous work, our model does not rely on hand-crafted rules or a sophisticated NLP pipeline; it is instead trainable end-to-end via sequence-to-sequence learning. Automatic evaluation results show that our system significantly outperforms the state-of-the-art rulebased system. In human evaluations, questions generated by our system are also rated as being more natural (i.e., grammaticality, fluency) and as more difficult to answer (in terms of syntactic and lexical divergence from the original text and reasoning needed to answer). Output: (Task | Modality | Domain | Training Style | Text Length | Language Required | Single-Sentence Summary) Task: question generation Modality: text Domain: N/A Training Style: fully supervised Text Length: paragraph-level Language Required: N/A Single-Sentence Summary: We propose an improved end-to-end system for automatic question generation. â€“ Abstract: We present a self-supervised approach to estimate flow in camera image and top-view grid map sequences using fully convolutional neural networks in the domain of automated driving. We extend existing approaches for self-supervised optical flow estimation by adding a regularizer expressing motion consistency assuming a static environment. However, as this assumption is violated for other moving traffic participants we also estimate a mask to scale this regularization. Adding a regularization towards motion consistency improves convergence and flow estimation accuracy. Furthermore, we scale the errors due to spatial flow inconsistency by a mask that we derive from the motion mask. This improves accuracy in regions where the flow drastically changes due to a better separation between static and dynamic environment. We apply our approach to optical flow estimation from camera image sequences, validate on odometry estimation and suggest a method to iteratively increase optical flow estimation accuracy using the generated motion masks. Finally, we provide quantitative and qualitative results based on the