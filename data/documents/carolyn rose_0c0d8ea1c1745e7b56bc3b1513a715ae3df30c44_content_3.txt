Title: Linguistic representations for fewer-shot relation extraction across domains
Authors: Sireesh Gururaja, Ritam Dutt, Tinglong Liao, Carolyn Ros√©
Section: 6 Results and Discussion
when the choice of source domain imposes a performance penalty. Interestingly, an intuitive notion of "domain distance" fails to explain when transfer will be helpful. EFGC and RISeC both come from the cooking domain, but though RISeC and MSCorpus negatively influence each other in transfer, MSCorpus and EFGC in the baseline case have very little difference from the transfer case. Transfer between the abstract categories of "cooking" dataset and "materials science" dataset is highly variable. Notably, we observe that the benefits we derive from transfer seem asymmetrical: even datasets that transfer well in one direction might not in the other direction. We see markedly better results transferring from EFGC to RISeC, for instance, than we see in the reverse direction, and we see a similar result (though less consistent) for transfer from EFGC to MSCorpus as compared to the reverse. What is the impact of linguistic structure on the performance of few-shot RE in-domain? When factoring in the effect of our graph-aware models, we see that they help models generalize, both in the few-shot in-domain setting, as well as the transfer setting. Where transfer itself causes the performance of the baseline model to degrade, however, we see that the addition of linguistic representations sometimes makes up for that gap almost entirely. In the case of the 10-shot MSCorpus to RISeC transfer, we see that the baseline transfer model performs an average 2.7 points worse than the baseline from-scratch model (48.5 vs. 45.3), but that the dependency models perform very similarly (51.5 vs. 51.6). In cases where the transfer pairs are well-matched, however, we see that while the baseline results remain similar, the benefit that the models derive from the linguistic representations is much more pronounced in the transfer setting. In the 10-shot transfer in both directions between EFGC and MSCorpus, as well as the EFCG to RISeC case, transfer models that incorporate dependencies and AMRs overperform their in-domain counterparts by between 3 and 7 points.