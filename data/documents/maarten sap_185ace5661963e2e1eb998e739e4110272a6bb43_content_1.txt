Title: COBRA Frames: Contextual Reasoning about Effects and Harms of Offensive Statements
Authors: Xuhui Zhou, Hao Zhu, Akhila Yerukola, Thomas Davidson, Jena D. Hwang, Swabha Swayamdipta, Maarten Sap
Section: 6 Conclusion & Discussion
minority speech (Bender et al., 2021; Bommasani et al., 2021). The pervasive issue of bias in offensive language detection and in LLMs more generally requires exercising extra caution. We deliberately generate multiple contexts for every statement as an indirect means of managing the biases. Nevertheless, it is a compelling direction for future research to investigate the nature of biases latent in distilled contexts for harmful speech and further investigate their potential impact. For example, it would be valuable to collect human-annotated data on COBRA to compare with the machine-generated data. However, we must also recognize that humans are not immune to biases (Sap et al., 2019b, 2022), and therefore, such investigations should be carefully designed. Limited Contextual Variables Although COBRACORPUS has rich contexts, capturing the full context of statements is challenging. Future work should explore incorporating more quantitative features (e.g., the number of followers of the speaker) to supplement contextual variables such as social role and power dynamics. In this work, we focus on the immediate context of a toxic statement. However, we recognize that the context of a toxic statement can be much longer. We have observed significant effects even in relatively brief contexts, indicating the potential for improved performance when more extended contexts are present. We believe that future research could explore the influence of richer contexts by including other modalities (e.g., images, videos, etc.). Limited Identity Descriptions Our work focused on distilling the most salient identity charac- teristics that could affect the implications of toxicity of statements. This often resulted in generic identity labels such as “a white person” or “A Black woman” being generated without social roles. This risks essentialism, i.e., the assumption that all members of a demographic group have inherent qualities and experiences, which can be harmful and perpetuate stereotypical thinking (Chen and Ratliff, 2018; Mandalaywala et al., 2018; Kurzwelly et al., 2020). Future work should explore incorporating more specific identity descriptions that circumvent the risk of essentializing groups. English Only We only look at a US-centric perspective in our investigation. Obviously, online hate and abuse is manifested in many languages (Arango Monnar et al., 2022), so we hope future work will adapt our frames to different languages and different cultures. Subjectivity in Offensiveness Not everyone agrees that things are offensive, or has the same interpretation of offensiveness (depending on their own background and beliefs; Sap et al., 2022). Our in-context prompts and qualification likely make both our machine-generated explanations and human annotations prescriptive (Röttger et al., 2021), in contrast to a more descriptive