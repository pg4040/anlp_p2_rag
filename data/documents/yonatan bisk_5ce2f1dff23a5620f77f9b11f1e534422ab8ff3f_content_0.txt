Title: Plan, Eliminate, and Track â€” Language Models are Good Teachers for Embodied Agents
Authors: Yue Wu, So Yeon Min, Yonatan Bisk, Ruslan Salakhutdinov, Amos Azaria, Yuanzhi Li, Tom M. Mitchell, Shrimai Prabhumoye
Section: 5. Conclusion, Limitations, and Future Work
In this work, we propose the Plan, Eliminate, and Track (PET) framework that uses pre-trained LLMs to assist an embodied agent in three steps. Our PET framework requires no fine-tuning and is designed to be compatible with any goal-conditional embodied agents. In our experiments, we combine PET with a novel Action Attention agent that handles the dynamic action space in AlfWorld. Our Action Attention agent greatly outperforms the BUTLER baseline. In addition, since the PET framework is not trained to fit the training set tasks, it demonstrates better generalization to unseen human goal specification tasks. Finally, our ablation studies show the Plan and Track modules together improve the performance of Eliminate module to achieve the best performance. Our results show that LLMs can be a good source of common sense and procedural knowledge for embodied agents, and multiple LLMs may be used in coordination with each other to further improve effectiveness. One of the major limitations of our current system design is that the Track module (progress tracker) does not re-visit finished sub-tasks. If for example, the agent is executing sub-tasks [picked up a pan, put the pan on countertop], and it picked up a pan but put it in the fridge (undo pickup action). Since the progress tracker does not take into consideration previous progress being undone, the system may break in this situation. Future work can focus on adding sub-task-level dynamic replanning to address this limitation or explore other ways in which LLMs can assist the learning of the policy (i.e., reading an instruction manual about the environment).