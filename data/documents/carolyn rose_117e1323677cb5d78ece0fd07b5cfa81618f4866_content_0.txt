Title: Using counterfactual contrast to improve compositional generalization for multi-step quantitative reasoning
Authors: Armineh Nourbakhsh, Sameena Shah, Carolyn Rosé
Section: A For every submission:
3 A1. Did you describe the limitations of your work? 8 3 A2. Did you discuss any potential risks of your work? 6.3, 6.4, 8 3 A3. Do the abstract and introduction summarize the paper’s main claims? 1 7 A4. Have you used AI writing assistants when working on this paper? Left blank. B 3 Did you use or create scientific artifacts? 5.1, 5.2 3 B1. Did you cite the creators of artifacts you used? 5.1, 5.2 3 B2. Did you discuss the license or terms for use and / or distribution of any artifacts? 5.1, 5.2 3 B3. Did you discuss if your use of existing artifact(s) was consistent with their intended use, provided that it was specified? For the artifacts you create, do you specify intended use and whether that is compatible with the original access conditions (in particular, derivatives of data accessed for research purposes should not be used outside of research contexts)? 5.1, 5.2 7 B4. Did you discuss the steps taken to check whether the data that was collected / used contains any information that names or uniquely identifies individual people or offensive content, and the steps taken to protect / anonymize it? The data is based on publicly available corporate reports. 3 B5. Did you provide documentation of the artifacts, e.g., coverage of domains, languages, and linguistic phenomena, demographic groups represented, etc.? 5.1, 5.2 3 B6. Did you report relevant statistics like the number of examples, details of train / test / dev splits, etc. for the data that you used / created? Even for commonly-used benchmark datasets, include the number of examples in train / validation / test splits, as these provide necessary context for a reader to understand experimental results. For example, small differences in accuracy on large test sets may be significant, while on small test sets they may not be. 1 C 3 Did you run computational experiments? 5 3 C1. Did you report the number of parameters in the models used, the total computational budget (e.g., GPU hours), and computing infrastructure used? 5 The Responsible NLP Checklist used at ACL 2023 is adopted from NAACL 2022, with the addition of a question on AI writing assistance. 3 C2. Did you discuss the experimental setup, including hyperparameter search and best-found hyperparameter values? 5 3 C3. Did you report descriptive statistics about your results (e.g., error bars around results, summary statistics from sets of experiments), and is it transparent whether you are reporting the max, mean, etc. or just a single