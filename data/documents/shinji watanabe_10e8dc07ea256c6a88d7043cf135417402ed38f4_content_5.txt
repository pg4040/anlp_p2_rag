Title: Prompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot Task Generalization
Authors: Puyuan Peng, Brian Yan, Shinji Watanabe, David Harwath
Section: 2. The Whisper model
this section, we investigate Whisper’s ability to perform En→X speech translation (ST). Note that Whisper is trained on both multilingual ASR and X→En speech translation (ST), but never on En→X ST. Studying Whisper’s zero-shot performance on En→X ST could be a way to measure the speech understanding capabilities that emerge from large scale, multilingual, multitask training. we emphasize that the goal of this section is not to achieve SotA performance, but to study the model’s emergent, zero-shot translation ability across different language families, amounts of training data, and model sizes. Approach. The default prompt for ST is to use <|st|> as the task token. However, we found that <|st|> would lead Whisper to only output English no matter what language token is used, unless we constrained the output vocabulary. To instruct Whisper to do En→X ST, we propose to use task token <|asr|> instead, and use language token correspond to the language X. See table 1 for a example of the default and our proposed approach. Counter-intuitive as it might be (using <|asr|> for ST), as we’ll show later, our prompt outperforms the default prompt significantly, and even comes close to supervised approaches for some languages. Datasets and implementation details. We pick Arabic, Mandarin, Catalan and German in CoVoST2 [29], to achieve a resource- and topology-wise diverse evaluation. To be able to compare with supervised, unsupervised, and other zero-shot ST approaches [30], we also evaluate Whisper on En→Ru and En→De from MuST-C V1 [31], and En→Fr from LibriTrans [32]. As for vocabulary constrain, for Arabic, Mandarin, and Russian, we use the unicode range to constrain the vocab to only contain tokens that belong to their scripts; for German, Catalan, and French we constrain the vocab to only contain tokens that are the top K% most frequent in their training set text. K is tuned for CoVoST2 on the development set. For MuST-C and Libri-Trans, we set K to be 40% for German and 50% for French based on CoVoST2 tuning results. Results. In Figure 3, we show different Whisper models’ performance on the four CoVoST2 languages. In general, for our proposed prompt, bigger models perform better across languages, and vocabulary constrained generation outperforms unconstrained generation. As for the default prompt (green bars), we didn’t show its performance for unconstrained generation as it only output English text, and for constrained generation, it also performs vert poorly except for Mandarin. We compare Whisper’s performance with other models in table 55. Whisper performs reasonably on all three directions, and especially well on En→Ru.