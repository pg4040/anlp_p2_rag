Title: Multi-Objective Improvement of Android Applications
Authors: James, Callan, Justyna Petke
Section: 1 Introduction
parameter optimization. To the best of our knowledge, no GI work so far has attempted to improve and find trade-offs between multiple properties of Android apps, and no approach has attempted to improve either the memory consumption or bandwidth usage of Android apps, which we target in this work. Previous work on applying GI in the Android domain revealed several practical challenges: 1) due to the complexity of the Android build system and significant use of UI elements, a minor change usually requires a time-costly process of installation on the actual device for testing 2) tests themselves are scarce, and 3) performance fitness measurements used in the desktop domain are not accurate enough to witness performance issues in Android apps, yet users deem wait time of just 150ms as ‘laggy’ (Tolia et al (2006)). We overcome these challenges. We utilise the Robolectric testing library (Robolectric Develop. Team (2023)) which mimics UI behaviour, allowing for quick unit testing, without need for installation on an actual mobile or tablet device. This simulation-based approach provides us with means of utilising performance measurement tools unavailable on Android devices. In order to validate our proposed approach, we created a tool, GIDroid (2023), for running multi-objective (MO) GI on Android applications. We provide three fitness functions, to improve runtime, memory, and bandwidth use. GIDroid contains three MO algorithms (NSGA-II (Deb et al (2000)), NSGA-III (Deb and Jain (2014)), and SPEA2 (Kim et al (2004))). Based on work by Callan et al (2022), who mined nonfunctional improvements made by Android developers, we implement in GIDroid two novel mutation operators, specifically designed to mimic human-made edits. These cache results of repeated calls, aiming to save memory use. When using GI, we validate the patches that we generate using the program’s test suite and validate the best-improving final patches manually. This ensures that our patches do not disrupt the functionality of the program. However, most open-source Android applications do not have test suites, and those that do are limited, achieving a median line coverage of 23% (Pecorelli et al (2020)). This meant that we had to create tests for all the benchmarks on which we ran GI.1 We selected Android apps that contain real-world non-functional-propertyimproving commits, in order to see if GIDroid can re-discover changes made by Android developers. Moreover, we use the latest versions of these applications, to see if we can find as-yet-undiscovered improvements. Overall, we created a benchmark of 21 versions of 7 Android apps, which we open source for future work. GIDroid was able to