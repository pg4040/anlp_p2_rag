Title: Provable Robust Watermarking for AI-Generated Text
Authors: Xuandong Zhao, Prabhanjan Ananth, Lei Li, Yu-Xiang Wang
Section: C.2 Robustness / Security guarantees
= 1, ..., n. For a high-probability result, we also need a stronger version. Assumption C.9 (On-average-high-entropy (high probability)). We say that a language model’s probability distribution p with a prompt x satisfies (ξ, β)-on-average-high-entropy if with probability at least 1− β over the generated sequence y1:n, 1 n max {∥∥∥∥∥ n∑ t=1 pt ∥∥∥∥∥ , n∑ t=1 ∥pt∥2 , ∥∥∥∥∥ n∑ t=1 pt ∥∥∥∥∥ ∞ , n∑ t=1 ∥pt∥2∞ } ≤ ξ. The behavior is similar to that of the expectation version of the assumption. When pt is nearly uniform, pt[i] = O(1/N), then ξ = O(1/ √ N). When pt is supported only on one token, then ξ = 1. In practice, ξ is a small constant. As we will present in the main theorem, as long as ξ ≍ δ, the number of green list tokens is guaranteed to grow faster γn as n gets larger. One may also ask whether it is necessary to make entropy assumptions on the conditional probabilities instead of the marginal probabilities induced by p or p̂, but this is unfortunately not sufficient as illustrated in the following example. Example C.10 (Marginal high entropy is insufficient). Let the prompt x be “Generate the first token uniformly at random, then repeat the token you generated for the remaining n− 1 tokens”. In this case, a good language model that follows the instruction will have Pp(yt = i) = 1/N for all i and all t = 1, ..., n marginally, which implies that the entropy is the maximum and for any green list G, Pp(yt ∈ G) = γ. On the other hand, with probability γ, |y|G = n and with probability 1 − γ, |y|G = 0. There isn’t any concentration around γn possible. Moreover, check that if we apply watermark, then Pp̂(yt ∈ G) = γe δ γeδ+(1−γ) for all t and all G. This changes the probability of seeing |y|G = n slightly but the two world remains indistinguishable.