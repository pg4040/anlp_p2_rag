Title: Practical Probabilistic Model-based Deep Reinforcement Learning by Integrating Dropout Uncertainty and Trajectory Sampling
Authors: Wenjun Huang, Yunduan Cui, Huiyun Li, Xinyu Wu
Section: V. CONCLUSION
In this paper, DPETS, a novel probabilistic MBRL approach based on neural networks was proposed to tackle the issues of prediction stability, prediction accuracy and policy quality in probabilistic MBRL. DPETS stably predicted the system uncertainty by introducing a restrictive MC Dropout that naturally combined dropout and trajectory sampling. A loss function with fitting error correction was proposed to reduce the approximation error of neural networks while improving its accuracy in long-term prediction. An uncertain state propagation that filters aleatoric uncertainty was further developed to enhance the control capability of MPC-based policy. Validated by six benchmark tasks under additional disturbances and one practical robot arm control task, DPETS not only outperformed the related MBRL approaches in average returns and convergence velocity but also achieved superior control performance compared with well-known model-free RL methods with significant sample efficiency. These results indicated the potential of DPETS as a stable and sample-efficient MBRL approach to solve control problems under complicated disturbances from a probabilistic perspective.