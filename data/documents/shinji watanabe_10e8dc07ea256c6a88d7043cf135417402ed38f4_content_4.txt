Title: Prompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot Task Generalization
Authors: Puyuan Peng, Brian Yan, Shinji Watanabe, David Harwath
Section: 2. The Whisper model
of two language tokens in prompt, and 2. the threshold on Whisper’s LID confidence score, above which we use the single detected language’s token instead of concatenating two language tokens. Whisper Large with concat (<|zh|> first) outperforms all other models and prompts combinations on both datasets, and a threshold of 0.9 works the best for ASCEND, and 1.0 i.e. always concatenating two language tokens, works the best for SEAME. Results. Table 3 shows the performance of Whisper Large on the validation set of ASCEND and SEAME. In addition to default and our proposed concat prompts, we also show results when we fixed the language token to be <|zh|> or <|en|> for analysis purposes. We see that the concat method performs the best on both datasets, and in particular it provides 19% relative improvement on Total MER (mixed error rate) on SEAME compared to default. Secondly, with prompt <|zh|>, Whisper performs much better on pure Mandarin utterances on ASCEND (16.3) than SEAME (26.3). Similar results are observed for pure English utterances. This indicates 4We set the probabilities of the languages other than the two to be 0. that Whisper’s monolingual ASR performance is much worse on SEAME than on ASCEND. Next we note that on SEAME, when we use default instead of <|en|>, En WER increased from 33.8 to 85.5, while on ASCEND, WER was 31.8 in both cases. This indicates that i.e. Whisper’s LID performance for detecting English is much worse on SEAME than on ASCEND. To understand how do different language prompts steer Whisper’s output. We manually examined the error modes, and found a common scenario where the model outputs monolingual translation for code-switched utterances. This is especially interesting when Whisper does English to Mandarin translation, as the model was only trained to perform X→En translation. This phenomenon inspired us to quantitatively study En→X translation capabilities of Whisper in section 5. The test set results for CS-ASR are shown in table 4. We see that with concat, Whisper achieves a new SotA for ASCEND, while on SEAME there is still an considerable gap between zero-shot Whisper and SotA. Remarks. Recall that ASCEND is Chinese accented, and SEAME is Singaporean and Malaysian accented, and based on our discussion on table 3, we hypothesize that the performance gap on ASCEND and SEAME is because Whisper’s LID and ASR performance vary drastically on different accents, even though the underlying languages are the same. We leave a more comprehensive investigation of this hypothesis for future work. 5. En to X speech translation In