Title: Understanding the Effect of Model Compression on Social Bias in Large Language Models
Authors: Gustavo Gonçalves, Emma Strubell
Section: A Details of Metric Calculation
A.1 SEAT The SEAT task shares the same task as WEAT task, which is defined by four word sets, two attribute sets, and two target sets. For example, to decide the presence of gender bias the two attribute sets are disjoint sets given by: 1) a masculine set of words, such as {’man’, ’boy’, ’he’, ...}, and 2) a set of feminine words {’woman’, ’girl’, ’her’, ...}. The target sets will characterize concepts such as ’sports’ and ’culinary’. WEAT evaluates how close are the attribute sets from the target sets to determine the existence of bias. Mathematically this is given by: s(A,B,X, Y ) = ∑ x∈X s(x,A,B)− ∑ y∈Y s(y,A,B) (1) Where A and B represent the attribute sets, and X and Y are the target sets of words. The s function in Equation (1) denotes mean cosine similarity between the target word embeddings and the attribute word embeddings: s(w,A,B)= 1 |A| ∑ a∈A cos(w, a)− 1|B| ∑ b∈B cos(w, b). (2) The reported score of the benchmark (effect size) is given by: d = µ({s(x,A,B)}x∈X)− µ({s(y,A,B)}y∈Y ) σ({s(t,X, Y )}t∈A∪B) (3) Where µ and σ are the mean and standard deviation respectively. Equation (3) is designed so that scores closer to zero indicate the smallest possible degree of bias. SEAT extends the previous formulation by considering the distance sentence embeddings instead of word embeddings. B Additional Plots and Tables Table 5: LM Scores vs. Biases on the SS dataset of the int8 models, at the same steps with the best LM Score for the original (full-precision) models (Table 2) Table 6: LM Scores vs. Biases on the SS dataset of the original (full-precision) models, at the same steps with the best LM Score for the int8 models (Table 3)