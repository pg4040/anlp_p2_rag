Title: Completing Visual Objects via Bridging Generation and Segmentation
Authors: Xiang Li, Yinpeng Chen, Chung-Ching Lin, Hao Chen, Kai Hu, Rita Singh, Bhiksha Raj, Lijuan Wang, Zicheng Liu
Section: B. More Discussion
the generated background object can result from the learned inter-object correlation from the frozen Stable Diffusion model (Rombach et al., 2022). As the generated background object typically will not be segmented in the segmentation stage, it will not influence the performance of MaskComp. C. More Experiments Failure case analysis. We present a failure case in Fig. 14, where MaskComp exhibits a misunderstanding of the pose of a person bending over, resulting in the generation of a hat at the waist. We attribute this generation of an unrealistic image to the uncommon pose of the partial human. Given that the majority of individuals in the AHP training set have their heads up and feet down, MaskComp may have a tendency to generate images in this typical position. We consider that with a more diverse dataset, including images of individuals in unusual poses, MaskComp could potentially yield superior results in handling similar cases. Impact of segmentation errors in intermediate stages. Despite the robust capabilities of the CompNet and SAM models, they can still generate low-quality images and inaccurate segmentation results. In Fig. 15, we show a case where the intermediate stage of IMD produces a human with an extra right arm. To address this, we implement three key strategies: (1) Error Mitigation during Segmentation with SAM: As shown in Fig. 15, SAM effectively filters out incorrectly predicted components, such as a misidentified right arm, resulting in a more coherent shape for subsequent iterations. SAMâ€™s robust instance understanding capability extends to not only accurately segmenting objects with regular shapes but also filtering out irrelevant parts when additional objects/parts are generated. (2) Error Suppression through Mask Voting: In cases where only a few generated images exhibit errors, the impact of these errors can be mitigated through mask voting. The generated images are converted to masks, and if only a minority displays errors, their influence is diminished through the voting operation. (3) Error Tolerance in IMD Iteration: We train the CompNet to handle a wide range of occluded masks. Consequently, if the conditioned mask undergoes minimal improvement or degradation due to the noises in a given iteration, it can still be improved in the subsequent iteration. While this may slightly extend the convergence time, it is not anticipated to have a significant impact on the ultimate image quality. More implementation details. We leverage two types of occlusion strategies during the training of CompNet. First, we randomly sample a point on the object region, and then randomly occlude a rectangle area with the sampled point as