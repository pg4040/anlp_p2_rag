Title: Prompting the Hidden Talent of Web-Scale Speech Models for Zero-Shot Task Generalization
Authors: Puyuan Peng, Brian Yan, Shinji Watanabe, David Harwath
Section: 6. Conclusion
representation learning,” IEEE Access, 2019. [24] G. I. Winata, A. F. Aji, Z.-X. Yong, and T. Solorio, “The decades progress on code-switching research in nlp: A systematic survey on trends and challenges,” ArXiv preprint, 2022. [25] H. Lovenia, S. Cahyawijaya, G. Winata, P. Xu, Y. Xu, Z. Liu, R. Frieske, T. Yu, W. Dai, E. J. Barezi, Q. Chen, X. Ma, B. Shi, and P. Fung, “ASCEND: A spontaneous Chinese-English dataset for code-switching in multi-turn conversation,” in LREC, 2022. [26] D.-C. Lyu, T. P. Tan, C. E. Siong, and H. Li, “Seame: a mandarinenglish code-switching speech corpus in south-east asia,” in Interspeech, 2010. [27] T. Nguyen, N. Tran, L. Deng, T. G. da Silva, M. Radzihovsky, R. Hsiao, H. Mason, S. Braun, E. McDermott, D. Can, P. Swietojanski, L. Verwimp, S. Oyman, T. Arvizo, H. Silovsky, A. Ghoshal, M. J. Martel, B. R. Ambati, and M. Ali, “Optimizing bilingual neural transducer with synthetic code-switching text generation,” ArXiv, 2022. [28] S. Watanabe, T. Hori, S. Karita, T. Hayashi, J. Nishitoba, Y. Unno, N. E. Y. Soplin, J. Heymann, M. Wiesner, N. Chen, A. Renduchintala, and T. Ochiai, “Espnet: End-to-end speech processing toolkit,” in Interspeech, 2018. [29] C. Wang, A. Wu, and J. Pino, “Covost 2: A massively multilingual speech-to-text translation corpus,” 2020. [30] C. Wang, H. Inaguma, P.-J. Chen, I. Kulikov, Y. Tang, W.-N. Hsu, M. Auli, and J. M. Pino, “Simple and effective unsupervised speech translation,” ArXiv, 2022. [31] M. A. Di Gangi, R. Cattoni, L. Bentivogli, M. Negri, and M. Turchi, “MuST-C: a Multilingual Speech Translation Corpus,” in NAACLHLT, 2019. [32] A. C. Kocabiyikoglu, L. Besacier, and O. Kraif, “Augmenting librispeech with French translations: A multimodal corpus for direct speech translation evaluation,” in LREC, 2018. [33] C. Escolano, M. R. Costa-jussà, J. A. R. Fonollosa, and C. Segura, “Enabling zero-shot multilingual spoken language translation with language-specific encoders and decoders,” ASRU, 2020. [34] P.-A. Duquenne, H. Gong, B. Sagot, and H. Schwenk, “T-modules: Translation modules for zero-shot cross-modal machine translation,” in EMNLP, 2022. [35] C. Wang, Y. Tang, X. Ma, A. Wu, D. Okhonko, and J. Pino, “Fairseq S2T: Fast speech-to-text modeling with fairseq,” in AACL: System Demonstrations, 2020. [36] Y. Chung, W. Weng, S. Tong, and J. R. Glass, “Towards unsupervised speech-to-text translation,” in ICASSP, 2019.