Title: TORCHAUDIO 2.1: ADVANCING SPEECH RECOGNITION, SELF-SUPERVISED LEARNING, AND AUDIO PROCESSING COMPONENTS FOR PYTORCH
Authors: Jeff Hwang, Moto Hira, Caroline Chen, Xiaohui Zhang, Zhaoheng Ni, Guangzhi Sun, Pingchuan Ma, Ruizhe Huang, Vineel Pratap, Yuekai Zhang, Anurag Kumar, Chin-Yun Yu, Chuang Zhu, Chunxi Liu, Jacob Kahn, Mirco Ravanelli, Peng Sun, Shinji Watanabe, Yangyang Shi, Yumeng Tao, Robin Scheibler, Samuele Cornell, Sean Kim, Stavros Petridis
Section: 8. REFERENCES
Ott, Sergey Edunov, Alexei Baevski, Angela Fan, Sam Gross, et al., “fairseq: A fast, extensible toolkit for sequence modeling,” in North American Chapter of the Association for Computational Linguistics, 2019, pp. 48–53. [17] Oleksii Kuchaiev, Jason Li, Huyen Nguyen, Oleksii Hrinchuk, Ryan Leary, et al., “Nemo: a toolkit for building ai applications using neural modules,” arXiv preprint arXiv:1909.09577, 2019. [18] Shu-wen Yang, Po-Han Chi, Yung-Sung Chuang, Cheng-I Jeff Lai, Kushal Lakhotia, et al., “Superb: Speech processing universal performance benchmark,” arXiv preprint arXiv:2105.01051, 2021. [19] William Chen, Xuankai Chang, Yifan Peng, Zhaoheng Ni, Soumi Maiti, et al., “Reducing barriers to self-supervised learning: Hubert pre-training with academic compute,” arXiv preprint arXiv:2306.06672, 2023. [20] Jacob D Kahn, Vineel Pratap, Tatiana Likhomanenko, Qiantong Xu, Awni Hannun, et al., “Flashlight: Enabling innovation in tools for machine learning,” in ICML. PMLR, 2022, pp. 10557–10574. [21] Kenneth Heafield, “Kenlm: Faster and smaller language model queries,” in Proceedings of the Sixth Workshop on Statistical Machine Translation, USA, 2011, WMT ’11, p. 187–197, Association for Computational Linguistics. [22] Pengcheng Guo, Florian Boyer, Xuankai Chang, Tomoki Hayashi, Yosuke Higuchi, et al., “Recent developments on espnet toolkit boosted by conformer,” in ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2021, pp. 5874–5878. [23] Dmitriy Serdyuk, Otavio Braga, and Olivier Siohan, “Transformerbased video front-ends for audio-visual speech recognition for single and multi-person video,” in Interspeech, 2022, pp. 2833–2837. [24] Bowen Shi, Wei-Ning Hsu, Kushal Lakhotia, and Abdelrahman Mohamed, “Learning audio-visual speech representation by masked multimodal cluster prediction,” in ICLR, 2022. [25] Pingchuan Ma, Alexandros Haliassos, Adriana Fernandez-Lopez, Honglie Chen, Stavros Petridis, et al., “Auto-avsr: Audio-visual speech recognition with automatic labels,” in ICASSP, 2023, pp. 1–5. [26] Pingchuan Ma, Niko Moritz, Stavros Petridis, Christian Fuegen, and Maja Pantic, “Streaming audio-visual speech recognition with alignment regularization,” in Interspeech, 2023. [27] Ludwig Kürzinger, Dominik Winkelbauer, Lujun Li, Tobias Watzel, and Gerhard Rigoll, “Ctc-segmentation of large corpora for german end-to-end speech recognition,” in International Conference on Speech and Computer. Springer, 2020, pp. 267–278. [28] Vineel Pratap, Awni Hannun, Qiantong Xu, Jeff Cai, Jacob Kahn, et al., “Wav2letter++: A fast open-source speech recognition system,” in ICASSP. IEEE, 2019, pp. 6460–6464. [29] Vineel Pratap, Andros Tjandra, Bowen Shi, Paden Tomasello, Arun Babu, et al., “Scaling speech technology to 1,000+ languages,” 2023. [30] Reinhold Haeb-Umbach, Shinji Watanabe, Tomohiro Nakatani, Michiel Bacchiani, Bjorn Hoffmeister, et al., “Speech processing for digital home assistants: Combining signal processing with deep-learning techniques,” IEEE Signal processing magazine, vol. 36, no. 6, pp. 111–124, 2019. [31] Shoko Araki, Masahiro Okada, Takuya