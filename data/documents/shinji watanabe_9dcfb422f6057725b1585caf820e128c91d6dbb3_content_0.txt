Title: IMPROVING MASSIVELY MULTILINGUAL ASR WITH AUXILIARY CTC OBJECTIVES
Authors: William Chen, Brian Yan, Jiatong Shi, Yifan Peng, Soumi Maiti, Shinji Watanabe
Section: 8. REFERENCES
[1] S. Watanabe, T. Hori, and J. R. Hershey, “Language independent end-to-end architecture for joint language identification and speech recognition,” in Proc. ASRU, 2017, pp. 265–271. [2] A. Bapna, C. Cherry, Y. Zhang, et al., “mSLAM: Massively multilingual joint pre-training for speech and text,” arXiv preprint arXiv:2202.01374, 2022. [3] Y. Lu, M. Huang, X. Qu, et al., “Language adaptive cross-lingual speech representation learning with sparse sharing sub-networks,” in Proc. ICASSP, 2022, pp. 6882–6886. [4] X. Li, F. Metze, D. R. Mortensen, et al., “ASR2K: Speech Recognition for Around 2000 Languages without Audio,” in Proc. Interspeech, 2022, pp. 4885– 4889. [5] P. Ogayo, G. Neubig, and A. W Black, “Building African Voices,” in Proc. Interspeech, 2022, pp. 1263–1267. [6] C. Zhang, B. Li, T. Sainath, et al., “Streaming end-to-end multilingual speech recognition with joint language identification,” Proc. Interspeech, 2022. [7] J. Bai, B. Li, Y. Zhang, et al., “Joint unsupervised and supervised training for multilingual asr,” in Proc. ICASSP, 2022. [8] B. Li, R. Pang, Y. Zhang, et al., “Massively multilingual asr: A lifelong learning solution,” in Proc. ICASSP, 2022, pp. 6397–6401. [9] O. Adams, M. Wiesner, S. Watanabe, et al., “Massively multilingual adversarial speech recognition,” in Proc. NAACL-HLT, 2019, pp. 96–108. [10] V. Pratap, A. Sriram, P. Tomasello, et al., “Massively Multilingual ASR: 50 Languages, 1 Model, 1 Billion Parameters,” in Proc. Interspeech, 2020, pp. 4751– 4755. [11] W. Hou, Y. Dong, B. Zhuang, et al., “Large-Scale End-to-End Multilingual Speech Recognition and Language Identification with Multi-Task Learning,” in Proc. Interspeech, 2020, pp. 1037–1041. [12] X. Li, S. Dalmia, J. Li, et al., “Universal phone recognition with a multilingual allophone system,” in Proc. ICASSP, 2020, pp. 8249–8253. [13] A. Conneau, A. Baevski, R. Collobert, et al., “Unsupervised Cross-Lingual Representation Learning for Speech Recognition,” in Proc. Interspeech, 2021, pp. 2426–2430. [14] B. Li, R. Pang, T. N. Sainath, et al., “Scaling end-to-end models for large-scale multilingual asr,” in Proc. ASRU, 2021, pp. 1011–1018. [15] B. Yan, S. Dalmia, D. R. Mortensen, et al., “Differentiable allophone graphs for language-universal speech recognition,” in Proc. Interspeech, 2021. [16] L. Zhou, J. Li, E. Sun, et al., “A configurable multilingual model is all you need to recognize all languages,” in Proc. ICASSP, 2022, pp. 6422–6426. [17] M. J. F. Gales, K. M. Knill, A. Ragni, et al., “Speech recognition and keyword spotting for low-resource languages: Babel project research at CUED,” in Proc. 4th Workshop on Spoken Language Technologies for Under-Resourced Languages (SLTU 2014), 2014, pp. 16–23. [18] R. Ardila, M. Branson, K. Davis, et al., “Common