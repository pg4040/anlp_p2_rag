Title: EXPLORING THE INTEGRATION OF SPEECH SEPARATION AND RECOGNITION WITH SELF-SUPERVISED LEARNING REPRESENTATION
Authors: Yoshiki Masuyama, Xuankai Chang, Wangyou Zhang, Samuele Cornell, Zhong-Qiu Wang, Nobutaka Ono, Yanmin Qian, Shinji Watanabe
Section: 6. REFERENCES
Zhang et al., “End-to-end dereverberation, beamforming, and speech recognition in a cocktail party,” IEEE/ACM Trans. Audio, Speech, Lang. Process., vol. 30, pp. 3173– 3188, 2022. [41] C. Boeddeker and et al., “Convolutive transfer function invariant SDR training criteria for multi-channel reverberant speech separation,” in Proc. ICASSP, 2021, pp. 8428–8432. [42] Y. J. Lu and et al., “Towards low-distortion multi-channel speech enhancement: The ESPNET-SE submission to the L3DAS22 challenge,” in Proc. ICASSP, 2022, pp. 9201– 9205. [43] T. von Neumann and et al., “End-to-end training of time domain audio separation and recognition,” in Proc. ICASSP, 2020, pp. 7004–7008. [44] W. Zhang et al., “End-to-end far-field speech recognition with unified dereverberation and beamforming,” in Proc. Interspeech, 2020, pp. 324–328. [45] J. Zhang et al., “Time-domain speech extraction with spatial information and multi speaker conditioning mechanism,” in Proc. ICASSP, 2021, pp. 6084–6088.