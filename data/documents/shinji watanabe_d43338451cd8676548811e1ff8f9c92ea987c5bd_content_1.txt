Title: REPRODUCING WHISPER-STYLE TRAINING USING AN OPEN-SOURCE TOOLKIT AND PUBLICLY AVAILABLE DATA
Authors: Yifan Peng, Jinchuan Tian, Brian Yan, Dan Berrebbi, Xuankai Chang, Xinjian Li, Jiatong Shi, Siddhant Arora, William Chen, Roshan Sharma, Wangyou Zhang, Yui Sudo, Muhammad Shakeel, Jee-weon Jung, Soumi Maiti, Shinji Watanabe
Section: 7. REFERENCES
An Evolving, MultiDomain ASR Corpus with 10,000 Hours of Transcribed Audio,” in Proc. Interspeech, 2021. [26] Vassil Panayotov et al., “Librispeech: An ASR corpus based on public domain audio books,” in ICASSP, 2015. [27] Roldano Cattoni et al., “Must-c: A multilingual corpus for end-to-end speech translation,” Computer speech & language, vol. 66, pp. 101155, 2021. [28] Patrick K O’Neill et al., “Spgispeech: 5,000 hours of transcribed financial audio for fully formatted end-to-end speech recognition,” arXiv:2104.02014, 2021. [29] François Hernandez et al., “Ted-lium 3: Twice as much data and corpus repartition for experiments on speaker adaptation,” in Speech & Computer, 2018, pp. 198–208. [30] Rong Ye et al., “Gigast: A 10,000-hour pseudo speech translation corpus,” arXiv:2204.03939, 2022. [31] Vineel Pratap et al., “Mls: A large-scale multilingual dataset for speech research,” arXiv:2012.03411, 2020. [32] Binbin Zhang et al., “Wenetspeech: A 10000+ hours multidomain mandarin corpus for speech recognition,” in Proc. ICASSP, 2022. [33] “aidatatang 200zh, a free Chinese Mandarin speech corpus by Beijing DataTang Technology Co., Ltd,” . [34] Jean Carletta, “Unleashing the killer corpus: experiences in creating the multi-everything AMI Meeting Corpus,” Lang. Res. Eval., vol. 41, pp. 181–190, 2007. [35] “The babel program: https://www.iarpa.gov/index.php/researchprograms/babel,” . [36] Rosana Ardila et al., “Common voice: A massivelymultilingual speech corpus,” arXiv:1912.06670, 2019. [37] J.J. Godfrey et al., “SWITCHBOARD: telephone speech corpus for research and development,” in Proc. ICASSP, 1992. [38] Matt Post et al., “Improved speech-to-text translation with the fisher and callhome Spanish-English speech translation corpus,” 2013. [39] Alexis Conneau et al., “FLEURS: Few-Shot Learning Evaluation of Universal Representations of Speech,” in Proc. SLT, 2022. [40] Jeong-Uk Bang et al., “Ksponspeech: Korean spontaneous speech corpus for automatic speech recognition,” Applied Sciences, vol. 10, no. 19, pp. 6936, 2020. [41] Zehui Yang et al., “Open source magicdata-ramc: A rich annotated mandarin conversational (ramc) speech dataset,” arXiv:2203.16844, 2022. [42] Yue Yin, Daijiro Mori, et al., “ReazonSpeech: A Free and Massive Corpus for Japanese ASR,” 2023. [43] Anna Slizhikova et al., “Russian Open Speech To Text (STT/ASR) Dataset,” 2020. [44] Junichi Yamagishi et al., “CSTR VCTK Corpus: English Multi-speaker Corpus for CSTR Voice Cloning Toolkit,” 2019. [45] “VoxForge: http://www.voxforge.org/,” . [46] Changhan Wang et al., “VoxPopuli: A Large-Scale Multilingual Speech Corpus for Representation Learning, SemiSupervised Learning and Interpretation,” in Proc. ACL, 2021. [47] Douglas B Paul and Janet Baker, “The design for the Wall Street Journal-based CSR corpus,” in Proc. Workshop on Speech and Natural Language, 1992. [48] Suyoun Kim, Takaaki Hori, and Shinji Watanabe, “Joint ctcattention based end-to-end speech recognition using multi-task learning,” in Proc. ICASSP,