Title: Multimodal Learning Without Labeled Multimodal Data: Guarantees and Applications
Authors: Paul Pu Liang, Chun Kai Ling, Yun Cheng, Alex Obolenskiy, Yudong Liu, Rohan Pandey, Alex Wilf, Louis-Philippe Morency, Ruslan Salakhutdinov
Section: B Experimental Details
0 ≤ 1 = S. Real-world datasets which fall into agreement synergy include UR-FUNNY where there is low disagreement in predicting humor α = 0.03, and relatively high synergy S = 0.18, which results in a loose lower bound Sdisagree = 0.01 ≤ 0.18 = S. 3. On upper bounds for synergy: We also run experiments to obtain estimated upper bounds on synthetic and MultiBench datasets. The quality of the upper bound shows some intriguing relationships with that of lower bounds. For distributions with perfect agreement synergy such as y = x1 XOR x2 (Table 2b), S = 1 ≥ 1 = S is really close to true synergy, Sagree = 1 ≤ 1 = S is also tight, but Sdisagree = 0 ≤ 1 = S is loose. For distributions with disagreement synergy (Table 2a), S = 0.52 ≥ 0.13 = S far exceeds actual synergy, Sagree = −0.3 ≤ 1 = S is much lower than actual synergy, but Sdisagree = 0.13 ≤ 0.16 = S is tight (see relationships in Figure 8). Finally, while some upper bounds (e.g., MUSTARD, MIMIC) are close to true S, some of the other examples in Table 1 show bounds that are quite weak. This could be because (i) there indeed exists high synergy distributions that match Di and DM , but these are rare in the real world, or (ii) our approximation used in Theorem 4 is mathematically loose. We leave these as open directions for future work.