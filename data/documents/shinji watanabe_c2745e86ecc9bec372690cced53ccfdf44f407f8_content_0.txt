Title: ENHANCING END-TO-END CONVERSATIONAL SPEECH TRANSLATION THROUGH TARGET LANGUAGE CONTEXT UTILIZATION
Authors: Amir Hussein, Brian Yan, Antonios Anastasopoulos, Shinji Watanabe, Sanjeev Khudanpur
Section: 7. REFERENCES
[1] O. Köksal and N. Yürük, “The role of translator in intercultural communication,” International Journal of Curriculum and Instruction, vol. 12, no. 1, pp. 327–338, 2020. [2] F. Stentiford and M. Steer, “Machine translation of speech,” in Speech and language processing, 1990, pp. 183–196. [3] E. Ansari et al., “FINDINGS OF THE IWSLT 2020 EVALUATION CAMPAIGN,” in Proceedings of the 17th International Conference on Spoken Language Translation, 2020, pp. 1–34. [4] A. Waibel et al., “Janus: A speech-to-speech translation system using connectionist and symbolic processing strategies,” in Acoustics, speech, and signal processing, IEEE international conference on, 1991, pp. 793–796. [5] N. Bertoldi and M. Federico, “A new decoder for spoken language translation based on confusion networks,” in Proc. ASRU, 2005, pp. 86– 91. [6] M. Sperber, J. Niehues, and A. Waibel, “Toward robust neural machine translation for noisy input sequences,” in Proceedings of the 14th International Conference on Spoken Language Translation, 2017, pp. 90–96. [7] J. Pino et al., “Harnessing indirect training data for end-to-end automatic speech translation: Tricks of the trade,” in Proceedings of the 16th International Conference on Spoken Language Translation, 2019. [8] J. Yang et al., “JHU IWSLT 2022 dialect speech translation system description,” in Proceedings of the 19th International Conference on Spoken Language Translation (IWSLT 2022), 2022, pp. 319–326. [9] A. Berard et al., “Listen and translate: A proof of concept for end-toend speech-to-text translation,” in Proceedings of the NIPS Workshop on end-to-end learning for speech and audio processing, 2016. [10] A. Berard et al., “End-to-end automatic speech translation of audiobooks,” in Proc. ICASSP, 2018, pp. 6224–6228. [11] S. Dalmia et al., “Searchable hidden intermediates for end-to-end models of decomposable sequence tasks,” in Proc. NAACL, 2021, pp. 1882–1896. [12] M. Gaido et al., “End-to-end speech-translation with knowledge distillation: FBK@IWSLT2020,” in Proceedings of the 17th International Conference on Spoken Language Translation, 2020, pp. 80–88. [13] B. Yan et al., “Espnet-st-v2: Multipurpose spoken language translation toolkit,” ArXiv preprint, vol. abs/2304.04596, 2023. [14] L. K. Guillou, “Incorporating pronoun function into statistical machine translation,” 2016. [15] A. Rios Gonzales, L. Mascarell, and R. Sennrich, “Improving word sense disambiguation in neural machine translation with sense embeddings,” in Proceedings of the Second Conference on Machine Translation, 2017, pp. 11–19. [16] E. Voita, R. Sennrich, and I. Titov, “When a good translation is wrong in context: Context-aware machine translation improves on deixis, ellipsis, and lexical cohesion,” in Proc. ACL, 2019, pp. 1198–1212. [17] L. Wang et al., “Exploiting cross-sentence context for neural machine translation,” in Proc. EMNLP, 2017, pp. 2826–2831. [18] L. Miculicich