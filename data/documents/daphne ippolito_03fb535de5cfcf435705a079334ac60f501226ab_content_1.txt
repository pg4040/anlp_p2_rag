Title: Reverse-Engineering Decoding Strategies Given Blackbox Access to a Language Generation System
Authors: Daphne Ippolito, Nicholas Carlini, Katherine Lee, Milad Nasr, Yun William Yu
Section: D Challenges
distribution to use for top-p estimation by keeping around a database of distributions from a bunch of different models, and then comparing the output distribution from the blackbox system to each distribution in the database. We can then choose to estimate p using the known distribution with the lowest relative entropy with the blackbox’s one. D.1 Chosen Prompt Details Here we describe the actual prompts used in our experiments. For the NOUNS and ADVERBS prompts, we assumed access to the GPT-2 vocabulary and used Spacy (en_core_web_sm) to identify all tokens in the vocabulary corresponding to nouns and adverbs. In all experiments with these prompts, we used 16 randomly selected exemplars from these lists. An example prompt for NOUNS is: “List of nouns chosen completely randomly: negativity diarrhea problems eloqu money aspect vertex fraternity stone breast skies pushes probabilities ink north creditor”. In our experiments estimating top-k, for each system being evaluated, we varied the random seed, resulting in a slightly different prompt. We did this to avoid any systematic biases resulting from always using the same choice of exemplars. For the non-exemplar-based prompts, we did not assume vocabulary access and instead relied on the expectation that letters, digits, and common words are present in most model vocabularies. As mentioned in the main paper, different prompts were needed to attack ChatGPT than for the experiments on open-source models because ChatGPT expects its inputs to be in a conversation format and it does not offer control over the number of words generated (without careful prompt design, it tends to return tens to hundreds of words). Table 5 gives the prompts used to attack ChatGPT.