Title: Abstractive summarization with deep reinforcement learning using semantic similarity rewards
Authors: Figen Beken Fikri, Kemal Oflazer, Berrin Yanıkoğlu, Figen Beken
Section: 6. Summary and conclusion
In this work, we focused on two main issues in abstractive summarization: how to evaluate the results and what is a good training objective. We presented semantic similarity-based summarization evaluation measures and a reinforcement learning framework with the semantic similarity rewards. We proposed evaluationmeasures using similarity scores obtained by fine-tuning the BERTurk model using cross-encoder and bi-encodermodel architectures onNLI-TR (Budur et al. 2020) and STSb-TR (Beken Fikri et al. 2021) datasets. We showed that the proposed evaluation measures have better correlations with human evaluations compared to ROUGE scores, according to both Pearson and Spearman correlations. We further showed that using bi-encoder and cross-encoder similarities as rewards improved the model results in terms of the proposed evaluation measures, as well as BERTScore and ROUGE scores. Our qualitative analyses demonstrated that the proposed models can generate summaries that are more similar to the ground truth, as compared to MLE-only models and RL models with ROUGE rewards. It is worth mentioning that our rewards are not model-dependent in our reinforcement learning framework and can be explored in other downstream sequence-to-sequence tasks like paraphrase generation, text simplification, and semantic search. Also, the suggested framework can be applied to other languages following the described methodology. Acknowledgments. None. Competing interests. The authors declare none.