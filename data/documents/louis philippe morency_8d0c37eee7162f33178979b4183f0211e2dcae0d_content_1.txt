Title: DIFFERENCE-MASKING: Choosing What to Mask in Continued Pretraining
Authors: Alex Wilf, Syeda Nahida Akter, Leena Mathur, Paul Pu Liang, Sheryl Mathew, Mengrou Shou, Eric Nyberg, Louis-Philippe Morency
Section: 5.2 What is masked?
specifically text or audio modalities. As such, we would expect that our continued pretraining strategy would choose to prioritize masking tokens representing human body language more often in Social-IQ than in TVQA. We found that this was in fact the case. Interestingly, we found that AttnMask baseline also picked up on a similar trend in its attempt to mask based on where attention already focuses, although the trend is much more pronounced in our approach. The findings in Table 2 demonstrate that DIFFERENCE-MASKING chooses to mask substantially fewer visual tokens corresponding to people than to objects in TVQA, (40%) in comparison to Social-IQ (90%). On the Social-IQ dataset, where the performance difference is more pronounced over the closest baseline (â†‘ 1.76% over AttnMask), the difference between the proportion of tokens masked from people by these approaches is also most pronounced (90% in DIFFERENCEMASKING vs 19% in AttnMask).