Title: The Troubling Emergence of Hallucination in Large Language Models â€“ An Extensive Definition, Quantification, and Prescriptive Remediations
Authors: Vipula Rawte, Swagata Chakraborty, Agnibh Pathak, Anubhav Sarkar, S.M Towhidul Islam Tonmoy, Aman Chadha, Amit Sheth, Amitava Das
Section: 
approaches is the inevitable future avenue (cf. Appendix F.3). 7 Conclusion and Future Avenues The enthusiasm and achievements surrounding LLMs have led to their widespread adoption, and this trend is only expected to flourish. However, one of the most significant challenges faced by LLMs today is hallucination. In light of this, benchmark and Hallucination Vulnerability Index (HVI) will continue to serve the wider scientific community and aid policy-makers. benchmark and HVI will be publicly open for further collaborative updates. Two proposed mitigation techniques can serve as baselines. 8 Discussion and Limitations Discussion: On June 14th, 2023, the European Parliament successfully passed its version of the EU AI Act (European-Parliament, 2023). Subsequently, a team of researchers from the Stanford Institute for Human-Centered Artificial Intelligence (HAI) embarked on investigating the extent to which Foundation Model Providers comply with the EU AI Act. Their initial findings are presented in the publication (Bommasani et al., 2023). In this study, the authors put forward a grading system consisting of 12 aspects for evaluating LLMs. These aspects include (i) data sources, (ii) data governance, (iii) copyrighted data, (iv) compute, (v) energy, (vi) capabilities & limitations, (vii) risk & mitigations, (viii) evaluation, (ix) testing, (x) machine-generated content, (xi) member states, and (xii) downstream documentation. The overall grading of each LLM can be observed in Fig. 8. While this study is commendable, it appears to be inherently incomplete due to the ever-evolving nature of LLMs. Since all scores are assigned manually, any future changes will require a reassessment of this rubric, while HVI is auto-computable. Furthermore, we propose that HVI should be considered the most suitable category for assessing risk and mitigations, as well as the evaluation of machine-generated content. Limitations: In this paper, we present a unique and extensive benchmark corpus for hallucination called . We propose two main types of hallucination: (i) Factual Mirage and (ii) Silver Lining, each further divided into intrinsic and extrinsic subcategories. Additionally, we introduce six detailed categories of hallucination along with a measure of its intensity. We believe the following aspects require critical attention in future endeavors. Limitation 1: For the sake of simplicity, we have only considered one category per sentence during annotation, although we acknowledge the presence of multi-class and multi-label instances. For instance, in the following example, there are two kinds of hallucination, namely Time Wrap and Numeric Nuisance present in the shown sentence. We would like to explore this direction in the immediate future. ALARMING Prompt: Engineering effort to build Eiffel tower AI-generated text: ...Designed by Gustave