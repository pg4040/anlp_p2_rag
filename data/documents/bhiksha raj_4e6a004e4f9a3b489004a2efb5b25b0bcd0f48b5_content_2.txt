Title: Understanding Political Polarisation using Language Models: A dataset and method
Authors: Samiran Gode, Supreeth Bare, Bhiksha Raj, Hyungon Yoo
Section: Related Work
Task. (Palakodety, KhudaBukhsh, and Carbonell 2020) demonstrates the ability of BERT and similar LM’s to track community perception, aggregate opinions and compare the popularity of political parties and candidates. This is demonstrative of our work as we intend to use BERT for the purpose of sentiment analysis. The authors conclude by stating that the LM can be used as a pipeline for extracting Data in the future. In (Hamilton, Leskovec, and Jurafsky 2016) the authors try to counter the problem of word meaning changing semantically with context. They propose a robust method by using embeddings. These are then evaluated with the ’Law of Conformity’ and ’The Law of Innovation’. These display the role of frequency and polysemy in the building structural blocks of language. These blocks will be crucial for 2 reasons, (1) The meaning changes may adversely affect sentiment analysis and thus affect results. Thus frequency and polysemy must be duly curtailed. (2) The embedding research is fundamental as we are using embedding-based models. Specifically Word2vec.