Title: Clever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in Large Language Models
Authors: Natalie Shapira, Mosh Levy, Seyed Hossein Alavi, Xuhui Zhou, Yejin Choi, Yoav Goldberg, Maarten Sap, Vered Shwartz
Section: 8.6 ToMi’ subsets analysis
Table 8 provides the complete results from the evaluation of GPT-3.5 on the ToMi’ dataset. The same overall conclusion can be drawn from this table as well: although the model can correctly answer simple reading comprehension questions, it doesn’t answer questions that require ToM skill (first and second order) with similar accuracy. We divided the results into the average score and joint score. The average score is calculated as a simple average on the different types of questions, while the joint score is considers the prediction as correct only if the model answered correctly all the questions from the same story (with a total of 30 stories). The average results emphasize the major gaps between the model’s accuracy on reading comprehension questions to first order questions (“Chloe will look for the boots in the”) and between the first order questions to the second order questions (“Chloe think that Jackson searches for the boots in the”). The joint score reveals that even when the model correctly answers questions about the story, it might still fail to answer more complex questions.