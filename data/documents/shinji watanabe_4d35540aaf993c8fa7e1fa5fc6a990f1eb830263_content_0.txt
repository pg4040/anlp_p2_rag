Title: A New Benchmark of Aphasia Speech Recognition and Detection Based on E-Branchformer and Multi-task Learning
Authors: Jiyang Tang, William Chen, Xuankai Chang, Shinji Watanabe, Brian MacWhinney
Section: 6. References
[1] M. Danly and B. Shapiro, “Speech prosody in broca’s aphasia,” Brain and Language, vol. 16, no. 2, pp. 171–190, 1982. [2] S. Ash et al., “Speech errors in progressive non-fluent aphasia,” en, Brain and Language, vol. 113, no. 1, pp. 13–20, 2010. [3] A. Baevski et al., “Wav2vec 2.0: A framework for selfsupervised learning of speech representations,” in Proc. NeurIPS, 2020. [4] G. Chatzoudis et al., “Zero-shot cross-lingual aphasia detection using automatic speech recognition,” in Proc. Interspeech, 2022. [5] I. G. Torre, M. Romero, and A. Álvarez, “Improving aphasic speech recognition by using novel semi-supervised learning methods on aphasiabank for english and spanish,” Applied Sciences, vol. 11, no. 19, 2021. [6] D. Le and E. Provost, “Improving automatic recognition of aphasic speech with aphasiabank,” in Proc. Interspeech, 2016, pp. 2681–2685. [7] M. Perez, Z. Aldeneh, and E. Provost, “Aphasic speech recognition using a mixture of speech intelligibility experts,” in Proc. Interspeech, 2020, pp. 4986–4990. [8] D. Le, K. Licata, and E. Provost, “Automatic quantitative analysis of spontaneous aphasic speech,” Speech Communication, vol. 100, pp. 1–12, 2018. [9] Y. Qin, T. Lee, and A. Kong, “Automatic assessment of speech impairment in cantonese-speaking people with aphasia,” IEEE Journal of Selected Topics in Signal Processing, vol. 14, no. 2, pp. 331–345, 2020. [10] Y. Qin et al., “An end-to-end approach to automatic speech assessment for cantonese-speaking people with aphasia,” Journal of Signal Processing Systems, vol. 92, pp. 819–830, 2019. [11] A. Balagopalan et al., “Cross-language aphasia detection using optimal transport domain adaptation,” in NeurIPS, 2019. [12] Y. Qin, T. Lee, and A. Kong, “Automatic speech assessment for aphasic patients based on syllable-level embedding and suprasegmental duration features,” in Proc. ICASSP, 2018, pp. 5994– 5998. [13] Y. Qin et al., “Automatic speech assessment for people with aphasia using TDNN-BLSTM with multi-task learning,” in Proc. Interspeech, 2018, pp. 3418–3422. [14] A. Kertesz, “Western aphasia battery–revised,” 2007. [15] Y. Qin et al., “Aphasia detection for cantonese-speaking and mandarin-speaking patients using pre-trained language models,” in Proc. ISCSLP, 2022, pp. 359–363. [16] K. Dunfield and G. Neumann, “Automatic quantitative prediction of severity in fluent aphasia using sentence representation similarity,” in Proceedings of the RaPID Workshop., 2020. [17] S. Watanabe et al., “Hybrid ctc/attention architecture for endto-end speech recognition,” IEEE Journal of Selected Topics in Signal Processing, vol. 11, no. 8, pp. 1240–1253, 2017. [18] K. Kim et al., “E-branchformer: Branchformer with enhanced merging for speech recognition,” in Proc. SLT, 2023, pp. 84–91. [19] S. Chen et al., “Wavlm: Large-scale self-supervised pre-training for full stack speech processing,” IEEE