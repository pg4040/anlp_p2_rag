Title: AUTOREPLY: Detecting Nonsense in Dialogue Introspectively with Discriminative Replies
Authors: Weiyan Shi, Emily Dinan, Adithya Renduchintala, Daniel Fried, Athul Paul Jacob, Zhou Yu, Mike Lewis
Section: A.5.2 Hard Categories without Hand-crafted Replies
the test set. We also show the test performance of “AUTOREPLY (num=2805)” on this subset for comparison (since it is the best model on the whole set, and uses hand-crafted replies to tune the parameters). The best reply is “hmm, thats the way” with a test F1 of 0.3077. Because G′w is an estimation of contrastive examples, and the rewritten messages are not necessarily about “correct justification” (could be about order proposal, or anything). So AUTOREPLY-generated replies might capture the semantic meaning of “justification” (because it’s contrastive to order proposal, etc), instead of “correct” justification. That’s why the top replies also include “yes i see your point,”, which is usually a follow-up reply for making justification. But from the test F1 comparable to the best AUTOREPLY model on the whole set, we see that AUTOREPLY is still doing its job in discriminating the bad situations and the good situations. And we believe that if the contrastive examples are related to “correct justification”, AUTOREPLY is able to generate more human-understandable wrong-justification-related replies. If we reduce the training examples further to only five examples in Bw and the five good examples correspondent to them, we can still generate 9673 replies (because there are only five good examples to contrastive against, we prune less and obtain more replies), the top ones are also listed in Table 11. This shows with a proper contrastive example set, even if the bad situation is hard to design manual reply for and even if we only have super limited annotations, AUTOREPLY can still generate large number of discriminative replies. Algorithm 1 AUTOREPLY 1: Input: Language Model L, response prefix r0, step t, p, K, topn, prune step tprune, max step T , bad messages examples {Bi}, good messages examples {Gi} 2: result = [] 3: # prune 4: if t >= tprune and need_prune(rcur, {Bi}, {Gi}) then 5: return [] 6: end if 7: if t < T then 8: # for each bad example, get next tokens to expand 9: tok_to_bad_exs = dict() 10: for ex in {Bi} do 11: for tok in get_top_tokens(M , ex, rcur, topp=p) do 12: tok_to_bad_exs.append(ex) 13: end for 14: end for 15: # for each good example, get next tokens to expand 16: tok_to_good_exs = dict() 17: for ex in {Gi} do 18: for tok in get_top_tokens(M , ex, rcur, topp=p) do 19: tok_to_good_exs.append(ex) 20: end for 21: end for 22: # sort based on the number of bad examples 23: tok_to_bad_exs = sorted(tok_to_bad_exs) 24: tok_to_bad_exs = tok_to_bad_exs[:topn] 25: for