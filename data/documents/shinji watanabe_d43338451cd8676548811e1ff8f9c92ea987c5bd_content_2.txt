Title: REPRODUCING WHISPER-STYLE TRAINING USING AN OPEN-SOURCE TOOLKIT AND PUBLICLY AVAILABLE DATA
Authors: Yifan Peng, Jinchuan Tian, Brian Yan, Dan Berrebbi, Xuankai Chang, Xinjian Li, Jiatong Shi, Siddhant Arora, William Chen, Roshan Sharma, Wangyou Zhang, Yui Sudo, Muhammad Shakeel, Jee-weon Jung, Soumi Maiti, Shinji Watanabe
Section: 7. REFERENCES
2017. [49] Daniel S. Park, William Chan, et al., “SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition,” in Proc. Interspeech, 2019. [50] Takaaki Hori, Shinji Watanabe, and John R Hershey, “Joint CTC/attention decoding for end-to-end speech recognition,” in Proc. ACL, 2017. [51] A. Paszke et al., “Pytorch: An imperative style, highperformance deep learning library,” in NeurIPS, 2019. [52] Anmol Gulati et al., “Conformer: Convolution-augmented Transformer for Speech Recognition,” in Proc. Interspeech, 2020. [53] Yifan Peng, Siddharth Dalmia, Ian Lane, and Shinji Watanabe, “Branchformer: Parallel MLP-attention architectures to capture local and global context for speech recognition and understanding,” in Proc. ICML, 2022. [54] Kwangyoun Kim et al., “E-Branchformer: Branchformer with Enhanced Merging for Speech Recognition,” in Proc. SLT, 2022. [55] Sehoon Kim et al., “Squeezeformer: An efficient transformer for automatic speech recognition,” in Proc. NeurIPS, 2022. [56] Taku Kudo and John Richardson, “SentencePiece: A simple and language independent subword tokenizer and detokenizer for neural text processing,” 2018. [57] Yifan Peng et al., “A Comparative Study on E-Branchformer vs Conformer in Speech Recognition, Translation, and Understanding Tasks,” in Proc. Interspeech, 2023. [58] Koichi Miyazaki, Masato Murata, and Tomoki Koriyama, “Structured State Space Decoder for Speech Recognition and Synthesis,” in Proc. ICASSP, 2023. [59] Heng-Jui Chang et al., “DistilHuBERT: Speech representation learning by layer-wise distillation of hidden-unit BERT,” in Proc. ICASSP, 2022. [60] Cheng-I Jeff Lai et al., “PARP: Prune, Adjust and Re-Prune for Self-Supervised Speech Recognition,” in Proc. NeurIPS, 2021. [61] Yifan Peng et al., “Structured Pruning of Self-Supervised Pretrained Models for Speech Recognition and Understanding,” in Proc. ICASSP, 2023. [62] Yifan Peng, Yui Sudo, et al., “DPHuBERT: Joint Distillation and Pruning of Self-Supervised Speech Models,” in Proc. Interspeech, 2023. [63] Yizeng Han, Gao Huang, et al., “Dynamic neural networks: A survey,” vol. 44, no. 11, pp. 7436–7456, 2021. [64] Yifan Peng, Jaesong Lee, et al., “I3D: Transformer architectures with input-dependent dynamic depth for speech recognition,” in Proc. ICASSP, 2023. [65] German I Parisi, Ronald Kemker, et al., “Continual lifelong learning with neural networks: A review,” Neural networks, vol. 113, pp. 54–71, 2019. [66] Raphael Olivier and Bhiksha Raj, “There is more than one kind of robustness: Fooling whisper with adversarial examples,” arXiv:2210.17316, 2022. [67] Thanh Tam Nguyen et al., “A survey of machine unlearning,” arXiv:2209.02299, 2022.