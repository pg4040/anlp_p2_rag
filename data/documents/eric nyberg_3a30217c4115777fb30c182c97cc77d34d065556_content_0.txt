Title: InPars-Light: Cost-Effective Unsupervised Training of Effi- cient Rankers
Authors: Leonid Boytsov, Preksha Patel, Vivek Sourabh, Riddhi Nisar, Sayani Kundu, Ramya Ramanathan, Eric Nyberg
Section: A Appendix
A.1 Statistical Testing with Multiple-Seed Models To compute statistical significance using a paired statistical test between results from models A and B, one first has to compute the values of an accuracy metric (e.g., MRR) for each query separately. Let mAi and mBi be sequences of query-specific metric values for models A and B, respectively. The paired statistical test is then carried out using a sequence of differences mAi − mBi . This procedure is not directly applicable when each model is presented by multiple outcomes/seeds. To overcome this issue, we (1) obtain a set of query- and seed-specific metric values, and (2) average them over seeds, thus, reducing the problem to a single-seed statistical testing. In more details, let mAis and mBis be sets of query- and seed-specific metric values for models A and B, respectively. Recall that we have three seeds, so s ∈ {1, 2, 3}. Then, we obtain seed-average runs mAi = 1/3 ∑3 s=1 m A is and mBi = 1/3 ∑3 s=1 m B is and compute statistical significance using a paired difference test. A.2 Cost and Efficiency In the following sub-section, we discuss both the ranking efficiency and query-generation cost. Although one may argue that the cost of generation using open-source models is negligibly small, in reality this is true only if one owns their own hardware and generates enough queries to justify the initial investment. Thus, we make a more reasonable assessment assuming that the user can employ a cheap cloud service. Cost of Query Generation. For the original InPars Bonifacio et al. (2022), the cost of generation for the GPT-3 Curie model is $0.002 per one thousand tokens. The token count includes the length of the prompt and the prompting document.14 We estimate that (depending on the collection) a single generation involves 300 to 500 tokens: long-document collections Robust04 and TREC-COVID both have close to 500 tokens per generation. Taking an estimate of 500 tokens per generation, the cost of querying OpenAI GPT-3 Curie API can be up to $100 for Robust04 and TREC-COVID. Assuming that sampling from the 137-B FLAN model (used by (Dai et al., 2022)) to be as expensive as from the largest GPT-3 model Davinci (which has a similar number of parameters), each generation in the Promptagator study (Dai et al., 2022), was 10x more expensive compared to InPars study (Bonifacio et al., 2022). Moreover, because Dai et al. (2022) generated one million samples per collection, the Promptagator recipe was about two orders of magnitude more expensive