Title: ENHANCING END-TO-END CONVERSATIONAL SPEECH TRANSLATION THROUGH TARGET LANGUAGE CONTEXT UTILIZATION
Authors: Amir Hussein, Brian Yan, Antonios Anastasopoulos, Shinji Watanabe, Sanjeev Khudanpur
Section: 7. REFERENCES
et al., “Document-level neural machine translation with hierarchical attention networks,” in Proc. EMNLP, 2018, pp. 2947– 2954. [19] E. Voita et al., “Context-aware neural machine translation learns anaphora resolution,” in Proc. ACL, 2018, pp. 1264–1274. [20] A. Lopes et al., “Document-level neural MT: A systematic comparison,” in Proceedings of the 22nd Annual Conference of the European Association for Machine Translation, 2020, pp. 225–234. [21] Z. Zheng et al., “Towards making the most of context in neural machine translation,” in Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence, IJCAI 2020, C. Bessiere, Ed., 2020, pp. 3983–3989. [22] S. Shon et al., “Context-aware fine-tuning of self-supervised speech models,” in Proc. ICASSP, 2023, pp. 1–5. [23] T. Hori et al., “Advanced long-context end-to-end speech recognition using context-expanded transformers,” in Proc. Interspeech, H. Hermansky et al., Eds., 2021, pp. 2097–2101. [24] S. Kim and F. Metze, “Acoustic-to-word models with conversational context information,” in Proc. ACL, 2019, pp. 2766–2771. [25] S. Kim, S. Dalmia, and F. Metze, “Cross-attention end-to-end ASR for two-party conversations,” in Proc. Interspeech, G. Kubin and Z. Kacic, Eds., 2019, pp. 4380–4384. [26] A. Radford et al., “Robust speech recognition via large-scale weak supervision,” ArXiv preprint, vol. abs/2212.04356, 2022. [27] Z. Tian et al., “How to make context more useful? an empirical study on context-aware neural conversational models,” in Proc. ACL, 2017, pp. 231–236. [28] B. Gain, R. Haque, and A. Ekbal, “Not all contexts are important: The impact of effective context in conversational neural machine translation,” in 2021 International Joint Conference on Neural Networks (IJCNN), 2021, pp. 1–8. [29] B. Zhang et al., “Beyond sentence-level end-to-end speech translation: Context helps,” in Proc. ACL, 2021, pp. 2566–2578. [30] A. Vaswani et al., “Attention is all you need,” in Proc. NeurIPS, I. Guyon et al., Eds., 2017, pp. 5998–6008. [31] N. Kanda et al., “Serialized output training for end-to-end overlapped speech recognition,” in Proc. Interspeech, H. Meng, B. Xu, and T. F. Zheng, Eds., 2020, pp. 2797–2801. [32] B. Yan et al., “CTC alignments improve autoregressive translation,” in Proc. ACL, 2023, pp. 1623–1639. [33] M. Post et al., “Improved speech-to-text translation with the fisher and callhome Spanish-English speech translation corpus,” in Proceedings of the 10th International Workshop on Spoken Language Translation: Papers, 2013. [34] E. Ansari et al., “FINDINGS OF THE IWSLT 2020 EVALUATION CAMPAIGN,” in Proceedings of the 17th International Conference on Spoken Language Translation, 2020, pp. 1–34. [35] Z. Song et al., “Collecting natural SMS and chat conversations in multiple languages: The BOLT phase 2 corpus,” in Proceedings of