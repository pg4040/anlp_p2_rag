Title: A Vector Quantized Approach for Text to Speech Synthesis on Real-World Spontaneous Speech
Authors: Li-Wei Chen, Shinji Watanabe, Alexander Rudnicky
Section: 5.2 Performance
MOS-N scores. However, the P-FID of MQTTS is noticeably lower than that of VITS, suggesting that MQTTS generates more diverse samples. We conjecture that generating speech signals in parallel is a much harder task compared to autoregressive modeling. Therefore, non-autoregressive models tend to focus on a smaller set of common speaking styles across the corpus due to insufficient capacity. If we scale VITS from 40M to 100M, we see a decrease in P-FID with the same MOS-N, suggesting that bigger model capacity enables modeling of higher diversity, but without improvements in naturalness. We did not include a 200M version of VITS as we failed to find a configuration that makes the training converge. 5 sam- ples with the same text from both systems in Figure 4 further support our claim of the diversity comparison. This might also explain the lower MCD of VITS, where the syntheses have conservative prosody patterns that are more tolerant in terms of MCD. One possible example is the duration of internal pauses. VITS syntheses mostly contain short intermittent pauses, while MQTTS often generates longer pauses while not uncommon in natural speech can potentially cause large misalignment with the ground truth, lowering MCD. MQTTS performs better in terms of both intelligibility and speaker transferability. We find MQTTS captures utterance-level properties (i.e., emotion, speaking rate) better compared to VITS. For naturalness, we observe a consistently improving MOS-N of MQTTS as the model capacity grows. It demonstrates different scaling properties: higher model capacity brings naturalness to MQTTS, but diversity to VITS. Comparing the same parameter size (100M) for both VITS and MQTTS, MQTTS wins out in all metrics except MCD, which we explained earlier. This suggests MQTTS is generally better than VITS, given enough resources. Additionally, we observed overfitting for both 100M and 200M of MQTTS, but with a higher severity for the 200M version. This explains the little improvement from 100M to 200M and suggests that a larger training corpus is needed for further improvement. Error Analysis. Despite the better average performance of MQTTS in Table 2, we find that it suffers from lower sampling robustness compared to non-autoregressive systems. This is reasonable as higher diversity inevitably comes with a higher risk of sampling poor syntheses. We observe unnaturally prolonged vowels in some samples with speaker reference speech of a slower speaking style, which is seldom the case for VITS. In addition, samples that start with a poor recording environment often result in bad syntheses. Deletion errors, which we consider more undesirable than substitution, are also more