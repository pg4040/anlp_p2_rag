Title: Contextualized Networks Reveal Heterogeneous Transcriptomic Regulation in Tumors at Sample-Specific Resolution
Authors: Caleb N. Ellington, Benjamin J. Lengerich, Thomas B.K. Watkins, Jiekun Yang, Manolis Kellis, Eric P. Xing
Section: 
model. Relative to disease-specific151 model inference (the best baseline method), contextualized networks reduce modeling error on average by 14.6% for152 Markov networks, 18.1% for neighborhood selection, and 20.2% for correlation networks. Contextualized graphical153 models achieve this improved predictive performance by accounting for contextual dependencies in model parameters154 without imposing prior assumptions on the form of these dependencies. As a result, contextualized graphical mod-155 els capture context-specific effects that can be overlooked by group-level modeling approaches (e.g. cluster-specific,156 disease-specific models).157 Contextualized Networks Share Power Between All Cancer Types and Infer Models for Un-158 seen Diseases159 Contextualization relates transcriptional regulation to genomic variation through a context encoder (Fig. 1). During160 training, the encoder learns to modify the parameters of a downstream network model in response to contextual signals.161 At test time, the encoder uses learned context signals to generalize between sparsely sampled contexts. Rare or162 undersampled diseases like Kidney Chromophobe (KICH) and Glioblastoma multiforme (GBM) can benefit from163 contextual signals learned from well-sampled diseases in similar tissues (Figure 2b). In disease-specific modeling,164 these smaller subpopulations must either be lumped within a larger tissue group, ignoring subpopulation heterogeneity,165 or modeled individually, sacrificing statistical power in a "large p small n" regime. For example, there are n = 75166 training samples from KICH patients, while each disease-specific network has 50 Ã— 50 edges, or p = 2500 parameters;167 estimating a disease-specific network from such limited data would be prohibitively high-variance.168 Furthermore, contextualization adapts models to unseen contexts at test time, responding to even extreme dis-169 tribution shift (Fig. 2a). For completely unseen contexts, the context encoder can still leverage learned relationships170 between contexts and models to infer zero-shot network models on-demand. We evaluate model performance through a171 disease-fold cross vaidation, where we hold out each of the 25 disease types in turn and learn to contextualize networks172 on the remaining 24. Notably, disease-specific modeling cannot be applied in this regime. In contrast, contextualized173 networks improve model performance and reduce error on 22 or 25 hold-out diseases, even when generalizing to an174 entirely new disease type.175 5 (a) Contextualized Graphs are Generated On-Demand for Held-Out Disease Types (b) Contextualized Graphs Generalize to Held-Out Patients and Improve Accuracy by Learning to Model Intra-disease Heterogeneity Markov Graph Inference Method Figure 2: Performance of Contextualized Markov Networks. (a) Disease-fold cross-validation, in which each of the 25 disease types are held out from training and evaluated only at testing time. Disease-specific network inference cannot be applied in this regime. (b) Testing on held-out patients. Results are from 30 bootstrapped